{
    "731201ab4fd1c4ff30b0010460f9979ab5505a29": {
        "filename_old": "streamlit_app.py",
        "source_old": "import json\nimport os\nfrom typing import List\n\nimport networkx as nx\nimport nltk\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom annotated_text import annotated_text, parameters\nfrom streamlit_extras import add_vertical_space as avs\nfrom streamlit_extras.badges import badge\n\nfrom scripts.similarity.get_score import *\nfrom scripts.utils import get_filenames_from_dir\nfrom scripts.utils.logger import init_logging_config\n\n# Set page configuration\nst.set_page_config(\n    page_title=\"Resume Matcher\",\n    page_icon=\"Assets/img/favicon.ico\",\n    initial_sidebar_state=\"auto\",\n)\n\ninit_logging_config()\ncwd = find_path(\"Resume-Matcher\")\nconfig_path = os.path.join(cwd, \"scripts\", \"similarity\")\n\ntry:\n    nltk.data.find(\"tokenizers/punkt\")\nexcept LookupError:\n    nltk.download(\"punkt\")\n\nparameters.SHOW_LABEL_SEPARATOR = False\nparameters.BORDER_RADIUS = 3\nparameters.PADDING = \"0.5 0.25rem\"\n\n\ndef create_star_graph(nodes_and_weights, title):\n    # Create an empty graph\n    G = nx.Graph()\n\n    # Add the central node\n    central_node = \"resume\"\n    G.add_node(central_node)\n\n    # Add nodes and edges with weights to the graph\n    for node, weight in nodes_and_weights:\n        G.add_node(node)\n        G.add_edge(central_node, node, weight=weight * 100)\n\n    # Get position layout for nodes\n    pos = nx.spring_layout(G)\n\n    # Create edge trace\n    edge_x = []\n    edge_y = []\n    for edge in G.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None])\n        edge_y.extend([y0, y1, None])\n\n    edge_trace = go.Scatter(\n        x=edge_x,\n        y=edge_y,\n        line=dict(width=0.5, color=\"#888\"),\n        hoverinfo=\"none\",\n        mode=\"lines\",\n    )\n\n    # Create node trace\n    node_x = []\n    node_y = []\n    for node in G.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n\n    node_trace = go.Scatter(\n        x=node_x,\n        y=node_y,\n        mode=\"markers\",\n        hoverinfo=\"text\",\n        marker=dict(\n            showscale=True,\n            colorscale=\"Rainbow\",\n            reversescale=True,\n            color=[],\n            size=10,\n            colorbar=dict(\n                thickness=15,\n                title=\"Node Connections\",\n                xanchor=\"left\",\n                titleside=\"right\",\n            ),\n            line_width=2,\n        ),\n    )\n\n    # Color node points by number of connections\n    node_adjacencies = []\n    node_text = []\n    for node in G.nodes():\n        adjacencies = list(G.adj[node])  # changes here\n        node_adjacencies.append(len(adjacencies))\n        node_text.append(f\"{node}<br># of connections: {len(adjacencies)}\")\n\n    node_trace.marker.color = node_adjacencies\n    node_trace.text = node_text\n\n    # Create the figure\n    fig = go.Figure(\n        data=[edge_trace, node_trace],\n        layout=go.Layout(\n            title=title,\n            titlefont_size=16,\n            showlegend=False,\n            hovermode=\"closest\",\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        ),\n    )\n\n    # Show the figure\n    st.plotly_chart(fig)\n\n\ndef create_annotated_text(\n    input_string: str, word_list: List[str], annotation: str, color_code: str\n):\n    # Tokenize the input string\n    tokens = nltk.word_tokenize(input_string)\n\n    # Convert the list to a set for quick lookups\n    word_set = set(word_list)\n\n    # Initialize an empty list to hold the annotated text\n    annotated_text = []\n\n    for token in tokens:\n        # Check if the token is in the set\n        if token in word_set:\n            # If it is, append a tuple with the token, annotation, and color code\n            annotated_text.append((token, annotation, color_code))\n        else:\n            # If it's not, just append the token as a string\n            annotated_text.append(token)\n\n    return annotated_text\n\n\ndef read_json(filename):\n    with open(filename) as f:\n        data = json.load(f)\n    return data\n\n\ndef tokenize_string(input_string):\n    tokens = nltk.word_tokenize(input_string)\n    return tokens\n\n\n# Display the main title and subheaders\nst.title(\":blue[Resume Matcher]\")\nwith st.sidebar:\n    st.image(\"Assets/img/header_image.png\")\n    st.subheader(\n        \"Free and Open Source ATS to help your resume pass the screening stage.\"\n    )\n    st.markdown(\n        \"Check the website [www.resumematcher.fyi](https://www.resumematcher.fyi/)\"\n    )\n\n    st.markdown(\n        \"Give Resume Matcher a \u2b50 on [GitHub](https://github.com/srbhr/resume-matcher)\"\n    )\n\n    badge(type=\"github\", name=\"srbhr/Resume-Matcher\")\n    st.markdown(\"For updates follow me on Twitter.\")\n    badge(type=\"twitter\", name=\"_srbhr_\")\n    st.markdown(\n        \"If you like the project and would like to further help in development please consider \ud83d\udc47\"\n    )\n    badge(type=\"buymeacoffee\", name=\"srbhr\")\n\nst.divider()\navs.add_vertical_space(1)\n\nresume_names = get_filenames_from_dir(\"Data/Processed/Resumes\")\n\n\nst.markdown(\n    f\"##### There are {len(resume_names)} resumes present. Please select one from the menu below:\"\n)\noutput = st.selectbox(f\"\", resume_names)\n\n\navs.add_vertical_space(5)\n\n# st.write(\"You have selected \", output, \" printing the resume\")\nselected_file = read_json(\"Data/Processed/Resumes/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Parsed Resume Data\")\nst.caption(\n    \"This text is parsed from your resume. This is how it'll look like after getting parsed by an ATS.\"\n)\nst.caption(\"Utilize this to understand how to make your resume ATS friendly.\")\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_file[\"clean_data\"])\n\navs.add_vertical_space(3)\nst.write(\"Now let's take a look at the extracted keywords from the resume.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"],\n        selected_file[\"extracted_keywords\"],\n        \"KW\",\n        \"#0B666A\",\n    )\n)\n\navs.add_vertical_space(5)\nst.write(\"Now let's take a look at the extracted entities from the resume.\")\n\n# Call the function with your data\ncreate_star_graph(selected_file[\"keyterms\"], \"Entities from Resume\")\n\ndf2 = pd.DataFrame(selected_file[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_file[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from your Resume\",\n)\nst.write(fig)\n\navs.add_vertical_space(5)\n\njob_descriptions = get_filenames_from_dir(\"Data/Processed/JobDescription\")\n\n\nst.markdown(\n    f\"##### There are {len(job_descriptions)} job descriptions present. Please select one from the menu below:\"\n)\noutput = st.selectbox(\"\", job_descriptions)\n\n\navs.add_vertical_space(5)\n\nselected_jd = read_json(\"Data/Processed/JobDescription/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Job Description\")\nst.caption(\n    \"Currently in the pipeline I'm parsing this from PDF but it'll be from txt or copy paste.\"\n)\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_jd[\"clean_data\"])\n\nst.markdown(\"#### Common Words between Job Description and Resumes Highlighted.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"], selected_jd[\"extracted_keywords\"], \"JD\", \"#F24C3D\"\n    )\n)\n\nst.write(\"Now let's take a look at the extracted entities from the job description.\")\n\n# Call the function with your data\ncreate_star_graph(selected_jd[\"keyterms\"], \"Entities from Job Description\")\n\ndf2 = pd.DataFrame(selected_jd[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_jd[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from the selected Job Description\",\n)\nst.write(fig)\n\navs.add_vertical_space(3)\n\nresume_string = \" \".join(selected_file[\"extracted_keywords\"])\njd_string = \" \".join(selected_jd[\"extracted_keywords\"])\nresult = get_score(resume_string, jd_string)\nsimilarity_score = round(result[0].score * 100, 2)\nscore_color = \"green\"\nif similarity_score < 60:\n    score_color = \"red\"\nelif 60 <= similarity_score < 75:\n    score_color = \"orange\"\nst.markdown(\n    f\"Similarity Score obtained for the resume and job description is \"\n    f'<span style=\"color:{score_color};font-size:24px; font-weight:Bold\">{similarity_score}</span>',\n    unsafe_allow_html=True,\n)\n\n# Go back to top\nst.markdown(\"[:arrow_up: Back to Top](#resume-matcher)\")\n",
        "filename_new": "streamlit_app.py",
        "source_new": "import json\nimport os\nfrom typing import List\n\nimport networkx as nx\nimport nltk\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom annotated_text import annotated_text, parameters\nfrom streamlit_extras import add_vertical_space as avs\nfrom streamlit_extras.badges import badge\n\nfrom scripts.similarity.get_score import *\nfrom scripts.utils import get_filenames_from_dir\nfrom scripts.utils.logger import init_logging_config\n\n# Set page configuration\nst.set_page_config(\n    page_title=\"Resume Matcher\",\n    page_icon=\"Assets/img/favicon.ico\",\n    initial_sidebar_state=\"auto\",\n)\n\ninit_logging_config()\ncwd = find_path(\"Resume-Matcher\")\nconfig_path = os.path.join(cwd, \"scripts\", \"similarity\")\n\ntry:\n    nltk.data.find(\"tokenizers/punkt_tab\")\nexcept LookupError:\n    nltk.download(\"punkt_tab\")\n\nparameters.SHOW_LABEL_SEPARATOR = False\nparameters.BORDER_RADIUS = 3\nparameters.PADDING = \"0.5 0.25rem\"\n\n\ndef create_star_graph(nodes_and_weights, title):\n    # Create an empty graph\n    G = nx.Graph()\n\n    # Add the central node\n    central_node = \"resume\"\n    G.add_node(central_node)\n\n    # Add nodes and edges with weights to the graph\n    for node, weight in nodes_and_weights:\n        G.add_node(node)\n        G.add_edge(central_node, node, weight=weight * 100)\n\n    # Get position layout for nodes\n    pos = nx.spring_layout(G)\n\n    # Create edge trace\n    edge_x = []\n    edge_y = []\n    for edge in G.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None])\n        edge_y.extend([y0, y1, None])\n\n    edge_trace = go.Scatter(\n        x=edge_x,\n        y=edge_y,\n        line=dict(width=0.5, color=\"#888\"),\n        hoverinfo=\"none\",\n        mode=\"lines\",\n    )\n\n    # Create node trace\n    node_x = []\n    node_y = []\n    for node in G.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n\n    node_trace = go.Scatter(\n        x=node_x,\n        y=node_y,\n        mode=\"markers\",\n        hoverinfo=\"text\",\n        marker=dict(\n            showscale=True,\n            colorscale=\"Rainbow\",\n            reversescale=True,\n            color=[],\n            size=10,\n            colorbar=dict(\n                thickness=15,\n                title=\"Node Connections\",\n                xanchor=\"left\",\n                titleside=\"right\",\n            ),\n            line_width=2,\n        ),\n    )\n\n    # Color node points by number of connections\n    node_adjacencies = []\n    node_text = []\n    for node in G.nodes():\n        adjacencies = list(G.adj[node])  # changes here\n        node_adjacencies.append(len(adjacencies))\n        node_text.append(f\"{node}<br># of connections: {len(adjacencies)}\")\n\n    node_trace.marker.color = node_adjacencies\n    node_trace.text = node_text\n\n    # Create the figure\n    fig = go.Figure(\n        data=[edge_trace, node_trace],\n        layout=go.Layout(\n            title=title,\n            titlefont_size=16,\n            showlegend=False,\n            hovermode=\"closest\",\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        ),\n    )\n\n    # Show the figure\n    st.plotly_chart(fig)\n\n\ndef create_annotated_text(\n    input_string: str, word_list: List[str], annotation: str, color_code: str\n):\n    # Tokenize the input string\n    tokens = nltk.word_tokenize(input_string)\n\n    # Convert the list to a set for quick lookups\n    word_set = set(word_list)\n\n    # Initialize an empty list to hold the annotated text\n    annotated_text = []\n\n    for token in tokens:\n        # Check if the token is in the set\n        if token in word_set:\n            # If it is, append a tuple with the token, annotation, and color code\n            annotated_text.append((token, annotation, color_code))\n        else:\n            # If it's not, just append the token as a string\n            annotated_text.append(token)\n\n    return annotated_text\n\n\ndef read_json(filename):\n    with open(filename) as f:\n        data = json.load(f)\n    return data\n\n\ndef tokenize_string(input_string):\n    tokens = nltk.word_tokenize(input_string)\n    return tokens\n\n\n# Display the main title and subheaders\nst.title(\":blue[Resume Matcher]\")\nwith st.sidebar:\n    st.image(\"Assets/img/header_image.png\")\n    st.subheader(\n        \"Free and Open Source ATS to help your resume pass the screening stage.\"\n    )\n    st.markdown(\n        \"Check the website [www.resumematcher.fyi](https://www.resumematcher.fyi/)\"\n    )\n\n    st.markdown(\n        \"Give Resume Matcher a \u2b50 on [GitHub](https://github.com/srbhr/resume-matcher)\"\n    )\n\n    badge(type=\"github\", name=\"srbhr/Resume-Matcher\")\n    st.markdown(\"For updates follow me on Twitter.\")\n    badge(type=\"twitter\", name=\"_srbhr_\")\n    st.markdown(\n        \"If you like the project and would like to further help in development please consider \ud83d\udc47\"\n    )\n    badge(type=\"buymeacoffee\", name=\"srbhr\")\n\nst.divider()\navs.add_vertical_space(1)\n\nresume_names = get_filenames_from_dir(\"Data/Processed/Resumes\")\n\n\nst.markdown(\n    f\"##### There are {len(resume_names)} resumes present. Please select one from the menu below:\"\n)\noutput = st.selectbox(f\"\", resume_names)\n\n\navs.add_vertical_space(5)\n\n# st.write(\"You have selected \", output, \" printing the resume\")\nselected_file = read_json(\"Data/Processed/Resumes/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Parsed Resume Data\")\nst.caption(\n    \"This text is parsed from your resume. This is how it'll look like after getting parsed by an ATS.\"\n)\nst.caption(\"Utilize this to understand how to make your resume ATS friendly.\")\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_file[\"clean_data\"])\n\navs.add_vertical_space(3)\nst.write(\"Now let's take a look at the extracted keywords from the resume.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"],\n        selected_file[\"extracted_keywords\"],\n        \"KW\",\n        \"#0B666A\",\n    )\n)\n\navs.add_vertical_space(5)\nst.write(\"Now let's take a look at the extracted entities from the resume.\")\n\n# Call the function with your data\ncreate_star_graph(selected_file[\"keyterms\"], \"Entities from Resume\")\n\ndf2 = pd.DataFrame(selected_file[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_file[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from your Resume\",\n)\nst.write(fig)\n\navs.add_vertical_space(5)\n\njob_descriptions = get_filenames_from_dir(\"Data/Processed/JobDescription\")\n\n\nst.markdown(\n    f\"##### There are {len(job_descriptions)} job descriptions present. Please select one from the menu below:\"\n)\noutput = st.selectbox(\"\", job_descriptions)\n\n\navs.add_vertical_space(5)\n\nselected_jd = read_json(\"Data/Processed/JobDescription/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Job Description\")\nst.caption(\n    \"Currently in the pipeline I'm parsing this from PDF but it'll be from txt or copy paste.\"\n)\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_jd[\"clean_data\"])\n\nst.markdown(\"#### Common Words between Job Description and Resumes Highlighted.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"], selected_jd[\"extracted_keywords\"], \"JD\", \"#F24C3D\"\n    )\n)\n\nst.write(\"Now let's take a look at the extracted entities from the job description.\")\n\n# Call the function with your data\ncreate_star_graph(selected_jd[\"keyterms\"], \"Entities from Job Description\")\n\ndf2 = pd.DataFrame(selected_jd[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_jd[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from the selected Job Description\",\n)\nst.write(fig)\n\navs.add_vertical_space(3)\n\nresume_string = \" \".join(selected_file[\"extracted_keywords\"])\njd_string = \" \".join(selected_jd[\"extracted_keywords\"])\nresult = get_score(resume_string, jd_string)\nsimilarity_score = round(result[0].score * 100, 2)\nscore_color = \"green\"\nif similarity_score < 60:\n    score_color = \"red\"\nelif 60 <= similarity_score < 75:\n    score_color = \"orange\"\nst.markdown(\n    f\"Similarity Score obtained for the resume and job description is \"\n    f'<span style=\"color:{score_color};font-size:24px; font-weight:Bold\">{similarity_score}</span>',\n    unsafe_allow_html=True,\n)\n\n# Go back to top\nst.markdown(\"[:arrow_up: Back to Top](#resume-matcher)\")\n",
        "additions": 2,
        "deletions": 2,
        "cyclomatic_complexity_new": 10
    },
    "88f14b8b121337a82c5c70d68e03d28bb3ddac4d": {
        "filename_old": "streamlit_interactive.py",
        "source_old": "# Import necessary libraries\nimport json\nimport os\nfrom typing import List\n\nimport networkx as nx\nimport nltk\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom annotated_text import annotated_text, parameters\nfrom streamlit_extras import add_vertical_space as avs\nfrom streamlit_extras.badges import badge\n\nfrom scripts import JobDescriptionProcessor, ResumeProcessor\nfrom scripts.parsers import ParseJobDesc, ParseResume\nfrom scripts.ReadPdf import read_single_pdf\nfrom scripts.similarity.get_score import *\nfrom scripts.utils import get_filenames_from_dir\n\n# Set page configuration\nst.set_page_config(\n    page_title=\"Resume Matcher\",\n    page_icon=\"Assets/img/favicon.ico\",\n    initial_sidebar_state=\"auto\",\n    layout=\"wide\",\n)\n\n# Find the current working directory and configuration path\ncwd = find_path(\"Resume-Matcher\")\nconfig_path = os.path.join(cwd, \"scripts\", \"similarity\")\n\n# Check if NLTK punkt data is available, if not, download it\ntry:\n    nltk.data.find(\"tokenizers/punkt\")\nexcept LookupError:\n    nltk.download(\"punkt\")\n\n# Set some visualization parameters using the annotated_text library\nparameters.SHOW_LABEL_SEPARATOR = False\nparameters.BORDER_RADIUS = 3\nparameters.PADDING = \"0.5 0.25rem\"\n\n\n# Function to set session state variables\ndef update_session_state(key, val):\n    st.session_state[key] = val\n\n\n# Function to delete all files in a directory\ndef delete_from_dir(filepath: str) -> bool:\n    try:\n        for file in os.scandir(filepath):\n            os.remove(file.path)\n\n        return True\n    except OSError as error:\n        print(f\"Exception: {error}\")\n        return False\n\n\n# Function to create a star-shaped graph visualization\ndef create_star_graph(nodes_and_weights, title):\n    \"\"\"\n    Create a star-shaped graph visualization.\n\n    Args:\n        nodes_and_weights (list): List of tuples containing nodes and their weights.\n        title (str): Title for the graph.\n\n    Returns:\n        None\n    \"\"\"\n    # Create an empty graph\n    graph = nx.Graph()\n\n    # Add the central node\n    central_node = \"resume\"\n    graph.add_node(central_node)\n\n    # Add nodes and edges with weights to the graph\n    for node, weight in nodes_and_weights:\n        graph.add_node(node)\n        graph.add_edge(central_node, node, weight=weight * 100)\n\n    # Get position layout for nodes\n    pos = nx.spring_layout(graph)\n\n    # Create edge trace\n    edge_x = []\n    edge_y = []\n    for edge in graph.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None])\n        edge_y.extend([y0, y1, None])\n\n    edge_trace = go.Scatter(\n        x=edge_x,\n        y=edge_y,\n        line=dict(width=0.5, color=\"#888\"),\n        hoverinfo=\"none\",\n        mode=\"lines\",\n    )\n\n    # Create node trace\n    node_x = []\n    node_y = []\n    for node in graph.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n\n    node_trace = go.Scatter(\n        x=node_x,\n        y=node_y,\n        mode=\"markers\",\n        hoverinfo=\"text\",\n        marker=dict(\n            showscale=True,\n            colorscale=\"Rainbow\",\n            reversescale=True,\n            color=[],\n            size=10,\n            colorbar=dict(\n                thickness=15,\n                title=\"Node Connections\",\n                xanchor=\"left\",\n                titleside=\"right\",\n            ),\n            line_width=2,\n        ),\n    )\n\n    # Color node points by number of connections\n    node_adjacencies = []\n    node_text = []\n    for node in graph.nodes():\n        adjacencies = list(graph.adj[node])  # Changes here\n        node_adjacencies.append(len(adjacencies))\n        node_text.append(f\"{node}<br># of connections: {len(adjacencies)}\")\n\n    node_trace.marker.color = node_adjacencies\n    node_trace.text = node_text\n\n    # Create the figure\n    figure = go.Figure(\n        data=[edge_trace, node_trace],\n        layout=go.Layout(\n            title=title,\n            titlefont=dict(size=16),\n            showlegend=False,\n            hovermode=\"closest\",\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        ),\n    )\n\n    # Show the figure\n    st.plotly_chart(figure, use_container_width=True)\n\n\n# Function to create annotated text with highlighting\ndef create_annotated_text(\n    input_string: str, word_list: List[str], annotation: str, color_code: str\n):\n    \"\"\"\n    Create annotated text with highlighted keywords.\n\n    Args:\n        input_string (str): The input text.\n        word_list (List[str]): List of keywords to be highlighted.\n        annotation (str): Annotation label for highlighted keywords.\n        color_code (str): Color code for highlighting.\n\n    Returns:\n        List: Annotated text with highlighted keywords.\n    \"\"\"\n    # Tokenize the input string\n    tokens = nltk.word_tokenize(input_string)\n\n    # Convert the list to a set for quick lookups\n    word_set = set(word_list)\n\n    # Initialize an empty list to hold the annotated text\n    ret_annotated_text = []\n\n    for token in tokens:\n        # Check if the token is in the set\n        if token in word_set:\n            # If it is, append a tuple with the token, annotation, and color code\n            ret_annotated_text.append((token, annotation, color_code))\n        else:\n            # If it's not, just append the token as a string\n            ret_annotated_text.append(token)\n\n    return ret_annotated_text\n\n\n# Function to read JSON data from a file\ndef read_json(filename):\n    \"\"\"\n    Read JSON data from a file.\n\n    Args:\n        filename (str): The path to the JSON file.\n\n    Returns:\n        dict: The JSON data.\n    \"\"\"\n    with open(filename) as f:\n        data = json.load(f)\n    return data\n\n\n# Function to tokenize a string\ndef tokenize_string(input_string):\n    \"\"\"\n    Tokenize a string into words.\n\n    Args:\n        input_string (str): The input string.\n\n    Returns:\n        List[str]: List of tokens.\n    \"\"\"\n    tokens = nltk.word_tokenize(input_string)\n    return tokens\n\n\n# Cleanup processed resume / job descriptions\ndelete_from_dir(os.path.join(cwd, \"Data\", \"Processed\", \"Resumes\"))\ndelete_from_dir(os.path.join(cwd, \"Data\", \"Processed\", \"JobDescription\"))\n\n# Set default session states for first run\nif \"resumeUploaded\" not in st.session_state.keys():\n    update_session_state(\"resumeUploaded\", \"Pending\")\n    update_session_state(\"resumePath\", \"\")\nif \"jobDescriptionUploaded\" not in st.session_state.keys():\n    update_session_state(\"jobDescriptionUploaded\", \"Pending\")\n    update_session_state(\"jobDescriptionPath\", \"\")\n\n# Display the main title and sub-headers\nst.title(\":blue[Resume Matcher]\")\nwith st.sidebar:\n    st.image(\"Assets/img/header_image.png\")\n    st.subheader(\n        \"Free and Open Source ATS to help your resume pass the screening stage.\"\n    )\n    st.markdown(\n        \"Check the website [www.resumematcher.fyi](https://www.resumematcher.fyi/)\"\n    )\n    st.markdown(\n        \"Give Resume Matcher a \u2b50 on [GitHub](https://github.com/srbhr/resume-matcher)\"\n    )\n    badge(type=\"github\", name=\"srbhr/Resume-Matcher\")\n    st.markdown(\"For updates follow me on Twitter.\")\n    badge(type=\"twitter\", name=\"_srbhr_\")\n    st.markdown(\n        \"If you like the project and would like to further help in development please consider \ud83d\udc47\"\n    )\n    badge(type=\"buymeacoffee\", name=\"srbhr\")\n\nst.divider()\navs.add_vertical_space(1)\n\nwith st.container():\n    resumeCol, jobDescriptionCol = st.columns(2)\n    with resumeCol:\n        uploaded_Resume = st.file_uploader(\"Choose a Resume\", type=\"pdf\")\n        if uploaded_Resume is not None:\n            if st.session_state[\"resumeUploaded\"] == \"Pending\":\n                save_path_resume = os.path.join(\n                    cwd, \"Data\", \"Resumes\", uploaded_Resume.name\n                )\n\n                with open(save_path_resume, mode=\"wb\") as w:\n                    w.write(uploaded_Resume.getvalue())\n\n                if os.path.exists(save_path_resume):\n                    st.toast(\n                        f\"File {uploaded_Resume.name} is successfully saved!\", icon=\"\u2714\ufe0f\"\n                    )\n                    update_session_state(\"resumeUploaded\", \"Uploaded\")\n                    update_session_state(\"resumePath\", save_path_resume)\n        else:\n            update_session_state(\"resumeUploaded\", \"Pending\")\n            update_session_state(\"resumePath\", \"\")\n\n    with jobDescriptionCol:\n        uploaded_JobDescription = st.file_uploader(\n            \"Choose a Job Description\", type=\"pdf\"\n        )\n        if uploaded_JobDescription is not None:\n            if st.session_state[\"jobDescriptionUploaded\"] == \"Pending\":\n                save_path_jobDescription = os.path.join(\n                    cwd, \"Data\", \"JobDescription\", uploaded_JobDescription.name\n                )\n\n                with open(save_path_jobDescription, mode=\"wb\") as w:\n                    w.write(uploaded_JobDescription.getvalue())\n\n                if os.path.exists(save_path_jobDescription):\n                    st.toast(\n                        f\"File {uploaded_JobDescription.name} is successfully saved!\",\n                        icon=\"\u2714\ufe0f\",\n                    )\n                    update_session_state(\"jobDescriptionUploaded\", \"Uploaded\")\n                    update_session_state(\"jobDescriptionPath\", save_path_jobDescription)\n        else:\n            update_session_state(\"jobDescriptionUploaded\", \"Pending\")\n            update_session_state(\"jobDescriptionPath\", \"\")\n\nwith st.spinner(\"Please wait...\"):\n    if (\n        uploaded_Resume is not None\n        and st.session_state[\"jobDescriptionUploaded\"] == \"Uploaded\"\n        and uploaded_JobDescription is not None\n        and st.session_state[\"jobDescriptionUploaded\"] == \"Uploaded\"\n    ):\n\n        resumeProcessor = ParseResume(read_single_pdf(st.session_state[\"resumePath\"]))\n        jobDescriptionProcessor = ParseJobDesc(\n            read_single_pdf(st.session_state[\"jobDescriptionPath\"])\n        )\n\n        # Resume / JD output\n        selected_file = resumeProcessor.get_JSON()\n        selected_jd = jobDescriptionProcessor.get_JSON()\n\n        # Add containers for each row to avoid overlap\n\n        # Parsed data\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Parsed Resume Data\"):\n                    st.caption(\n                        \"This text is parsed from your resume. This is how it'll look like after getting parsed by an \"\n                        \"ATS.\"\n                    )\n                    st.caption(\n                        \"Utilize this to understand how to make your resume ATS friendly.\"\n                    )\n                    avs.add_vertical_space(3)\n                    st.write(selected_file[\"clean_data\"])\n\n            with jobDescriptionCol:\n                with st.expander(\"Parsed Job Description\"):\n                    st.caption(\n                        \"Currently in the pipeline I'm parsing this from PDF but it'll be from txt or copy paste.\"\n                    )\n                    avs.add_vertical_space(3)\n                    st.write(selected_jd[\"clean_data\"])\n\n        # Extracted keywords\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Extracted Keywords\"):\n                    st.write(\n                        \"Now let's take a look at the extracted keywords from the resume.\"\n                    )\n                    annotated_text(\n                        create_annotated_text(\n                            selected_file[\"clean_data\"],\n                            selected_file[\"extracted_keywords\"],\n                            \"KW\",\n                            \"#0B666A\",\n                        )\n                    )\n            with jobDescriptionCol:\n                with st.expander(\"Extracted Keywords\"):\n                    st.write(\n                        \"Now let's take a look at the extracted keywords from the job description.\"\n                    )\n                    annotated_text(\n                        create_annotated_text(\n                            selected_jd[\"clean_data\"],\n                            selected_jd[\"extracted_keywords\"],\n                            \"KW\",\n                            \"#0B666A\",\n                        )\n                    )\n\n        # Star graph visualization\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Extracted Entities\"):\n                    st.write(\n                        \"Now let's take a look at the extracted entities from the resume.\"\n                    )\n\n                    # Call the function with your data\n                    create_star_graph(selected_file[\"keyterms\"], \"Entities from Resume\")\n            with jobDescriptionCol:\n                with st.expander(\"Extracted Entities\"):\n                    st.write(\n                        \"Now let's take a look at the extracted entities from the job description.\"\n                    )\n\n                    # Call the function with your data\n                    create_star_graph(\n                        selected_jd[\"keyterms\"], \"Entities from Job Description\"\n                    )\n\n        # Keywords and values\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Keywords & Values\"):\n                    df1 = pd.DataFrame(\n                        selected_file[\"keyterms\"], columns=[\"keyword\", \"value\"]\n                    )\n\n                    # Create the dictionary\n                    keyword_dict = {}\n                    for keyword, value in selected_file[\"keyterms\"]:\n                        keyword_dict[keyword] = value * 100\n\n                    fig = go.Figure(\n                        data=[\n                            go.Table(\n                                header=dict(\n                                    values=[\"Keyword\", \"Value\"],\n                                    font=dict(size=12, color=\"white\"),\n                                    fill_color=\"#1d2078\",\n                                ),\n                                cells=dict(\n                                    values=[\n                                        list(keyword_dict.keys()),\n                                        list(keyword_dict.values()),\n                                    ],\n                                    line_color=\"darkslategray\",\n                                    fill_color=\"#6DA9E4\",\n                                ),\n                            )\n                        ]\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n            with jobDescriptionCol:\n                with st.expander(\"Keywords & Values\"):\n                    df2 = pd.DataFrame(\n                        selected_jd[\"keyterms\"], columns=[\"keyword\", \"value\"]\n                    )\n\n                    # Create the dictionary\n                    keyword_dict = {}\n                    for keyword, value in selected_jd[\"keyterms\"]:\n                        keyword_dict[keyword] = value * 100\n\n                    fig = go.Figure(\n                        data=[\n                            go.Table(\n                                header=dict(\n                                    values=[\"Keyword\", \"Value\"],\n                                    font=dict(size=12, color=\"white\"),\n                                    fill_color=\"#1d2078\",\n                                ),\n                                cells=dict(\n                                    values=[\n                                        list(keyword_dict.keys()),\n                                        list(keyword_dict.values()),\n                                    ],\n                                    line_color=\"darkslategray\",\n                                    fill_color=\"#6DA9E4\",\n                                ),\n                            )\n                        ]\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n\n        # Treemaps\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Key Topics\"):\n                    fig = px.treemap(\n                        df1,\n                        path=[\"keyword\"],\n                        values=\"value\",\n                        color_continuous_scale=\"Rainbow\",\n                        title=\"Key Terms/Topics Extracted from your Resume\",\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n\n            with jobDescriptionCol:\n                with st.expander(\"Key Topics\"):\n                    fig = px.treemap(\n                        df2,\n                        path=[\"keyword\"],\n                        values=\"value\",\n                        color_continuous_scale=\"Rainbow\",\n                        title=\"Key Terms/Topics Extracted from Job Description\",\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n\n        avs.add_vertical_space(2)\n        st.markdown(\"#### Similarity Score\")\n        print(\"Config file parsed successfully:\")\n        resume_string = \" \".join(selected_file[\"extracted_keywords\"])\n        jd_string = \" \".join(selected_jd[\"extracted_keywords\"])\n        result = get_score(resume_string, jd_string)\n        similarity_score = round(result[0].score * 100, 2)\n\n        # Default color to green\n        score_color = \"green\"\n        if similarity_score < 60:\n            score_color = \"red\"\n        elif 60 <= similarity_score < 75:\n            score_color = \"orange\"\n\n        st.markdown(\n            f\"Similarity Score obtained for the resume and job description is \"\n            f'<span style=\"color:{score_color};font-size:24px; font-weight:Bold\">{similarity_score}</span>',\n            unsafe_allow_html=True,\n        )\n\n        avs.add_vertical_space(2)\n        with st.expander(\"Common words between Resume and Job Description:\"):\n            annotated_text(\n                create_annotated_text(\n                    selected_file[\"clean_data\"],\n                    selected_jd[\"extracted_keywords\"],\n                    \"JD\",\n                    \"#F24C3D\",\n                )\n            )\n\nst.divider()\n\n# Go back to top\nst.markdown(\"[:arrow_up: Back to Top](#resume-matcher)\")\n",
        "filename_new": "streamlit_interactive.py",
        "source_new": "# Import necessary libraries\nimport json\nimport os\nfrom typing import List\n\nimport networkx as nx\nimport nltk\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom annotated_text import annotated_text, parameters\nfrom streamlit_extras import add_vertical_space as avs\nfrom streamlit_extras.badges import badge\n\nfrom scripts import JobDescriptionProcessor, ResumeProcessor\nfrom scripts.parsers import ParseJobDesc, ParseResume\nfrom scripts.ReadPdf import read_single_pdf\nfrom scripts.similarity.get_score import *\nfrom scripts.utils import get_filenames_from_dir\n\n# Set page configuration\nst.set_page_config(\n    page_title=\"Resume Matcher\",\n    page_icon=\"Assets/img/favicon.ico\",\n    initial_sidebar_state=\"auto\",\n    layout=\"wide\",\n)\n\n# Find the current working directory and configuration path\ncwd = find_path(\"Resume-Matcher\")\nconfig_path = os.path.join(cwd, \"scripts\", \"similarity\")\n\n# Check if NLTK punkt_tab data is available, if not, download it\ntry:\n    nltk.data.find(\"tokenizers/punkt_tab\")\nexcept LookupError:\n    nltk.download(\"punkt_tab\")\n\n# Set some visualization parameters using the annotated_text library\nparameters.SHOW_LABEL_SEPARATOR = False\nparameters.BORDER_RADIUS = 3\nparameters.PADDING = \"0.5 0.25rem\"\n\n\n# Function to set session state variables\ndef update_session_state(key, val):\n    st.session_state[key] = val\n\n\n# Function to delete all files in a directory\ndef delete_from_dir(filepath: str) -> bool:\n    try:\n        for file in os.scandir(filepath):\n            os.remove(file.path)\n\n        return True\n    except OSError as error:\n        print(f\"Exception: {error}\")\n        return False\n\n\n# Function to create a star-shaped graph visualization\ndef create_star_graph(nodes_and_weights, title):\n    \"\"\"\n    Create a star-shaped graph visualization.\n\n    Args:\n        nodes_and_weights (list): List of tuples containing nodes and their weights.\n        title (str): Title for the graph.\n\n    Returns:\n        None\n    \"\"\"\n    # Create an empty graph\n    graph = nx.Graph()\n\n    # Add the central node\n    central_node = \"resume\"\n    graph.add_node(central_node)\n\n    # Add nodes and edges with weights to the graph\n    for node, weight in nodes_and_weights:\n        graph.add_node(node)\n        graph.add_edge(central_node, node, weight=weight * 100)\n\n    # Get position layout for nodes\n    pos = nx.spring_layout(graph)\n\n    # Create edge trace\n    edge_x = []\n    edge_y = []\n    for edge in graph.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None])\n        edge_y.extend([y0, y1, None])\n\n    edge_trace = go.Scatter(\n        x=edge_x,\n        y=edge_y,\n        line=dict(width=0.5, color=\"#888\"),\n        hoverinfo=\"none\",\n        mode=\"lines\",\n    )\n\n    # Create node trace\n    node_x = []\n    node_y = []\n    for node in graph.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n\n    node_trace = go.Scatter(\n        x=node_x,\n        y=node_y,\n        mode=\"markers\",\n        hoverinfo=\"text\",\n        marker=dict(\n            showscale=True,\n            colorscale=\"Rainbow\",\n            reversescale=True,\n            color=[],\n            size=10,\n            colorbar=dict(\n                thickness=15,\n                title=\"Node Connections\",\n                xanchor=\"left\",\n                titleside=\"right\",\n            ),\n            line_width=2,\n        ),\n    )\n\n    # Color node points by number of connections\n    node_adjacencies = []\n    node_text = []\n    for node in graph.nodes():\n        adjacencies = list(graph.adj[node])  # Changes here\n        node_adjacencies.append(len(adjacencies))\n        node_text.append(f\"{node}<br># of connections: {len(adjacencies)}\")\n\n    node_trace.marker.color = node_adjacencies\n    node_trace.text = node_text\n\n    # Create the figure\n    figure = go.Figure(\n        data=[edge_trace, node_trace],\n        layout=go.Layout(\n            title=title,\n            titlefont=dict(size=16),\n            showlegend=False,\n            hovermode=\"closest\",\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        ),\n    )\n\n    # Show the figure\n    st.plotly_chart(figure, use_container_width=True)\n\n\n# Function to create annotated text with highlighting\ndef create_annotated_text(\n    input_string: str, word_list: List[str], annotation: str, color_code: str\n):\n    \"\"\"\n    Create annotated text with highlighted keywords.\n\n    Args:\n        input_string (str): The input text.\n        word_list (List[str]): List of keywords to be highlighted.\n        annotation (str): Annotation label for highlighted keywords.\n        color_code (str): Color code for highlighting.\n\n    Returns:\n        List: Annotated text with highlighted keywords.\n    \"\"\"\n    # Tokenize the input string\n    tokens = nltk.word_tokenize(input_string)\n\n    # Convert the list to a set for quick lookups\n    word_set = set(word_list)\n\n    # Initialize an empty list to hold the annotated text\n    ret_annotated_text = []\n\n    for token in tokens:\n        # Check if the token is in the set\n        if token in word_set:\n            # If it is, append a tuple with the token, annotation, and color code\n            ret_annotated_text.append((token, annotation, color_code))\n        else:\n            # If it's not, just append the token as a string\n            ret_annotated_text.append(token)\n\n    return ret_annotated_text\n\n\n# Function to read JSON data from a file\ndef read_json(filename):\n    \"\"\"\n    Read JSON data from a file.\n\n    Args:\n        filename (str): The path to the JSON file.\n\n    Returns:\n        dict: The JSON data.\n    \"\"\"\n    with open(filename) as f:\n        data = json.load(f)\n    return data\n\n\n# Function to tokenize a string\ndef tokenize_string(input_string):\n    \"\"\"\n    Tokenize a string into words.\n\n    Args:\n        input_string (str): The input string.\n\n    Returns:\n        List[str]: List of tokens.\n    \"\"\"\n    tokens = nltk.word_tokenize(input_string)\n    return tokens\n\n\n# Cleanup processed resume / job descriptions\ndelete_from_dir(os.path.join(cwd, \"Data\", \"Processed\", \"Resumes\"))\ndelete_from_dir(os.path.join(cwd, \"Data\", \"Processed\", \"JobDescription\"))\n\n# Set default session states for first run\nif \"resumeUploaded\" not in st.session_state.keys():\n    update_session_state(\"resumeUploaded\", \"Pending\")\n    update_session_state(\"resumePath\", \"\")\nif \"jobDescriptionUploaded\" not in st.session_state.keys():\n    update_session_state(\"jobDescriptionUploaded\", \"Pending\")\n    update_session_state(\"jobDescriptionPath\", \"\")\n\n# Display the main title and sub-headers\nst.title(\":blue[Resume Matcher]\")\nwith st.sidebar:\n    st.image(\"Assets/img/header_image.png\")\n    st.subheader(\n        \"Free and Open Source ATS to help your resume pass the screening stage.\"\n    )\n    st.markdown(\n        \"Check the website [www.resumematcher.fyi](https://www.resumematcher.fyi/)\"\n    )\n    st.markdown(\n        \"Give Resume Matcher a \u2b50 on [GitHub](https://github.com/srbhr/resume-matcher)\"\n    )\n    badge(type=\"github\", name=\"srbhr/Resume-Matcher\")\n    st.markdown(\"For updates follow me on Twitter.\")\n    badge(type=\"twitter\", name=\"_srbhr_\")\n    st.markdown(\n        \"If you like the project and would like to further help in development please consider \ud83d\udc47\"\n    )\n    badge(type=\"buymeacoffee\", name=\"srbhr\")\n\nst.divider()\navs.add_vertical_space(1)\n\nwith st.container():\n    resumeCol, jobDescriptionCol = st.columns(2)\n    with resumeCol:\n        uploaded_Resume = st.file_uploader(\"Choose a Resume\", type=\"pdf\")\n        if uploaded_Resume is not None:\n            if st.session_state[\"resumeUploaded\"] == \"Pending\":\n                save_path_resume = os.path.join(\n                    cwd, \"Data\", \"Resumes\", uploaded_Resume.name\n                )\n\n                with open(save_path_resume, mode=\"wb\") as w:\n                    w.write(uploaded_Resume.getvalue())\n\n                if os.path.exists(save_path_resume):\n                    st.toast(\n                        f\"File {uploaded_Resume.name} is successfully saved!\", icon=\"\u2714\ufe0f\"\n                    )\n                    update_session_state(\"resumeUploaded\", \"Uploaded\")\n                    update_session_state(\"resumePath\", save_path_resume)\n        else:\n            update_session_state(\"resumeUploaded\", \"Pending\")\n            update_session_state(\"resumePath\", \"\")\n\n    with jobDescriptionCol:\n        uploaded_JobDescription = st.file_uploader(\n            \"Choose a Job Description\", type=\"pdf\"\n        )\n        if uploaded_JobDescription is not None:\n            if st.session_state[\"jobDescriptionUploaded\"] == \"Pending\":\n                save_path_jobDescription = os.path.join(\n                    cwd, \"Data\", \"JobDescription\", uploaded_JobDescription.name\n                )\n\n                with open(save_path_jobDescription, mode=\"wb\") as w:\n                    w.write(uploaded_JobDescription.getvalue())\n\n                if os.path.exists(save_path_jobDescription):\n                    st.toast(\n                        f\"File {uploaded_JobDescription.name} is successfully saved!\",\n                        icon=\"\u2714\ufe0f\",\n                    )\n                    update_session_state(\"jobDescriptionUploaded\", \"Uploaded\")\n                    update_session_state(\"jobDescriptionPath\", save_path_jobDescription)\n        else:\n            update_session_state(\"jobDescriptionUploaded\", \"Pending\")\n            update_session_state(\"jobDescriptionPath\", \"\")\n\nwith st.spinner(\"Please wait...\"):\n    if (\n        uploaded_Resume is not None\n        and st.session_state[\"jobDescriptionUploaded\"] == \"Uploaded\"\n        and uploaded_JobDescription is not None\n        and st.session_state[\"jobDescriptionUploaded\"] == \"Uploaded\"\n    ):\n\n        resumeProcessor = ParseResume(read_single_pdf(st.session_state[\"resumePath\"]))\n        jobDescriptionProcessor = ParseJobDesc(\n            read_single_pdf(st.session_state[\"jobDescriptionPath\"])\n        )\n\n        # Resume / JD output\n        selected_file = resumeProcessor.get_JSON()\n        selected_jd = jobDescriptionProcessor.get_JSON()\n\n        # Add containers for each row to avoid overlap\n\n        # Parsed data\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Parsed Resume Data\"):\n                    st.caption(\n                        \"This text is parsed from your resume. This is how it'll look like after getting parsed by an \"\n                        \"ATS.\"\n                    )\n                    st.caption(\n                        \"Utilize this to understand how to make your resume ATS friendly.\"\n                    )\n                    avs.add_vertical_space(3)\n                    st.write(selected_file[\"clean_data\"])\n\n            with jobDescriptionCol:\n                with st.expander(\"Parsed Job Description\"):\n                    st.caption(\n                        \"Currently in the pipeline I'm parsing this from PDF but it'll be from txt or copy paste.\"\n                    )\n                    avs.add_vertical_space(3)\n                    st.write(selected_jd[\"clean_data\"])\n\n        # Extracted keywords\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Extracted Keywords\"):\n                    st.write(\n                        \"Now let's take a look at the extracted keywords from the resume.\"\n                    )\n                    annotated_text(\n                        create_annotated_text(\n                            selected_file[\"clean_data\"],\n                            selected_file[\"extracted_keywords\"],\n                            \"KW\",\n                            \"#0B666A\",\n                        )\n                    )\n            with jobDescriptionCol:\n                with st.expander(\"Extracted Keywords\"):\n                    st.write(\n                        \"Now let's take a look at the extracted keywords from the job description.\"\n                    )\n                    annotated_text(\n                        create_annotated_text(\n                            selected_jd[\"clean_data\"],\n                            selected_jd[\"extracted_keywords\"],\n                            \"KW\",\n                            \"#0B666A\",\n                        )\n                    )\n\n        # Star graph visualization\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Extracted Entities\"):\n                    st.write(\n                        \"Now let's take a look at the extracted entities from the resume.\"\n                    )\n\n                    # Call the function with your data\n                    create_star_graph(selected_file[\"keyterms\"], \"Entities from Resume\")\n            with jobDescriptionCol:\n                with st.expander(\"Extracted Entities\"):\n                    st.write(\n                        \"Now let's take a look at the extracted entities from the job description.\"\n                    )\n\n                    # Call the function with your data\n                    create_star_graph(\n                        selected_jd[\"keyterms\"], \"Entities from Job Description\"\n                    )\n\n        # Keywords and values\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Keywords & Values\"):\n                    df1 = pd.DataFrame(\n                        selected_file[\"keyterms\"], columns=[\"keyword\", \"value\"]\n                    )\n\n                    # Create the dictionary\n                    keyword_dict = {}\n                    for keyword, value in selected_file[\"keyterms\"]:\n                        keyword_dict[keyword] = value * 100\n\n                    fig = go.Figure(\n                        data=[\n                            go.Table(\n                                header=dict(\n                                    values=[\"Keyword\", \"Value\"],\n                                    font=dict(size=12, color=\"white\"),\n                                    fill_color=\"#1d2078\",\n                                ),\n                                cells=dict(\n                                    values=[\n                                        list(keyword_dict.keys()),\n                                        list(keyword_dict.values()),\n                                    ],\n                                    line_color=\"darkslategray\",\n                                    fill_color=\"#6DA9E4\",\n                                ),\n                            )\n                        ]\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n            with jobDescriptionCol:\n                with st.expander(\"Keywords & Values\"):\n                    df2 = pd.DataFrame(\n                        selected_jd[\"keyterms\"], columns=[\"keyword\", \"value\"]\n                    )\n\n                    # Create the dictionary\n                    keyword_dict = {}\n                    for keyword, value in selected_jd[\"keyterms\"]:\n                        keyword_dict[keyword] = value * 100\n\n                    fig = go.Figure(\n                        data=[\n                            go.Table(\n                                header=dict(\n                                    values=[\"Keyword\", \"Value\"],\n                                    font=dict(size=12, color=\"white\"),\n                                    fill_color=\"#1d2078\",\n                                ),\n                                cells=dict(\n                                    values=[\n                                        list(keyword_dict.keys()),\n                                        list(keyword_dict.values()),\n                                    ],\n                                    line_color=\"darkslategray\",\n                                    fill_color=\"#6DA9E4\",\n                                ),\n                            )\n                        ]\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n\n        # Treemaps\n        with st.container():\n            resumeCol, jobDescriptionCol = st.columns(2)\n            with resumeCol:\n                with st.expander(\"Key Topics\"):\n                    fig = px.treemap(\n                        df1,\n                        path=[\"keyword\"],\n                        values=\"value\",\n                        color_continuous_scale=\"Rainbow\",\n                        title=\"Key Terms/Topics Extracted from your Resume\",\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n\n            with jobDescriptionCol:\n                with st.expander(\"Key Topics\"):\n                    fig = px.treemap(\n                        df2,\n                        path=[\"keyword\"],\n                        values=\"value\",\n                        color_continuous_scale=\"Rainbow\",\n                        title=\"Key Terms/Topics Extracted from Job Description\",\n                    )\n                    st.plotly_chart(fig, use_container_width=True)\n\n        avs.add_vertical_space(2)\n        st.markdown(\"#### Similarity Score\")\n        print(\"Config file parsed successfully:\")\n        resume_string = \" \".join(selected_file[\"extracted_keywords\"])\n        jd_string = \" \".join(selected_jd[\"extracted_keywords\"])\n        result = get_score(resume_string, jd_string)\n        similarity_score = round(result[0].score * 100, 2)\n\n        # Default color to green\n        score_color = \"green\"\n        if similarity_score < 60:\n            score_color = \"red\"\n        elif 60 <= similarity_score < 75:\n            score_color = \"orange\"\n\n        st.markdown(\n            f\"Similarity Score obtained for the resume and job description is \"\n            f'<span style=\"color:{score_color};font-size:24px; font-weight:Bold\">{similarity_score}</span>',\n            unsafe_allow_html=True,\n        )\n\n        avs.add_vertical_space(2)\n        with st.expander(\"Common words between Resume and Job Description:\"):\n            annotated_text(\n                create_annotated_text(\n                    selected_file[\"clean_data\"],\n                    selected_jd[\"extracted_keywords\"],\n                    \"JD\",\n                    \"#F24C3D\",\n                )\n            )\n\nst.divider()\n\n# Go back to top\nst.markdown(\"[:arrow_up: Back to Top](#resume-matcher)\")\n",
        "additions": 3,
        "deletions": 3,
        "cyclomatic_complexity_new": 14
    },
    "7e60d1a1fae2b8387a90c7474209a61e83503376": {
        "filename_old": "streamlit_second.py",
        "source_old": "import json\nfrom typing import List\n\nimport networkx as nx\nimport nltk\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom annotated_text import annotated_text, parameters\nfrom streamlit_extras import add_vertical_space as avs\nfrom streamlit_extras.badges import badge\n\nfrom scripts.utils import get_filenames_from_dir\n\n# Set page configuration\nst.set_page_config(\n    page_title=\"Resume Matcher\",\n    page_icon=\"Assets/img/favicon.ico\",\n    initial_sidebar_state=\"auto\",\n)\n\nnltk.download(\"punkt\")\n\nparameters.SHOW_LABEL_SEPARATOR = False\nparameters.BORDER_RADIUS = 3\nparameters.PADDING = \"0.5 0.25rem\"\n\n\ndef create_star_graph(nodes_and_weights, title):\n    # Create an empty graph\n    G = nx.Graph()\n\n    # Add the central node\n    central_node = \"resume\"\n    G.add_node(central_node)\n\n    # Add nodes and edges with weights to the graph\n    for node, weight in nodes_and_weights:\n        G.add_node(node)\n        G.add_edge(central_node, node, weight=weight * 100)\n\n    # Get position layout for nodes\n    pos = nx.spring_layout(G)\n\n    # Create edge trace\n    edge_x = []\n    edge_y = []\n    for edge in G.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None])\n        edge_y.extend([y0, y1, None])\n\n    edge_trace = go.Scatter(\n        x=edge_x,\n        y=edge_y,\n        line=dict(width=0.5, color=\"#888\"),\n        hoverinfo=\"none\",\n        mode=\"lines\",\n    )\n\n    # Create node trace\n    node_x = []\n    node_y = []\n    for node in G.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n\n    node_trace = go.Scatter(\n        x=node_x,\n        y=node_y,\n        mode=\"markers\",\n        hoverinfo=\"text\",\n        marker=dict(\n            showscale=True,\n            colorscale=\"Rainbow\",\n            reversescale=True,\n            color=[],\n            size=10,\n            colorbar=dict(\n                thickness=15,\n                title=\"Node Connections\",\n                xanchor=\"left\",\n                titleside=\"right\",\n            ),\n            line_width=2,\n        ),\n    )\n\n    # Color node points by number of connections\n    node_adjacencies = []\n    node_text = []\n    for node in G.nodes():\n        adjacencies = list(G.adj[node])  # changes here\n        node_adjacencies.append(len(adjacencies))\n        node_text.append(f\"{node}<br># of connections: {len(adjacencies)}\")\n\n    node_trace.marker.color = node_adjacencies\n    node_trace.text = node_text\n\n    # Create the figure\n    fig = go.Figure(\n        data=[edge_trace, node_trace],\n        layout=go.Layout(\n            title=title,\n            titlefont_size=16,\n            showlegend=False,\n            hovermode=\"closest\",\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        ),\n    )\n\n    # Show the figure\n    st.plotly_chart(fig)\n\n\ndef create_annotated_text(\n    input_string: str, word_list: List[str], annotation: str, color_code: str\n):\n    # Tokenize the input string\n    tokens = nltk.word_tokenize(input_string)\n\n    # Convert the list to a set for quick lookups\n    word_set = set(word_list)\n\n    # Initialize an empty list to hold the annotated text\n    annotated_text = []\n\n    for token in tokens:\n        # Check if the token is in the set\n        if token in word_set:\n            # If it is, append a tuple with the token, annotation, and color code\n            annotated_text.append((token, annotation, color_code))\n        else:\n            # If it's not, just append the token as a string\n            annotated_text.append(token)\n\n    return annotated_text\n\n\ndef read_json(filename):\n    with open(filename) as f:\n        data = json.load(f)\n    return data\n\n\ndef tokenize_string(input_string):\n    tokens = nltk.word_tokenize(input_string)\n    return tokens\n\n\n# Display the main title and subheaders\nst.title(\":blue[Resume Matcher]\")\nwith st.sidebar:\n    st.image(\"Assets/img/header_image.png\")\n    st.subheader(\n        \"Free and Open Source ATS to help your resume pass the screening stage.\"\n    )\n    st.markdown(\n        \"Check the website [www.resumematcher.fyi](https://www.resumematcher.fyi/)\"\n    )\n\n    st.markdown(\n        \"Give Resume Matcher a \u2b50 on [GitHub](https://github.com/srbhr/resume-matcher)\"\n    )\n\n    badge(type=\"github\", name=\"srbhr/Resume-Matcher\")\n    st.markdown(\"For updates follow me on Twitter.\")\n    badge(type=\"twitter\", name=\"_srbhr_\")\n    st.markdown(\n        \"If you like the project and would like to further help in development please consider \ud83d\udc47\"\n    )\n    badge(type=\"buymeacoffee\", name=\"srbhr\")\n\nst.divider()\navs.add_vertical_space(1)\n\nresume_names = get_filenames_from_dir(\"Data/Processed/Resumes\")\n\noutput = st.selectbox(\n    f\"There are {len(resume_names)} resumes present. Please select one from the menu below:\",\n    resume_names,\n)\n\navs.add_vertical_space(5)\n\nselected_file = read_json(\"Data/Processed/Resumes/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Parsed Resume Data\")\nst.caption(\n    \"This text is parsed from your resume. This is how it'll look like after getting parsed by an ATS.\"\n)\nst.caption(\"Utilize this to understand how to make your resume ATS friendly.\")\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_file[\"clean_data\"])\n\navs.add_vertical_space(3)\nst.write(\"Now let's take a look at the extracted keywords from the resume.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"],\n        selected_file[\"extracted_keywords\"],\n        \"KW\",\n        \"#0B666A\",\n    )\n)\n\navs.add_vertical_space(5)\nst.write(\"Now let's take a look at the extracted entities from the resume.\")\n\n# Call the function with your data\ncreate_star_graph(selected_file[\"keyterms\"], \"Entities from Resume\")\n\ndf2 = pd.DataFrame(selected_file[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_file[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from your Resume\",\n)\nst.write(fig)\n\navs.add_vertical_space(5)\n\njob_descriptions = get_filenames_from_dir(\"Data/Processed/JobDescription\")\n\noutput = st.selectbox(\n    f\"There are {len(job_descriptions)} job descriptions present. Please select one from the menu below:\",\n    job_descriptions,\n)\n\navs.add_vertical_space(5)\n\nselected_jd = read_json(\"Data/Processed/JobDescription/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Job Description\")\nst.caption(\n    \"Currently in the pipeline I'm parsing this from PDF but it'll be from txt or copy paste.\"\n)\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_jd[\"clean_data\"])\n\nst.markdown(\"#### Common Words between Job Description and Resumes Highlighted.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"], selected_jd[\"extracted_keywords\"], \"JD\", \"#F24C3D\"\n    )\n)\n\nst.write(\"Now let's take a look at the extracted entities from the job description.\")\n\n# Call the function with your data\ncreate_star_graph(selected_jd[\"keyterms\"], \"Entities from Job Description\")\n\ndf2 = pd.DataFrame(selected_jd[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_jd[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from the selected Job Description\",\n)\nst.write(fig)\n\navs.add_vertical_space(5)\n\nst.divider()\n\nst.markdown(\"## Vector Similarity Scores\")\nst.caption(\"Powered by Qdrant Vector Search\")\nst.info(\"These are pre-computed queries\", icon=\"\u2139\")\nst.warning(\n    \"Running Qdrant or Sentence Transformers without having capacity is not recommended\",\n    icon=\"\u26a0\",\n)\n\n\n# Your data\ndata = [\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.62658,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.43777737,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne \",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.39835533,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.3915512,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.3519544,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.6541866,\n    },\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.59806436,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.5951386,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne \",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.57700855,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.38489106,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.76813436,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne'\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.60440844,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.56080043,\n    },\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.5395049,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.3859515,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.5449441,\n    },\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.53476423,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.5313871,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne \",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.44446343,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.3616274,\n    },\n]\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Create different DataFrames based on the query and sort by score\ndf1 = df[df[\"query\"] == \"Job Description Product Manager\"].sort_values(\n    by=\"score\", ascending=False\n)\ndf2 = df[df[\"query\"] == \"Job Description Senior Full Stack Engineer\"].sort_values(\n    by=\"score\", ascending=False\n)\ndf3 = df[df[\"query\"] == \"Job Description Front End Engineer\"].sort_values(\n    by=\"score\", ascending=False\n)\ndf4 = df[df[\"query\"] == \"Job Description Java Developer\"].sort_values(\n    by=\"score\", ascending=False\n)\n\n\ndef plot_df(df, title):\n    fig = px.bar(df, x=\"text\", y=df[\"score\"] * 100, title=title)\n    st.plotly_chart(fig)\n\n\nst.markdown(\"### Bar plots of scores based on similarity to Job Description.\")\n\nst.subheader(\":blue[Legend]\")\nst.text(\"Alfred Pennyworth :  Product Manager\")\nst.text(\"Barry Allen :  Front End Developer\")\nst.text(\"Harvey Dent :  Machine Learning Engineer\")\nst.text(\"Bruce Wayne :  Fullstack Developer (MERN)\")\nst.text(\"John Doe :  Fullstack Developer (Java)\")\n\n\nplot_df(df1, \"Job Description Product Manager 10+ Years of Exper\")\nplot_df(df2, \"Job Description Senior Full Stack Engineer 5+ Year\")\nplot_df(df3, \"Job Description Front End Engineer 2 Years of Expe\")\nplot_df(df4, \"Job Description Java Developer 3 Years of Experien\")\n\n\navs.add_vertical_space(3)\n\n# Go back to top\nst.markdown(\"[:arrow_up: Back to Top](#resume-matcher)\")\n",
        "filename_new": "streamlit_second.py",
        "source_new": "import json\nfrom typing import List\n\nimport networkx as nx\nimport nltk\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport streamlit as st\nfrom annotated_text import annotated_text, parameters\nfrom streamlit_extras import add_vertical_space as avs\nfrom streamlit_extras.badges import badge\n\nfrom scripts.utils import get_filenames_from_dir\n\n# Set page configuration\nst.set_page_config(\n    page_title=\"Resume Matcher\",\n    page_icon=\"Assets/img/favicon.ico\",\n    initial_sidebar_state=\"auto\",\n)\n\n# Check if NLTK punkt_tab data is available, if not, download it\ntry:\n    nltk.data.find(\"tokenizers/punkt_tab\")\nexcept LookupError:\n    nltk.download(\"punkt_tab\")\n\nparameters.SHOW_LABEL_SEPARATOR = False\nparameters.BORDER_RADIUS = 3\nparameters.PADDING = \"0.5 0.25rem\"\n\n\ndef create_star_graph(nodes_and_weights, title):\n    # Create an empty graph\n    G = nx.Graph()\n\n    # Add the central node\n    central_node = \"resume\"\n    G.add_node(central_node)\n\n    # Add nodes and edges with weights to the graph\n    for node, weight in nodes_and_weights:\n        G.add_node(node)\n        G.add_edge(central_node, node, weight=weight * 100)\n\n    # Get position layout for nodes\n    pos = nx.spring_layout(G)\n\n    # Create edge trace\n    edge_x = []\n    edge_y = []\n    for edge in G.edges():\n        x0, y0 = pos[edge[0]]\n        x1, y1 = pos[edge[1]]\n        edge_x.extend([x0, x1, None])\n        edge_y.extend([y0, y1, None])\n\n    edge_trace = go.Scatter(\n        x=edge_x,\n        y=edge_y,\n        line=dict(width=0.5, color=\"#888\"),\n        hoverinfo=\"none\",\n        mode=\"lines\",\n    )\n\n    # Create node trace\n    node_x = []\n    node_y = []\n    for node in G.nodes():\n        x, y = pos[node]\n        node_x.append(x)\n        node_y.append(y)\n\n    node_trace = go.Scatter(\n        x=node_x,\n        y=node_y,\n        mode=\"markers\",\n        hoverinfo=\"text\",\n        marker=dict(\n            showscale=True,\n            colorscale=\"Rainbow\",\n            reversescale=True,\n            color=[],\n            size=10,\n            colorbar=dict(\n                thickness=15,\n                title=\"Node Connections\",\n                xanchor=\"left\",\n                titleside=\"right\",\n            ),\n            line_width=2,\n        ),\n    )\n\n    # Color node points by number of connections\n    node_adjacencies = []\n    node_text = []\n    for node in G.nodes():\n        adjacencies = list(G.adj[node])  # changes here\n        node_adjacencies.append(len(adjacencies))\n        node_text.append(f\"{node}<br># of connections: {len(adjacencies)}\")\n\n    node_trace.marker.color = node_adjacencies\n    node_trace.text = node_text\n\n    # Create the figure\n    fig = go.Figure(\n        data=[edge_trace, node_trace],\n        layout=go.Layout(\n            title=title,\n            titlefont_size=16,\n            showlegend=False,\n            hovermode=\"closest\",\n            margin=dict(b=20, l=5, r=5, t=40),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n        ),\n    )\n\n    # Show the figure\n    st.plotly_chart(fig)\n\n\ndef create_annotated_text(\n    input_string: str, word_list: List[str], annotation: str, color_code: str\n):\n    # Tokenize the input string\n    tokens = nltk.word_tokenize(input_string)\n\n    # Convert the list to a set for quick lookups\n    word_set = set(word_list)\n\n    # Initialize an empty list to hold the annotated text\n    annotated_text = []\n\n    for token in tokens:\n        # Check if the token is in the set\n        if token in word_set:\n            # If it is, append a tuple with the token, annotation, and color code\n            annotated_text.append((token, annotation, color_code))\n        else:\n            # If it's not, just append the token as a string\n            annotated_text.append(token)\n\n    return annotated_text\n\n\ndef read_json(filename):\n    with open(filename) as f:\n        data = json.load(f)\n    return data\n\n\ndef tokenize_string(input_string):\n    tokens = nltk.word_tokenize(input_string)\n    return tokens\n\n\n# Display the main title and subheaders\nst.title(\":blue[Resume Matcher]\")\nwith st.sidebar:\n    st.image(\"Assets/img/header_image.png\")\n    st.subheader(\n        \"Free and Open Source ATS to help your resume pass the screening stage.\"\n    )\n    st.markdown(\n        \"Check the website [www.resumematcher.fyi](https://www.resumematcher.fyi/)\"\n    )\n\n    st.markdown(\n        \"Give Resume Matcher a \u2b50 on [GitHub](https://github.com/srbhr/resume-matcher)\"\n    )\n\n    badge(type=\"github\", name=\"srbhr/Resume-Matcher\")\n    st.markdown(\"For updates follow me on Twitter.\")\n    badge(type=\"twitter\", name=\"_srbhr_\")\n    st.markdown(\n        \"If you like the project and would like to further help in development please consider \ud83d\udc47\"\n    )\n    badge(type=\"buymeacoffee\", name=\"srbhr\")\n\nst.divider()\navs.add_vertical_space(1)\n\nresume_names = get_filenames_from_dir(\"Data/Processed/Resumes\")\n\noutput = st.selectbox(\n    f\"There are {len(resume_names)} resumes present. Please select one from the menu below:\",\n    resume_names,\n)\n\navs.add_vertical_space(5)\n\nselected_file = read_json(\"Data/Processed/Resumes/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Parsed Resume Data\")\nst.caption(\n    \"This text is parsed from your resume. This is how it'll look like after getting parsed by an ATS.\"\n)\nst.caption(\"Utilize this to understand how to make your resume ATS friendly.\")\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_file[\"clean_data\"])\n\navs.add_vertical_space(3)\nst.write(\"Now let's take a look at the extracted keywords from the resume.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"],\n        selected_file[\"extracted_keywords\"],\n        \"KW\",\n        \"#0B666A\",\n    )\n)\n\navs.add_vertical_space(5)\nst.write(\"Now let's take a look at the extracted entities from the resume.\")\n\n# Call the function with your data\ncreate_star_graph(selected_file[\"keyterms\"], \"Entities from Resume\")\n\ndf2 = pd.DataFrame(selected_file[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_file[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from your Resume\",\n)\nst.write(fig)\n\navs.add_vertical_space(5)\n\njob_descriptions = get_filenames_from_dir(\"Data/Processed/JobDescription\")\n\noutput = st.selectbox(\n    f\"There are {len(job_descriptions)} job descriptions present. Please select one from the menu below:\",\n    job_descriptions,\n)\n\navs.add_vertical_space(5)\n\nselected_jd = read_json(\"Data/Processed/JobDescription/\" + output)\n\navs.add_vertical_space(2)\nst.markdown(\"#### Job Description\")\nst.caption(\n    \"Currently in the pipeline I'm parsing this from PDF but it'll be from txt or copy paste.\"\n)\navs.add_vertical_space(3)\n# st.json(selected_file)\nst.write(selected_jd[\"clean_data\"])\n\nst.markdown(\"#### Common Words between Job Description and Resumes Highlighted.\")\n\nannotated_text(\n    create_annotated_text(\n        selected_file[\"clean_data\"], selected_jd[\"extracted_keywords\"], \"JD\", \"#F24C3D\"\n    )\n)\n\nst.write(\"Now let's take a look at the extracted entities from the job description.\")\n\n# Call the function with your data\ncreate_star_graph(selected_jd[\"keyterms\"], \"Entities from Job Description\")\n\ndf2 = pd.DataFrame(selected_jd[\"keyterms\"], columns=[\"keyword\", \"value\"])\n\n# Create the dictionary\nkeyword_dict = {}\nfor keyword, value in selected_jd[\"keyterms\"]:\n    keyword_dict[keyword] = value * 100\n\nfig = go.Figure(\n    data=[\n        go.Table(\n            header=dict(\n                values=[\"Keyword\", \"Value\"], font=dict(size=12), fill_color=\"#070A52\"\n            ),\n            cells=dict(\n                values=[list(keyword_dict.keys()), list(keyword_dict.values())],\n                line_color=\"darkslategray\",\n                fill_color=\"#6DA9E4\",\n            ),\n        )\n    ]\n)\nst.plotly_chart(fig)\n\nst.divider()\n\nfig = px.treemap(\n    df2,\n    path=[\"keyword\"],\n    values=\"value\",\n    color_continuous_scale=\"Rainbow\",\n    title=\"Key Terms/Topics Extracted from the selected Job Description\",\n)\nst.write(fig)\n\navs.add_vertical_space(5)\n\nst.divider()\n\nst.markdown(\"## Vector Similarity Scores\")\nst.caption(\"Powered by Qdrant Vector Search\")\nst.info(\"These are pre-computed queries\", icon=\"\u2139\")\nst.warning(\n    \"Running Qdrant or Sentence Transformers without having capacity is not recommended\",\n    icon=\"\u26a0\",\n)\n\n\n# Your data\ndata = [\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.62658,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.43777737,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne \",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.39835533,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.3915512,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Product Manager\",\n        \"score\": 0.3519544,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.6541866,\n    },\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.59806436,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.5951386,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne \",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.57700855,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Senior Full Stack Engineer\",\n        \"score\": 0.38489106,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.76813436,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne'\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.60440844,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.56080043,\n    },\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.5395049,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Front End Engineer\",\n        \"score\": 0.3859515,\n    },\n    {\n        \"text\": \"{'resume': 'JOHN DOE\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.5449441,\n    },\n    {\n        \"text\": \"{'resume': 'Alfred Pennyworth\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.53476423,\n    },\n    {\n        \"text\": \"{'resume': 'Barry Allen\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.5313871,\n    },\n    {\n        \"text\": \"{'resume': 'Bruce Wayne \",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.44446343,\n    },\n    {\n        \"text\": \"{'resume': 'Harvey Dent\",\n        \"query\": \"Job Description Java Developer\",\n        \"score\": 0.3616274,\n    },\n]\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Create different DataFrames based on the query and sort by score\ndf1 = df[df[\"query\"] == \"Job Description Product Manager\"].sort_values(\n    by=\"score\", ascending=False\n)\ndf2 = df[df[\"query\"] == \"Job Description Senior Full Stack Engineer\"].sort_values(\n    by=\"score\", ascending=False\n)\ndf3 = df[df[\"query\"] == \"Job Description Front End Engineer\"].sort_values(\n    by=\"score\", ascending=False\n)\ndf4 = df[df[\"query\"] == \"Job Description Java Developer\"].sort_values(\n    by=\"score\", ascending=False\n)\n\n\ndef plot_df(df, title):\n    fig = px.bar(df, x=\"text\", y=df[\"score\"] * 100, title=title)\n    st.plotly_chart(fig)\n\n\nst.markdown(\"### Bar plots of scores based on similarity to Job Description.\")\n\nst.subheader(\":blue[Legend]\")\nst.text(\"Alfred Pennyworth :  Product Manager\")\nst.text(\"Barry Allen :  Front End Developer\")\nst.text(\"Harvey Dent :  Machine Learning Engineer\")\nst.text(\"Bruce Wayne :  Fullstack Developer (MERN)\")\nst.text(\"John Doe :  Fullstack Developer (Java)\")\n\n\nplot_df(df1, \"Job Description Product Manager 10+ Years of Exper\")\nplot_df(df2, \"Job Description Senior Full Stack Engineer 5+ Year\")\nplot_df(df3, \"Job Description Front End Engineer 2 Years of Expe\")\nplot_df(df4, \"Job Description Java Developer 3 Years of Experien\")\n\n\navs.add_vertical_space(3)\n\n# Go back to top\nst.markdown(\"[:arrow_up: Back to Top](#resume-matcher)\")\n",
        "additions": 5,
        "deletions": 1,
        "cyclomatic_complexity_new": 11
    }
}