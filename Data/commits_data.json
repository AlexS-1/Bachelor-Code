{
    ".env.template": [],
    "Cargo.lock": [],
    "Cargo.toml": [],
    "config.rs": [
        {
            "commit": "662bc2752345ef37cb394b2dd709b269dab86fd1",
            "timestamp": "2019-10-08T19:33:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated dependencies and fixed disable_admin_token description",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -298,7 +298,7 @@ make_config! {\n         /// that do not support WAL. Please make sure you read project wiki on the topic before changing this setting.\n         enable_db_wal:          bool,   false,  def,    true;\n \n-        /// Disable Admin Token (Know the risks!) |> Disables the Admin Token for the admin page so you may use your own auth in-front\n+        /// Bypass admin page security (Know the risks!) |> Disables the Admin Token for the admin page so you may use your own auth in-front\n         disable_admin_token:    bool,   true,   def,    false;\n     },\n \n",
            "comment_added_diff": [
                [
                    301,
                    "        /// Bypass admin page security (Know the risks!) |> Disables the Admin Token for the admin page so you may use your own auth in-front"
                ]
            ]
        },
        {
            "commit": "881c1978eb8e2eaea2467e6b3bf79d2d91196ec1",
            "timestamp": "2019-10-08T19:34:47+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Error when the URL scheme doesn't match the database type",
            "additions": 20,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -366,6 +366,26 @@ make_config! {\n }\n \n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n+    let db_url = cfg.database_url.to_lowercase();\n+    \n+    if cfg!(feature = \"sqlite\") {\n+        if db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\") {\n+            err!(\"`DATABASE_URL` is meant for MySQL or Postgres, while this server is meant for SQLite\")\n+        }\n+    }\n+\n+    if cfg!(feature = \"mysql\") {\n+        if !db_url.starts_with(\"mysql:\") {\n+            err!(\"`DATABASE_URL` should start with mysql: when using the MySQL server\")\n+        }\n+    }\n+\n+    if cfg!(feature = \"postgresql\") {\n+        if !db_url.starts_with(\"postgresql:\") {\n+            err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n+        }\n+    }\n+\n     if let Some(ref token) = cfg.admin_token {\n         if token.trim().is_empty() {\n             err!(\"`ADMIN_TOKEN` is enabled but has an empty value. To enable the admin page without token, use `DISABLE_ADMIN_TOKEN`\")\n",
            "comment_added_diff": []
        },
        {
            "commit": "3b7a5bd1023c6ade04c7f04345568be1f4bedabe",
            "timestamp": "2019-10-16T07:11:16+02:00",
            "author": "vpl",
            "commit_message": "Move 2FA email config to after SMTP config",
            "additions": 12,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -328,18 +328,6 @@ make_config! {\n         _duo_akey:              Pass,   false,  option;\n     },\n \n-    /// Email 2FA Settings\n-    email_2fa: _enable_email_2fa {\n-        /// Enabled |> Disabling will prevent users from setting up new email 2FA and using existing email 2FA configured\n-        _enable_email_2fa:      bool,   true,   auto,    |c| c._enable_smtp && c.smtp_host.is_some();\n-        /// Token number length |> Length of the numbers in an email token. Minimum of 6. Maximum is 19.\n-        email_token_size:       u32,    true,   def,      6;\n-        /// Token expiration time |> Maximum time in seconds a token is valid. The time the user has to open email client and copy token.\n-        email_expiration_time:  u64,    true,   def,      600;\n-        /// Maximum attempts |> Maximum attempts before an email token is reset and a new email will need to be sent\n-        email_attempts_limit:   u64,    true,   def,      3;\n-    },\n-\n     /// SMTP Email Settings\n     smtp: _enable_smtp {\n         /// Enabled\n@@ -363,6 +351,18 @@ make_config! {\n         /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]\n         smtp_auth_mechanism:    String, true,   option;\n     },\n+\n+    /// Email 2FA Settings\n+    email_2fa: _enable_email_2fa {\n+        /// Enabled |> Disabling will prevent users from setting up new email 2FA and using existing email 2FA configured\n+        _enable_email_2fa:      bool,   true,   auto,    |c| c._enable_smtp && c.smtp_host.is_some();\n+        /// Token number length |> Length of the numbers in an email token. Minimum of 6. Maximum is 19.\n+        email_token_size:       u32,    true,   def,      6;\n+        /// Token expiration time |> Maximum time in seconds a token is valid. The time the user has to open email client and copy token.\n+        email_expiration_time:  u64,    true,   def,      600;\n+        /// Maximum attempts |> Maximum attempts before an email token is reset and a new email will need to be sent\n+        email_attempts_limit:   u64,    true,   def,      3;\n+    },\n }\n \n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n",
            "comment_added_diff": [
                [
                    355,
                    "    /// Email 2FA Settings"
                ],
                [
                    357,
                    "        /// Enabled |> Disabling will prevent users from setting up new email 2FA and using existing email 2FA configured"
                ],
                [
                    359,
                    "        /// Token number length |> Length of the numbers in an email token. Minimum of 6. Maximum is 19."
                ],
                [
                    361,
                    "        /// Token expiration time |> Maximum time in seconds a token is valid. The time the user has to open email client and copy token."
                ],
                [
                    363,
                    "        /// Maximum attempts |> Maximum attempts before an email token is reset and a new email will need to be sent"
                ]
            ]
        },
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 6,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -368,22 +368,16 @@ make_config! {\n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     let db_url = cfg.database_url.to_lowercase();\n     \n-    if cfg!(feature = \"sqlite\") {\n-        if db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\") {\n-            err!(\"`DATABASE_URL` is meant for MySQL or Postgres, while this server is meant for SQLite\")\n-        }\n+    if cfg!(feature = \"sqlite\") && (db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\")) {\n+        err!(\"`DATABASE_URL` is meant for MySQL or Postgres, while this server is meant for SQLite\")\n     }\n \n-    if cfg!(feature = \"mysql\") {\n-        if !db_url.starts_with(\"mysql:\") {\n-            err!(\"`DATABASE_URL` should start with mysql: when using the MySQL server\")\n-        }\n+    if cfg!(feature = \"mysql\") && !db_url.starts_with(\"mysql:\") {\n+        err!(\"`DATABASE_URL` should start with mysql: when using the MySQL server\")\n     }\n \n-    if cfg!(feature = \"postgresql\") {\n-        if !db_url.starts_with(\"postgresql:\") {\n-            err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n-        }\n+    if cfg!(feature = \"postgresql\") && !db_url.starts_with(\"postgresql:\") {\n+        err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n     }\n \n     if let Some(ref token) = cfg.admin_token {\n",
            "comment_added_diff": []
        },
        {
            "commit": "c52adef919419a1e823fbc26c49aaef9032248ff",
            "timestamp": "2019-11-06T21:39:33+01:00",
            "author": "BlackDex",
            "commit_message": "Added configurable smtp timeout.\n\n - Added config option for smtp timeout\n - Lowered default timeout to 15 seconds instead of default 60.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -350,6 +350,8 @@ make_config! {\n         smtp_password:          Pass,   true,   option;\n         /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]\n         smtp_auth_mechanism:    String, true,   option;\n+        /// SMTP connection timeout |> Number of seconds when to stop trying to connect to the SMTP server\n+        smtp_timeout:           u64,     true,   def,     15;\n     },\n \n     /// Email 2FA Settings\n",
            "comment_added_diff": [
                [
                    353,
                    "        /// SMTP connection timeout |> Number of seconds when to stop trying to connect to the SMTP server"
                ]
            ]
        },
        {
            "commit": "3f6809bcdf88268543c0ee75ae6c3a3fbcf23df8",
            "timestamp": "2019-11-07T17:11:29+01:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue/request #705\n\nAdded a config option to disable time drifted totp codes.\nDefault is false, since this is what the RFC recommends.",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -275,6 +275,10 @@ make_config! {\n         /// Note that the checkbox would still be present, but ignored.\n         disable_2fa_remember:   bool,   true,   def,    false;\n \n+        /// Disable authenticator time drifted codes to be valid |> Enabling this only allows the current TOTP code to be valid\n+        /// TOTP codes of the previous and next 30 seconds will be invalid.\n+        authenticator_disable_time_drift:     bool,   true,  def,    false;\n+\n         /// Require new device emails |> When a user logs in an email is required to be sent.\n         /// If sending the email fails the login attempt will fail.\n         require_device_email:   bool,   true,   def,     false;\n",
            "comment_added_diff": [
                [
                    278,
                    "        /// Disable authenticator time drifted codes to be valid |> Enabling this only allows the current TOTP code to be valid"
                ],
                [
                    279,
                    "        /// TOTP codes of the previous and next 30 seconds will be invalid."
                ]
            ]
        },
        {
            "commit": "64d6f72e6c71dec7cbcb5992f31473c416d0678e",
            "timestamp": "2019-11-16T15:01:45-07:00",
            "author": "tomuta",
            "commit_message": "Add the ability to disable signups, but allow signups from a whitelist\n\nThis feature can be enabled by setting SIGNUPS_ALLOWED=false and\nproviding a comma-separated list of whitelisted domains in\nSIGNUPS_DOMAINS_WHITELIST.\n\nFixes #727",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -243,6 +243,8 @@ make_config! {\n         disable_icon_download:  bool,   true,   def,    false;\n         /// Allow new signups |> Controls if new users can register. Note that while this is disabled, users could still be invited\n         signups_allowed:        bool,   true,   def,    true;\n+        /// Allow signups only from this list of comma-separated domains\n+        signups_domains_whitelist: String, true, def,   \"\".to_string();\n         /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are disabled\n         invitations_allowed:    bool,   true,   def,    true;\n         /// Password iterations |> Number of server-side passwords hashing iterations.\n@@ -491,6 +493,16 @@ impl Config {\n         self.update_config(builder)\n     }\n \n+    pub fn can_signup_user(&self, email: &str) -> bool {\n+        let e: Vec<&str> = email.rsplitn(2, \"@\").collect();\n+        if e.len() != 2 || e[0].is_empty() || e[1].is_empty() {\n+            warn!(\"Failed to parse email address '{}'\", email);\n+            return false\n+        }\n+        \n+        self.signups_domains_whitelist().split(\",\").any(|d| d == e[0])\n+    }\n+\n     pub fn delete_user_config(&self) -> Result<(), Error> {\n         crate::util::delete_file(&CONFIG_FILE)?;\n \n",
            "comment_added_diff": [
                [
                    246,
                    "        /// Allow signups only from this list of comma-separated domains"
                ]
            ]
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 11,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -243,6 +243,12 @@ make_config! {\n         disable_icon_download:  bool,   true,   def,    false;\n         /// Allow new signups |> Controls if new users can register. Note that while this is disabled, users could still be invited\n         signups_allowed:        bool,   true,   def,    true;\n+        /// Require email verification on signups. This will prevent logins from succeeding until the address has been verified\n+        signups_verify:         bool,   true,   def,    false;\n+        /// If signups require email verification, automatically re-send verification email if it hasn't been sent for a while (in seconds)\n+        signups_verify_resend_time: u64, true,  def,    3_600;\n+        /// If signups require email verification, limit how many emails are automatically sent when login is attempted (0 means no limit)\n+        signups_verify_resend_limit: u32, true, def,    6;\n         /// Allow signups only from this list of comma-separated domains\n         signups_domains_whitelist: String, true, def,   \"\".to_string();\n         /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are disabled\n@@ -595,6 +601,8 @@ fn load_templates(path: &str) -> Handlebars {\n     }\n \n     // First register default templates here\n+    reg!(\"email/change_email\", \".html\");\n+    reg!(\"email/delete_account\", \".html\");\n     reg!(\"email/invite_accepted\", \".html\");\n     reg!(\"email/invite_confirmed\", \".html\");\n     reg!(\"email/new_device_logged_in\", \".html\");\n@@ -602,6 +610,9 @@ fn load_templates(path: &str) -> Handlebars {\n     reg!(\"email/pw_hint_some\", \".html\");\n     reg!(\"email/send_org_invite\", \".html\");\n     reg!(\"email/twofactor_email\", \".html\");\n+    reg!(\"email/verify_email\", \".html\");\n+    reg!(\"email/welcome\", \".html\");\n+    reg!(\"email/welcome_must_verify\", \".html\");\n \n     reg!(\"admin/base\");\n     reg!(\"admin/login\");\n",
            "comment_added_diff": [
                [
                    246,
                    "        /// Require email verification on signups. This will prevent logins from succeeding until the address has been verified"
                ],
                [
                    248,
                    "        /// If signups require email verification, automatically re-send verification email if it hasn't been sent for a while (in seconds)"
                ],
                [
                    250,
                    "        /// If signups require email verification, limit how many emails are automatically sent when login is attempted (0 means no limit)"
                ]
            ]
        },
        {
            "commit": "1e224220a855fb65263d9b67df2a520791b5a882",
            "timestamp": "2019-11-28T21:59:05+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated deps and fixed some lints",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -500,13 +500,13 @@ impl Config {\n     }\n \n     pub fn can_signup_user(&self, email: &str) -> bool {\n-        let e: Vec<&str> = email.rsplitn(2, \"@\").collect();\n+        let e: Vec<&str> = email.rsplitn(2, '@').collect();\n         if e.len() != 2 || e[0].is_empty() || e[1].is_empty() {\n             warn!(\"Failed to parse email address '{}'\", email);\n             return false\n         }\n         \n-        self.signups_domains_whitelist().split(\",\").any(|d| d == e[0])\n+        self.signups_domains_whitelist().split(',').any(|d| d == e[0])\n     }\n \n     pub fn delete_user_config(&self) -> Result<(), Error> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "8d1b72b9512b90775e671b7ba08cd552a0aabd13",
            "timestamp": "2019-12-06T22:46:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Collapsed log messages from 3 lines per request to 2 and hidden the ones valued as less informative.\nUse LOG_LEVEL debug or trace to recover them.\n\nRemoved LOG_MOUNTS and bundled it with LOG_LEVEL debug and trace.\n\nRemoved duplicate error messages\n\nMade websocket not proxied message more prominent, but only print it once.",
            "additions": 0,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -294,9 +294,6 @@ make_config! {\n         /// Reload templates (Dev) |> When this is set to true, the templates get reloaded with every request.\n         /// ONLY use this during development, as it can slow down the server\n         reload_templates:       bool,   true,   def,    false;\n-\n-        /// Log routes at launch (Dev)\n-        log_mounts:             bool,   true,   def,    false;\n         /// Enable extended logging\n         extended_logging:       bool,   false,  def,    true;\n         /// Enable the log to output to Syslog\n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 7,
            "deletions": 20,
            "change_type": "MODIFY",
            "diff": "@@ -378,7 +378,6 @@ make_config! {\n \n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     let db_url = cfg.database_url.to_lowercase();\n-    \n     if cfg!(feature = \"sqlite\") && (db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\")) {\n         err!(\"`DATABASE_URL` is meant for MySQL or Postgres, while this server is meant for SQLite\")\n     }\n@@ -447,12 +446,7 @@ impl Config {\n         validate_config(&config)?;\n \n         Ok(Config {\n-            inner: RwLock::new(Inner {\n-                templates: load_templates(&config.templates_folder),\n-                config,\n-                _env,\n-                _usr,\n-            }),\n+            inner: RwLock::new(Inner { templates: load_templates(&config.templates_folder), config, _env, _usr }),\n         })\n     }\n \n@@ -500,9 +494,8 @@ impl Config {\n         let e: Vec<&str> = email.rsplitn(2, '@').collect();\n         if e.len() != 2 || e[0].is_empty() || e[1].is_empty() {\n             warn!(\"Failed to parse email address '{}'\", email);\n-            return false\n+            return false;\n         }\n-        \n         self.signups_domains_whitelist().split(',').any(|d| d == e[0])\n     }\n \n@@ -634,9 +627,7 @@ impl HelperDef for CaseHelper {\n         rc: &mut RenderContext<'reg>,\n         out: &mut dyn Output,\n     ) -> HelperResult {\n-        let param = h\n-            .param(0)\n-            .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"case\\\"\"))?;\n+        let param = h.param(0).ok_or_else(|| RenderError::new(\"Param not found for helper \\\"case\\\"\"))?;\n         let value = param.value().clone();\n \n         if h.params().iter().skip(1).any(|x| x.value() == &value) {\n@@ -658,14 +649,10 @@ impl HelperDef for JsEscapeHelper {\n         _: &mut RenderContext<'reg>,\n         out: &mut dyn Output,\n     ) -> HelperResult {\n-        let param = h\n-            .param(0)\n-            .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n-\n-        let value = param\n-            .value()\n-            .as_str()\n-            .ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n+        let param = h.param(0).ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n+\n+        let value =\n+            param.value().as_str().ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n \n         let escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n         let quoted_value = format!(\"&quot;{}&quot;\", escaped_value);\n",
            "comment_added_diff": []
        },
        {
            "commit": "88c56de97b48bb5b9b8af350d0d0e0d5f080ff0e",
            "timestamp": "2019-12-27T18:42:39+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Config option for client IP header",
            "additions": 12,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -185,19 +185,24 @@ macro_rules! make_config {\n             }\n         }\n     }};\n+    ( @build $value:expr, $config:expr, gen, $default_fn:expr ) => {{\n+        let f: &dyn Fn(&ConfigItems) -> _ = &$default_fn;\n+        f($config)\n+    }};\n }\n \n //STRUCTURE:\n // /// Short description (without this they won't appear on the list)\n // group {\n //   /// Friendly Name |> Description (Optional)\n-//   name: type, is_editable, none_action, <default_value (Optional)>\n+//   name: type, is_editable, action, <default_value (Optional)>\n // }\n //\n-// Where none_action applied when the value wasn't provided and can be:\n+// Where action applied when the value wasn't provided and can be:\n //  def:    Use a default value\n //  auto:   Value is auto generated based on other values\n //  option: Value is optional\n+//  gen:    Value is always autogenerated and it's original value ignored\n make_config! {\n     folders {\n         ///  Data folder |> Main data folder\n@@ -266,6 +271,11 @@ make_config! {\n \n     /// Advanced settings\n     advanced {\n+        /// Client IP header |> If not present, the remote IP is used.\n+        /// Set to the string \"none\" (without quotes), to disable any headers and just use the remote IP\n+        ip_header:              String, true,   def,    \"X-Real-IP\".to_string();\n+        /// Internal IP header property, used to avoid recomputing each time\n+        _ip_header_enabled:     bool,   false,  gen,    |c| &c.ip_header.trim().to_lowercase() != \"none\";\n         /// Positive icon cache expiry |> Number of seconds to consider that an already cached icon is fresh. After this period, the icon will be redownloaded\n         icon_cache_ttl:         u64,    true,   def,    2_592_000;\n         /// Negative icon cache expiry |> Number of seconds before trying to download an icon that failed again.\n",
            "comment_added_diff": [
                [
                    198,
                    "//   name: type, is_editable, action, <default_value (Optional)>"
                ],
                [
                    201,
                    "// Where action applied when the value wasn't provided and can be:"
                ],
                [
                    205,
                    "//  gen:    Value is always autogenerated and it's original value ignored"
                ],
                [
                    274,
                    "        /// Client IP header |> If not present, the remote IP is used."
                ],
                [
                    275,
                    "        /// Set to the string \"none\" (without quotes), to disable any headers and just use the remote IP"
                ],
                [
                    277,
                    "        /// Internal IP header property, used to avoid recomputing each time"
                ]
            ]
        },
        {
            "commit": "d212dfe735e59128667a4c579e52ce7e86b53a94",
            "timestamp": "2020-01-20T22:28:54+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Accept y/n, True/False, 1/0 as booleans in environment vars",
            "additions": 8,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -2,7 +2,7 @@ use std::process::exit;\n use std::sync::RwLock;\n \n use crate::error::Error;\n-use crate::util::get_env;\n+use crate::util::{get_env, get_env_bool};\n \n lazy_static! {\n     pub static ref CONFIG: Config = Config::load().unwrap_or_else(|e| {\n@@ -23,7 +23,7 @@ macro_rules! make_config {\n         $group:ident $(: $group_enabled:ident)? {\n         $(\n             $(#[doc = $doc:literal])+\n-            $name:ident : $ty:ty, $editable:literal, $none_action:ident $(, $default:expr)?;\n+            $name:ident : $ty:ident, $editable:literal, $none_action:ident $(, $default:expr)?;\n         )+},\n     )+) => {\n         pub struct Config { inner: RwLock<Inner> }\n@@ -50,9 +50,9 @@ macro_rules! make_config {\n \n                 let mut builder = ConfigBuilder::default();\n                 $($(\n-                    builder.$name = get_env(&stringify!($name).to_uppercase());\n+                    builder.$name = make_config! { @getenv &stringify!($name).to_uppercase(), $ty };\n                 )+)+\n-\n+                \n                 builder\n             }\n \n@@ -189,6 +189,10 @@ macro_rules! make_config {\n         let f: &dyn Fn(&ConfigItems) -> _ = &$default_fn;\n         f($config)\n     }};\n+\n+    ( @getenv $name:expr, bool ) => { get_env_bool($name) };\n+    ( @getenv $name:expr, $ty:ident ) => { get_env($name) };\n+\n }\n \n //STRUCTURE:\n",
            "comment_added_diff": []
        },
        {
            "commit": "ff7b4a3d38f07eb5687ae9beaa044777f07dadba",
            "timestamp": "2020-01-26T15:29:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update handlebars to 3.0 which included performance improvements.\nUpdated lettre to newer git revision, which should give better error messages now.",
            "additions": 46,
            "deletions": 49,
            "change_type": "MODIFY",
            "diff": "@@ -29,7 +29,7 @@ macro_rules! make_config {\n         pub struct Config { inner: RwLock<Inner> }\n \n         struct Inner {\n-            templates: Handlebars,\n+            templates: Handlebars<'static>,\n             config: ConfigItems,\n \n             _env: ConfigBuilder,\n@@ -572,7 +572,7 @@ impl Config {\n     ) -> Result<String, crate::error::Error> {\n         if CONFIG.reload_templates() {\n             warn!(\"RELOADING TEMPLATES\");\n-            let hb = load_templates(CONFIG.templates_folder().as_ref());\n+            let hb = load_templates(CONFIG.templates_folder());\n             hb.render(name, data).map_err(Into::into)\n         } else {\n             let hb = &CONFIG.inner.read().unwrap().templates;\n@@ -581,17 +581,18 @@ impl Config {\n     }\n }\n \n-use handlebars::{\n-    Context, Handlebars, Helper, HelperDef, HelperResult, Output, RenderContext, RenderError, Renderable,\n-};\n+use handlebars::{Context, Handlebars, Helper, HelperResult, Output, RenderContext, RenderError, Renderable};\n \n-fn load_templates(path: &str) -> Handlebars {\n+fn load_templates<P>(path: P) -> Handlebars<'static>\n+where\n+    P: AsRef<std::path::Path>,\n+{\n     let mut hb = Handlebars::new();\n     // Error on missing params\n     hb.set_strict_mode(true);\n     // Register helpers\n-    hb.register_helper(\"case\", Box::new(CaseHelper));\n-    hb.register_helper(\"jsesc\", Box::new(JsEscapeHelper));\n+    hb.register_helper(\"case\", Box::new(case_helper));\n+    hb.register_helper(\"jsesc\", Box::new(js_escape_helper));\n \n     macro_rules! reg {\n         ($name:expr) => {{\n@@ -630,48 +631,44 @@ fn load_templates(path: &str) -> Handlebars {\n     hb\n }\n \n-pub struct CaseHelper;\n-\n-impl HelperDef for CaseHelper {\n-    fn call<'reg: 'rc, 'rc>(\n-        &self,\n-        h: &Helper<'reg, 'rc>,\n-        r: &'reg Handlebars,\n-        ctx: &Context,\n-        rc: &mut RenderContext<'reg>,\n-        out: &mut dyn Output,\n-    ) -> HelperResult {\n-        let param = h.param(0).ok_or_else(|| RenderError::new(\"Param not found for helper \\\"case\\\"\"))?;\n-        let value = param.value().clone();\n-\n-        if h.params().iter().skip(1).any(|x| x.value() == &value) {\n-            h.template().map(|t| t.render(r, ctx, rc, out)).unwrap_or(Ok(()))\n-        } else {\n-            Ok(())\n-        }\n+fn case_helper<'reg, 'rc>(\n+    h: &Helper<'reg, 'rc>,\n+    r: &'reg Handlebars,\n+    ctx: &'rc Context,\n+    rc: &mut RenderContext<'reg, 'rc>,\n+    out: &mut dyn Output,\n+) -> HelperResult {\n+    let param = h\n+        .param(0)\n+        .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"case\\\"\"))?;\n+    let value = param.value().clone();\n+\n+    if h.params().iter().skip(1).any(|x| x.value() == &value) {\n+        h.template().map(|t| t.render(r, ctx, rc, out)).unwrap_or(Ok(()))\n+    } else {\n+        Ok(())\n     }\n }\n \n-pub struct JsEscapeHelper;\n-\n-impl HelperDef for JsEscapeHelper {\n-    fn call<'reg: 'rc, 'rc>(\n-        &self,\n-        h: &Helper<'reg, 'rc>,\n-        _: &'reg Handlebars,\n-        _: &Context,\n-        _: &mut RenderContext<'reg>,\n-        out: &mut dyn Output,\n-    ) -> HelperResult {\n-        let param = h.param(0).ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n-\n-        let value =\n-            param.value().as_str().ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n-\n-        let escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n-        let quoted_value = format!(\"&quot;{}&quot;\", escaped_value);\n-\n-        out.write(&quoted_value)?;\n-        Ok(())\n-    }\n+fn js_escape_helper<'reg, 'rc>(\n+    h: &Helper<'reg, 'rc>,\n+    _r: &'reg Handlebars,\n+    _ctx: &'rc Context,\n+    _rc: &mut RenderContext<'reg, 'rc>,\n+    out: &mut dyn Output,\n+) -> HelperResult {\n+    let param = h\n+        .param(0)\n+        .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n+\n+    let value = param\n+        .value()\n+        .as_str()\n+        .ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n+\n+    let escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n+    let quoted_value = format!(\"&quot;{}&quot;\", escaped_value);\n+\n+    out.write(&quoted_value)?;\n+    Ok(())\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "e277f7d1c12dc90d3a4ec63b7c6b88613fa56f5c",
            "timestamp": "2020-01-26T13:34:56-07:00",
            "author": "tomuta",
            "commit_message": "Fix change email when no whitelist is configured\n\nFixes issue #792",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -510,7 +510,12 @@ impl Config {\n             warn!(\"Failed to parse email address '{}'\", email);\n             return false;\n         }\n-        self.signups_domains_whitelist().split(',').any(|d| d == e[0])\n+        \n+        // Allow signups if the whitelist is empty/not configured\n+        // (it doesn't contain any domains), or if it matches at least\n+        // one domain.\n+        let whitelist_str = self.signups_domains_whitelist();\n+        whitelist_str.is_empty() || whitelist_str.split(',').filter(|s| !s.is_empty()).any(|d| d == e[0])\n     }\n \n     pub fn delete_user_config(&self) -> Result<(), Error> {\n",
            "comment_added_diff": [
                [
                    514,
                    "        // Allow signups if the whitelist is empty/not configured"
                ],
                [
                    515,
                    "        // (it doesn't contain any domains), or if it matches at least"
                ],
                [
                    516,
                    "        // one domain."
                ]
            ]
        },
        {
            "commit": "c4101162d667aa7be34c662198b126079d058833",
            "timestamp": "2020-01-29T11:32:42+00:00",
            "author": "Miro Prasil",
            "commit_message": "SIGNUPS_ALLOWED with no whitelist [fixes #830]\n\nThis reverts back to `SIGNUPS_ALLOWED` when there is no domain whitelist\nset. The functionality was broken in 64d6f72.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -515,7 +515,7 @@ impl Config {\n         // (it doesn't contain any domains), or if it matches at least\n         // one domain.\n         let whitelist_str = self.signups_domains_whitelist();\n-        whitelist_str.is_empty() || whitelist_str.split(',').filter(|s| !s.is_empty()).any(|d| d == e[0])\n+        ( whitelist_str.is_empty() && CONFIG.signups_allowed() )|| whitelist_str.split(',').filter(|s| !s.is_empty()).any(|d| d == e[0])\n     }\n \n     pub fn delete_user_config(&self) -> Result<(), Error> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "480ba933fa01f2fa09e515fe238784c4cd3c2576",
            "timestamp": "2020-01-30T22:10:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Don't error if admin token is empty but disabled",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -405,7 +405,7 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     }\n \n     if let Some(ref token) = cfg.admin_token {\n-        if token.trim().is_empty() {\n+        if token.trim().is_empty() && !cfg.disable_admin_token {\n             err!(\"`ADMIN_TOKEN` is enabled but has an empty value. To enable the admin page without token, use `DISABLE_ADMIN_TOKEN`\")\n         }\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "8867626de898bb8416ed8319806b1c220d57dcb1",
            "timestamp": "2020-02-04T22:14:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add option to change invitation org name, fixes #825\nAdd option to allow additional iframe ancestors, fixes #843\nSort the rocket routes before printing them",
            "additions": 7,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -271,6 +271,9 @@ make_config! {\n \n         /// Admin page token |> The token used to authenticate in this very same page. Changing it here won't deauthorize the current session\n         admin_token:            Pass,   true,   option;\n+\n+        /// Invitation organization name |> Name shown in the invitation emails that don't come from a specific organization\n+        invitation_org_name:    String, true,   def,    \"Bitwarden_RS\".to_string();\n     },\n \n     /// Advanced settings\n@@ -299,7 +302,7 @@ make_config! {\n \n         /// Disable authenticator time drifted codes to be valid |> Enabling this only allows the current TOTP code to be valid\n         /// TOTP codes of the previous and next 30 seconds will be invalid.\n-        authenticator_disable_time_drift:     bool,   true,  def,    false;\n+        authenticator_disable_time_drift: bool, true, def, false;\n \n         /// Require new device emails |> When a user logs in an email is required to be sent.\n         /// If sending the email fails the login attempt will fail.\n@@ -323,6 +326,9 @@ make_config! {\n \n         /// Bypass admin page security (Know the risks!) |> Disables the Admin Token for the admin page so you may use your own auth in-front\n         disable_admin_token:    bool,   true,   def,    false;\n+\n+        /// Allowed iframe ancestors (Know the risks!) |> Allows other domains to embed the web vault into an iframe, useful for embedding into secure intranets\n+        allowed_iframe_ancestors: String, true, def,    String::new();\n     },\n \n     /// Yubikey settings\n",
            "comment_added_diff": [
                [
                    275,
                    "        /// Invitation organization name |> Name shown in the invitation emails that don't come from a specific organization"
                ],
                [
                    330,
                    "        /// Allowed iframe ancestors (Know the risks!) |> Allows other domains to embed the web vault into an iframe, useful for embedding into secure intranets"
                ]
            ]
        },
        {
            "commit": "325039c31695ac981da3b88dbbe6c6f40c6a180d",
            "timestamp": "2020-02-17T22:56:26+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Attachment size limits, per-user and per-organization",
            "additions": 5,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -246,6 +246,11 @@ make_config! {\n         /// HIBP Api Key |> HaveIBeenPwned API Key, request it here: https://haveibeenpwned.com/API/Key\n         hibp_api_key:           Pass,   true,   option;\n \n+        /// Per-user attachment limit (KB) |> Limit in kilobytes for a users attachments, once the limit is exceeded it won't be possible to upload more\n+        user_attachment_limit:  i64,    true,   option;\n+        /// Per-organization attachment limit (KB) |> Limit in kilobytes for an organization attachments, once the limit is exceeded it won't be possible to upload more\n+        org_attachment_limit:   i64,    true,   option;\n+\n         /// Disable icon downloads |> Set to true to disable icon downloading, this would still serve icons from\n         /// $ICON_CACHE_FOLDER, but it won't produce any external network request. Needs to set $ICON_CACHE_TTL to 0,\n         /// otherwise it will delete them and they won't be downloaded again.\n",
            "comment_added_diff": [
                [
                    249,
                    "        /// Per-user attachment limit (KB) |> Limit in kilobytes for a users attachments, once the limit is exceeded it won't be possible to upload more"
                ],
                [
                    251,
                    "        /// Per-organization attachment limit (KB) |> Limit in kilobytes for an organization attachments, once the limit is exceeded it won't be possible to upload more"
                ]
            ]
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 21,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,8 @@\n use std::process::exit;\n use std::sync::RwLock;\n \n+use reqwest::Url;\n+\n use crate::error::Error;\n use crate::util::{get_env, get_env_bool};\n \n@@ -240,6 +242,10 @@ make_config! {\n         domain:                 String, true,   def,    \"http://localhost\".to_string();\n         /// Domain Set |> Indicates if the domain is set by the admin. Otherwise the default will be used.\n         domain_set:             bool,   false,  def,    false;\n+        /// Domain origin |> Domain URL origin (in https://example.com:8443/path, https://example.com:8443 is the origin)\n+        domain_origin:          String, false,  auto,   |c| extract_url_origin(&c.domain);\n+        /// Domain path |> Domain URL path (in https://example.com:8443/path, /path is the path)\n+        domain_path:            String, false,  auto,   |c| extract_url_path(&c.domain);\n         /// Enable web vault\n         web_vault_enabled:      bool,   false,  def,    true;\n \n@@ -457,6 +463,21 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     Ok(())\n }\n \n+/// Extracts an RFC 6454 web origin from a URL.\n+fn extract_url_origin(url: &str) -> String {\n+    let url = Url::parse(url).expect(\"valid URL\");\n+\n+    url.origin().ascii_serialization()\n+}\n+\n+/// Extracts the path from a URL.\n+/// All trailing '/' chars are trimmed, even if the path is a lone '/'.\n+fn extract_url_path(url: &str) -> String {\n+    let url = Url::parse(url).expect(\"valid URL\");\n+\n+    url.path().trim_end_matches('/').to_string()\n+}\n+\n impl Config {\n     pub fn load() -> Result<Self, Error> {\n         // Loading from env and file\n",
            "comment_added_diff": [
                [
                    245,
                    "        /// Domain origin |> Domain URL origin (in https://example.com:8443/path, https://example.com:8443 is the origin)"
                ],
                [
                    247,
                    "        /// Domain path |> Domain URL path (in https://example.com:8443/path, /path is the path)"
                ],
                [
                    466,
                    "/// Extracts an RFC 6454 web origin from a URL."
                ],
                [
                    473,
                    "/// Extracts the path from a URL."
                ],
                [
                    474,
                    "/// All trailing '/' chars are trimmed, even if the path is a lone '/'."
                ]
            ]
        },
        {
            "commit": "cd8907542a5d128d36309a4c9218ea3f4bd07df3",
            "timestamp": "2020-02-23T14:55:27+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Make sure the provided domain contains the protocol and show a useful error when it doesn't",
            "additions": 19,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -420,6 +420,11 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     if cfg!(feature = \"postgresql\") && !db_url.starts_with(\"postgresql:\") {\n         err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n     }\n+    \n+    let dom = cfg.domain.to_lowercase(); \n+    if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {\n+        err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\"); \n+    }\n \n     if let Some(ref token) = cfg.admin_token {\n         if token.trim().is_empty() && !cfg.disable_admin_token {\n@@ -465,17 +470,25 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n /// Extracts an RFC 6454 web origin from a URL.\n fn extract_url_origin(url: &str) -> String {\n-    let url = Url::parse(url).expect(\"valid URL\");\n-\n-    url.origin().ascii_serialization()\n+    match Url::parse(url) {\n+        Ok(u) => u.origin().ascii_serialization(),\n+        Err(e) => {\n+            println!(\"Error validating domain: {}\", e);\n+            String::new()\n+        }\n+    }\n }\n \n /// Extracts the path from a URL.\n /// All trailing '/' chars are trimmed, even if the path is a lone '/'.\n fn extract_url_path(url: &str) -> String {\n-    let url = Url::parse(url).expect(\"valid URL\");\n-\n-    url.path().trim_end_matches('/').to_string()\n+    match Url::parse(url) {\n+        Ok(u) => u.path().trim_end_matches('/').to_string(),\n+        Err(_) => {\n+            // We already print it in the method above, no need to do it again\n+            String::new()\n+        }\n+    }\n }\n \n impl Config {\n",
            "comment_added_diff": [
                [
                    425,
                    "    if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {"
                ],
                [
                    426,
                    "        err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\");"
                ],
                [
                    488,
                    "            // We already print it in the method above, no need to do it again"
                ]
            ]
        },
        {
            "commit": "5f61607419fb329442ebbdd98832cb14349d33ab",
            "timestamp": "2020-02-26T11:02:22+01:00",
            "author": "BlackDex",
            "commit_message": "Added SMTP test button in the admin gui\n\n- Added a test button for checking the e-mail settings.\n- Fixed a bug with the _post JavaScript function:\n  A function was overwriten with a variable and errors were not handled\ncorrectly like a 500 for example.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -634,6 +634,7 @@ where\n     reg!(\"email/verify_email\", \".html\");\n     reg!(\"email/welcome\", \".html\");\n     reg!(\"email/welcome_must_verify\", \".html\");\n+    reg!(\"email/smtp_test\", \".html\");\n \n     reg!(\"admin/base\");\n     reg!(\"admin/login\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "5a974c7b944a66adf72d4615004b894ba16ea6bd",
            "timestamp": "2020-02-26T16:49:56+01:00",
            "author": "BlackDex",
            "commit_message": "Added SMTP test button in the admin gui\n\n- Added a test button for checking the e-mail settings.\n- Fixed a bug with the _post JavaScript function:\n  A function was overwriten with a variable and errors were not handled\ncorrectly like a 500 for example.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -668,6 +668,7 @@ where\n     reg!(\"email/verify_email\", \".html\");\n     reg!(\"email/welcome\", \".html\");\n     reg!(\"email/welcome_must_verify\", \".html\");\n+    reg!(\"email/smtp_test\", \".html\");\n \n     reg!(\"admin/base\");\n     reg!(\"admin/login\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "70f3ab8ec3d6ccfd8ec8c71c888459de484d9b43",
            "timestamp": "2020-03-09T22:04:03+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Migrate lazy_static to once_cell, less macro magic and slightly faster",
            "additions": 14,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -1,3 +1,4 @@\n+use once_cell::sync::Lazy;\n use std::process::exit;\n use std::sync::RwLock;\n \n@@ -6,16 +7,17 @@ use reqwest::Url;\n use crate::error::Error;\n use crate::util::{get_env, get_env_bool};\n \n-lazy_static! {\n-    pub static ref CONFIG: Config = Config::load().unwrap_or_else(|e| {\n+static CONFIG_FILE: Lazy<String> = Lazy::new(|| {\n+    let data_folder = get_env(\"DATA_FOLDER\").unwrap_or_else(|| String::from(\"data\"));\n+    get_env(\"CONFIG_FILE\").unwrap_or_else(|| format!(\"{}/config.json\", data_folder))\n+});\n+\n+pub static CONFIG: Lazy<Config> = Lazy::new(|| {\n+    Config::load().unwrap_or_else(|e| {\n         println!(\"Error loading config:\\n\\t{:?}\\n\", e);\n         exit(12)\n-    });\n-    pub static ref CONFIG_FILE: String = {\n-        let data_folder = get_env(\"DATA_FOLDER\").unwrap_or_else(|| String::from(\"data\"));\n-        get_env(\"CONFIG_FILE\").unwrap_or_else(|| format!(\"{}/config.json\", data_folder))\n-    };\n-}\n+    })\n+});\n \n pub type Pass = String;\n \n@@ -54,7 +56,7 @@ macro_rules! make_config {\n                 $($(\n                     builder.$name = make_config! { @getenv &stringify!($name).to_uppercase(), $ty };\n                 )+)+\n-                \n+\n                 builder\n             }\n \n@@ -420,8 +422,8 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     if cfg!(feature = \"postgresql\") && !db_url.starts_with(\"postgresql:\") {\n         err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n     }\n-    \n-    let dom = cfg.domain.to_lowercase(); \n+\n+    let dom = cfg.domain.to_lowercase();\n     if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {\n         err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\"); \n     }\n@@ -555,7 +557,7 @@ impl Config {\n             warn!(\"Failed to parse email address '{}'\", email);\n             return false;\n         }\n-        \n+\n         // Allow signups if the whitelist is empty/not configured\n         // (it doesn't contain any domains), or if it matches at least\n         // one domain.\n",
            "comment_added_diff": []
        },
        {
            "commit": "c2a324e5da24bf2b59b5ccb745335783b4ea633f",
            "timestamp": "2020-04-09T01:42:27-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up domain whitelist logic\n\n* Make `SIGNUPS_DOMAINS_WHITELIST` override the `SIGNUPS_ALLOWED` setting.\n  Otherwise, a common pitfall is to set `SIGNUPS_DOMAINS_WHITELIST` without\n  realizing that `SIGNUPS_ALLOWED=false` must also be set.\n\n* Whitespace is now accepted in `SIGNUPS_DOMAINS_WHITELIST`. That is,\n  `foo.com, bar.com` is now equivalent to `foo.com,bar.com`.\n\n* Add validation on `SIGNUPS_DOMAINS_WHITELIST`. For example, `foo.com,`\n  is rejected as containing an empty token.",
            "additions": 27,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -112,6 +112,8 @@ macro_rules! make_config {\n                 )+)+\n                 config.domain_set = _domain_set;\n \n+                config.signups_domains_whitelist = config.signups_domains_whitelist.trim().to_lowercase();\n+\n                 config\n             }\n         }\n@@ -263,7 +265,7 @@ make_config! {\n         /// $ICON_CACHE_FOLDER, but it won't produce any external network request. Needs to set $ICON_CACHE_TTL to 0,\n         /// otherwise it will delete them and they won't be downloaded again.\n         disable_icon_download:  bool,   true,   def,    false;\n-        /// Allow new signups |> Controls if new users can register. Note that while this is disabled, users could still be invited\n+        /// Allow new signups |> Controls whether new users can register. Users can be invited by the bitwarden_rs admin even if this is disabled\n         signups_allowed:        bool,   true,   def,    true;\n         /// Require email verification on signups. This will prevent logins from succeeding until the address has been verified\n         signups_verify:         bool,   true,   def,    false;\n@@ -271,9 +273,9 @@ make_config! {\n         signups_verify_resend_time: u64, true,  def,    3_600;\n         /// If signups require email verification, limit how many emails are automatically sent when login is attempted (0 means no limit)\n         signups_verify_resend_limit: u32, true, def,    6;\n-        /// Allow signups only from this list of comma-separated domains\n+        /// Email domain whitelist |> Allow signups only from this list of comma-separated domains, even when signups are otherwise disabled\n         signups_domains_whitelist: String, true, def,   \"\".to_string();\n-        /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are disabled\n+        /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are otherwise disabled\n         invitations_allowed:    bool,   true,   def,    true;\n         /// Password iterations |> Number of server-side passwords hashing iterations.\n         /// The changes only apply when a user changes their password. Not recommended to lower the value\n@@ -428,6 +430,11 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n         err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\"); \n     }\n \n+    let whitelist = &cfg.signups_domains_whitelist;\n+    if !whitelist.is_empty() && whitelist.split(',').any(|d| d.trim().is_empty()) {\n+        err!(\"`SIGNUPS_DOMAINS_WHITELIST` contains empty tokens\");\n+    }\n+\n     if let Some(ref token) = cfg.admin_token {\n         if token.trim().is_empty() && !cfg.disable_admin_token {\n             err!(\"`ADMIN_TOKEN` is enabled but has an empty value. To enable the admin page without token, use `DISABLE_ADMIN_TOKEN`\")\n@@ -551,18 +558,29 @@ impl Config {\n         self.update_config(builder)\n     }\n \n-    pub fn can_signup_user(&self, email: &str) -> bool {\n+    /// Tests whether an email's domain is in signups_domains_whitelist.\n+    /// Returns false if no whitelist is set.\n+    pub fn is_email_domain_whitelisted(&self, email: &str) -> bool {\n         let e: Vec<&str> = email.rsplitn(2, '@').collect();\n         if e.len() != 2 || e[0].is_empty() || e[1].is_empty() {\n             warn!(\"Failed to parse email address '{}'\", email);\n             return false;\n         }\n+        let email_domain = e[0];\n+        let whitelist = self.signups_domains_whitelist();\n \n-        // Allow signups if the whitelist is empty/not configured\n-        // (it doesn't contain any domains), or if it matches at least\n-        // one domain.\n-        let whitelist_str = self.signups_domains_whitelist();\n-        ( whitelist_str.is_empty() && CONFIG.signups_allowed() )|| whitelist_str.split(',').filter(|s| !s.is_empty()).any(|d| d == e[0])\n+        !whitelist.is_empty() && whitelist.split(',').any(|d| d.trim() == email_domain)\n+    }\n+\n+    /// Tests whether signup is allowed for an email address, taking into\n+    /// account the signups_allowed and signups_domains_whitelist settings.\n+    pub fn is_signup_allowed(&self, email: &str) -> bool {\n+        if !self.signups_domains_whitelist().is_empty() {\n+            // The whitelist setting overrides the signups_allowed setting.\n+            self.is_email_domain_whitelisted(email)\n+        } else {\n+            self.signups_allowed()\n+        }\n     }\n \n     pub fn delete_user_config(&self) -> Result<(), Error> {\n",
            "comment_added_diff": [
                [
                    268,
                    "        /// Allow new signups |> Controls whether new users can register. Users can be invited by the bitwarden_rs admin even if this is disabled"
                ],
                [
                    276,
                    "        /// Email domain whitelist |> Allow signups only from this list of comma-separated domains, even when signups are otherwise disabled"
                ],
                [
                    278,
                    "        /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are otherwise disabled"
                ],
                [
                    561,
                    "    /// Tests whether an email's domain is in signups_domains_whitelist."
                ],
                [
                    562,
                    "    /// Returns false if no whitelist is set."
                ],
                [
                    575,
                    "    /// Tests whether signup is allowed for an email address, taking into"
                ],
                [
                    576,
                    "    /// account the signups_allowed and signups_domains_whitelist settings."
                ],
                [
                    579,
                    "            // The whitelist setting overrides the signups_allowed setting."
                ]
            ]
        },
        {
            "commit": "0a68de6c24a51e4e221ae5afb43d2cfc6b48dac1",
            "timestamp": "2020-04-09T20:55:08-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Warn on empty `ADMIN_TOKEN` instead of bailing out\n\nThe admin page will still be disabled.\n\nFixes #849.",
            "additions": 9,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -430,7 +430,8 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n     if let Some(ref token) = cfg.admin_token {\n         if token.trim().is_empty() && !cfg.disable_admin_token {\n-            err!(\"`ADMIN_TOKEN` is enabled but has an empty value. To enable the admin page without token, use `DISABLE_ADMIN_TOKEN`\")\n+            println!(\"[WARNING] `ADMIN_TOKEN` is enabled but has an empty value, so the admin page will be disabled.\");\n+            println!(\"[WARNING] To enable the admin page without a token, use `DISABLE_ADMIN_TOKEN`.\");\n         }\n     }\n \n@@ -617,6 +618,13 @@ impl Config {\n         }\n     }\n \n+    /// Tests whether the admin token is set to a non-empty value.\n+    pub fn is_admin_token_set(&self) -> bool {\n+        let token = self.admin_token();\n+\n+        !token.is_none() && !token.unwrap().trim().is_empty()\n+    }\n+\n     pub fn render_template<T: serde::ser::Serialize>(\n         &self,\n         name: &str,\n",
            "comment_added_diff": [
                [
                    621,
                    "    /// Tests whether the admin token is set to a non-empty value."
                ]
            ]
        },
        {
            "commit": "86685c1cd2f8d1d8771bcd97d5dd5aa3c3efd4b9",
            "timestamp": "2020-04-11T14:51:36-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Ensure email domain comparison is case-insensitive",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -566,7 +566,7 @@ impl Config {\n             warn!(\"Failed to parse email address '{}'\", email);\n             return false;\n         }\n-        let email_domain = e[0];\n+        let email_domain = e[0].to_lowercase();\n         let whitelist = self.signups_domains_whitelist();\n \n         !whitelist.is_empty() && whitelist.split(',').any(|d| d.trim() == email_domain)\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -640,7 +640,7 @@ impl Config {\n     pub fn is_admin_token_set(&self) -> bool {\n         let token = self.admin_token();\n \n-        !token.is_none() && !token.unwrap().trim().is_empty()\n+        token.is_some() && !token.unwrap().trim().is_empty()\n     }\n \n     pub fn render_template<T: serde::ser::Serialize>(\n",
            "comment_added_diff": []
        },
        {
            "commit": "632f4d545367b5ab1cefce66bc526e5dc0a786de",
            "timestamp": "2020-05-07T18:02:37-04:00",
            "author": "theycallmesteve",
            "commit_message": "Whitespace fixes",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -135,7 +135,6 @@ macro_rules! make_config {\n                     (inner._env.build(), inner.config.clone())\n                 };\n \n-\n                 fn _get_form_type(rust_type: &str) -> &'static str {\n                     match rust_type {\n                         \"Pass\" => \"password\",\n",
            "comment_added_diff": []
        },
        {
            "commit": "a3149335571d47af810aff3665665f0eb5c9f168",
            "timestamp": "2020-05-24T14:38:19-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Allow email changes for existing accounts even when signups are disabled",
            "additions": 6,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -558,9 +558,10 @@ impl Config {\n         self.update_config(builder)\n     }\n \n-    /// Tests whether an email's domain is in signups_domains_whitelist.\n-    /// Returns false if no whitelist is set.\n-    pub fn is_email_domain_whitelisted(&self, email: &str) -> bool {\n+    /// Tests whether an email's domain is allowed. A domain is allowed if it\n+    /// is in signups_domains_whitelist, or if no whitelist is set (so there\n+    /// are no domain restrictions in effect).\n+    pub fn is_email_domain_allowed(&self, email: &str) -> bool {\n         let e: Vec<&str> = email.rsplitn(2, '@').collect();\n         if e.len() != 2 || e[0].is_empty() || e[1].is_empty() {\n             warn!(\"Failed to parse email address '{}'\", email);\n@@ -569,7 +570,7 @@ impl Config {\n         let email_domain = e[0].to_lowercase();\n         let whitelist = self.signups_domains_whitelist();\n \n-        !whitelist.is_empty() && whitelist.split(',').any(|d| d.trim() == email_domain)\n+        whitelist.is_empty() || whitelist.split(',').any(|d| d.trim() == email_domain)\n     }\n \n     /// Tests whether signup is allowed for an email address, taking into\n@@ -577,7 +578,7 @@ impl Config {\n     pub fn is_signup_allowed(&self, email: &str) -> bool {\n         if !self.signups_domains_whitelist().is_empty() {\n             // The whitelist setting overrides the signups_allowed setting.\n-            self.is_email_domain_whitelisted(email)\n+            self.is_email_domain_allowed(email)\n         } else {\n             self.signups_allowed()\n         }\n",
            "comment_added_diff": [
                [
                    561,
                    "    /// Tests whether an email's domain is allowed. A domain is allowed if it"
                ],
                [
                    562,
                    "    /// is in signups_domains_whitelist, or if no whitelist is set (so there"
                ],
                [
                    563,
                    "    /// are no domain restrictions in effect)."
                ]
            ]
        },
        {
            "commit": "3c66deb5cc7a4387e4176d2a5bdd3f321f09a6bd",
            "timestamp": "2020-05-28T10:46:25+02:00",
            "author": "BlackDex",
            "commit_message": "Redesign of the admin interface.\n\nMain changes:\n - Splitted up settings and users into two separate pages.\n - Added verified shield when the e-mail address has been verified.\n - Added the amount of personal items in the database to the users overview.\n - Added Organizations and Diagnostics pages.\n   - Shows if DNS resolving works.\n   - Shows if there is a posible time drift.\n   - Shows current versions of server and web-vault.\n - Optimized logo-gray.png using optipng\n\nItems which can be added later:\n - Amount of cipher items accessible for a user, not only his personal items.\n - Amount of users per Org\n - Version update check in the diagnostics overview.\n - Copy/Pasteable runtime config which has sensitive data changed or removed for support questions either on the forum or github issues.\n - Option to delete Orgs and all its passwords (when there are no members anymore).\n - Etc....",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -700,7 +700,10 @@ where\n \n     reg!(\"admin/base\");\n     reg!(\"admin/login\");\n-    reg!(\"admin/page\");\n+    reg!(\"admin/settings\");\n+    reg!(\"admin/users\");\n+    reg!(\"admin/organizations\");\n+    reg!(\"admin/diagnostics\");\n \n     // And then load user templates to overwrite the defaults\n     // Use .hbs extension for the files\n",
            "comment_added_diff": []
        },
        {
            "commit": "624791e09a41b6b1489db731256a7d73a880133d",
            "timestamp": "2020-07-04T16:13:27-04:00",
            "author": "Armaan Tobaccowalla",
            "commit_message": "Allow postgres:// DATABASE_URL",
            "additions": 4,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -412,7 +412,9 @@ make_config! {\n \n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     let db_url = cfg.database_url.to_lowercase();\n-    if cfg!(feature = \"sqlite\") && (db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\")) {\n+    if cfg!(feature = \"sqlite\")\n+        && (db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\") || db_url.starts_with(\"postgres:\"))\n+    {\n         err!(\"`DATABASE_URL` is meant for MySQL or Postgres, while this server is meant for SQLite\")\n     }\n \n@@ -420,7 +422,7 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n         err!(\"`DATABASE_URL` should start with mysql: when using the MySQL server\")\n     }\n \n-    if cfg!(feature = \"postgresql\") && !db_url.starts_with(\"postgresql:\") {\n+    if cfg!(feature = \"postgresql\") && !(db_url.starts_with(\"postgresql:\") || db_url.starts_with(\"postgres:\")) {\n         err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "596c9b869185a86d7619024066c80a008102199e",
            "timestamp": "2020-07-05T01:59:15+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add option to set name during HELO in email settings",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -394,7 +394,9 @@ make_config! {\n         /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]\n         smtp_auth_mechanism:    String, true,   option;\n         /// SMTP connection timeout |> Number of seconds when to stop trying to connect to the SMTP server\n-        smtp_timeout:           u64,     true,   def,     15;\n+        smtp_timeout:           u64,    true,   def,     15;\n+        /// Server name sent during HELO |> By default this value should be is on the machine's hostname, but might need to be changed in case it trips some anti-spam filters\n+        helo_name:              String, true,   option;\n     },\n \n     /// Email 2FA Settings\n",
            "comment_added_diff": [
                [
                    398,
                    "        /// Server name sent during HELO |> By default this value should be is on the machine's hostname, but might need to be changed in case it trips some anti-spam filters"
                ]
            ]
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 5,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -1,11 +1,13 @@\n-use once_cell::sync::Lazy;\n use std::process::exit;\n use std::sync::RwLock;\n \n+use once_cell::sync::Lazy;\n use reqwest::Url;\n \n-use crate::error::Error;\n-use crate::util::{get_env, get_env_bool};\n+use crate::{\n+    error::Error,\n+    util::{get_env, get_env_bool},\n+};\n \n static CONFIG_FILE: Lazy<String> = Lazy::new(|| {\n     let data_folder = get_env(\"DATA_FOLDER\").unwrap_or_else(|| String::from(\"data\"));\n",
            "comment_added_diff": []
        },
        {
            "commit": "d348f12a0e7f9a6e4d1193324a0d6446fa943d00",
            "timestamp": "2020-07-22T21:50:49-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add config option for log timestamp format",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -329,6 +329,8 @@ make_config! {\n         reload_templates:       bool,   true,   def,    false;\n         /// Enable extended logging\n         extended_logging:       bool,   false,  def,    true;\n+        /// Log timestamp format\n+        log_timestamp_format:   String, true,   def,    \"%Y-%m-%d %H:%M:%S\".to_string();\n         /// Enable the log to output to Syslog\n         use_syslog:             bool,   false,  def,    false;\n         /// Log file path\n",
            "comment_added_diff": [
                [
                    332,
                    "        /// Log timestamp format"
                ]
            ]
        },
        {
            "commit": "071a3b2a32e1d9cb31b3b2e38442fd33d6512639",
            "timestamp": "2020-07-23T14:19:51-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Log timestamps with milliseconds by default",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -330,7 +330,7 @@ make_config! {\n         /// Enable extended logging\n         extended_logging:       bool,   false,  def,    true;\n         /// Log timestamp format\n-        log_timestamp_format:   String, true,   def,    \"%Y-%m-%d %H:%M:%S\".to_string();\n+        log_timestamp_format:   String, true,   def,    \"%Y-%m-%d %H:%M:%S.%3f\".to_string();\n         /// Enable the log to output to Syslog\n         use_syslog:             bool,   false,  def,    false;\n         /// Log file path\n",
            "comment_added_diff": []
        },
        {
            "commit": "570d6c8bf97d6c554a9f5265c9cc9aa4e8482f24",
            "timestamp": "2020-08-05T22:35:29-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for restricting org creation to certain users",
            "additions": 24,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -115,6 +115,7 @@ macro_rules! make_config {\n                 config.domain_set = _domain_set;\n \n                 config.signups_domains_whitelist = config.signups_domains_whitelist.trim().to_lowercase();\n+                config.org_creation_users = config.org_creation_users.trim().to_lowercase();\n \n                 config\n             }\n@@ -276,6 +277,9 @@ make_config! {\n         signups_verify_resend_limit: u32, true, def,    6;\n         /// Email domain whitelist |> Allow signups only from this list of comma-separated domains, even when signups are otherwise disabled\n         signups_domains_whitelist: String, true, def,   \"\".to_string();\n+        /// Org creation users |> Allow org creation only by this list of comma-separated user emails.\n+        /// Blank or 'all' means all users can create orgs; 'none' means no users can create orgs.\n+        org_creation_users:     String, true,   def,    \"\".to_string();\n         /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are otherwise disabled\n         invitations_allowed:    bool,   true,   def,    true;\n         /// Password iterations |> Number of server-side passwords hashing iterations.\n@@ -442,6 +446,13 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n         err!(\"`SIGNUPS_DOMAINS_WHITELIST` contains empty tokens\");\n     }\n \n+    let org_creation_users = cfg.org_creation_users.trim().to_lowercase();\n+    if !(org_creation_users.is_empty() || org_creation_users == \"all\" || org_creation_users == \"none\") {\n+        if org_creation_users.split(',').any(|u| !u.contains('@')) {\n+            err!(\"`ORG_CREATION_USERS` contains invalid email addresses\");\n+        }\n+    }\n+\n     if let Some(ref token) = cfg.admin_token {\n         if token.trim().is_empty() && !cfg.disable_admin_token {\n             println!(\"[WARNING] `ADMIN_TOKEN` is enabled but has an empty value, so the admin page will be disabled.\");\n@@ -592,6 +603,19 @@ impl Config {\n         }\n     }\n \n+    /// Tests whether the specified user is allowed to create an organization.\n+    pub fn is_org_creation_allowed(&self, email: &str) -> bool {\n+        let users = self.org_creation_users();\n+        if users == \"\" || users == \"all\" {\n+            true\n+        } else if users == \"none\" {\n+            false\n+        } else {\n+            let email = email.to_lowercase();\n+            users.split(',').any(|u| u.trim() == email)\n+        }\n+    }\n+\n     pub fn delete_user_config(&self) -> Result<(), Error> {\n         crate::util::delete_file(&CONFIG_FILE)?;\n \n",
            "comment_added_diff": [
                [
                    280,
                    "        /// Org creation users |> Allow org creation only by this list of comma-separated user emails."
                ],
                [
                    281,
                    "        /// Blank or 'all' means all users can create orgs; 'none' means no users can create orgs."
                ],
                [
                    606,
                    "    /// Tests whether the specified user is allowed to create an organization."
                ]
            ]
        },
        {
            "commit": "c05dc50f53b3beb47f467ff00013754bff8a04b7",
            "timestamp": "2020-08-22T17:35:55-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add more docs on the `email_token_size` setting",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -411,7 +411,7 @@ make_config! {\n     email_2fa: _enable_email_2fa {\n         /// Enabled |> Disabling will prevent users from setting up new email 2FA and using existing email 2FA configured\n         _enable_email_2fa:      bool,   true,   auto,    |c| c._enable_smtp && c.smtp_host.is_some();\n-        /// Token number length |> Length of the numbers in an email token. Minimum of 6. Maximum is 19.\n+        /// Email token size |> Number of digits in an email token (min: 6, max: 19). Note that the Bitwarden clients are hardcoded to mention 6 digit codes regardless of this setting.\n         email_token_size:       u32,    true,   def,      6;\n         /// Token expiration time |> Maximum time in seconds a token is valid. The time the user has to open email client and copy token.\n         email_expiration_time:  u64,    true,   def,      600;\n",
            "comment_added_diff": [
                [
                    414,
                    "        /// Email token size |> Number of digits in an email token (min: 6, max: 19). Note that the Bitwarden clients are hardcoded to mention 6 digit codes regardless of this setting."
                ]
            ]
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 3,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -5,6 +5,7 @@ use once_cell::sync::Lazy;\n use reqwest::Url;\n \n use crate::{\n+    db::DbConnType,\n     error::Error,\n     util::{get_env, get_env_bool},\n };\n@@ -421,20 +422,9 @@ make_config! {\n }\n \n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n-    let db_url = cfg.database_url.to_lowercase();\n-    if cfg!(feature = \"sqlite\")\n-        && (db_url.starts_with(\"mysql:\") || db_url.starts_with(\"postgresql:\") || db_url.starts_with(\"postgres:\"))\n-    {\n-        err!(\"`DATABASE_URL` is meant for MySQL or Postgres, while this server is meant for SQLite\")\n-    }\n \n-    if cfg!(feature = \"mysql\") && !db_url.starts_with(\"mysql:\") {\n-        err!(\"`DATABASE_URL` should start with mysql: when using the MySQL server\")\n-    }\n-\n-    if cfg!(feature = \"postgresql\") && !(db_url.starts_with(\"postgresql:\") || db_url.starts_with(\"postgres:\")) {\n-        err!(\"`DATABASE_URL` should start with postgresql: when using the PostgreSQL server\")\n-    }\n+    // Validate connection URL is valid and DB feature is enabled\n+    DbConnType::from_url(&cfg.database_url)?;\n \n     let dom = cfg.domain.to_lowercase();\n     if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {\n",
            "comment_added_diff": [
                [
                    426,
                    "    // Validate connection URL is valid and DB feature is enabled"
                ]
            ]
        },
        {
            "commit": "c877583979ab0bd76c135b1d88d58298bb9e3680",
            "timestamp": "2020-09-12T21:47:24+02:00",
            "author": "BlackDex",
            "commit_message": "Allow multiple SMTP Auth meganisms.\n\n- Allow all SMTP Auth meganisms supported by Lettre.\n- The config value order is leading and values can be separated by a\n  comma ','\n- Case doesn't matter, and invalid values are ignored.\n- Warning is printed when no valid value is found at all.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -400,7 +400,7 @@ make_config! {\n         smtp_username:          String, true,   option;\n         /// Password\n         smtp_password:          Pass,   true,   option;\n-        /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]\n+        /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]. Multiple options need to be separated by a comma.\n         smtp_auth_mechanism:    String, true,   option;\n         /// SMTP connection timeout |> Number of seconds when to stop trying to connect to the SMTP server\n         smtp_timeout:           u64,    true,   def,     15;\n@@ -428,7 +428,7 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n     let dom = cfg.domain.to_lowercase();\n     if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {\n-        err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\"); \n+        err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\");\n     }\n \n     let whitelist = &cfg.signups_domains_whitelist;\n",
            "comment_added_diff": [
                [
                    403,
                    "        /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]. Multiple options need to be separated by a comma."
                ],
                [
                    431,
                    "        err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\");"
                ]
            ]
        },
        {
            "commit": "f847c6e22519beb3acb03fb1ed02698cd4917e2f",
            "timestamp": "2020-09-19T17:09:58+02:00",
            "author": "BlackDex",
            "commit_message": "Updated the config options descriptions.\n\nMade some small changes to the description of the config options for\nSMTP. Some were a bit cryptic and missing some extra descriptions.\n\nAlso made it more clear which type of secured smtp connection is going\nto used.",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -386,9 +386,9 @@ make_config! {\n         _enable_smtp:           bool,   true,   def,     true;\n         /// Host\n         smtp_host:              String, true,   option;\n-        /// Enable SSL\n+        /// Enable Secure SMTP |> (Explicit) - Enabling this by default would use STARTTLS (Standard ports 587 or 25)\n         smtp_ssl:               bool,   true,   def,     true;\n-        /// Use explicit TLS |> Enabling this would force the use of an explicit TLS connection, instead of upgrading an insecure one with STARTTLS\n+        /// Force TLS |> (Implicit) - Enabling this would force the use of an SSL/TLS connection, instead of upgrading an insecure one with STARTTLS (Standard port 465)\n         smtp_explicit_tls:      bool,   true,   def,     false;\n         /// Port\n         smtp_port:              u16,    true,   auto,    |c| if c.smtp_explicit_tls {465} else if c.smtp_ssl {587} else {25};\n@@ -400,7 +400,7 @@ make_config! {\n         smtp_username:          String, true,   option;\n         /// Password\n         smtp_password:          Pass,   true,   option;\n-        /// Json form auth mechanism |> Defaults for ssl is \"Plain\" and \"Login\" and nothing for non-ssl connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]. Multiple options need to be separated by a comma.\n+        /// SMTP Auth mechanism |> Defaults for SSL is \"Plain\" and \"Login\" and nothing for Non-SSL connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]. Multiple options need to be separated by a comma ','.\n         smtp_auth_mechanism:    String, true,   option;\n         /// SMTP connection timeout |> Number of seconds when to stop trying to connect to the SMTP server\n         smtp_timeout:           u64,    true,   def,     15;\n",
            "comment_added_diff": [
                [
                    389,
                    "        /// Enable Secure SMTP |> (Explicit) - Enabling this by default would use STARTTLS (Standard ports 587 or 25)"
                ],
                [
                    391,
                    "        /// Force TLS |> (Implicit) - Enabling this would force the use of an SSL/TLS connection, instead of upgrading an insecure one with STARTTLS (Standard port 465)"
                ],
                [
                    403,
                    "        /// SMTP Auth mechanism |> Defaults for SSL is \"Plain\" and \"Login\" and nothing for Non-SSL connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]. Multiple options need to be separated by a comma ','."
                ]
            ]
        },
        {
            "commit": "729c9cff41cc74055f8397fae7f60084dcf4b71b",
            "timestamp": "2020-10-03T22:32:00+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Retry initial db connection, with adjustable option",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -347,6 +347,9 @@ make_config! {\n         /// that do not support WAL. Please make sure you read project wiki on the topic before changing this setting.\n         enable_db_wal:          bool,   false,  def,    true;\n \n+        /// Max database connection retries |> Number of times to retry the database connection during startup, with 1 second between each retry, set to 0 to retry indefinitely\n+        db_connection_retries:  u32,    false,  def,    15;\n+\n         /// Bypass admin page security (Know the risks!) |> Disables the Admin Token for the admin page so you may use your own auth in-front\n         disable_admin_token:    bool,   true,   def,    false;\n \n",
            "comment_added_diff": [
                [
                    350,
                    "        /// Max database connection retries |> Number of times to retry the database connection during startup, with 1 second between each retry, set to 0 to retry indefinitely"
                ]
            ]
        },
        {
            "commit": "b9daa59e5d05f1050e6ba4199352953493a57dfb",
            "timestamp": "2020-10-09T10:29:02+02:00",
            "author": "Rob Watson",
            "commit_message": "Add DATABASE_MAX_CONNS config setting",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -222,6 +222,8 @@ make_config! {\n         data_folder:            String, false,  def,    \"data\".to_string();\n         /// Database URL\n         database_url:           String, false,  auto,   |c| format!(\"{}/{}\", c.data_folder, \"db.sqlite3\");\n+        /// Database connection pool size\n+        database_max_conns:     u32,    false,  def,    10;\n         /// Icon cache folder\n         icon_cache_folder:      String, false,  auto,   |c| format!(\"{}/{}\", c.data_folder, \"icon_cache\");\n         /// Attachments folder\n@@ -429,6 +431,14 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     // Validate connection URL is valid and DB feature is enabled\n     DbConnType::from_url(&cfg.database_url)?;\n \n+    let limit = 256;\n+    if cfg.database_max_conns < 1 || cfg.database_max_conns > limit {\n+        err!(format!(\n+            \"`DATABASE_MAX_CONNS` contains an invalid value. Ensure it is between 1 and {}.\",\n+            limit,\n+        ));\n+    }\n+\n     let dom = cfg.domain.to_lowercase();\n     if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {\n         err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\");\n",
            "comment_added_diff": [
                [
                    225,
                    "        /// Database connection pool size"
                ]
            ]
        },
        {
            "commit": "d11d663c5c7ff12d1eb737c9e073d50f5c3f5a53",
            "timestamp": "2020-11-12T13:40:26+01:00",
            "author": "BlackDex",
            "commit_message": "Added error handling during dotenv loading\n\nSome issue people report are because of misconfiguration or bad .env\nfiles. To mittigate this i added error handling for this.\n\n- Panic/Quit on a LineParse error, which indicates bad .env file format.\n- Emits a info message when there is no .env file found.\n- Emits a warning message when there is a .env file, but not no\n  permissions.\n- Emits a warning on every other message not specifically catched.",
            "additions": 26,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -53,7 +53,32 @@ macro_rules! make_config {\n \n         impl ConfigBuilder {\n             fn from_env() -> Self {\n-                dotenv::from_path(\".env\").ok();\n+                match dotenv::from_path(\".env\") {\n+                    Ok(_) => (),\n+                    Err(e) => match e {\n+                        dotenv::Error::LineParse(msg, pos) => {\n+                            panic!(\"Error loading the .env file:\\nNear {:?} on position {}\\nPlease fix and restart!\\n\", msg, pos);\n+                        },\n+                        dotenv::Error::Io(ioerr) => match ioerr.kind() {\n+                            std::io::ErrorKind::NotFound => {\n+                                println!(\"[INFO] No .env file found.\\n\");\n+                                ()\n+                            },\n+                            std::io::ErrorKind::PermissionDenied => {\n+                                println!(\"[WARNING] Permission Denied while trying to read the .env file!\\n\");\n+                                ()\n+                            },\n+                            _ => {\n+                                println!(\"[WARNING] Reading the .env file failed:\\n{:?}\\n\", ioerr);\n+                                ()\n+                            }\n+                        },\n+                        _ => {\n+                            println!(\"[WARNING] Reading the .env file failed:\\n{:?}\\n\", e);\n+                            ()\n+                        }\n+                    }\n+                };\n \n                 let mut builder = ConfigBuilder::default();\n                 $($(\n",
            "comment_added_diff": []
        },
        {
            "commit": "6faaeaae6649ddfa9a1b4b424a27e6792b1f90b3",
            "timestamp": "2020-11-18T12:07:08+01:00",
            "author": "BlackDex",
            "commit_message": "Updated email processing.\n\n- Added an option to enable smtp debugging via SMTP_DEBUG. This will\n  trigger a trace of the smtp commands sent/received to/from the mail\nserver. Useful when troubleshooting.\n- Added two options to ignore invalid certificates which either do not\n  match at all, or only doesn't match the hostname.\n- Updated lettre to the latest alpha.4 version.",
            "additions": 18,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -413,29 +413,35 @@ make_config! {\n     /// SMTP Email Settings\n     smtp: _enable_smtp {\n         /// Enabled\n-        _enable_smtp:           bool,   true,   def,     true;\n+        _enable_smtp:                  bool,   true,   def,     true;\n         /// Host\n-        smtp_host:              String, true,   option;\n+        smtp_host:                     String, true,   option;\n         /// Enable Secure SMTP |> (Explicit) - Enabling this by default would use STARTTLS (Standard ports 587 or 25)\n-        smtp_ssl:               bool,   true,   def,     true;\n+        smtp_ssl:                      bool,   true,   def,     true;\n         /// Force TLS |> (Implicit) - Enabling this would force the use of an SSL/TLS connection, instead of upgrading an insecure one with STARTTLS (Standard port 465)\n-        smtp_explicit_tls:      bool,   true,   def,     false;\n+        smtp_explicit_tls:             bool,   true,   def,     false;\n         /// Port\n-        smtp_port:              u16,    true,   auto,    |c| if c.smtp_explicit_tls {465} else if c.smtp_ssl {587} else {25};\n+        smtp_port:                     u16,    true,   auto,    |c| if c.smtp_explicit_tls {465} else if c.smtp_ssl {587} else {25};\n         /// From Address\n-        smtp_from:              String, true,   def,     String::new();\n+        smtp_from:                     String, true,   def,     String::new();\n         /// From Name\n-        smtp_from_name:         String, true,   def,     \"Bitwarden_RS\".to_string();\n+        smtp_from_name:                String, true,   def,     \"Bitwarden_RS\".to_string();\n         /// Username\n-        smtp_username:          String, true,   option;\n+        smtp_username:                 String, true,   option;\n         /// Password\n-        smtp_password:          Pass,   true,   option;\n+        smtp_password:                 Pass,   true,   option;\n         /// SMTP Auth mechanism |> Defaults for SSL is \"Plain\" and \"Login\" and nothing for Non-SSL connections. Possible values: [\"Plain\", \"Login\", \"Xoauth2\"]. Multiple options need to be separated by a comma ','.\n-        smtp_auth_mechanism:    String, true,   option;\n+        smtp_auth_mechanism:           String, true,   option;\n         /// SMTP connection timeout |> Number of seconds when to stop trying to connect to the SMTP server\n-        smtp_timeout:           u64,    true,   def,     15;\n+        smtp_timeout:                  u64,    true,   def,     15;\n         /// Server name sent during HELO |> By default this value should be is on the machine's hostname, but might need to be changed in case it trips some anti-spam filters\n-        helo_name:              String, true,   option;\n+        helo_name:                     String, true,   option;\n+        /// Enable SMTP debugging (Know the risks!) |> DANGEROUS: Enabling this will output very detailed SMTP messages. This could contain sensitive information like passwords and usernames! Only enable this during troubleshooting!\n+        smtp_debug:                    bool,   true,   def,     false;\n+        /// Accept Invalid Certs (Know the risks!) |> DANGEROUS: Allow invalid certificates. This option introduces significant vulnerabilities to man-in-the-middle attacks!\n+        smtp_accept_invalid_certs:     bool,   true,   def,     false;\n+        /// Accept Invalid Hostnames (Know the risks!) |> DANGEROUS: Allow invalid hostnames. This option introduces significant vulnerabilities to man-in-the-middle attacks!\n+        smtp_accept_invalid_hostnames: bool,   true,   def,     false;\n     },\n \n     /// Email 2FA Settings\n",
            "comment_added_diff": [
                [
                    439,
                    "        /// Enable SMTP debugging (Know the risks!) |> DANGEROUS: Enabling this will output very detailed SMTP messages. This could contain sensitive information like passwords and usernames! Only enable this during troubleshooting!"
                ],
                [
                    441,
                    "        /// Accept Invalid Certs (Know the risks!) |> DANGEROUS: Allow invalid certificates. This option introduces significant vulnerabilities to man-in-the-middle attacks!"
                ],
                [
                    443,
                    "        /// Accept Invalid Hostnames (Know the risks!) |> DANGEROUS: Allow invalid hostnames. This option introduces significant vulnerabilities to man-in-the-middle attacks!"
                ]
            ]
        },
        {
            "commit": "48baf723a422f0a4964807b12b002a589799d6ee",
            "timestamp": "2020-12-08T17:34:18+01:00",
            "author": "BlackDex",
            "commit_message": "Updated icon downloading\n\n- Added more checks to prevent panics (Removed unwrap)\n- Try do download from base domain or add www when the provided domain\n  fails\n- Added some more domain validation checks to prevent errors\n- Added the ICON_BLACKLIST_REGEX to a Lazy Static HashMap which\n  speeds-up the checks!\n- Validate the Regex before starting/config change.\n- Some cleanups\n- Disabled some noisy debugging from 2 crates.",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -527,6 +527,16 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n         }\n     }\n \n+    // Check if the icon blacklist regex is valid\n+    if let Some(ref r) = cfg.icon_blacklist_regex {\n+        use regex::Regex;\n+        let validate_regex = Regex::new(&r);\n+        match validate_regex {\n+            Ok(_) => (),\n+            Err(e) => err!(format!(\"`ICON_BLACKLIST_REGEX` is invalid: {:#?}\", e)),\n+        }\n+    }\n+\n     Ok(())\n }\n \n",
            "comment_added_diff": [
                [
                    530,
                    "    // Check if the icon blacklist regex is valid"
                ]
            ]
        },
        {
            "commit": "235ff447367ec37adcef52921350271b3c5b9378",
            "timestamp": "2021-01-19T17:55:21+01:00",
            "author": "BlackDex",
            "commit_message": "Updated the admin interface\n\nMostly updated the admin interface, also some small other items.\n\n- Added more diagnostic information to (hopefully) decrease issue\n  reporting, or at least solve them quicker.\n- Added an option to generate a support string which can be used to\n  copy/paste on the forum or during the creation of an issue. It will\ntry to hide the sensitive information automatically.\n- Changed the `Created At` and `Last Active` info to be in a column and\n  able to sort them in the users overview.\n- Some small layout changes.\n- Updated javascript and css files to the latest versions available.\n- Decreased the png file sizes using `oxipng`\n- Updated target='_blank' links to have rel='noreferrer' to prevent\n  javascript window.opener modifications.",
            "additions": 64,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -2,6 +2,7 @@ use std::process::exit;\n use std::sync::RwLock;\n \n use once_cell::sync::Lazy;\n+use regex::Regex;\n use reqwest::Url;\n \n use crate::{\n@@ -22,6 +23,21 @@ pub static CONFIG: Lazy<Config> = Lazy::new(|| {\n     })\n });\n \n+static PRIVACY_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"[\\w]\").unwrap());\n+const PRIVACY_CONFIG: &[&str] = &[\n+    \"allowed_iframe_ancestors\",\n+    \"database_url\",\n+    \"domain_origin\",\n+    \"domain_path\",\n+    \"domain\",\n+    \"helo_name\",\n+    \"org_creation_users\",\n+    \"signups_domains_whitelist\",\n+    \"smtp_from\",\n+    \"smtp_host\",\n+    \"smtp_username\",\n+];\n+\n pub type Pass = String;\n \n macro_rules! make_config {\n@@ -52,6 +68,7 @@ macro_rules! make_config {\n         }\n \n         impl ConfigBuilder {\n+            #[allow(clippy::field_reassign_with_default)]\n             fn from_env() -> Self {\n                 match dotenv::from_path(\".env\") {\n                     Ok(_) => (),\n@@ -196,8 +213,37 @@ macro_rules! make_config {\n                     }, )+\n                     ]}, )+ ])\n             }\n+\n+            pub fn get_support_json(&self) -> serde_json::Value {\n+                let cfg = {\n+                    let inner = &self.inner.read().unwrap();\n+                    inner.config.clone()\n+                };\n+\n+                json!({ $($(\n+                    stringify!($name): make_config!{ @supportstr $name, cfg.$name, $ty, $none_action },\n+                )+)+ })\n+            }\n+        }\n+    };\n+\n+    // Support string print\n+    ( @supportstr $name:ident, $value:expr, Pass, option ) => { $value.as_ref().map(|_| String::from(\"***\")) }; // Optional pass, we map to an Option<String> with \"***\"\n+    ( @supportstr $name:ident, $value:expr, Pass, $none_action:ident ) => { String::from(\"***\") }; // Required pass, we return \"***\"\n+    ( @supportstr $name:ident, $value:expr, $ty:ty, option ) => { // Optional other value, we return as is or convert to string to apply the privacy config\n+        if PRIVACY_CONFIG.contains(&stringify!($name)) {\n+            json!($value.as_ref().map(|x| PRIVACY_REGEX.replace_all(&x.to_string(), \"${1}*\").to_string()))\n+        } else {\n+            json!($value)\n         }\n     };\n+    ( @supportstr $name:ident, $value:expr, $ty:ty, $none_action:ident ) => { // Required other value, we return as is or convert to string to apply the privacy config\n+        if PRIVACY_CONFIG.contains(&stringify!($name)) {\n+             json!(PRIVACY_REGEX.replace_all(&$value.to_string(), \"${1}*\").to_string())\n+         } else {\n+             json!($value)\n+         }\n+    };\n \n     // Group or empty string\n     ( @show ) => { \"\" };\n@@ -458,7 +504,6 @@ make_config! {\n }\n \n fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n-\n     // Validate connection URL is valid and DB feature is enabled\n     DbConnType::from_url(&cfg.database_url)?;\n \n@@ -472,7 +517,9 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n     let dom = cfg.domain.to_lowercase();\n     if !dom.starts_with(\"http://\") && !dom.starts_with(\"https://\") {\n-        err!(\"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\");\n+        err!(\n+            \"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\"\n+        );\n     }\n \n     let whitelist = &cfg.signups_domains_whitelist;\n@@ -481,10 +528,10 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n     }\n \n     let org_creation_users = cfg.org_creation_users.trim().to_lowercase();\n-    if !(org_creation_users.is_empty() || org_creation_users == \"all\" || org_creation_users == \"none\") {\n-        if org_creation_users.split(',').any(|u| !u.contains('@')) {\n-            err!(\"`ORG_CREATION_USERS` contains invalid email addresses\");\n-        }\n+    if !(org_creation_users.is_empty() || org_creation_users == \"all\" || org_creation_users == \"none\")\n+        && org_creation_users.split(',').any(|u| !u.contains('@'))\n+    {\n+        err!(\"`ORG_CREATION_USERS` contains invalid email addresses\");\n     }\n \n     if let Some(ref token) = cfg.admin_token {\n@@ -529,7 +576,6 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n     // Check if the icon blacklist regex is valid\n     if let Some(ref r) = cfg.icon_blacklist_regex {\n-        use regex::Regex;\n         let validate_regex = Regex::new(&r);\n         match validate_regex {\n             Ok(_) => (),\n@@ -577,7 +623,12 @@ impl Config {\n         validate_config(&config)?;\n \n         Ok(Config {\n-            inner: RwLock::new(Inner { templates: load_templates(&config.templates_folder), config, _env, _usr }),\n+            inner: RwLock::new(Inner {\n+                templates: load_templates(&config.templates_folder),\n+                config,\n+                _env,\n+                _usr,\n+            }),\n         })\n     }\n \n@@ -650,7 +701,7 @@ impl Config {\n     /// Tests whether the specified user is allowed to create an organization.\n     pub fn is_org_creation_allowed(&self, email: &str) -> bool {\n         let users = self.org_creation_users();\n-        if users == \"\" || users == \"all\" {\n+        if users.is_empty() || users == \"all\" {\n             true\n         } else if users == \"none\" {\n             false\n@@ -704,8 +755,10 @@ impl Config {\n             let akey_s = data_encoding::BASE64.encode(&akey);\n \n             // Save the new value\n-            let mut builder = ConfigBuilder::default();\n-            builder._duo_akey = Some(akey_s.clone());\n+            let builder = ConfigBuilder {\n+                _duo_akey: Some(akey_s.clone()),\n+                ..Default::default()\n+            };\n             self.update_config_partial(builder).ok();\n \n             akey_s\n",
            "comment_added_diff": [
                [
                    230,
                    "    // Support string print"
                ],
                [
                    231,
                    "    ( @supportstr $name:ident, $value:expr, Pass, option ) => { $value.as_ref().map(|_| String::from(\"***\")) }; // Optional pass, we map to an Option<String> with \"***\""
                ],
                [
                    232,
                    "    ( @supportstr $name:ident, $value:expr, Pass, $none_action:ident ) => { String::from(\"***\") }; // Required pass, we return \"***\""
                ],
                [
                    233,
                    "    ( @supportstr $name:ident, $value:expr, $ty:ty, option ) => { // Optional other value, we return as is or convert to string to apply the privacy config"
                ],
                [
                    240,
                    "    ( @supportstr $name:ident, $value:expr, $ty:ty, $none_action:ident ) => { // Required other value, we return as is or convert to string to apply the privacy config"
                ],
                [
                    521,
                    "            \"DOMAIN variable needs to contain the protocol (http, https). Use 'http[s]://bw.example.com' instead of 'bw.example.com'\""
                ]
            ]
        },
        {
            "commit": "58606796246110b8d49deb69e7d2ec352041bd94",
            "timestamp": "2021-01-31T20:07:42+01:00",
            "author": "BlackDex",
            "commit_message": "Updated dependencies and small mail fixes\n\n- Updated rust nightly\n- Updated depenencies\n- Removed unicode support for regex (less dependencies)\n- Fixed dependency and nightly changes/deprications\n- Some mail changes for less spam point triggering",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -557,6 +557,10 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n             err!(\"Both `SMTP_HOST` and `SMTP_FROM` need to be set for email support\")\n         }\n \n+        if !cfg.smtp_from.contains('@') {\n+            err!(\"SMTP_FROM does not contain a mandatory @ sign\")\n+        }\n+\n         if cfg.smtp_username.is_some() != cfg.smtp_password.is_some() {\n             err!(\"Both `SMTP_USERNAME` and `SMTP_PASSWORD` need to be set to enable email authentication\")\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "705d840ea3271738db43e096a1c45d1c9a694d6f",
            "timestamp": "2021-02-03T18:43:54+01:00",
            "author": "BlackDex",
            "commit_message": "Extra features for admin interface.\n\n- Able to modify the user type per organization\n- Able to remove a whole organization\n- Added podman detection\n- Only show web-vault update when not running a containerized\n  bitwarden_rs\n\nSolves #936",
            "additions": 9,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -872,14 +872,20 @@ fn js_escape_helper<'reg, 'rc>(\n         .param(0)\n         .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n \n+    let no_quote = h\n+        .param(1)\n+        .is_some();\n+\n     let value = param\n         .value()\n         .as_str()\n         .ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n \n-    let escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n-    let quoted_value = format!(\"&quot;{}&quot;\", escaped_value);\n+    let mut escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n+    if ! no_quote {\n+        escaped_value = format!(\"&quot;{}&quot;\", escaped_value);\n+    }\n \n-    out.write(&quoted_value)?;\n+    out.write(&escaped_value)?;\n     Ok(())\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "e794b397d386a778d7d5c4ab25bf0965206434fd",
            "timestamp": "2021-02-03T23:47:48+01:00",
            "author": "BlackDex",
            "commit_message": "Fixed small buggy in validation",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -557,7 +557,7 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n             err!(\"Both `SMTP_HOST` and `SMTP_FROM` need to be set for email support\")\n         }\n \n-        if !cfg.smtp_from.contains('@') {\n+        if cfg.smtp_host.is_some() && !cfg.smtp_from.contains('@') {\n             err!(\"SMTP_FROM does not contain a mandatory @ sign\")\n         }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -299,6 +299,8 @@ make_config! {\n         icon_cache_folder:      String, false,  auto,   |c| format!(\"{}/{}\", c.data_folder, \"icon_cache\");\n         /// Attachments folder\n         attachments_folder:     String, false,  auto,   |c| format!(\"{}/{}\", c.data_folder, \"attachments\");\n+        /// Sends folder\n+        sends_folder:           String, false,  auto,   |c| format!(\"{}/{}\", c.data_folder, \"sends\");\n         /// Templates folder\n         templates_folder:       String, false,  auto,   |c| format!(\"{}/{}\", c.data_folder, \"templates\");\n         /// Session JWT key\n",
            "comment_added_diff": [
                [
                    302,
                    "        /// Sends folder"
                ]
            ]
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 2,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -878,9 +878,7 @@ fn js_escape_helper<'reg, 'rc>(\n         .param(0)\n         .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n \n-    let no_quote = h\n-        .param(1)\n-        .is_some();\n+    let no_quote = h.param(1).is_some();\n \n     let value = param\n         .value()\n@@ -888,7 +886,7 @@ fn js_escape_helper<'reg, 'rc>(\n         .ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n \n     let mut escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n-    if ! no_quote {\n+    if !no_quote {\n         escaped_value = format!(\"&quot;{}&quot;\", escaped_value);\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "73ff8d79f70b36483d1d33587cdc9549c8e472bd",
            "timestamp": "2021-04-05T23:07:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add a generic job scheduler\n\nAlso rewrite deletion of old sends using the job scheduler.",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -316,6 +316,14 @@ make_config! {\n         /// Websocket port\n         websocket_port:         u16,    false,  def,    3012;\n     },\n+    jobs {\n+        /// Job scheduler poll interval |> How often the job scheduler thread checks for jobs to run.\n+        /// Set to 0 to globally disable scheduled jobs.\n+        job_poll_interval_ms:   u64,    false,  def,    30_000;\n+        /// Send purge schedule |> Cron schedule of the job that checks for Sends past their deletion date.\n+        /// Defaults to hourly. Set blank to disable this job.\n+        send_purge_schedule:    String, false,  def,    \"0 0 * * * *\".to_string();\n+    },\n \n     /// General settings\n     settings {\n",
            "comment_added_diff": [
                [
                    320,
                    "        /// Job scheduler poll interval |> How often the job scheduler thread checks for jobs to run."
                ],
                [
                    321,
                    "        /// Set to 0 to globally disable scheduled jobs."
                ],
                [
                    323,
                    "        /// Send purge schedule |> Cron schedule of the job that checks for Sends past their deletion date."
                ],
                [
                    324,
                    "        /// Defaults to hourly. Set blank to disable this job."
                ]
            ]
        },
        {
            "commit": "d77333576b1268cd24f17348ffe6d72e07855f54",
            "timestamp": "2021-04-05T23:07:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for auto-deleting trashed items\n\nUpstream will soon auto-delete trashed items after 30 days, but some people\nuse the trash as an archive folder, so to avoid unexpected data loss, this\nimplementation requires the user to explicitly enable auto-deletion.",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -323,6 +323,9 @@ make_config! {\n         /// Send purge schedule |> Cron schedule of the job that checks for Sends past their deletion date.\n         /// Defaults to hourly. Set blank to disable this job.\n         send_purge_schedule:    String, false,  def,    \"0 0 * * * *\".to_string();\n+        /// Trash purge schedule |> Cron schedule of the job that checks for trashed items to delete permanently.\n+        /// Defaults to daily. Set blank to disable this job.\n+        trash_purge_schedule:   String, false,  def,    \"0 0 0 * * *\".to_string();\n     },\n \n     /// General settings\n@@ -347,6 +350,11 @@ make_config! {\n         /// Per-organization attachment limit (KB) |> Limit in kilobytes for an organization attachments, once the limit is exceeded it won't be possible to upload more\n         org_attachment_limit:   i64,    true,   option;\n \n+        /// Trash auto-delete days |> Number of days to wait before auto-deleting a trashed item.\n+        /// If unset, trashed items are not auto-deleted. This setting applies globally, so make\n+        /// sure to inform all users of any changes to this setting.\n+        trash_auto_delete_days: i64,    true,   option;\n+\n         /// Disable icon downloads |> Set to true to disable icon downloading, this would still serve icons from\n         /// $ICON_CACHE_FOLDER, but it won't produce any external network request. Needs to set $ICON_CACHE_TTL to 0,\n         /// otherwise it will delete them and they won't be downloaded again.\n",
            "comment_added_diff": [
                [
                    326,
                    "        /// Trash purge schedule |> Cron schedule of the job that checks for trashed items to delete permanently."
                ],
                [
                    327,
                    "        /// Defaults to daily. Set blank to disable this job."
                ],
                [
                    353,
                    "        /// Trash auto-delete days |> Number of days to wait before auto-deleting a trashed item."
                ],
                [
                    354,
                    "        /// If unset, trashed items are not auto-deleted. This setting applies globally, so make"
                ],
                [
                    355,
                    "        /// sure to inform all users of any changes to this setting."
                ]
            ]
        },
        {
            "commit": "90e0b7fec6cc025561f9f732fb06d15f72e5c892",
            "timestamp": "2021-04-05T23:20:08-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Offset scheduled jobs by 5 minutes\n\nThis is intended to avoid contention with database backups that many users\nprobably schedule to start at exactly the top of an hour.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -322,10 +322,10 @@ make_config! {\n         job_poll_interval_ms:   u64,    false,  def,    30_000;\n         /// Send purge schedule |> Cron schedule of the job that checks for Sends past their deletion date.\n         /// Defaults to hourly. Set blank to disable this job.\n-        send_purge_schedule:    String, false,  def,    \"0 0 * * * *\".to_string();\n+        send_purge_schedule:    String, false,  def,    \"0 5 * * * *\".to_string();\n         /// Trash purge schedule |> Cron schedule of the job that checks for trashed items to delete permanently.\n         /// Defaults to daily. Set blank to disable this job.\n-        trash_purge_schedule:   String, false,  def,    \"0 0 0 * * *\".to_string();\n+        trash_purge_schedule:   String, false,  def,    \"0 5 0 * * *\".to_string();\n     },\n \n     /// General settings\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 5,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -511,10 +511,7 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n     let limit = 256;\n     if cfg.database_max_conns < 1 || cfg.database_max_conns > limit {\n-        err!(format!(\n-            \"`DATABASE_MAX_CONNS` contains an invalid value. Ensure it is between 1 and {}.\",\n-            limit,\n-        ));\n+        err!(format!(\"`DATABASE_MAX_CONNS` contains an invalid value. Ensure it is between 1 and {}.\", limit,));\n     }\n \n     let dom = cfg.domain.to_lowercase();\n@@ -855,9 +852,7 @@ fn case_helper<'reg, 'rc>(\n     rc: &mut RenderContext<'reg, 'rc>,\n     out: &mut dyn Output,\n ) -> HelperResult {\n-    let param = h\n-        .param(0)\n-        .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"case\\\"\"))?;\n+    let param = h.param(0).ok_or_else(|| RenderError::new(\"Param not found for helper \\\"case\\\"\"))?;\n     let value = param.value().clone();\n \n     if h.params().iter().skip(1).any(|x| x.value() == &value) {\n@@ -874,16 +869,12 @@ fn js_escape_helper<'reg, 'rc>(\n     _rc: &mut RenderContext<'reg, 'rc>,\n     out: &mut dyn Output,\n ) -> HelperResult {\n-    let param = h\n-        .param(0)\n-        .ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n+    let param = h.param(0).ok_or_else(|| RenderError::new(\"Param not found for helper \\\"js_escape\\\"\"))?;\n \n     let no_quote = h.param(1).is_some();\n \n-    let value = param\n-        .value()\n-        .as_str()\n-        .ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n+    let value =\n+        param.value().as_str().ok_or_else(|| RenderError::new(\"Param for helper \\\"js_escape\\\" is not a String\"))?;\n \n     let mut escaped_value = value.replace('\\\\', \"\").replace('\\'', \"\\\\x22\").replace('\\\"', \"\\\\x27\");\n     if !no_quote {\n",
            "comment_added_diff": []
        },
        {
            "commit": "d75a80bd2dbe21e5a1eb2b0a6b18a9422441e071",
            "timestamp": "2021-04-11T22:57:17-04:00",
            "author": "Olivier Martin",
            "commit_message": "Resolves dani-garcia/bitwarden_rs#981\n* a user without 2fa trying to join a 2fa org will fail, but user gets an email to enable 2fa\n* a user disabling 2fa will be removed from 2fa orgs; user gets an email for each org\n* an org enabling 2fa policy will remove users without 2fa; users get an email",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -842,6 +842,7 @@ where\n     reg!(\"email/new_device_logged_in\", \".html\");\n     reg!(\"email/pw_hint_none\", \".html\");\n     reg!(\"email/pw_hint_some\", \".html\");\n+    reg!(\"email/send_2fa_removed_from_org\", \".html\");\n     reg!(\"email/send_org_invite\", \".html\");\n     reg!(\"email/twofactor_email\", \".html\");\n     reg!(\"email/verify_email\", \".html\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -359,7 +359,7 @@ make_config! {\n         /// $ICON_CACHE_FOLDER, but it won't produce any external network request. Needs to set $ICON_CACHE_TTL to 0,\n         /// otherwise it will delete them and they won't be downloaded again.\n         disable_icon_download:  bool,   true,   def,    false;\n-        /// Allow new signups |> Controls whether new users can register. Users can be invited by the bitwarden_rs admin even if this is disabled\n+        /// Allow new signups |> Controls whether new users can register. Users can be invited by the vaultwarden admin even if this is disabled\n         signups_allowed:        bool,   true,   def,    true;\n         /// Require email verification on signups. This will prevent logins from succeeding until the address has been verified\n         signups_verify:         bool,   true,   def,    false;\n@@ -385,7 +385,7 @@ make_config! {\n         admin_token:            Pass,   true,   option;\n \n         /// Invitation organization name |> Name shown in the invitation emails that don't come from a specific organization\n-        invitation_org_name:    String, true,   def,    \"Bitwarden_RS\".to_string();\n+        invitation_org_name:    String, true,   def,    \"Vaultwarden\".to_string();\n     },\n \n     /// Advanced settings\n@@ -434,7 +434,7 @@ make_config! {\n         /// Log level\n         log_level:              String, false,  def,    \"Info\".to_string();\n \n-        /// Enable DB WAL |> Turning this off might lead to worse performance, but might help if using bitwarden_rs on some exotic filesystems,\n+        /// Enable DB WAL |> Turning this off might lead to worse performance, but might help if using vaultwarden on some exotic filesystems,\n         /// that do not support WAL. Please make sure you read project wiki on the topic before changing this setting.\n         enable_db_wal:          bool,   false,  def,    true;\n \n@@ -489,7 +489,7 @@ make_config! {\n         /// From Address\n         smtp_from:                     String, true,   def,     String::new();\n         /// From Name\n-        smtp_from_name:                String, true,   def,     \"Bitwarden_RS\".to_string();\n+        smtp_from_name:                String, true,   def,     \"Vaultwarden\".to_string();\n         /// Username\n         smtp_username:                 String, true,   option;\n         /// Password\n",
            "comment_added_diff": [
                [
                    362,
                    "        /// Allow new signups |> Controls whether new users can register. Users can be invited by the vaultwarden admin even if this is disabled"
                ],
                [
                    437,
                    "        /// Enable DB WAL |> Turning this off might lead to worse performance, but might help if using vaultwarden on some exotic filesystems,"
                ]
            ]
        },
        {
            "commit": "7cb19ef767142b773ab44a457940844589432a74",
            "timestamp": "2021-05-08T17:46:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated branding, email and crates\n\n- Updated branding for admin and emails\n- Updated crates and some deprications\n- Removed newline-converter because this is built-in into lettre\n- Updated email templates to use a shared header and footer template\n- Also trigger SMTP SSL When TLS is selected without SSL\n  Resolves #1641",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -832,6 +832,10 @@ where\n     }\n \n     // First register default templates here\n+    reg!(\"email/email_header\");\n+    reg!(\"email/email_footer\");\n+    reg!(\"email/email_footer_text\");\n+\n     reg!(\"email/change_email\", \".html\");\n     reg!(\"email/delete_account\", \".html\");\n     reg!(\"email/invite_accepted\", \".html\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ff8014adda15c8d37c30556044b0e96f067da47",
            "timestamp": "2021-05-11T20:07:32-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add `sends_allowed` config setting\n\nThis provides global control over whether users can create Bitwarden Sends.",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -342,6 +342,10 @@ make_config! {\n         /// Enable web vault\n         web_vault_enabled:      bool,   false,  def,    true;\n \n+        /// Allow Sends |> Controls whether users are allowed to create Bitwarden Sends.\n+        /// This setting applies globally to all users. To control this on a per-org basis instead, use the \"Disable Send\" org policy.\n+        sends_allowed:          bool,   true,   def,    true;\n+\n         /// HIBP Api Key |> HaveIBeenPwned API Key, request it here: https://haveibeenpwned.com/API/Key\n         hibp_api_key:           Pass,   true,   option;\n \n",
            "comment_added_diff": [
                [
                    345,
                    "        /// Allow Sends |> Controls whether users are allowed to create Bitwarden Sends."
                ],
                [
                    346,
                    "        /// This setting applies globally to all users. To control this on a per-org basis instead, use the \"Disable Send\" org policy."
                ]
            ]
        },
        {
            "commit": "8615736e84f802833d0581b1d7f58e7daddc6340",
            "timestamp": "2021-06-19T19:22:19+02:00",
            "author": "BlackDex",
            "commit_message": "Multiple Admin Interface fixes and some others.\n\nMisc:\n- Fixed hadolint workflow, new git cli needs some extra arguments.\n- Add ignore paths to all specific on triggers.\n- Updated hadolint version.\n- Made SMTP_DEBUG read-only, since it can't be changed at runtime.\n\nAdmin:\n- Migrated from Bootstrap v4 to v5\n- Updated jquery to v3.6.0\n- Updated Datatables\n- Made Javascript strict\n- Added a way to show which ENV Vars are overridden.\n- Changed the way to provide data for handlebars.\n- Fixed date/time check.\n- Made support string use details and summary feature of markdown/github.",
            "additions": 25,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -57,6 +57,8 @@ macro_rules! make_config {\n \n             _env: ConfigBuilder,\n             _usr: ConfigBuilder,\n+\n+            _overrides: Vec<String>,\n         }\n \n         #[derive(Debug, Clone, Default, Deserialize, Serialize)]\n@@ -113,8 +115,7 @@ macro_rules! make_config {\n \n             /// Merges the values of both builders into a new builder.\n             /// If both have the same element, `other` wins.\n-            fn merge(&self, other: &Self, show_overrides: bool) -> Self {\n-                let mut overrides = Vec::new();\n+            fn merge(&self, other: &Self, show_overrides: bool, overrides: &mut Vec<String>) -> Self {\n                 let mut builder = self.clone();\n                 $($(\n                     if let v @Some(_) = &other.$name {\n@@ -176,9 +177,9 @@ macro_rules! make_config {\n             )+)+\n \n             pub fn prepare_json(&self) -> serde_json::Value {\n-                let (def, cfg) = {\n+                let (def, cfg, overriden) = {\n                     let inner = &self.inner.read().unwrap();\n-                    (inner._env.build(), inner.config.clone())\n+                    (inner._env.build(), inner.config.clone(), inner._overrides.clone())\n                 };\n \n                 fn _get_form_type(rust_type: &str) -> &'static str {\n@@ -210,6 +211,7 @@ macro_rules! make_config {\n                         \"default\": def.$name,\n                         \"type\":  _get_form_type(stringify!($ty)),\n                         \"doc\": _get_doc(concat!($($doc),+)),\n+                        \"overridden\": overriden.contains(&stringify!($name).to_uppercase()),\n                     }, )+\n                     ]}, )+ ])\n             }\n@@ -224,6 +226,15 @@ macro_rules! make_config {\n                     stringify!($name): make_config!{ @supportstr $name, cfg.$name, $ty, $none_action },\n                 )+)+ })\n             }\n+\n+            pub fn get_overrides(&self) -> Vec<String> {\n+                let overrides = {\n+                    let inner = &self.inner.read().unwrap();\n+                    inner._overrides.clone()\n+                };\n+\n+                overrides\n+            }\n         }\n     };\n \n@@ -505,7 +516,7 @@ make_config! {\n         /// Server name sent during HELO |> By default this value should be is on the machine's hostname, but might need to be changed in case it trips some anti-spam filters\n         helo_name:                     String, true,   option;\n         /// Enable SMTP debugging (Know the risks!) |> DANGEROUS: Enabling this will output very detailed SMTP messages. This could contain sensitive information like passwords and usernames! Only enable this during troubleshooting!\n-        smtp_debug:                    bool,   true,   def,     false;\n+        smtp_debug:                    bool,   false,  def,     false;\n         /// Accept Invalid Certs (Know the risks!) |> DANGEROUS: Allow invalid certificates. This option introduces significant vulnerabilities to man-in-the-middle attacks!\n         smtp_accept_invalid_certs:     bool,   true,   def,     false;\n         /// Accept Invalid Hostnames (Know the risks!) |> DANGEROUS: Allow invalid hostnames. This option introduces significant vulnerabilities to man-in-the-middle attacks!\n@@ -639,7 +650,8 @@ impl Config {\n         let _usr = ConfigBuilder::from_file(&CONFIG_FILE).unwrap_or_default();\n \n         // Create merged config, config file overwrites env\n-        let builder = _env.merge(&_usr, true);\n+        let mut _overrides = Vec::new();\n+        let builder = _env.merge(&_usr, true, &mut _overrides);\n \n         // Fill any missing with defaults\n         let config = builder.build();\n@@ -651,6 +663,7 @@ impl Config {\n                 config,\n                 _env,\n                 _usr,\n+                _overrides,\n             }),\n         })\n     }\n@@ -666,9 +679,10 @@ impl Config {\n         let config_str = serde_json::to_string_pretty(&builder)?;\n \n         // Prepare the combined config\n+        let mut overrides = Vec::new();\n         let config = {\n             let env = &self.inner.read().unwrap()._env;\n-            env.merge(&builder, false).build()\n+            env.merge(&builder, false, &mut overrides).build()\n         };\n         validate_config(&config)?;\n \n@@ -677,6 +691,7 @@ impl Config {\n             let mut writer = self.inner.write().unwrap();\n             writer.config = config;\n             writer._usr = builder;\n+            writer._overrides = overrides;\n         }\n \n         //Save to file\n@@ -690,7 +705,8 @@ impl Config {\n     pub fn update_config_partial(&self, other: ConfigBuilder) -> Result<(), Error> {\n         let builder = {\n             let usr = &self.inner.read().unwrap()._usr;\n-            usr.merge(&other, false)\n+            let mut _overrides = Vec::new();\n+            usr.merge(&other, false, &mut _overrides)\n         };\n         self.update_config(builder)\n     }\n@@ -751,6 +767,7 @@ impl Config {\n             let mut writer = self.inner.write().unwrap();\n             writer.config = config;\n             writer._usr = usr;\n+            writer._overrides = Vec::new();\n         }\n \n         Ok(())\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 1,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -81,20 +81,16 @@ macro_rules! make_config {\n                         dotenv::Error::Io(ioerr) => match ioerr.kind() {\n                             std::io::ErrorKind::NotFound => {\n                                 println!(\"[INFO] No .env file found.\\n\");\n-                                ()\n                             },\n                             std::io::ErrorKind::PermissionDenied => {\n                                 println!(\"[WARNING] Permission Denied while trying to read the .env file!\\n\");\n-                                ()\n                             },\n                             _ => {\n                                 println!(\"[WARNING] Reading the .env file failed:\\n{:?}\\n\", ioerr);\n-                                ()\n                             }\n                         },\n                         _ => {\n                             println!(\"[WARNING] Reading the .env file failed:\\n{:?}\\n\", e);\n-                            ()\n                         }\n                     }\n                 };\n@@ -610,7 +606,7 @@ fn validate_config(cfg: &ConfigItems) -> Result<(), Error> {\n \n     // Check if the icon blacklist regex is valid\n     if let Some(ref r) = cfg.icon_blacklist_regex {\n-        let validate_regex = Regex::new(&r);\n+        let validate_regex = Regex::new(r);\n         match validate_regex {\n             Ok(_) => (),\n             Err(e) => err!(format!(\"`ICON_BLACKLIST_REGEX` is invalid: {:#?}\", e)),\n",
            "comment_added_diff": []
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 1,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -770,13 +770,10 @@ impl Config {\n     }\n \n     pub fn private_rsa_key(&self) -> String {\n-        format!(\"{}.der\", CONFIG.rsa_key_filename())\n-    }\n-    pub fn private_rsa_key_pem(&self) -> String {\n         format!(\"{}.pem\", CONFIG.rsa_key_filename())\n     }\n     pub fn public_rsa_key(&self) -> String {\n-        format!(\"{}.pub.der\", CONFIG.rsa_key_filename())\n+        format!(\"{}.pub.pem\", CONFIG.rsa_key_filename())\n     }\n     pub fn mail_enabled(&self) -> bool {\n         let inner = &self.inner.read().unwrap().config;\n",
            "comment_added_diff": []
        },
        {
            "commit": "8ee5d51bd47279d5b23c409744fab6614af0e918",
            "timestamp": "2021-07-10T01:20:37-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Disable `show_password_hint` by default\n\nA setting that provides unauthenticated access to potentially sensitive data\nshouldn't be enabled by default.",
            "additions": 4,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -388,9 +388,10 @@ make_config! {\n         /// Password iterations |> Number of server-side passwords hashing iterations.\n         /// The changes only apply when a user changes their password. Not recommended to lower the value\n         password_iterations:    i32,    true,   def,    100_000;\n-        /// Show password hints |> Controls if the password hint should be shown directly in the web page.\n-        /// Otherwise, if email is disabled, there is no way to see the password hint\n-        show_password_hint:     bool,   true,   def,    true;\n+        /// Show password hint |> Controls whether a password hint should be shown directly in the web page\n+        /// if SMTP service is not configured. Not recommended for publicly-accessible instances as this\n+        /// provides unauthenticated access to potentially sensitive data.\n+        show_password_hint:     bool,   true,   def,    false;\n \n         /// Admin page token |> The token used to authenticate in this very same page. Changing it here won't deauthorize the current session\n         admin_token:            Pass,   true,   option;\n",
            "comment_added_diff": [
                [
                    391,
                    "        /// Show password hint |> Controls whether a password hint should be shown directly in the web page"
                ],
                [
                    392,
                    "        /// if SMTP service is not configured. Not recommended for publicly-accessible instances as this"
                ],
                [
                    393,
                    "        /// provides unauthenticated access to potentially sensitive data."
                ]
            ]
        },
        {
            "commit": "6ea95d1ede727942e4677cae8c80545123b98e81",
            "timestamp": "2021-07-13T15:17:03+02:00",
            "author": "BlackDex",
            "commit_message": "Updated attachment limit descriptions\n\nThe user and org attachment limit use `size` as wording while it should\nhave been `storage` since it isn't per attachment, but the sum of all attachments.\n\n- Changed the wording in the config/env\n- Changed the wording of the error messages.\n\nResolves #1818",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -356,9 +356,9 @@ make_config! {\n         /// HIBP Api Key |> HaveIBeenPwned API Key, request it here: https://haveibeenpwned.com/API/Key\n         hibp_api_key:           Pass,   true,   option;\n \n-        /// Per-user attachment limit (KB) |> Limit in kilobytes for a users attachments, once the limit is exceeded it won't be possible to upload more\n+        /// Per-user attachment storage limit (KB) |> Max kilobytes of attachment storage allowed per user. When this limit is reached, the user will not be allowed to upload further attachments.\n         user_attachment_limit:  i64,    true,   option;\n-        /// Per-organization attachment limit (KB) |> Limit in kilobytes for an organization attachments, once the limit is exceeded it won't be possible to upload more\n+        /// Per-organization attachment storage limit (KB) |> Max kilobytes of attachment storage allowed per org. When this limit is reached, org members will not be allowed to upload further attachments for ciphers owned by that org.\n         org_attachment_limit:   i64,    true,   option;\n \n         /// Trash auto-delete days |> Number of days to wait before auto-deleting a trashed item.\n",
            "comment_added_diff": [
                [
                    359,
                    "        /// Per-user attachment storage limit (KB) |> Max kilobytes of attachment storage allowed per user. When this limit is reached, the user will not be allowed to upload further attachments."
                ],
                [
                    361,
                    "        /// Per-organization attachment storage limit (KB) |> Max kilobytes of attachment storage allowed per org. When this limit is reached, org members will not be allowed to upload further attachments for ciphers owned by that org."
                ]
            ]
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 16,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -333,6 +333,12 @@ make_config! {\n         /// Trash purge schedule |> Cron schedule of the job that checks for trashed items to delete permanently.\n         /// Defaults to daily. Set blank to disable this job.\n         trash_purge_schedule:   String, false,  def,    \"0 5 0 * * *\".to_string();\n+        /// Emergency notification reminder schedule |> Cron schedule of the job that sends expiration reminders to emergency request grantors.\n+        /// Defaults to hourly. Set blank to disable this job.\n+        emergency_notification_reminder_schedule:   String, false,  def,    \"0 10 * * * *\".to_string();\n+        /// Emergency request timeout schedule |> Cron schedule of the job that checks for expired (i.e granted by timeout) emergency requests.\n+        /// Defaults to hourly. Set blank to disable this job.\n+        emergency_request_timeout_schedule:   String, false,  def,    \"0 15 * * * *\".to_string();\n     },\n \n     /// General settings\n@@ -385,6 +391,8 @@ make_config! {\n         org_creation_users:     String, true,   def,    \"\".to_string();\n         /// Allow invitations |> Controls whether users can be invited by organization admins, even when signups are otherwise disabled\n         invitations_allowed:    bool,   true,   def,    true;\n+        /// Allow emergency access |> Controls whether users can enable emergency access to their accounts\n+        emergency_access_allowed:    bool,   true,   def,    true;\n         /// Password iterations |> Number of server-side passwords hashing iterations.\n         /// The changes only apply when a user changes their password. Not recommended to lower the value\n         password_iterations:    i32,    true,   def,    100_000;\n@@ -855,11 +863,19 @@ where\n     reg!(\"email/delete_account\", \".html\");\n     reg!(\"email/invite_accepted\", \".html\");\n     reg!(\"email/invite_confirmed\", \".html\");\n+    reg!(\"email/emergency_access_invite_accepted\", \".html\");\n+    reg!(\"email/emergency_access_invite_confirmed\", \".html\");\n+    reg!(\"email/emergency_access_recovery_approved\", \".html\");\n+    reg!(\"email/emergency_access_recovery_initiated\", \".html\");\n+    reg!(\"email/emergency_access_recovery_rejected\", \".html\");\n+    reg!(\"email/emergency_access_recovery_reminder\", \".html\");\n+    reg!(\"email/emergency_access_recovery_timed_out\", \".html\");\n     reg!(\"email/new_device_logged_in\", \".html\");\n     reg!(\"email/pw_hint_none\", \".html\");\n     reg!(\"email/pw_hint_some\", \".html\");\n     reg!(\"email/send_2fa_removed_from_org\", \".html\");\n     reg!(\"email/send_org_invite\", \".html\");\n+    reg!(\"email/send_emergency_access_invite\", \".html\");\n     reg!(\"email/twofactor_email\", \".html\");\n     reg!(\"email/verify_email\", \".html\");\n     reg!(\"email/welcome\", \".html\");\n",
            "comment_added_diff": [
                [
                    336,
                    "        /// Emergency notification reminder schedule |> Cron schedule of the job that sends expiration reminders to emergency request grantors."
                ],
                [
                    337,
                    "        /// Defaults to hourly. Set blank to disable this job."
                ],
                [
                    339,
                    "        /// Emergency request timeout schedule |> Cron schedule of the job that checks for expired (i.e granted by timeout) emergency requests."
                ],
                [
                    340,
                    "        /// Defaults to hourly. Set blank to disable this job."
                ],
                [
                    394,
                    "        /// Allow emergency access |> Controls whether users can enable emergency access to their accounts"
                ]
            ]
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -874,6 +874,7 @@ where\n     reg!(\"email/pw_hint_none\", \".html\");\n     reg!(\"email/pw_hint_some\", \".html\");\n     reg!(\"email/send_2fa_removed_from_org\", \".html\");\n+    reg!(\"email/send_single_org_removed_from_org\", \".html\");\n     reg!(\"email/send_org_invite\", \".html\");\n     reg!(\"email/send_emergency_access_invite\", \".html\");\n     reg!(\"email/twofactor_email\", \".html\");\n",
            "comment_added_diff": []
        }
    ],
    "mod.rs": [
        {
            "commit": "6e5c03cc784b866f0b2481d91d49b36071576cb8",
            "timestamp": "2019-10-08T21:39:11+02:00",
            "author": "BlackDex",
            "commit_message": "Some modification when no HIBP API Key is set\n\n- Added an URL with the useraccount for manual check.\n- Added support for HTTP(S)_PROXY for hibp.",
            "additions": 16,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -141,8 +141,11 @@ fn hibp_breach(username: String) -> JsonResult {\n     use reqwest::{header::USER_AGENT, Client};\n \n     if let Some(api_key) = crate::CONFIG.hibp_api_key() {\n-        let res = Client::new()\n-            .get(&url)\n+        let hibp_client = Client::builder()\n+            .use_sys_proxy()\n+            .build()?;\n+\n+        let res = hibp_client.get(&url)\n             .header(USER_AGENT, user_agent)\n             .header(\"hibp-api-key\", api_key)\n             .send()?;\n@@ -156,9 +159,17 @@ fn hibp_breach(username: String) -> JsonResult {\n         Ok(Json(value))\n     } else {\n         Ok(Json(json!([{\n-            \"title\": \"--- Error! ---\",\n-            \"description\": \"HaveIBeenPwned API key not set! Go to https://haveibeenpwned.com/API/Key\",\n-            \"logopath\": \"/bwrs_static/error-x.svg\"\n+            \"Name\": \"HaveIBeenPwned\",\n+            \"Title\": \"--- Error! ---\",\n+            \"Domain\": \"haveibeenpwned.com\",\n+            \"BreachDate\": \"2019-08-18T00:00:00Z\",\n+            \"AddedDate\": \"2019-08-18T00:00:00Z\",\n+            \"Description\": format!(\"HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a><br/><br/>Or go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.\", account=username),\n+            \"LogoPath\": \"/bwrs_static/error-x.svg\",\n+            \"PwnCount\": 0,\n+            \"DataClasses\": [\n+                \"Error - No API key\"\n+            ]\n         }])))\n     }\n }\n",
            "comment_added_diff": [
                [
                    167,
                    "            \"Description\": format!(\"HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a><br/><br/>Or go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.\", account=username),"
                ]
            ]
        },
        {
            "commit": "edc482c8ea36fdefa2913cfd54eb52af5045eb24",
            "timestamp": "2019-10-08T22:29:12+02:00",
            "author": "BlackDex",
            "commit_message": "Changed HIBP Error message.\n\n- Moved the manual link to the check to the top.\n- Clearified that hibp is a payed service.\n- Changed error logo to hibp logo.",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -160,15 +160,15 @@ fn hibp_breach(username: String) -> JsonResult {\n     } else {\n         Ok(Json(json!([{\n             \"Name\": \"HaveIBeenPwned\",\n-            \"Title\": \"--- Error! ---\",\n+            \"Title\": \"Manual HIBP Check\",\n             \"Domain\": \"haveibeenpwned.com\",\n             \"BreachDate\": \"2019-08-18T00:00:00Z\",\n             \"AddedDate\": \"2019-08-18T00:00:00Z\",\n-            \"Description\": format!(\"HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a><br/><br/>Or go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.\", account=username),\n-            \"LogoPath\": \"/bwrs_static/error-x.svg\",\n+            \"Description\": format!(\"Go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.<br/><br/>HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a> to purchase an API key from HaveIBeenPwned.<br/><br/>\", account=username),\n+            \"LogoPath\": \"/bwrs_static/hibp.png\",\n             \"PwnCount\": 0,\n             \"DataClasses\": [\n-                \"Error - No API key\"\n+                \"Error - No API key set!\"\n             ]\n         }])))\n     }\n",
            "comment_added_diff": [
                [
                    167,
                    "            \"Description\": format!(\"Go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.<br/><br/>HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a> to purchase an API key from HaveIBeenPwned.<br/><br/>\", account=username),"
                ]
            ]
        },
        {
            "commit": "2cde814aaa956c0eb90e810601348781a32bf617",
            "timestamp": "2019-10-11T12:08:40+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed a bug with the sqlite backup feature.\n\nWhen a custom path is used the backup feature does not work.\nChanged it so it will take the path of the sqlite file and use that.",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -52,12 +52,16 @@ pub fn get_connection() -> Result<Connection, ConnectionError> {\n \n /// Creates a back-up of the database using sqlite3\n pub fn backup_database() -> Result<(), Error> {\n+    use std::path::Path;\n+    let db_url = CONFIG.database_url();\n+    let db_path = Path::new(&db_url).parent().unwrap();\n+\n     let now: DateTime<Utc> = Utc::now();\n     let file_date = now.format(\"%Y%m%d\").to_string();\n     let backup_command: String = format!(\"{}{}{}\", \".backup 'db_\", file_date, \".sqlite3'\");\n \n     Command::new(\"sqlite3\")\n-        .current_dir(\"./data\")\n+        .current_dir(db_path)\n         .args(&[\"db.sqlite3\", &backup_command])\n         .output()\n         .expect(\"Can't open database, sqlite3 is not available, make sure it's installed and available on the PATH\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "fccc0a4b05323bed8d9dd1a1b2ceee85c4aa5593",
            "timestamp": "2019-10-25T21:48:10+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update rocket to latest master\nDowngrade rust version to fix cargo issue\nSet rustup profile to minimal",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -76,7 +76,8 @@ impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n     type Error = ();\n \n     fn from_request(request: &'a Request<'r>) -> request::Outcome<DbConn, ()> {\n-        let pool = request.guard::<State<Pool>>()?;\n+        // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c\n+        let pool = try_outcome!(request.guard::<State<Pool>>());\n         match pool.get() {\n             Ok(conn) => Outcome::Success(DbConn(conn)),\n             Err(_) => Outcome::Failure((Status::ServiceUnavailable, ())),\n",
            "comment_added_diff": [
                [
                    79,
                    "        // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c"
                ]
            ]
        },
        {
            "commit": "3442eb1b9da50d3007d994c25543f3ec04f7a397",
            "timestamp": "2019-11-04T14:30:24+01:00",
            "author": "BlackDex",
            "commit_message": "Trying to fix issue #687\n\n- Using an older commit from rocket repo",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -76,8 +76,7 @@ impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n     type Error = ();\n \n     fn from_request(request: &'a Request<'r>) -> request::Outcome<DbConn, ()> {\n-        // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c\n-        let pool = try_outcome!(request.guard::<State<Pool>>());\n+        let pool = request.guard::<State<Pool>>()?;\n         match pool.get() {\n             Ok(conn) => Outcome::Success(DbConn(conn)),\n             Err(_) => Outcome::Failure((Status::ServiceUnavailable, ())),\n",
            "comment_added_diff": []
        },
        {
            "commit": "85dbf4e16c60e9657552f6cedab3e5111115fe7c",
            "timestamp": "2019-11-05T21:29:04+13:00",
            "author": "Patrick Li",
            "commit_message": "Don't include excluded global equivalent domains during sync\n\nFixes #681",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -81,6 +81,10 @@ const GLOBAL_DOMAINS: &str = include_str!(\"../../static/global_domains.json\");\n \n #[get(\"/settings/domains\")]\n fn get_eq_domains(headers: Headers) -> JsonResult {\n+    _get_eq_domains(headers, false)\n+}\n+\n+fn _get_eq_domains(headers: Headers, no_excluded: bool) -> JsonResult {\n     let user = headers.user;\n     use serde_json::from_str;\n \n@@ -93,6 +97,10 @@ fn get_eq_domains(headers: Headers) -> JsonResult {\n         global.Excluded = excluded_globals.contains(&global.Type);\n     }\n \n+    if no_excluded {\n+        globals.retain(|g| !g.Excluded);\n+    }\n+\n     Ok(Json(json!({\n         \"EquivalentDomains\": equivalent_domains,\n         \"GlobalEquivalentDomains\": globals,\n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 3,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -149,11 +149,10 @@ fn hibp_breach(username: String) -> JsonResult {\n     use reqwest::{header::USER_AGENT, Client};\n \n     if let Some(api_key) = crate::CONFIG.hibp_api_key() {\n-        let hibp_client = Client::builder()\n-            .use_sys_proxy()\n-            .build()?;\n+        let hibp_client = Client::builder().use_sys_proxy().build()?;\n \n-        let res = hibp_client.get(&url)\n+        let res = hibp_client\n+            .get(&url)\n             .header(USER_AGENT, user_agent)\n             .header(\"hibp-api-key\", api_key)\n             .send()?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -172,7 +172,7 @@ fn hibp_breach(username: String) -> JsonResult {\n             \"BreachDate\": \"2019-08-18T00:00:00Z\",\n             \"AddedDate\": \"2019-08-18T00:00:00Z\",\n             \"Description\": format!(\"Go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.<br/><br/>HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a> to purchase an API key from HaveIBeenPwned.<br/><br/>\", account=username),\n-            \"LogoPath\": \"/bwrs_static/hibp.png\",\n+            \"LogoPath\": \"bwrs_static/hibp.png\",\n             \"PwnCount\": 0,\n             \"DataClasses\": [\n                 \"Error - No API key set!\"\n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -7,6 +7,7 @@ mod user;\n mod collection;\n mod organization;\n mod two_factor;\n+mod org_policy;\n \n pub use self::attachment::Attachment;\n pub use self::cipher::Cipher;\n@@ -17,3 +18,4 @@ pub use self::organization::Organization;\n pub use self::organization::{UserOrgStatus, UserOrgType, UserOrganization};\n pub use self::two_factor::{TwoFactor, TwoFactorType};\n pub use self::user::{Invitation, User};\n+pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n\\ No newline at end of file\n",
            "comment_added_diff": []
        },
        {
            "commit": "1b4b40c95dab106a5b06b8b1685004b59abf21dd",
            "timestamp": "2020-03-14T23:12:45+01:00",
            "author": "BlackDex",
            "commit_message": "Updated reqwest to the latest version.\n\n- Use the blocking client (no async).\n- Disabled gzip.\n- use_sys_proxy is now default.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -146,10 +146,10 @@ fn hibp_breach(username: String) -> JsonResult {\n         username\n     );\n \n-    use reqwest::{header::USER_AGENT, Client};\n+    use reqwest::{header::USER_AGENT, blocking::Client};\n \n     if let Some(api_key) = crate::CONFIG.hibp_api_key() {\n-        let hibp_client = Client::builder().use_sys_proxy().build()?;\n+        let hibp_client = Client::builder().build()?;\n \n         let res = hibp_client\n             .get(&url)\n",
            "comment_added_diff": []
        },
        {
            "commit": "078234d8b3b8524e82a18c802fda6f3bccc6fc9f",
            "timestamp": "2020-03-16T16:36:44+01:00",
            "author": "BlackDex",
            "commit_message": "Small change for rocket compatibilty",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -76,7 +76,8 @@ impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n     type Error = ();\n \n     fn from_request(request: &'a Request<'r>) -> request::Outcome<DbConn, ()> {\n-        let pool = request.guard::<State<Pool>>()?;\n+        // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c\n+        let pool = try_outcome!(request.guard::<State<Pool>>());\n         match pool.get() {\n             Ok(conn) => Outcome::Success(DbConn(conn)),\n             Err(_) => Outcome::Failure((Status::ServiceUnavailable, ())),\n",
            "comment_added_diff": [
                [
                    79,
                    "        // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c"
                ]
            ]
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -2,7 +2,7 @@ mod accounts;\n mod ciphers;\n mod folders;\n mod organizations;\n-pub(crate) mod two_factor;\n+pub mod two_factor;\n \n pub fn routes() -> Vec<Route> {\n     let mut mod_routes = routes![\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 5,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,6 @@\n use data_encoding::BASE32;\n use rocket::Route;\n use rocket_contrib::json::Json;\n-use serde_json;\n use serde_json::Value;\n \n use crate::api::{JsonResult, JsonUpcase, NumberOrString, PasswordData};\n@@ -12,11 +11,11 @@ use crate::db::{\n     DbConn,\n };\n \n-pub(crate) mod authenticator;\n-pub(crate) mod duo;\n-pub(crate) mod email;\n-pub(crate) mod u2f;\n-pub(crate) mod yubikey;\n+pub mod authenticator;\n+pub mod duo;\n+pub mod email;\n+pub mod u2f;\n+pub mod yubikey;\n \n pub fn routes() -> Vec<Route> {\n     let mut routes = routes![\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,5 @@\n mod admin;\n-pub(crate) mod core;\n+pub mod core;\n mod icons;\n mod identity;\n mod notifications;\n",
            "comment_added_diff": []
        },
        {
            "commit": "dfdf4473ea89087a5d055a7d9fdcda62fa727c58",
            "timestamp": "2020-05-08T13:36:35-04:00",
            "author": "theycallmesteve",
            "commit_message": "Rename to_json_list to to_json_provder to reflect the response model",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -38,7 +38,7 @@ pub fn routes() -> Vec<Route> {\n #[get(\"/two-factor\")]\n fn get_twofactor(headers: Headers, conn: DbConn) -> JsonResult {\n     let twofactors = TwoFactor::find_by_user(&headers.user.uuid, &conn);\n-    let twofactors_json: Vec<Value> = twofactors.iter().map(TwoFactor::to_json_list).collect();\n+    let twofactors_json: Vec<Value> = twofactors.iter().map(TwoFactor::to_json_provider).collect();\n \n     Ok(Json(json!({\n         \"Data\": twofactors_json,\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 7,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -29,14 +29,15 @@ pub fn routes() -> Vec<Route> {\n // Move this somewhere else\n //\n use rocket::Route;\n-\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::api::{EmptyResult, JsonResult, JsonUpcase};\n-use crate::auth::Headers;\n-use crate::db::DbConn;\n-use crate::error::Error;\n+use crate::{\n+    api::{EmptyResult, JsonResult, JsonUpcase},\n+    auth::Headers,\n+    db::DbConn,\n+    error::Error,\n+};\n \n #[put(\"/devices/identifier/<uuid>/clear-token\")]\n fn clear_device_token(uuid: String) -> EmptyResult {\n@@ -146,7 +147,7 @@ fn hibp_breach(username: String) -> JsonResult {\n         username\n     );\n \n-    use reqwest::{header::USER_AGENT, blocking::Client};\n+    use reqwest::{blocking::Client, header::USER_AGENT};\n \n     if let Some(api_key) = crate::CONFIG.hibp_api_key() {\n         let hibp_client = Client::builder().build()?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 8,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -3,12 +3,14 @@ use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::api::{JsonResult, JsonUpcase, NumberOrString, PasswordData};\n-use crate::auth::Headers;\n-use crate::crypto;\n-use crate::db::{\n-    models::{TwoFactor, User},\n-    DbConn,\n+use crate::{\n+    api::{JsonResult, JsonUpcase, NumberOrString, PasswordData},\n+    auth::Headers,\n+    crypto,\n+    db::{\n+        models::{TwoFactor, User},\n+        DbConn,\n+    },\n };\n \n pub mod authenticator;\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 11,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -5,23 +5,25 @@ mod identity;\n mod notifications;\n mod web;\n \n-pub use self::admin::routes as admin_routes;\n-pub use self::core::routes as core_routes;\n-pub use self::icons::routes as icons_routes;\n-pub use self::identity::routes as identity_routes;\n-pub use self::notifications::routes as notifications_routes;\n-pub use self::notifications::{start_notification_server, Notify, UpdateType};\n-pub use self::web::routes as web_routes;\n-\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n+pub use crate::api::{\n+    admin::routes as admin_routes,\n+    core::routes as core_routes,\n+    icons::routes as icons_routes,\n+    identity::routes as identity_routes,\n+    notifications::routes as notifications_routes,\n+    notifications::{start_notification_server, Notify, UpdateType},\n+    web::routes as web_routes,\n+};\n+use crate::util;\n+\n // Type aliases for API methods results\n type ApiResult<T> = Result<T, crate::error::Error>;\n pub type JsonResult = ApiResult<Json<Value>>;\n pub type EmptyResult = ApiResult<()>;\n \n-use crate::util;\n type JsonUpcase<T> = Json<util::UpCase<T>>;\n type JsonUpcaseVec<T> = Json<Vec<util::UpCase<T>>>;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 9,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -1,18 +1,14 @@\n-use std::ops::Deref;\n-\n-use diesel::r2d2;\n-use diesel::r2d2::ConnectionManager;\n-use diesel::{Connection as DieselConnection, ConnectionError};\n-\n-use rocket::http::Status;\n-use rocket::request::{self, FromRequest};\n-use rocket::{Outcome, Request, State};\n+use std::process::Command;\n \n-use crate::error::Error;\n use chrono::prelude::*;\n-use std::process::Command;\n+use diesel::{r2d2, r2d2::ConnectionManager, Connection as DieselConnection, ConnectionError};\n+use rocket::{\n+    http::Status,\n+    request::{self, FromRequest},\n+    Outcome, Request, State,\n+};\n \n-use crate::CONFIG;\n+use crate::{error::Error, CONFIG};\n \n /// An alias to the database connection used\n #[cfg(feature = \"sqlite\")]\n@@ -86,7 +82,7 @@ impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n }\n \n // For the convenience of using an &DbConn as a &Database.\n-impl Deref for DbConn {\n+impl std::ops::Deref for DbConn {\n     type Target = Connection;\n     fn deref(&self) -> &Self::Target {\n         &self.0\n",
            "comment_added_diff": []
        },
        {
            "commit": "32cfaab5eefa1564b31819685a7b51f4a5025a59",
            "timestamp": "2020-07-23T21:07:04+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated dependencies and changed rocket request imports",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -4,8 +4,8 @@ use chrono::prelude::*;\n use diesel::{r2d2, r2d2::ConnectionManager, Connection as DieselConnection, ConnectionError};\n use rocket::{\n     http::Status,\n-    request::{self, FromRequest},\n-    Outcome, Request, State,\n+    request::{FromRequest, Outcome},\n+    Request, State,\n };\n \n use crate::{error::Error, CONFIG};\n@@ -71,7 +71,7 @@ pub fn backup_database() -> Result<(), Error> {\n impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n     type Error = ();\n \n-    fn from_request(request: &'a Request<'r>) -> request::Outcome<DbConn, ()> {\n+    fn from_request(request: &'a Request<'r>) -> Outcome<DbConn, ()> {\n         // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c\n         let pool = try_outcome!(request.guard::<State<Pool>>());\n         match pool.get() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 269,
            "deletions": 36,
            "change_type": "MODIFY",
            "diff": "@@ -1,51 +1,203 @@\n use std::process::Command;\n \n use chrono::prelude::*;\n-use diesel::{r2d2, r2d2::ConnectionManager, Connection as DieselConnection, ConnectionError};\n+use diesel::r2d2::{ConnectionManager, Pool, PooledConnection};\n use rocket::{\n     http::Status,\n     request::{FromRequest, Outcome},\n     Request, State,\n };\n \n-use crate::{error::Error, CONFIG};\n-\n-/// An alias to the database connection used\n-#[cfg(feature = \"sqlite\")]\n-type Connection = diesel::sqlite::SqliteConnection;\n-#[cfg(feature = \"mysql\")]\n-type Connection = diesel::mysql::MysqlConnection;\n-#[cfg(feature = \"postgresql\")]\n-type Connection = diesel::pg::PgConnection;\n-\n-/// An alias to the type for a pool of Diesel connections.\n-type Pool = r2d2::Pool<ConnectionManager<Connection>>;\n-\n-/// Connection request guard type: a wrapper around an r2d2 pooled connection.\n-pub struct DbConn(pub r2d2::PooledConnection<ConnectionManager<Connection>>);\n+use crate::{\n+    error::{Error, MapResult},\n+    CONFIG,\n+};\n \n-pub mod models;\n-#[cfg(feature = \"sqlite\")]\n+#[cfg(sqlite)]\n #[path = \"schemas/sqlite/schema.rs\"]\n-pub mod schema;\n-#[cfg(feature = \"mysql\")]\n+pub mod __sqlite_schema;\n+\n+#[cfg(mysql)]\n #[path = \"schemas/mysql/schema.rs\"]\n-pub mod schema;\n-#[cfg(feature = \"postgresql\")]\n+pub mod __mysql_schema;\n+\n+#[cfg(postgresql)]\n #[path = \"schemas/postgresql/schema.rs\"]\n-pub mod schema;\n+pub mod __postgresql_schema;\n+\n+\n+// This is used to generate the main DbConn and DbPool enums, which contain one variant for each database supported\n+macro_rules! generate_connections {\n+    ( $( $name:ident: $ty:ty ),+ ) => {\n+        #[allow(non_camel_case_types, dead_code)]\n+        #[derive(Eq, PartialEq)]\n+        pub enum DbConnType { $( $name, )+ }\n+\n+        #[allow(non_camel_case_types)]\n+        pub enum DbConn { $( #[cfg($name)] $name(PooledConnection<ConnectionManager< $ty >>), )+ }\n+\n+        #[allow(non_camel_case_types)]\n+        pub enum DbPool { $( #[cfg($name)] $name(Pool<ConnectionManager< $ty >>), )+ }\n+\n+        impl DbPool {\n+            // For the given database URL, guess it's type, run migrations create pool and return it\n+            pub fn from_config() -> Result<Self, Error> {\n+                let url = CONFIG.database_url();\n+                let conn_type = DbConnType::from_url(&url)?;\n+\n+                match conn_type { $(\n+                    DbConnType::$name => {\n+                        #[cfg($name)]\n+                        {\n+                            paste::paste!{ [< $name _migrations >]::run_migrations(); }\n+                            let manager = ConnectionManager::new(&url);\n+                            let pool = Pool::builder().build(manager).map_res(\"Failed to create pool\")?;\n+                            return Ok(Self::$name(pool));\n+                        }\n+                        #[cfg(not($name))]\n+                        #[allow(unreachable_code)]\n+                        return unreachable!(\"Trying to use a DB backend when it's feature is disabled\");\n+                    },\n+                )+ }\n+            }\n+            // Get a connection from the pool\n+            pub fn get(&self) -> Result<DbConn, Error> {\n+                match self {  $(\n+                    #[cfg($name)]\n+                    Self::$name(p) => Ok(DbConn::$name(p.get().map_res(\"Error retrieving connection from pool\")?)),\n+                )+ }\n+            }\n+        }\n+    };\n+}\n \n-/// Initializes a database pool.\n-pub fn init_pool() -> Pool {\n-    let manager = ConnectionManager::new(CONFIG.database_url());\n+generate_connections! {\n+    sqlite: diesel::sqlite::SqliteConnection,\n+    mysql: diesel::mysql::MysqlConnection,\n+    postgresql: diesel::pg::PgConnection\n+}\n+\n+impl DbConnType {\n+    pub fn from_url(url: &str) -> Result<DbConnType, Error> {\n+        // Mysql\n+        if url.starts_with(\"mysql:\") {\n+            #[cfg(mysql)]\n+            return Ok(DbConnType::mysql);\n+\n+            #[cfg(not(mysql))]\n+            err!(\"`DATABASE_URL` is a MySQL URL, but the 'mysql' feature is not enabled\")\n+\n+        // Postgres\n+        } else if url.starts_with(\"postgresql:\") || url.starts_with(\"postgres:\") {\n+            #[cfg(postgresql)]\n+            return Ok(DbConnType::postgresql);\n \n-    r2d2::Pool::builder().build(manager).expect(\"Failed to create pool\")\n+            #[cfg(not(postgresql))]\n+            err!(\"`DATABASE_URL` is a PostgreSQL URL, but the 'postgresql' feature is not enabled\")\n+\n+        //Sqlite\n+        } else {\n+            #[cfg(sqlite)]\n+            return Ok(DbConnType::sqlite);\n+\n+            #[cfg(not(sqlite))]\n+            err!(\"`DATABASE_URL` looks like a SQLite URL, but 'sqlite' feature is not enabled\")\n+        }\n+    }\n }\n \n-pub fn get_connection() -> Result<Connection, ConnectionError> {\n-    Connection::establish(&CONFIG.database_url())\n+\n+#[macro_export]\n+macro_rules! db_run {\n+    // Same for all dbs\n+    ( $conn:ident: $body:block ) => {\n+        db_run! { $conn: sqlite, mysql, postgresql $body }\n+    };\n+\n+    // Different code for each db\n+    ( $conn:ident: $( $($db:ident),+ $body:block )+ ) => {\n+        #[allow(unused)] use diesel::prelude::*;\n+        match $conn {\n+            $($(\n+                #[cfg($db)]\n+                crate::db::DbConn::$db(ref $conn) => {\n+                    paste::paste! { \n+                        #[allow(unused)] use crate::db::[<__ $db _schema>]::{self as schema, *};\n+                        #[allow(unused)] use [<__ $db _model>]::*;\n+                        #[allow(unused)] use crate::db::FromDb;  \n+                    }\n+                    $body\n+                },\n+            )+)+\n+        }\n+    };\n }\n \n+\n+pub trait FromDb {\n+    type Output;\n+    fn from_db(self) -> Self::Output;\n+}\n+\n+// For each struct eg. Cipher, we create a CipherDb inside a module named __$db_model (where $db is sqlite, mysql or postgresql), \n+// to implement the Diesel traits. We also provide methods to convert between them and the basic structs. Later, that module will be auto imported when using db_run!\n+#[macro_export]\n+macro_rules! db_object {\n+    ( $(\n+        $( #[$attr:meta] )*\n+        pub struct $name:ident {\n+            $( $( #[$field_attr:meta] )* $vis:vis $field:ident : $typ:ty ),+\n+            $(,)?\n+        }\n+    )+ ) => { \n+        // Create the normal struct, without attributes\n+        $( pub struct $name { $( /*$( #[$field_attr] )**/ $vis $field : $typ, )+ } )+\n+        \n+        #[cfg(sqlite)]\n+        pub mod __sqlite_model     { $( db_object! { @db sqlite     |  $( #[$attr] )* | $name |  $( $( #[$field_attr] )* $field : $typ ),+ } )+ }\n+        #[cfg(mysql)]\n+        pub mod __mysql_model      { $( db_object! { @db mysql      |  $( #[$attr] )* | $name |  $( $( #[$field_attr] )* $field : $typ ),+ } )+ }\n+        #[cfg(postgresql)]\n+        pub mod __postgresql_model { $( db_object! { @db postgresql |  $( #[$attr] )* | $name |  $( $( #[$field_attr] )* $field : $typ ),+ } )+ }\n+    };\n+\n+    ( @db $db:ident | $( #[$attr:meta] )* | $name:ident | $( $( #[$field_attr:meta] )* $vis:vis $field:ident : $typ:ty),+) => {\n+        paste::paste! {\n+            #[allow(unused)] use super::*;\n+            #[allow(unused)] use diesel::prelude::*;\n+            #[allow(unused)] use crate::db::[<__ $db _schema>]::*;\n+\n+            $( #[$attr] )*\n+            pub struct [<$name Db>] { $(\n+                $( #[$field_attr] )* $vis $field : $typ,\n+            )+ }\n+\n+            impl [<$name Db>] {\n+                #[inline(always)] pub fn from_db(self) -> super::$name { super::$name { $( $field: self.$field, )+ } }\n+                #[inline(always)] pub fn to_db(x: &super::$name) -> Self { Self { $( $field: x.$field.clone(), )+ } }\n+            }\n+\n+            impl crate::db::FromDb for [<$name Db>] {\n+                type Output = super::$name;\n+                #[inline(always)] fn from_db(self) -> Self::Output { super::$name { $( $field: self.$field, )+ } }\n+            }\n+\n+            impl crate::db::FromDb for Vec<[<$name Db>]> {\n+                type Output = Vec<super::$name>;\n+                #[inline(always)] fn from_db(self) -> Self::Output { self.into_iter().map(crate::db::FromDb::from_db).collect() }\n+            }\n+\n+            impl crate::db::FromDb for Option<[<$name Db>]> {\n+                type Output = Option<super::$name>;\n+                #[inline(always)] fn from_db(self) -> Self::Output { self.map(crate::db::FromDb::from_db) }\n+            }\n+        }\n+    };\n+}\n+\n+// Reexport the models, needs to be after the macros are defined so it can access them\n+pub mod models;\n+\n /// Creates a back-up of the database using sqlite3\n pub fn backup_database() -> Result<(), Error> {\n     use std::path::Path;\n@@ -73,18 +225,99 @@ impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n \n     fn from_request(request: &'a Request<'r>) -> Outcome<DbConn, ()> {\n         // https://github.com/SergioBenitez/Rocket/commit/e3c1a4ad3ab9b840482ec6de4200d30df43e357c\n-        let pool = try_outcome!(request.guard::<State<Pool>>());\n+        let pool = try_outcome!(request.guard::<State<DbPool>>());\n         match pool.get() {\n-            Ok(conn) => Outcome::Success(DbConn(conn)),\n+            Ok(conn) => Outcome::Success(conn),\n             Err(_) => Outcome::Failure((Status::ServiceUnavailable, ())),\n         }\n     }\n }\n \n-// For the convenience of using an &DbConn as a &Database.\n-impl std::ops::Deref for DbConn {\n-    type Target = Connection;\n-    fn deref(&self) -> &Self::Target {\n-        &self.0\n+// Embed the migrations from the migrations folder into the application\n+// This way, the program automatically migrates the database to the latest version\n+// https://docs.rs/diesel_migrations/*/diesel_migrations/macro.embed_migrations.html\n+#[cfg(sqlite)]\n+mod sqlite_migrations {\n+    #[allow(unused_imports)]\n+    embed_migrations!(\"migrations/sqlite\");\n+\n+    pub fn run_migrations() {\n+        // Make sure the directory exists\n+        let url = crate::CONFIG.database_url();\n+        let path = std::path::Path::new(&url);\n+\n+        if let Some(parent) = path.parent() {\n+            if std::fs::create_dir_all(parent).is_err() {\n+                error!(\"Error creating database directory\");\n+                std::process::exit(1);\n+            }\n+        }\n+\n+        use diesel::{Connection, RunQueryDsl};\n+        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n+        let connection =\n+            diesel::sqlite::SqliteConnection::establish(&crate::CONFIG.database_url()).expect(\"Can't connect to DB\");\n+        // Disable Foreign Key Checks during migration\n+        \n+        // Scoped to a connection.\n+        diesel::sql_query(\"PRAGMA foreign_keys = OFF\")\n+            .execute(&connection)\n+            .expect(\"Failed to disable Foreign Key Checks during migrations\");\n+\n+        // Turn on WAL in SQLite\n+        if crate::CONFIG.enable_db_wal() {\n+            diesel::sql_query(\"PRAGMA journal_mode=wal\")\n+                .execute(&connection)\n+                .expect(\"Failed to turn on WAL\");\n+        }\n+\n+        embedded_migrations::run_with_output(&connection, &mut std::io::stdout()).expect(\"Can't run migrations\");\n+    }\n+}\n+\n+#[cfg(mysql)]\n+mod mysql_migrations {\n+    #[allow(unused_imports)]\n+    embed_migrations!(\"migrations/mysql\");\n+\n+    pub fn run_migrations() {\n+        use diesel::{Connection, RunQueryDsl};\n+        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n+        let connection =\n+            diesel::mysql::MysqlConnection::establish(&crate::CONFIG.database_url()).expect(\"Can't connect to DB\");\n+        // Disable Foreign Key Checks during migration\n+\n+        // Scoped to a connection/session.\n+        diesel::sql_query(\"SET FOREIGN_KEY_CHECKS = 0\")\n+            .execute(&connection)\n+            .expect(\"Failed to disable Foreign Key Checks during migrations\");\n+\n+        embedded_migrations::run_with_output(&connection, &mut std::io::stdout()).expect(\"Can't run migrations\");\n+    }\n+}\n+\n+#[cfg(postgresql)]\n+mod postgresql_migrations {\n+    #[allow(unused_imports)]\n+    embed_migrations!(\"migrations/postgresql\");\n+\n+    pub fn run_migrations() {\n+        use diesel::{Connection, RunQueryDsl};\n+        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n+        let connection =\n+            diesel::pg::PgConnection::establish(&crate::CONFIG.database_url()).expect(\"Can't connect to DB\");\n+        // Disable Foreign Key Checks during migration\n+        \n+        // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,\n+        // \"SET CONSTRAINTS sets the behavior of constraint checking within the\n+        // current transaction\", so this setting probably won't take effect for\n+        // any of the migrations since it's being run outside of a transaction.\n+        // Migrations that need to disable foreign key checks should run this\n+        // from within the migration script itself.\n+        diesel::sql_query(\"SET CONSTRAINTS ALL DEFERRED\")\n+            .execute(&connection)\n+            .expect(\"Failed to disable Foreign Key Checks during migrations\");\n+\n+        embedded_migrations::run_with_output(&connection, &mut std::io::stdout()).expect(\"Can't run migrations\");\n     }\n }\n",
            "comment_added_diff": [
                [
                    29,
                    "// This is used to generate the main DbConn and DbPool enums, which contain one variant for each database supported"
                ],
                [
                    43,
                    "            // For the given database URL, guess it's type, run migrations create pool and return it"
                ],
                [
                    63,
                    "            // Get a connection from the pool"
                ],
                [
                    82,
                    "        // Mysql"
                ],
                [
                    90,
                    "        // Postgres"
                ],
                [
                    98,
                    "        //Sqlite"
                ],
                [
                    112,
                    "    // Same for all dbs"
                ],
                [
                    117,
                    "    // Different code for each db"
                ],
                [
                    142,
                    "// For each struct eg. Cipher, we create a CipherDb inside a module named __$db_model (where $db is sqlite, mysql or postgresql),"
                ],
                [
                    143,
                    "// to implement the Diesel traits. We also provide methods to convert between them and the basic structs. Later, that module will be auto imported when using db_run!"
                ],
                [
                    153,
                    "        // Create the normal struct, without attributes"
                ],
                [
                    198,
                    "// Reexport the models, needs to be after the macros are defined so it can access them"
                ],
                [
                    236,
                    "// Embed the migrations from the migrations folder into the application"
                ],
                [
                    237,
                    "// This way, the program automatically migrates the database to the latest version"
                ],
                [
                    238,
                    "// https://docs.rs/diesel_migrations/*/diesel_migrations/macro.embed_migrations.html"
                ],
                [
                    245,
                    "        // Make sure the directory exists"
                ],
                [
                    257,
                    "        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)"
                ],
                [
                    260,
                    "        // Disable Foreign Key Checks during migration"
                ],
                [
                    262,
                    "        // Scoped to a connection."
                ],
                [
                    267,
                    "        // Turn on WAL in SQLite"
                ],
                [
                    285,
                    "        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)"
                ],
                [
                    288,
                    "        // Disable Foreign Key Checks during migration"
                ],
                [
                    290,
                    "        // Scoped to a connection/session."
                ],
                [
                    306,
                    "        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)"
                ],
                [
                    309,
                    "        // Disable Foreign Key Checks during migration"
                ],
                [
                    311,
                    "        // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,"
                ],
                [
                    312,
                    "        // \"SET CONSTRAINTS sets the behavior of constraint checking within the"
                ],
                [
                    313,
                    "        // current transaction\", so this setting probably won't take effect for"
                ],
                [
                    314,
                    "        // any of the migrations since it's being run outside of a transaction."
                ],
                [
                    315,
                    "        // Migrations that need to disable foreign key checks should run this"
                ],
                [
                    316,
                    "        // from within the migration script itself."
                ]
            ]
        },
        {
            "commit": "175d647e47fbd9abec4134c708199ba8aa1ec682",
            "timestamp": "2020-08-26T01:27:38-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Delete associated favorites when deleting a cipher or user\n\nThis prevents foreign key constraint violations.",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -1,21 +1,21 @@\n mod attachment;\n mod cipher;\n+mod collection;\n mod device;\n+mod favorite;\n mod folder;\n-mod user;\n-\n-mod collection;\n+mod org_policy;\n mod organization;\n mod two_factor;\n-mod org_policy;\n+mod user;\n \n pub use self::attachment::Attachment;\n pub use self::cipher::Cipher;\n pub use self::collection::{Collection, CollectionCipher, CollectionUser};\n pub use self::device::Device;\n+pub use self::favorite::Favorite;\n pub use self::folder::{Folder, FolderCipher};\n-pub use self::organization::Organization;\n-pub use self::organization::{UserOrgStatus, UserOrgType, UserOrganization};\n+pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n+pub use self::organization::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n pub use self::two_factor::{TwoFactor, TwoFactorType};\n pub use self::user::{Invitation, User};\n-pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n\\ No newline at end of file\n",
            "comment_added_diff": []
        },
        {
            "commit": "aaba1e836838a6dd75d65d83d47346d733e3e752",
            "timestamp": "2020-08-28T22:10:28+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix some clippy warnings and remove unused function",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -136,6 +136,7 @@ macro_rules! db_run {\n \n pub trait FromDb {\n     type Output;\n+    #[allow(clippy::wrong_self_convention)]\n     fn from_db(self) -> Self::Output;\n }\n \n@@ -173,7 +174,7 @@ macro_rules! db_object {\n             )+ }\n \n             impl [<$name Db>] {\n-                #[inline(always)] pub fn from_db(self) -> super::$name { super::$name { $( $field: self.$field, )+ } }\n+                #[allow(clippy::wrong_self_convention)] \n                 #[inline(always)] pub fn to_db(x: &super::$name) -> Self { Self { $( $field: x.$field.clone(), )+ } }\n             }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "729c9cff41cc74055f8397fae7f60084dcf4b71b",
            "timestamp": "2020-10-03T22:32:00+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Retry initial db connection, with adjustable option",
            "additions": 13,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -49,7 +49,7 @@ macro_rules! generate_connections {\n                     DbConnType::$name => {\n                         #[cfg($name)]\n                         {\n-                            paste::paste!{ [< $name _migrations >]::run_migrations(); }\n+                            paste::paste!{ [< $name _migrations >]::run_migrations()?; }\n                             let manager = ConnectionManager::new(&url);\n                             let pool = Pool::builder().build(manager).map_res(\"Failed to create pool\")?;\n                             return Ok(Self::$name(pool));\n@@ -242,7 +242,7 @@ mod sqlite_migrations {\n     #[allow(unused_imports)]\n     embed_migrations!(\"migrations/sqlite\");\n \n-    pub fn run_migrations() {\n+    pub fn run_migrations() -> Result<(), super::Error> {\n         // Make sure the directory exists\n         let url = crate::CONFIG.database_url();\n         let path = std::path::Path::new(&url);\n@@ -257,7 +257,7 @@ mod sqlite_migrations {\n         use diesel::{Connection, RunQueryDsl};\n         // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n         let connection =\n-            diesel::sqlite::SqliteConnection::establish(&crate::CONFIG.database_url()).expect(\"Can't connect to DB\");\n+            diesel::sqlite::SqliteConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n         \n         // Scoped to a connection.\n@@ -272,7 +272,8 @@ mod sqlite_migrations {\n                 .expect(\"Failed to turn on WAL\");\n         }\n \n-        embedded_migrations::run_with_output(&connection, &mut std::io::stdout()).expect(\"Can't run migrations\");\n+        embedded_migrations::run_with_output(&connection, &mut std::io::stdout())?;\n+        Ok(())\n     }\n }\n \n@@ -281,11 +282,11 @@ mod mysql_migrations {\n     #[allow(unused_imports)]\n     embed_migrations!(\"migrations/mysql\");\n \n-    pub fn run_migrations() {\n+    pub fn run_migrations() -> Result<(), super::Error> {\n         use diesel::{Connection, RunQueryDsl};\n         // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n         let connection =\n-            diesel::mysql::MysqlConnection::establish(&crate::CONFIG.database_url()).expect(\"Can't connect to DB\");\n+            diesel::mysql::MysqlConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n \n         // Scoped to a connection/session.\n@@ -293,7 +294,8 @@ mod mysql_migrations {\n             .execute(&connection)\n             .expect(\"Failed to disable Foreign Key Checks during migrations\");\n \n-        embedded_migrations::run_with_output(&connection, &mut std::io::stdout()).expect(\"Can't run migrations\");\n+        embedded_migrations::run_with_output(&connection, &mut std::io::stdout())?;\n+        Ok(())\n     }\n }\n \n@@ -302,11 +304,11 @@ mod postgresql_migrations {\n     #[allow(unused_imports)]\n     embed_migrations!(\"migrations/postgresql\");\n \n-    pub fn run_migrations() {\n+    pub fn run_migrations() -> Result<(), super::Error> {\n         use diesel::{Connection, RunQueryDsl};\n         // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n         let connection =\n-            diesel::pg::PgConnection::establish(&crate::CONFIG.database_url()).expect(\"Can't connect to DB\");\n+            diesel::pg::PgConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n         \n         // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,\n@@ -319,6 +321,7 @@ mod postgresql_migrations {\n             .execute(&connection)\n             .expect(\"Failed to disable Foreign Key Checks during migrations\");\n \n-        embedded_migrations::run_with_output(&connection, &mut std::io::stdout()).expect(\"Can't run migrations\");\n+        embedded_migrations::run_with_output(&connection, &mut std::io::stdout())?;\n+        Ok(())\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "b9daa59e5d05f1050e6ba4199352953493a57dfb",
            "timestamp": "2020-10-09T10:29:02+02:00",
            "author": "Rob Watson",
            "commit_message": "Add DATABASE_MAX_CONNS config setting",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -51,7 +51,10 @@ macro_rules! generate_connections {\n                         {\n                             paste::paste!{ [< $name _migrations >]::run_migrations()?; }\n                             let manager = ConnectionManager::new(&url);\n-                            let pool = Pool::builder().build(manager).map_res(\"Failed to create pool\")?;\n+                            let pool = Pool::builder()\n+                                .max_size(CONFIG.database_max_conns())\n+                                .build(manager)\n+                                .map_res(\"Failed to create pool\")?;\n                             return Ok(Self::$name(pool));\n                         }\n                         #[cfg(not($name))]\n",
            "comment_added_diff": []
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -18,4 +18,4 @@ pub use self::folder::{Folder, FolderCipher};\n pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n pub use self::organization::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n pub use self::two_factor::{TwoFactor, TwoFactorType};\n-pub use self::user::{Invitation, User};\n+pub use self::user::{Invitation, User, UserStampException};\n",
            "comment_added_diff": []
        },
        {
            "commit": "235ff447367ec37adcef52921350271b3c5b9378",
            "timestamp": "2021-01-19T17:55:21+01:00",
            "author": "BlackDex",
            "commit_message": "Updated the admin interface\n\nMostly updated the admin interface, also some small other items.\n\n- Added more diagnostic information to (hopefully) decrease issue\n  reporting, or at least solve them quicker.\n- Added an option to generate a support string which can be used to\n  copy/paste on the forum or during the creation of an issue. It will\ntry to hide the sensitive information automatically.\n- Changed the `Created At` and `Last Active` info to be in a column and\n  able to sort them in the users overview.\n- Some small layout changes.\n- Updated javascript and css files to the latest versions available.\n- Decreased the png file sizes using `oxipng`\n- Updated target='_blank' links to have rel='noreferrer' to prevent\n  javascript window.opener modifications.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -172,7 +172,7 @@ fn hibp_breach(username: String) -> JsonResult {\n             \"Domain\": \"haveibeenpwned.com\",\n             \"BreachDate\": \"2019-08-18T00:00:00Z\",\n             \"AddedDate\": \"2019-08-18T00:00:00Z\",\n-            \"Description\": format!(\"Go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.<br/><br/>HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">https://haveibeenpwned.com/API/Key</a> to purchase an API key from HaveIBeenPwned.<br/><br/>\", account=username),\n+            \"Description\": format!(\"Go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.<br/><br/>HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\">https://haveibeenpwned.com/API/Key</a> to purchase an API key from HaveIBeenPwned.<br/><br/>\", account=username),\n             \"LogoPath\": \"bwrs_static/hibp.png\",\n             \"PwnCount\": 0,\n             \"DataClasses\": [\n",
            "comment_added_diff": [
                [
                    175,
                    "            \"Description\": format!(\"Go to: <a href=\\\"https://haveibeenpwned.com/account/{account}\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\">https://haveibeenpwned.com/account/{account}</a> for a manual check.<br/><br/>HaveIBeenPwned API key not set!<br/>Go to <a href=\\\"https://haveibeenpwned.com/API/Key\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\">https://haveibeenpwned.com/API/Key</a> to purchase an API key from HaveIBeenPwned.<br/><br/>\", account=username),"
                ]
            ]
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -3,6 +3,7 @@ mod ciphers;\n mod folders;\n mod organizations;\n pub mod two_factor;\n+mod sends;\n \n pub fn routes() -> Vec<Route> {\n     let mut mod_routes = routes![\n@@ -20,6 +21,7 @@ pub fn routes() -> Vec<Route> {\n     routes.append(&mut folders::routes());\n     routes.append(&mut organizations::routes());\n     routes.append(&mut two_factor::routes());\n+    routes.append(&mut sends::routes());\n     routes.append(&mut mod_routes);\n \n     routes\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -8,6 +8,7 @@ mod org_policy;\n mod organization;\n mod two_factor;\n mod user;\n+mod send;\n \n pub use self::attachment::Attachment;\n pub use self::cipher::Cipher;\n@@ -19,3 +20,4 @@ pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n pub use self::organization::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n pub use self::two_factor::{TwoFactor, TwoFactorType};\n pub use self::user::{Invitation, User, UserStampException};\n+pub use self::send::{Send, SendType};\n\\ No newline at end of file\n",
            "comment_added_diff": []
        },
        {
            "commit": "1fc6c30652b59a9dd7495393075df2a22246fa02",
            "timestamp": "2021-03-22T19:57:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send deletion thread and updated users revision",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -5,6 +5,8 @@ mod organizations;\n pub mod two_factor;\n mod sends;\n \n+pub use sends::start_send_deletion_scheduler;\n+\n pub fn routes() -> Vec<Route> {\n     let mut mod_routes = routes![\n         clear_device_token,\n",
            "comment_added_diff": []
        },
        {
            "commit": "1fc6c30652b59a9dd7495393075df2a22246fa02",
            "timestamp": "2021-03-22T19:57:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send deletion thread and updated users revision",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -11,6 +11,7 @@ use serde_json::Value;\n pub use crate::api::{\n     admin::routes as admin_routes,\n     core::routes as core_routes,\n+    core::start_send_deletion_scheduler,\n     icons::routes as icons_routes,\n     identity::routes as identity_routes,\n     notifications::routes as notifications_routes,\n",
            "comment_added_diff": []
        },
        {
            "commit": "1fc6c30652b59a9dd7495393075df2a22246fa02",
            "timestamp": "2021-03-22T19:57:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send deletion thread and updated users revision",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -37,6 +37,7 @@ macro_rules! generate_connections {\n         pub enum DbConn { $( #[cfg($name)] $name(PooledConnection<ConnectionManager< $ty >>), )+ }\n \n         #[allow(non_camel_case_types)]\n+        #[derive(Clone)]\n         pub enum DbPool { $( #[cfg($name)] $name(Pool<ConnectionManager< $ty >>), )+ }\n \n         impl DbPool {\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 11,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -34,17 +34,18 @@ pub fn routes() -> Vec<Route> {\n //\n use rocket::Route;\n use rocket_contrib::json::Json;\n+use rocket::response::Response;\n use serde_json::Value;\n \n use crate::{\n-    api::{EmptyResult, JsonResult, JsonUpcase},\n+    api::{JsonResult, JsonUpcase},\n     auth::Headers,\n     db::DbConn,\n     error::Error,\n };\n \n #[put(\"/devices/identifier/<uuid>/clear-token\")]\n-fn clear_device_token(uuid: String) -> EmptyResult {\n+fn clear_device_token<'a>(uuid: String) -> Response<'a> {\n     // This endpoint doesn't have auth header\n \n     let _ = uuid;\n@@ -53,11 +54,11 @@ fn clear_device_token(uuid: String) -> EmptyResult {\n     // This only clears push token\n     // https://github.com/bitwarden/core/blob/master/src/Api/Controllers/DevicesController.cs#L109\n     // https://github.com/bitwarden/core/blob/master/src/Core/Services/Implementations/DeviceService.cs#L37\n-    Ok(())\n+    Response::new()\n }\n \n #[put(\"/devices/identifier/<uuid>/token\", data = \"<data>\")]\n-fn put_device_token(uuid: String, data: JsonUpcase<Value>, headers: Headers) -> JsonResult {\n+fn put_device_token(uuid: String, data: JsonUpcase<Value>, headers: Headers) -> Json<Value> {\n     let _data: Value = data.into_inner().data;\n     // Data has a single string value \"PushToken\"\n     let _ = uuid;\n@@ -65,13 +66,13 @@ fn put_device_token(uuid: String, data: JsonUpcase<Value>, headers: Headers) ->\n \n     // TODO: This should save the push token, but we don't have push functionality\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"Id\": headers.device.uuid,\n         \"Name\": headers.device.name,\n         \"Type\": headers.device.atype,\n         \"Identifier\": headers.device.uuid,\n         \"CreationDate\": crate::util::format_date(&headers.device.created_at),\n-    })))\n+    }))\n }\n \n #[derive(Serialize, Deserialize, Debug)]\n@@ -85,11 +86,11 @@ struct GlobalDomain {\n const GLOBAL_DOMAINS: &str = include_str!(\"../../static/global_domains.json\");\n \n #[get(\"/settings/domains\")]\n-fn get_eq_domains(headers: Headers) -> JsonResult {\n+fn get_eq_domains(headers: Headers) -> Json<Value> {\n     _get_eq_domains(headers, false)\n }\n \n-fn _get_eq_domains(headers: Headers, no_excluded: bool) -> JsonResult {\n+fn _get_eq_domains(headers: Headers, no_excluded: bool) -> Json<Value> {\n     let user = headers.user;\n     use serde_json::from_str;\n \n@@ -106,11 +107,11 @@ fn _get_eq_domains(headers: Headers, no_excluded: bool) -> JsonResult {\n         globals.retain(|g| !g.Excluded);\n     }\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"EquivalentDomains\": equivalent_domains,\n         \"GlobalEquivalentDomains\": globals,\n         \"Object\": \"domains\",\n-    })))\n+    }))\n }\n \n #[derive(Deserialize, Debug)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -38,15 +38,15 @@ pub fn routes() -> Vec<Route> {\n }\n \n #[get(\"/two-factor\")]\n-fn get_twofactor(headers: Headers, conn: DbConn) -> JsonResult {\n+fn get_twofactor(headers: Headers, conn: DbConn) -> Json<Value> {\n     let twofactors = TwoFactor::find_by_user(&headers.user.uuid, &conn);\n     let twofactors_json: Vec<Value> = twofactors.iter().map(TwoFactor::to_json_provider).collect();\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"Data\": twofactors_json,\n         \"Object\": \"list\",\n         \"ContinuationToken\": null,\n-    })))\n+    }))\n }\n \n #[post(\"/two-factor/get-recover\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "57e17d064813162b1a1017368ce651ea89ea8aad",
            "timestamp": "2021-03-28T00:10:01+01:00",
            "author": "BlackDex",
            "commit_message": "Updated diagnostics page\n\n- Added reverse proxy check\n- Better deffinition of internet proxy\n- Added SQL Server version detection",
            "additions": 56,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -125,16 +125,34 @@ macro_rules! db_run {\n             $($(\n                 #[cfg($db)]\n                 crate::db::DbConn::$db(ref $conn) => {\n-                    paste::paste! { \n+                    paste::paste! {\n                         #[allow(unused)] use crate::db::[<__ $db _schema>]::{self as schema, *};\n                         #[allow(unused)] use [<__ $db _model>]::*;\n-                        #[allow(unused)] use crate::db::FromDb;  \n+                        #[allow(unused)] use crate::db::FromDb;\n                     }\n                     $body\n                 },\n             )+)+\n         }\n     };\n+\n+    // Same for all dbs\n+    ( @raw $conn:ident: $body:block ) => {\n+        db_run! { @raw $conn: sqlite, mysql, postgresql $body }\n+    };\n+\n+    // Different code for each db\n+    ( @raw $conn:ident: $( $($db:ident),+ $body:block )+ ) => {\n+        #[allow(unused)] use diesel::prelude::*;\n+        match $conn {\n+            $($(\n+                #[cfg($db)]\n+                crate::db::DbConn::$db(ref $conn) => {\n+                    $body\n+                },\n+            )+)+\n+        }\n+    };\n }\n \n \n@@ -144,7 +162,7 @@ pub trait FromDb {\n     fn from_db(self) -> Self::Output;\n }\n \n-// For each struct eg. Cipher, we create a CipherDb inside a module named __$db_model (where $db is sqlite, mysql or postgresql), \n+// For each struct eg. Cipher, we create a CipherDb inside a module named __$db_model (where $db is sqlite, mysql or postgresql),\n // to implement the Diesel traits. We also provide methods to convert between them and the basic structs. Later, that module will be auto imported when using db_run!\n #[macro_export]\n macro_rules! db_object {\n@@ -154,10 +172,10 @@ macro_rules! db_object {\n             $( $( #[$field_attr:meta] )* $vis:vis $field:ident : $typ:ty ),+\n             $(,)?\n         }\n-    )+ ) => { \n+    )+ ) => {\n         // Create the normal struct, without attributes\n         $( pub struct $name { $( /*$( #[$field_attr] )**/ $vis $field : $typ, )+ } )+\n-        \n+\n         #[cfg(sqlite)]\n         pub mod __sqlite_model     { $( db_object! { @db sqlite     |  $( #[$attr] )* | $name |  $( $( #[$field_attr] )* $field : $typ ),+ } )+ }\n         #[cfg(mysql)]\n@@ -178,7 +196,7 @@ macro_rules! db_object {\n             )+ }\n \n             impl [<$name Db>] {\n-                #[allow(clippy::wrong_self_convention)] \n+                #[allow(clippy::wrong_self_convention)]\n                 #[inline(always)] pub fn to_db(x: &super::$name) -> Self { Self { $( $field: x.$field.clone(), )+ } }\n             }\n \n@@ -222,6 +240,36 @@ pub fn backup_database() -> Result<(), Error> {\n     Ok(())\n }\n \n+\n+use diesel::sql_types::Text;\n+#[derive(QueryableByName,Debug)]\n+struct SqlVersion {\n+    #[sql_type = \"Text\"]\n+    version: String,\n+}\n+\n+/// Get the SQL Server version\n+pub fn get_sql_server_version(conn: &DbConn) -> String {\n+    db_run! {@raw conn:\n+        postgresql, mysql {\n+            match diesel::sql_query(\"SELECT version() AS version;\").get_result::<SqlVersion>(conn).ok() {\n+                Some(v) => {\n+                    v.version\n+                },\n+                _ => \"Unknown\".to_string()\n+            }\n+        }\n+        sqlite {\n+            match diesel::sql_query(\"SELECT sqlite_version() AS version;\").get_result::<SqlVersion>(conn).ok() {\n+                Some(v) => {\n+                    v.version\n+                },\n+                _ => \"Unknown\".to_string()\n+            }\n+        }\n+    }\n+}\n+\n /// Attempts to retrieve a single connection from the managed database pool. If\n /// no pool is currently managed, fails with an `InternalServerError` status. If\n /// no connections are available, fails with a `ServiceUnavailable` status.\n@@ -263,7 +311,7 @@ mod sqlite_migrations {\n         let connection =\n             diesel::sqlite::SqliteConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n-        \n+\n         // Scoped to a connection.\n         diesel::sql_query(\"PRAGMA foreign_keys = OFF\")\n             .execute(&connection)\n@@ -314,7 +362,7 @@ mod postgresql_migrations {\n         let connection =\n             diesel::pg::PgConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n-        \n+\n         // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,\n         // \"SET CONSTRAINTS sets the behavior of constraint checking within the\n         // current transaction\", so this setting probably won't take effect for\n",
            "comment_added_diff": [
                [
                    139,
                    "    // Same for all dbs"
                ],
                [
                    144,
                    "    // Different code for each db"
                ],
                [
                    165,
                    "// For each struct eg. Cipher, we create a CipherDb inside a module named __$db_model (where $db is sqlite, mysql or postgresql),"
                ],
                [
                    251,
                    "/// Get the SQL Server version"
                ]
            ]
        },
        {
            "commit": "9caf4bf38381f4ec0680a4b29ba26f9c1921fba0",
            "timestamp": "2021-03-30T21:45:10+02:00",
            "author": "BlackDex",
            "commit_message": "Misc changes.\n\nSome small changes in general:\n- Moved the SQL Version check struct into the function.\n- Updated hadolint to 2.0.0\n- Fixed hadolint 2.0.0 warnings\n- Updated github workflows\n- Added .editorconfig for some general shared editor settings.",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -241,15 +241,15 @@ pub fn backup_database() -> Result<(), Error> {\n }\n \n \n-use diesel::sql_types::Text;\n-#[derive(QueryableByName,Debug)]\n-struct SqlVersion {\n-    #[sql_type = \"Text\"]\n-    version: String,\n-}\n-\n /// Get the SQL Server version\n pub fn get_sql_server_version(conn: &DbConn) -> String {\n+    use diesel::sql_types::Text;\n+    #[derive(QueryableByName)]\n+    struct SqlVersion {\n+        #[sql_type = \"Text\"]\n+        version: String,\n+    }\n+\n     db_run! {@raw conn:\n         postgresql, mysql {\n             match diesel::sql_query(\"SELECT version() AS version;\").get_result::<SqlVersion>(conn).ok() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -2,8 +2,8 @@ mod accounts;\n mod ciphers;\n mod folders;\n mod organizations;\n-pub mod two_factor;\n mod sends;\n+pub mod two_factor;\n \n pub use sends::start_send_deletion_scheduler;\n \n@@ -32,9 +32,9 @@ pub fn routes() -> Vec<Route> {\n //\n // Move this somewhere else\n //\n+use rocket::response::Response;\n use rocket::Route;\n use rocket_contrib::json::Json;\n-use rocket::response::Response;\n use serde_json::Value;\n \n use crate::{\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 3,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -25,7 +25,6 @@ pub mod __mysql_schema;\n #[path = \"schemas/postgresql/schema.rs\"]\n pub mod __postgresql_schema;\n \n-\n // This is used to generate the main DbConn and DbPool enums, which contain one variant for each database supported\n macro_rules! generate_connections {\n     ( $( $name:ident: $ty:ty ),+ ) => {\n@@ -110,7 +109,6 @@ impl DbConnType {\n     }\n }\n \n-\n #[macro_export]\n macro_rules! db_run {\n     // Same for all dbs\n@@ -155,7 +153,6 @@ macro_rules! db_run {\n     };\n }\n \n-\n pub trait FromDb {\n     type Output;\n     #[allow(clippy::wrong_self_convention)]\n@@ -240,7 +237,6 @@ pub fn backup_database() -> Result<(), Error> {\n     Ok(())\n }\n \n-\n /// Get the SQL Server version\n pub fn get_sql_server_version(conn: &DbConn) -> String {\n     use diesel::sql_types::Text;\n@@ -308,8 +304,7 @@ mod sqlite_migrations {\n \n         use diesel::{Connection, RunQueryDsl};\n         // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n-        let connection =\n-            diesel::sqlite::SqliteConnection::establish(&crate::CONFIG.database_url())?;\n+        let connection = diesel::sqlite::SqliteConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n \n         // Scoped to a connection.\n@@ -337,8 +332,7 @@ mod mysql_migrations {\n     pub fn run_migrations() -> Result<(), super::Error> {\n         use diesel::{Connection, RunQueryDsl};\n         // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n-        let connection =\n-            diesel::mysql::MysqlConnection::establish(&crate::CONFIG.database_url())?;\n+        let connection = diesel::mysql::MysqlConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n \n         // Scoped to a connection/session.\n@@ -359,8 +353,7 @@ mod postgresql_migrations {\n     pub fn run_migrations() -> Result<(), super::Error> {\n         use diesel::{Connection, RunQueryDsl};\n         // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n-        let connection =\n-            diesel::pg::PgConnection::establish(&crate::CONFIG.database_url())?;\n+        let connection = diesel::pg::PgConnection::establish(&crate::CONFIG.database_url())?;\n         // Disable Foreign Key Checks during migration\n \n         // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -6,9 +6,9 @@ mod favorite;\n mod folder;\n mod org_policy;\n mod organization;\n+mod send;\n mod two_factor;\n mod user;\n-mod send;\n \n pub use self::attachment::Attachment;\n pub use self::cipher::Cipher;\n@@ -18,6 +18,6 @@ pub use self::favorite::Favorite;\n pub use self::folder::{Folder, FolderCipher};\n pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n pub use self::organization::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n+pub use self::send::{Send, SendType};\n pub use self::two_factor::{TwoFactor, TwoFactorType};\n pub use self::user::{Invitation, User, UserStampException};\n-pub use self::send::{Send, SendType};\n\\ No newline at end of file\n",
            "comment_added_diff": []
        },
        {
            "commit": "95fc88ae5bef5f4d1e9a8da4f5de7c955fb75a19",
            "timestamp": "2021-04-05T15:09:16+02:00",
            "author": "BlackDex",
            "commit_message": "Some admin interface updates.\n\n- Fixed bug when web-vault is disabled.\n- Updated sql-server version check to be simpler thx to @weiznich ( https://github.com/dani-garcia/bitwarden_rs/pull/1548#discussion_r604767196 )\n- Use `VACUUM INTO` to create a SQLite backup instead of using the external sqlite3 application.\n  - This also removes the dependancy of having the sqlite3 packages installed on the final image unnecessary, and thus removed it.\n- Updated backup filename to also have the current time.\n- Add specific bitwarden_rs web-vault version check (to match letter patched versions)\n  Will work when https://github.com/dani-garcia/bw_web_builds/pull/33 is build (But still works without it also).",
            "additions": 20,
            "deletions": 36,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,3 @@\n-use std::process::Command;\n-\n use chrono::prelude::*;\n use diesel::r2d2::{ConnectionManager, Pool, PooledConnection};\n use rocket::{\n@@ -144,6 +142,7 @@ macro_rules! db_run {\n     // Different code for each db\n     ( @raw $conn:ident: $( $($db:ident),+ $body:block )+ ) => {\n         #[allow(unused)] use diesel::prelude::*;\n+        #[allow(unused_variables)]\n         match $conn {\n             $($(\n                 #[cfg($db)]\n@@ -221,21 +220,21 @@ macro_rules! db_object {\n // Reexport the models, needs to be after the macros are defined so it can access them\n pub mod models;\n \n-/// Creates a back-up of the database using sqlite3\n-pub fn backup_database() -> Result<(), Error> {\n-    use std::path::Path;\n-    let db_url = CONFIG.database_url();\n-    let db_path = Path::new(&db_url).parent().unwrap();\n-\n-    let now: DateTime<Utc> = Utc::now();\n-    let file_date = now.format(\"%Y%m%d\").to_string();\n-    let backup_command: String = format!(\"{}{}{}\", \".backup 'db_\", file_date, \".sqlite3'\");\n-\n-    Command::new(\"sqlite3\")\n-        .current_dir(db_path)\n-        .args(&[\"db.sqlite3\", &backup_command])\n-        .output()\n-        .expect(\"Can't open database, sqlite3 is not available, make sure it's installed and available on the PATH\");\n+/// Creates a back-up of the sqlite database\n+/// MySQL/MariaDB and PostgreSQL are not supported.\n+pub fn backup_database(conn: &DbConn) -> Result<(), Error> {\n+    db_run! {@raw conn:\n+        postgresql, mysql {\n+            err!(\"PostgreSQL and MySQL/MariaDB do not support this backup feature\");\n+        }\n+        sqlite {\n+            use std::path::Path;\n+            let db_url = CONFIG.database_url();\n+            let db_path = Path::new(&db_url).parent().unwrap().to_string_lossy();\n+            let file_date = Utc::now().format(\"%Y%m%d_%H%M%S\").to_string();\n+            diesel::sql_query(format!(\"VACUUM INTO '{}/db_{}.sqlite3'\", db_path, file_date)).execute(conn)?;\n+        }\n+    }\n \n     Ok(())\n }\n@@ -243,29 +242,14 @@ pub fn backup_database() -> Result<(), Error> {\n \n /// Get the SQL Server version\n pub fn get_sql_server_version(conn: &DbConn) -> String {\n-    use diesel::sql_types::Text;\n-    #[derive(QueryableByName)]\n-    struct SqlVersion {\n-        #[sql_type = \"Text\"]\n-        version: String,\n-    }\n-\n     db_run! {@raw conn:\n         postgresql, mysql {\n-            match diesel::sql_query(\"SELECT version() AS version;\").get_result::<SqlVersion>(conn).ok() {\n-                Some(v) => {\n-                    v.version\n-                },\n-                _ => \"Unknown\".to_string()\n-            }\n+            no_arg_sql_function!(version, diesel::sql_types::Text);\n+            diesel::select(version).get_result::<String>(conn).unwrap_or_else(|_| \"Unknown\".to_string())\n         }\n         sqlite {\n-            match diesel::sql_query(\"SELECT sqlite_version() AS version;\").get_result::<SqlVersion>(conn).ok() {\n-                Some(v) => {\n-                    v.version\n-                },\n-                _ => \"Unknown\".to_string()\n-            }\n+            no_arg_sql_function!(sqlite_version, diesel::sql_types::Text);\n+            diesel::select(sqlite_version).get_result::<String>(conn).unwrap_or_else(|_| \"Unknown\".to_string())\n         }\n     }\n }\n",
            "comment_added_diff": [
                [
                    223,
                    "/// Creates a back-up of the sqlite database"
                ],
                [
                    224,
                    "/// MySQL/MariaDB and PostgreSQL are not supported."
                ]
            ]
        },
        {
            "commit": "73ff8d79f70b36483d1d33587cdc9549c8e472bd",
            "timestamp": "2021-04-05T23:07:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add a generic job scheduler\n\nAlso rewrite deletion of old sends using the job scheduler.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ mod organizations;\n pub mod two_factor;\n mod sends;\n \n-pub use sends::start_send_deletion_scheduler;\n+pub use sends::purge_sends;\n \n pub fn routes() -> Vec<Route> {\n     let mut mod_routes = routes![\n",
            "comment_added_diff": []
        },
        {
            "commit": "73ff8d79f70b36483d1d33587cdc9549c8e472bd",
            "timestamp": "2021-04-05T23:07:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add a generic job scheduler\n\nAlso rewrite deletion of old sends using the job scheduler.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -10,8 +10,8 @@ use serde_json::Value;\n \n pub use crate::api::{\n     admin::routes as admin_routes,\n+    core::purge_sends,\n     core::routes as core_routes,\n-    core::start_send_deletion_scheduler,\n     icons::routes as icons_routes,\n     identity::routes as identity_routes,\n     notifications::routes as notifications_routes,\n",
            "comment_added_diff": []
        },
        {
            "commit": "d77333576b1268cd24f17348ffe6d72e07855f54",
            "timestamp": "2021-04-05T23:07:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for auto-deleting trashed items\n\nUpstream will soon auto-delete trashed items after 30 days, but some people\nuse the trash as an archive folder, so to avoid unexpected data loss, this\nimplementation requires the user to explicitly enable auto-deletion.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -5,6 +5,7 @@ mod organizations;\n pub mod two_factor;\n mod sends;\n \n+pub use ciphers::purge_trashed_ciphers;\n pub use sends::purge_sends;\n \n pub fn routes() -> Vec<Route> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "d77333576b1268cd24f17348ffe6d72e07855f54",
            "timestamp": "2021-04-05T23:07:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for auto-deleting trashed items\n\nUpstream will soon auto-delete trashed items after 30 days, but some people\nuse the trash as an archive folder, so to avoid unexpected data loss, this\nimplementation requires the user to explicitly enable auto-deletion.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -11,6 +11,7 @@ use serde_json::Value;\n pub use crate::api::{\n     admin::routes as admin_routes,\n     core::purge_sends,\n+    core::purge_trashed_ciphers,\n     core::routes as core_routes,\n     icons::routes as icons_routes,\n     identity::routes as identity_routes,\n",
            "comment_added_diff": []
        },
        {
            "commit": "155109dea120e109e1e027d4e1312b6adad4c231",
            "timestamp": "2021-04-06T21:04:37+01:00",
            "author": "Jake Howard",
            "commit_message": "Extract client creation to a single place",
            "additions": 2,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -43,6 +43,7 @@ use crate::{\n     auth::Headers,\n     db::DbConn,\n     error::Error,\n+    util::get_reqwest_client,\n };\n \n #[put(\"/devices/identifier/<uuid>/clear-token\")]\n@@ -147,20 +148,16 @@ fn put_eq_domains(data: JsonUpcase<EquivDomainData>, headers: Headers, conn: DbC\n \n #[get(\"/hibp/breach?<username>\")]\n fn hibp_breach(username: String) -> JsonResult {\n-    let user_agent = \"Bitwarden_RS\";\n     let url = format!(\n         \"https://haveibeenpwned.com/api/v3/breachedaccount/{}?truncateResponse=false&includeUnverified=false\",\n         username\n     );\n \n-    use reqwest::{blocking::Client, header::USER_AGENT};\n-\n     if let Some(api_key) = crate::CONFIG.hibp_api_key() {\n-        let hibp_client = Client::builder().build()?;\n+        let hibp_client = get_reqwest_client();\n \n         let res = hibp_client\n             .get(&url)\n-            .header(USER_AGENT, user_agent)\n             .header(\"hibp-api-key\", api_key)\n             .send()?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 3,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -8,14 +8,8 @@ pub mod two_factor;\n pub use sends::start_send_deletion_scheduler;\n \n pub fn routes() -> Vec<Route> {\n-    let mut mod_routes = routes![\n-        clear_device_token,\n-        put_device_token,\n-        get_eq_domains,\n-        post_eq_domains,\n-        put_eq_domains,\n-        hibp_breach,\n-    ];\n+    let mut mod_routes =\n+        routes![clear_device_token, put_device_token, get_eq_domains, post_eq_domains, put_eq_domains, hibp_breach,];\n \n     let mut routes = Vec::new();\n     routes.append(&mut accounts::routes());\n@@ -157,11 +151,7 @@ fn hibp_breach(username: String) -> JsonResult {\n     if let Some(api_key) = crate::CONFIG.hibp_api_key() {\n         let hibp_client = Client::builder().build()?;\n \n-        let res = hibp_client\n-            .get(&url)\n-            .header(USER_AGENT, user_agent)\n-            .header(\"hibp-api-key\", api_key)\n-            .send()?;\n+        let res = hibp_client.get(&url).header(USER_AGENT, user_agent).header(\"hibp-api-key\", api_key).send()?;\n \n         // If we get a 404, return a 404, it means no breached accounts\n         if res.status() == 404 {\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 1,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -20,13 +20,7 @@ pub mod u2f;\n pub mod yubikey;\n \n pub fn routes() -> Vec<Route> {\n-    let mut routes = routes![\n-        get_twofactor,\n-        get_recover,\n-        recover,\n-        disable_twofactor,\n-        disable_twofactor_put,\n-    ];\n+    let mut routes = routes![get_twofactor, get_recover, recover, disable_twofactor, disable_twofactor_put,];\n \n     routes.append(&mut authenticator::routes());\n     routes.append(&mut duo::routes());\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -54,9 +54,9 @@ impl NumberOrString {\n         use std::num::ParseIntError as PIE;\n         match self {\n             NumberOrString::Number(n) => Ok(n),\n-            NumberOrString::String(s) => s\n-                .parse()\n-                .map_err(|e: PIE| crate::Error::new(\"Can't convert to number\", e.to_string())),\n+            NumberOrString::String(s) => {\n+                s.parse().map_err(|e: PIE| crate::Error::new(\"Can't convert to number\", e.to_string()))\n+            }\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 1,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -314,9 +314,7 @@ mod sqlite_migrations {\n \n         // Turn on WAL in SQLite\n         if crate::CONFIG.enable_db_wal() {\n-            diesel::sql_query(\"PRAGMA journal_mode=wal\")\n-                .execute(&connection)\n-                .expect(\"Failed to turn on WAL\");\n+            diesel::sql_query(\"PRAGMA journal_mode=wal\").execute(&connection).expect(\"Failed to turn on WAL\");\n         }\n \n         embedded_migrations::run_with_output(&connection, &mut std::io::stdout())?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "d75a80bd2dbe21e5a1eb2b0a6b18a9422441e071",
            "timestamp": "2021-04-11T22:57:17-04:00",
            "author": "Olivier Martin",
            "commit_message": "Resolves dani-garcia/bitwarden_rs#981\n* a user without 2fa trying to join a 2fa org will fail, but user gets an email to enable 2fa\n* a user disabling 2fa will be removed from 2fa orgs; user gets an email for each org\n* an org enabling 2fa policy will remove users without 2fa; users get an email",
            "additions": 19,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -8,9 +8,10 @@ use crate::{\n     auth::Headers,\n     crypto,\n     db::{\n-        models::{TwoFactor, User},\n+        models::*,\n         DbConn,\n     },\n+    mail,\n };\n \n pub mod authenticator;\n@@ -134,6 +135,23 @@ fn disable_twofactor(data: JsonUpcase<DisableTwoFactorData>, headers: Headers, c\n         twofactor.delete(&conn)?;\n     }\n \n+    let twofactor_disabled = TwoFactor::find_by_user(&user.uuid, &conn).is_empty();\n+\n+    if twofactor_disabled {\n+        let policy_type = OrgPolicyType::TwoFactorAuthentication;\n+        let org_list = UserOrganization::find_by_user_and_policy(&user.uuid, policy_type, &conn);\n+\n+        for user_org in org_list.into_iter() {\n+\n+            if user_org.atype < UserOrgType::Admin {\n+                let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n+\n+                mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n+                user_org.delete(&conn)?;\n+            }\n+        }\n+    }\n+\n     Ok(Json(json!({\n         \"Enabled\": false,\n         \"Type\": type_,\n",
            "comment_added_diff": []
        },
        {
            "commit": "1db37bf3d06543c890612ff88193813035763034",
            "timestamp": "2021-04-12T21:54:57-04:00",
            "author": "Olivier Martin",
            "commit_message": "make error toast display detailed message\nreplace invite accept error message with the one from upstream\ncheck if config mail is enabled",
            "additions": 5,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -11,7 +11,7 @@ use crate::{\n         models::*,\n         DbConn,\n     },\n-    mail,\n+    mail, CONFIG,\n };\n \n pub mod authenticator;\n@@ -144,9 +144,11 @@ fn disable_twofactor(data: JsonUpcase<DisableTwoFactorData>, headers: Headers, c\n         for user_org in org_list.into_iter() {\n \n             if user_org.atype < UserOrgType::Admin {\n-                let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n \n-                mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n+                if CONFIG.mail_enabled() {\n+                    let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n+                    mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n+                }\n                 user_org.delete(&conn)?;\n             }\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "89a68741d6c049e827e84dc224566d1a61dda1f7",
            "timestamp": "2021-04-16T14:49:59-04:00",
            "author": "Olivier Martin",
            "commit_message": "ran cargo fmt --all",
            "additions": 1,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -7,10 +7,7 @@ use crate::{\n     api::{JsonResult, JsonUpcase, NumberOrString, PasswordData},\n     auth::Headers,\n     crypto,\n-    db::{\n-        models::*,\n-        DbConn,\n-    },\n+    db::{models::*, DbConn},\n     mail, CONFIG,\n };\n \n@@ -136,9 +133,7 @@ fn disable_twofactor(data: JsonUpcase<DisableTwoFactorData>, headers: Headers, c\n         let org_list = UserOrganization::find_by_user_and_policy(&user.uuid, policy_type, &conn);\n \n         for user_org in org_list.into_iter() {\n-\n             if user_org.atype < UserOrgType::Admin {\n-\n                 if CONFIG.mail_enabled() {\n                     let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n                     mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "1e5306b8203a7ebe24047910e6c690c18c6d827a",
            "timestamp": "2021-04-29T16:01:04+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove warning when compiling only with mysql and add compatibility mode with the old docker script names",
            "additions": 2,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,3 @@\n-use chrono::prelude::*;\n use diesel::r2d2::{ConnectionManager, Pool, PooledConnection};\n use rocket::{\n     http::Status,\n@@ -228,12 +227,11 @@ pub fn backup_database(conn: &DbConn) -> Result<(), Error> {\n             use std::path::Path;\n             let db_url = CONFIG.database_url();\n             let db_path = Path::new(&db_url).parent().unwrap().to_string_lossy();\n-            let file_date = Utc::now().format(\"%Y%m%d_%H%M%S\").to_string();\n+            let file_date = chrono::Utc::now().format(\"%Y%m%d_%H%M%S\").to_string();\n             diesel::sql_query(format!(\"VACUUM INTO '{}/db_{}.sqlite3'\", db_path, file_date)).execute(conn)?;\n+            Ok(())\n         }\n     }\n-\n-    Ok(())\n }\n \n /// Get the SQL Server version\n",
            "comment_added_diff": []
        },
        {
            "commit": "b8010be26b4e2d489f55ba01622f9b6e1685b3b1",
            "timestamp": "2021-05-02T17:49:25+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Extract some FromDb trait impls outside the macros so they aren't repeated, and fix some clippy lints",
            "additions": 19,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -157,6 +157,24 @@ pub trait FromDb {\n     fn from_db(self) -> Self::Output;\n }\n \n+impl<T: FromDb> FromDb for Vec<T> {\n+    type Output = Vec<T::Output>;\n+    #[allow(clippy::wrong_self_convention)]\n+    #[inline(always)]\n+    fn from_db(self) -> Self::Output {\n+        self.into_iter().map(crate::db::FromDb::from_db).collect()\n+    }\n+}\n+\n+impl<T: FromDb> FromDb for Option<T> {\n+    type Output = Option<T::Output>;\n+    #[allow(clippy::wrong_self_convention)]\n+    #[inline(always)]\n+    fn from_db(self) -> Self::Output {\n+        self.map(crate::db::FromDb::from_db)\n+    }\n+}\n+\n // For each struct eg. Cipher, we create a CipherDb inside a module named __$db_model (where $db is sqlite, mysql or postgresql),\n // to implement the Diesel traits. We also provide methods to convert between them and the basic structs. Later, that module will be auto imported when using db_run!\n #[macro_export]\n@@ -197,18 +215,9 @@ macro_rules! db_object {\n \n             impl crate::db::FromDb for [<$name Db>] {\n                 type Output = super::$name;\n+                #[allow(clippy::wrong_self_convention)]\n                 #[inline(always)] fn from_db(self) -> Self::Output { super::$name { $( $field: self.$field, )+ } }\n             }\n-\n-            impl crate::db::FromDb for Vec<[<$name Db>]> {\n-                type Output = Vec<super::$name>;\n-                #[inline(always)] fn from_db(self) -> Self::Output { self.into_iter().map(crate::db::FromDb::from_db).collect() }\n-            }\n-\n-            impl crate::db::FromDb for Option<[<$name Db>]> {\n-                type Output = Option<super::$name>;\n-                #[inline(always)] fn from_db(self) -> Self::Output { self.map(crate::db::FromDb::from_db) }\n-            }\n         }\n     };\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -17,6 +17,7 @@ pub mod authenticator;\n pub mod duo;\n pub mod email;\n pub mod u2f;\n+pub mod webauthn;\n pub mod yubikey;\n \n pub fn routes() -> Vec<Route> {\n@@ -26,6 +27,7 @@ pub fn routes() -> Vec<Route> {\n     routes.append(&mut duo::routes());\n     routes.append(&mut email::routes());\n     routes.append(&mut u2f::routes());\n+    routes.append(&mut webauthn::routes());\n     routes.append(&mut yubikey::routes());\n \n     routes\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -51,10 +51,10 @@ impl NumberOrString {\n         }\n     }\n \n-    fn into_i32(self) -> ApiResult<i32> {\n+    fn into_i32(&self) -> ApiResult<i32> {\n         use std::num::ParseIntError as PIE;\n         match self {\n-            NumberOrString::Number(n) => Ok(n),\n+            NumberOrString::Number(n) => Ok(*n),\n             NumberOrString::String(s) => {\n                 s.parse().map_err(|e: PIE| crate::Error::new(\"Can't convert to number\", e.to_string()))\n             }\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -114,7 +114,7 @@ macro_rules! db_run {\n     };\n \n     // Different code for each db\n-    ( $conn:ident: $( $($db:ident),+ $body:block )+ ) => {\n+    ( $conn:ident: $( $($db:ident),+ $body:block )+ ) => {{\n         #[allow(unused)] use diesel::prelude::*;\n         match $conn {\n             $($(\n@@ -128,7 +128,7 @@ macro_rules! db_run {\n                     $body\n                 },\n             )+)+\n-        }\n+        }}\n     };\n \n     // Same for all dbs\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -51,6 +51,7 @@ impl NumberOrString {\n         }\n     }\n \n+    #[allow(clippy::wrong_self_convention)]\n     fn into_i32(&self) -> ApiResult<i32> {\n         use std::num::ParseIntError as PIE;\n         match self {\n",
            "comment_added_diff": []
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 2,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -27,7 +27,6 @@ pub fn routes() -> Vec<Route> {\n //\n // Move this somewhere else\n //\n-use rocket::response::Response;\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n@@ -41,7 +40,7 @@ use crate::{\n };\n \n #[put(\"/devices/identifier/<uuid>/clear-token\")]\n-fn clear_device_token<'a>(uuid: String) -> Response<'a> {\n+fn clear_device_token<'a>(uuid: String) -> &'static str {\n     // This endpoint doesn't have auth header\n \n     let _ = uuid;\n@@ -50,7 +49,7 @@ fn clear_device_token<'a>(uuid: String) -> Response<'a> {\n     // This only clears push token\n     // https://github.com/bitwarden/core/blob/master/src/Api/Controllers/DevicesController.cs#L109\n     // https://github.com/bitwarden/core/blob/master/src/Core/Services/Implementations/DeviceService.cs#L37\n-    Response::new()\n+    \"\"\n }\n \n #[put(\"/devices/identifier/<uuid>/token\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0dcea757641b4f914960704066f2421622b69285",
            "timestamp": "2021-06-26T13:35:09+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused lifetime and double referencing",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -40,7 +40,7 @@ use crate::{\n };\n \n #[put(\"/devices/identifier/<uuid>/clear-token\")]\n-fn clear_device_token<'a>(uuid: String) -> &'static str {\n+fn clear_device_token(uuid: String) -> &'static str {\n     // This endpoint doesn't have auth header\n \n     let _ = uuid;\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,6 @@\n mod accounts;\n mod ciphers;\n+mod emergency_access;\n mod folders;\n mod organizations;\n mod sends;\n@@ -15,6 +16,7 @@ pub fn routes() -> Vec<Route> {\n     let mut routes = Vec::new();\n     routes.append(&mut accounts::routes());\n     routes.append(&mut ciphers::routes());\n+    routes.append(&mut emergency_access::routes());\n     routes.append(&mut folders::routes());\n     routes.append(&mut organizations::routes());\n     routes.append(&mut two_factor::routes());\n",
            "comment_added_diff": []
        },
        {
            "commit": "89b5f7c98d0e655f712e8adc732b2cf32adc771d",
            "timestamp": "2021-08-22T13:46:48+02:00",
            "author": "BlackDex",
            "commit_message": "Dependency updates\n\nUpdated several dependencies and switch to different totp library.\n\n- Switch oath with totp-lite\n  oauth hasn't been updated in a long while and some dependencies could not be updated any more\n  It now also validates a preseeding 0, as the previous library returned an int instead of a str which stripped a leading 0\n- Updated rust to the current latest nightly (including build image)\n- Updated bootstrap css and js\n- Updated hadolint to latest version\n- Updated default rust image from v1.53 to v1.54\n- Updated new nightly build/clippy messages",
            "additions": 0,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -278,7 +278,6 @@ impl<'a, 'r> FromRequest<'a, 'r> for DbConn {\n // https://docs.rs/diesel_migrations/*/diesel_migrations/macro.embed_migrations.html\n #[cfg(sqlite)]\n mod sqlite_migrations {\n-    #[allow(unused_imports)]\n     embed_migrations!(\"migrations/sqlite\");\n \n     pub fn run_migrations() -> Result<(), super::Error> {\n@@ -315,7 +314,6 @@ mod sqlite_migrations {\n \n #[cfg(mysql)]\n mod mysql_migrations {\n-    #[allow(unused_imports)]\n     embed_migrations!(\"migrations/mysql\");\n \n     pub fn run_migrations() -> Result<(), super::Error> {\n@@ -336,7 +334,6 @@ mod mysql_migrations {\n \n #[cfg(postgresql)]\n mod postgresql_migrations {\n-    #[allow(unused_imports)]\n     embed_migrations!(\"migrations/postgresql\");\n \n     pub fn run_migrations() -> Result<(), super::Error> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -7,6 +7,7 @@ mod sends;\n pub mod two_factor;\n \n pub use ciphers::purge_trashed_ciphers;\n+pub use emergency_access::{emergency_notification_reminder_job, emergency_request_timeout_job};\n pub use sends::purge_sends;\n \n pub fn routes() -> Vec<Route> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -13,6 +13,7 @@ pub use crate::api::{\n     core::purge_sends,\n     core::purge_trashed_ciphers,\n     core::routes as core_routes,\n+    core::{emergency_notification_reminder_job, emergency_request_timeout_job},\n     icons::routes as icons_routes,\n     identity::routes as identity_routes,\n     notifications::routes as notifications_routes,\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -2,6 +2,7 @@ mod attachment;\n mod cipher;\n mod collection;\n mod device;\n+mod emergency_access;\n mod favorite;\n mod folder;\n mod org_policy;\n@@ -14,6 +15,7 @@ pub use self::attachment::Attachment;\n pub use self::cipher::Cipher;\n pub use self::collection::{Collection, CollectionCipher, CollectionUser};\n pub use self::device::Device;\n+pub use self::emergency_access::{EmergencyAccess, EmergencyAccessStatus, EmergencyAccessType};\n pub use self::favorite::Favorite;\n pub use self::folder::{Folder, FolderCipher};\n pub use self::org_policy::{OrgPolicy, OrgPolicyType};\n",
            "comment_added_diff": []
        }
    ],
    "web.rs": [
        {
            "commit": "edc482c8ea36fdefa2913cfd54eb52af5045eb24",
            "timestamp": "2019-10-08T22:29:12+02:00",
            "author": "BlackDex",
            "commit_message": "Changed HIBP Error message.\n\n- Moved the manual link to the check to the top.\n- Clearified that hibp is a payed service.\n- Changed error logo to hibp logo.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -69,6 +69,7 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n         \"mail-github.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/mail-github.png\"))),\n         \"logo-gray.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/logo-gray.png\"))),\n         \"error-x.svg\" => Ok(Content(ContentType::SVG, include_bytes!(\"../static/images/error-x.svg\"))),\n+        \"hibp.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/hibp.png\"))),\n \n         \"bootstrap.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/bootstrap.css\"))),\n         \"bootstrap-native-v4.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native-v4.js\"))),\n",
            "comment_added_diff": []
        },
        {
            "commit": "8d1b72b9512b90775e671b7ba08cd552a0aabd13",
            "timestamp": "2019-12-06T22:46:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Collapsed log messages from 3 lines per request to 2 and hidden the ones valued as less informative.\nUse LOG_LEVEL debug or trace to recover them.\n\nRemoved LOG_MOUNTS and bundled it with LOG_LEVEL debug and trace.\n\nRemoved duplicate error messages\n\nMade websocket not proxied message more prominent, but only print it once.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -12,6 +12,8 @@ use crate::error::Error;\n use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n+    // If addding more routes here, consider also adding them to \n+    // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n     if CONFIG.web_vault_enabled() {\n         routes![web_index, app_id, web_files, attachments, alive, static_files]\n     } else {\n",
            "comment_added_diff": [
                [
                    15,
                    "    // If addding more routes here, consider also adding them to"
                ],
                [
                    16,
                    "    // crate::utils::LOGGED_ROUTES to make sure they appear in the log"
                ]
            ]
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 4,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -7,12 +7,12 @@ use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::util::Cached;\n use crate::error::Error;\n+use crate::util::Cached;\n use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n-    // If addding more routes here, consider also adding them to \n+    // If addding more routes here, consider also adding them to\n     // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n     if CONFIG.web_vault_enabled() {\n         routes![web_index, app_id, web_files, attachments, alive, static_files]\n@@ -23,9 +23,7 @@ pub fn routes() -> Vec<Route> {\n \n #[get(\"/\")]\n fn web_index() -> Cached<Option<NamedFile>> {\n-    Cached::short(NamedFile::open(\n-        Path::new(&CONFIG.web_vault_folder()).join(\"index.html\"),\n-    ).ok())\n+    Cached::short(NamedFile::open(Path::new(&CONFIG.web_vault_folder()).join(\"index.html\")).ok())\n }\n \n #[get(\"/app-id.json\")]\n@@ -79,4 +77,4 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n         \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n         _ => err!(\"Image not found\"),\n     }\n-}\n\\ No newline at end of file\n+}\n",
            "comment_added_diff": [
                [
                    15,
                    "    // If addding more routes here, consider also adding them to"
                ]
            ]
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 12,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -37,7 +37,17 @@ fn app_id() -> Cached<Content<Json<Value>>> {\n             {\n             \"version\": { \"major\": 1, \"minor\": 0 },\n             \"ids\": [\n-                &CONFIG.domain(),\n+                // Per <https://fidoalliance.org/specs/fido-v2.0-id-20180227/fido-appid-and-facets-v2.0-id-20180227.html#determining-the-facetid-of-a-calling-application>:\n+                //\n+                // \"In the Web case, the FacetID MUST be the Web Origin [RFC6454]\n+                // of the web page triggering the FIDO operation, written as\n+                // a URI with an empty path. Default ports are omitted and any\n+                // path component is ignored.\"\n+                //\n+                // This leaves it unclear as to whether the path must be empty,\n+                // or whether it can be non-empty and will be ignored. To be on\n+                // the safe side, use a proper web origin (with empty path).\n+                &CONFIG.domain_origin(),\n                 \"ios:bundle-id:com.8bit.bitwarden\",\n                 \"android:apk-key-hash:dUGFzUzf3lmHSLBDBIv+WaFyZMI\" ]\n             }]\n@@ -75,6 +85,6 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n         \"bootstrap-native-v4.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native-v4.js\"))),\n         \"md5.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/md5.js\"))),\n         \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n-        _ => err!(\"Image not found\"),\n+        _ => err!(format!(\"Static file not found: {}\", filename)),\n     }\n }\n",
            "comment_added_diff": [
                [
                    40,
                    "                // Per <https://fidoalliance.org/specs/fido-v2.0-id-20180227/fido-appid-and-facets-v2.0-id-20180227.html#determining-the-facetid-of-a-calling-application>:"
                ],
                [
                    41,
                    "                //"
                ],
                [
                    42,
                    "                // \"In the Web case, the FacetID MUST be the Web Origin [RFC6454]"
                ],
                [
                    43,
                    "                // of the web page triggering the FIDO operation, written as"
                ],
                [
                    44,
                    "                // a URI with an empty path. Default ports are omitted and any"
                ],
                [
                    45,
                    "                // path component is ignored.\""
                ],
                [
                    46,
                    "                //"
                ],
                [
                    47,
                    "                // This leaves it unclear as to whether the path must be empty,"
                ],
                [
                    48,
                    "                // or whether it can be non-empty and will be ignored. To be on"
                ],
                [
                    49,
                    "                // the safe side, use a proper web origin (with empty path)."
                ]
            ]
        },
        {
            "commit": "3c66deb5cc7a4387e4176d2a5bdd3f321f09a6bd",
            "timestamp": "2020-05-28T10:46:25+02:00",
            "author": "BlackDex",
            "commit_message": "Redesign of the admin interface.\n\nMain changes:\n - Splitted up settings and users into two separate pages.\n - Added verified shield when the e-mail address has been verified.\n - Added the amount of personal items in the database to the users overview.\n - Added Organizations and Diagnostics pages.\n   - Shows if DNS resolving works.\n   - Shows if there is a posible time drift.\n   - Shows current versions of server and web-vault.\n - Optimized logo-gray.png using optipng\n\nItems which can be added later:\n - Amount of cipher items accessible for a user, not only his personal items.\n - Amount of users per Org\n - Version update check in the diagnostics overview.\n - Copy/Pasteable runtime config which has sensitive data changed or removed for support questions either on the forum or github issues.\n - Option to delete Orgs and all its passwords (when there are no members anymore).\n - Etc....",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -78,6 +78,7 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n     match filename.as_ref() {\n         \"mail-github.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/mail-github.png\"))),\n         \"logo-gray.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/logo-gray.png\"))),\n+        \"shield-white.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/shield-white.png\"))),\n         \"error-x.svg\" => Ok(Content(ContentType::SVG, include_bytes!(\"../static/images/error-x.svg\"))),\n         \"hibp.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/hibp.png\"))),\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 2,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -1,15 +1,10 @@\n use std::path::{Path, PathBuf};\n \n-use rocket::http::ContentType;\n-use rocket::response::content::Content;\n-use rocket::response::NamedFile;\n-use rocket::Route;\n+use rocket::{http::ContentType, response::content::Content, response::NamedFile, Route};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::error::Error;\n-use crate::util::Cached;\n-use crate::CONFIG;\n+use crate::{error::Error, util::Cached, CONFIG};\n \n pub fn routes() -> Vec<Route> {\n     // If addding more routes here, consider also adding them to\n",
            "comment_added_diff": []
        },
        {
            "commit": "0822c0c128d3b71b13109bb8c0f94f73174440fe",
            "timestamp": "2020-08-31T16:40:21+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update admin page dependencies",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -78,7 +78,7 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n         \"hibp.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/hibp.png\"))),\n \n         \"bootstrap.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/bootstrap.css\"))),\n-        \"bootstrap-native-v4.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native-v4.js\"))),\n+        \"bootstrap-native.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native.js\"))),\n         \"md5.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/md5.js\"))),\n         \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n         _ => err!(format!(\"Static file not found: {}\", filename)),\n",
            "comment_added_diff": []
        },
        {
            "commit": "6a291040bde780fed730d98b660924ef85c3cd7a",
            "timestamp": "2020-09-19T22:19:55+02:00",
            "author": "BlackDex",
            "commit_message": "As requested here: https://bitwardenrs.discourse.group/t/searchable-user-list-on-admin-panel/299\n\n- Changed the table layout a bit.\n- Added functions to the tables:\n  + Search\n  + Sort\n  + Paginate",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -81,6 +81,9 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n         \"bootstrap-native.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native.js\"))),\n         \"md5.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/md5.js\"))),\n         \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n+        \"datatables.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/datatables.js\"))),\n+        \"datatables.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/datatables.css\"))),\n+        \"jquery-3.5.1.slim.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/jquery-3.5.1.slim.js\"))),\n         _ => err!(format!(\"Static file not found: {}\", filename)),\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "39106d440a10b8d8f262d569f4facd6c39957a76",
            "timestamp": "2021-02-26T21:48:01-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Remove `md5.js` dependency\n\nSwitch to the built-in WebCrypto APIs for computing identicon hashes.",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -79,7 +79,6 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n \n         \"bootstrap.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/bootstrap.css\"))),\n         \"bootstrap-native.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native.js\"))),\n-        \"md5.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/md5.js\"))),\n         \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n         \"datatables.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/datatables.js\"))),\n         \"datatables.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/datatables.css\"))),\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -10,7 +10,7 @@ pub fn routes() -> Vec<Route> {\n     // If addding more routes here, consider also adding them to\n     // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n     if CONFIG.web_vault_enabled() {\n-        routes![web_index, app_id, web_files, attachments, alive, static_files]\n+        routes![web_index, app_id, web_files, attachments, sends, alive, static_files]\n     } else {\n         routes![attachments, alive, static_files]\n     }\n@@ -60,6 +60,11 @@ fn attachments(uuid: String, file: PathBuf) -> Option<NamedFile> {\n     NamedFile::open(Path::new(&CONFIG.attachments_folder()).join(uuid).join(file)).ok()\n }\n \n+#[get(\"/sends/<send_id>/<file_id>\")]\n+fn sends(send_id: String, file_id: String) -> Option<NamedFile> {\n+    NamedFile::open(Path::new(&CONFIG.sends_folder()).join(send_id).join(file_id)).ok()\n+}\n+\n #[get(\"/alive\")]\n fn alive() -> Json<String> {\n     use crate::util::format_date;\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 40,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -76,18 +76,48 @@ fn alive() -> Json<String> {\n #[get(\"/bwrs_static/<filename>\")]\n fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n     match filename.as_ref() {\n-        \"mail-github.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/mail-github.png\"))),\n-        \"logo-gray.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/logo-gray.png\"))),\n-        \"shield-white.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/shield-white.png\"))),\n-        \"error-x.svg\" => Ok(Content(ContentType::SVG, include_bytes!(\"../static/images/error-x.svg\"))),\n+        \"mail-github.png\" => Ok(Content(\n+            ContentType::PNG,\n+            include_bytes!(\"../static/images/mail-github.png\"),\n+        )),\n+        \"logo-gray.png\" => Ok(Content(\n+            ContentType::PNG,\n+            include_bytes!(\"../static/images/logo-gray.png\"),\n+        )),\n+        \"shield-white.png\" => Ok(Content(\n+            ContentType::PNG,\n+            include_bytes!(\"../static/images/shield-white.png\"),\n+        )),\n+        \"error-x.svg\" => Ok(Content(\n+            ContentType::SVG,\n+            include_bytes!(\"../static/images/error-x.svg\"),\n+        )),\n         \"hibp.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/hibp.png\"))),\n \n-        \"bootstrap.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/bootstrap.css\"))),\n-        \"bootstrap-native.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native.js\"))),\n-        \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n-        \"datatables.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/datatables.js\"))),\n-        \"datatables.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/datatables.css\"))),\n-        \"jquery-3.5.1.slim.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/jquery-3.5.1.slim.js\"))),\n+        \"bootstrap.css\" => Ok(Content(\n+            ContentType::CSS,\n+            include_bytes!(\"../static/scripts/bootstrap.css\"),\n+        )),\n+        \"bootstrap-native.js\" => Ok(Content(\n+            ContentType::JavaScript,\n+            include_bytes!(\"../static/scripts/bootstrap-native.js\"),\n+        )),\n+        \"identicon.js\" => Ok(Content(\n+            ContentType::JavaScript,\n+            include_bytes!(\"../static/scripts/identicon.js\"),\n+        )),\n+        \"datatables.js\" => Ok(Content(\n+            ContentType::JavaScript,\n+            include_bytes!(\"../static/scripts/datatables.js\"),\n+        )),\n+        \"datatables.css\" => Ok(Content(\n+            ContentType::CSS,\n+            include_bytes!(\"../static/scripts/datatables.css\"),\n+        )),\n+        \"jquery-3.5.1.slim.js\" => Ok(Content(\n+            ContentType::JavaScript,\n+            include_bytes!(\"../static/scripts/jquery-3.5.1.slim.js\"),\n+        )),\n         _ => err!(format!(\"Static file not found: {}\", filename)),\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 14,
            "deletions": 40,
            "change_type": "MODIFY",
            "diff": "@@ -76,48 +76,22 @@ fn alive() -> Json<String> {\n #[get(\"/bwrs_static/<filename>\")]\n fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n     match filename.as_ref() {\n-        \"mail-github.png\" => Ok(Content(\n-            ContentType::PNG,\n-            include_bytes!(\"../static/images/mail-github.png\"),\n-        )),\n-        \"logo-gray.png\" => Ok(Content(\n-            ContentType::PNG,\n-            include_bytes!(\"../static/images/logo-gray.png\"),\n-        )),\n-        \"shield-white.png\" => Ok(Content(\n-            ContentType::PNG,\n-            include_bytes!(\"../static/images/shield-white.png\"),\n-        )),\n-        \"error-x.svg\" => Ok(Content(\n-            ContentType::SVG,\n-            include_bytes!(\"../static/images/error-x.svg\"),\n-        )),\n+        \"mail-github.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/mail-github.png\"))),\n+        \"logo-gray.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/logo-gray.png\"))),\n+        \"shield-white.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/shield-white.png\"))),\n+        \"error-x.svg\" => Ok(Content(ContentType::SVG, include_bytes!(\"../static/images/error-x.svg\"))),\n         \"hibp.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/hibp.png\"))),\n \n-        \"bootstrap.css\" => Ok(Content(\n-            ContentType::CSS,\n-            include_bytes!(\"../static/scripts/bootstrap.css\"),\n-        )),\n-        \"bootstrap-native.js\" => Ok(Content(\n-            ContentType::JavaScript,\n-            include_bytes!(\"../static/scripts/bootstrap-native.js\"),\n-        )),\n-        \"identicon.js\" => Ok(Content(\n-            ContentType::JavaScript,\n-            include_bytes!(\"../static/scripts/identicon.js\"),\n-        )),\n-        \"datatables.js\" => Ok(Content(\n-            ContentType::JavaScript,\n-            include_bytes!(\"../static/scripts/datatables.js\"),\n-        )),\n-        \"datatables.css\" => Ok(Content(\n-            ContentType::CSS,\n-            include_bytes!(\"../static/scripts/datatables.css\"),\n-        )),\n-        \"jquery-3.5.1.slim.js\" => Ok(Content(\n-            ContentType::JavaScript,\n-            include_bytes!(\"../static/scripts/jquery-3.5.1.slim.js\"),\n-        )),\n+        \"bootstrap.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/bootstrap.css\"))),\n+        \"bootstrap-native.js\" => {\n+            Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/bootstrap-native.js\")))\n+        }\n+        \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n+        \"datatables.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/datatables.js\"))),\n+        \"datatables.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/datatables.css\"))),\n+        \"jquery-3.5.1.slim.js\" => {\n+            Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/jquery-3.5.1.slim.js\")))\n+        }\n         _ => err!(format!(\"Static file not found: {}\", filename)),\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "7cb19ef767142b773ab44a457940844589432a74",
            "timestamp": "2021-05-08T17:46:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated branding, email and crates\n\n- Updated branding for admin and emails\n- Updated crates and some deprications\n- Removed newline-converter because this is built-in into lettre\n- Updated email templates to use a shared header and footer template\n- Also trigger SMTP SSL When TLS is selected without SSL\n  Resolves #1641",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -78,9 +78,11 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n     match filename.as_ref() {\n         \"mail-github.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/mail-github.png\"))),\n         \"logo-gray.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/logo-gray.png\"))),\n-        \"shield-white.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/shield-white.png\"))),\n         \"error-x.svg\" => Ok(Content(ContentType::SVG, include_bytes!(\"../static/images/error-x.svg\"))),\n         \"hibp.png\" => Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/hibp.png\"))),\n+        \"vaultwarden-icon.png\" => {\n+            Ok(Content(ContentType::PNG, include_bytes!(\"../static/images/vaultwarden-icon.png\")))\n+        }\n \n         \"bootstrap.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/bootstrap.css\"))),\n         \"bootstrap-native.js\" => {\n",
            "comment_added_diff": []
        },
        {
            "commit": "9133e2927d3189804431aa013bff2cf14fc812fb",
            "timestamp": "2021-05-15T22:46:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix attachment downloads\n\nUpstream switched to new upload/download APIs. Uploads fall back to the\nlegacy APIs for now, but not downloads apparently.",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -55,9 +55,9 @@ fn web_files(p: PathBuf) -> Cached<Option<NamedFile>> {\n     Cached::long(NamedFile::open(Path::new(&CONFIG.web_vault_folder()).join(p)).ok())\n }\n \n-#[get(\"/attachments/<uuid>/<file..>\")]\n-fn attachments(uuid: String, file: PathBuf) -> Option<NamedFile> {\n-    NamedFile::open(Path::new(&CONFIG.attachments_folder()).join(uuid).join(file)).ok()\n+#[get(\"/attachments/<uuid>/<file_id>\")]\n+fn attachments(uuid: String, file_id: String) -> Option<NamedFile> {\n+    NamedFile::open(Path::new(&CONFIG.attachments_folder()).join(uuid).join(file_id)).ok()\n }\n \n #[get(\"/sends/<send_id>/<file_id>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "8615736e84f802833d0581b1d7f58e7daddc6340",
            "timestamp": "2021-06-19T19:22:19+02:00",
            "author": "BlackDex",
            "commit_message": "Multiple Admin Interface fixes and some others.\n\nMisc:\n- Fixed hadolint workflow, new git cli needs some extra arguments.\n- Add ignore paths to all specific on triggers.\n- Updated hadolint version.\n- Made SMTP_DEBUG read-only, since it can't be changed at runtime.\n\nAdmin:\n- Migrated from Bootstrap v4 to v5\n- Updated jquery to v3.6.0\n- Updated Datatables\n- Made Javascript strict\n- Added a way to show which ENV Vars are overridden.\n- Changed the way to provide data for handlebars.\n- Fixed date/time check.\n- Made support string use details and summary feature of markdown/github.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -91,8 +91,8 @@ fn static_files(filename: String) -> Result<Content<&'static [u8]>, Error> {\n         \"identicon.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/identicon.js\"))),\n         \"datatables.js\" => Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/datatables.js\"))),\n         \"datatables.css\" => Ok(Content(ContentType::CSS, include_bytes!(\"../static/scripts/datatables.css\"))),\n-        \"jquery-3.5.1.slim.js\" => {\n-            Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/jquery-3.5.1.slim.js\")))\n+        \"jquery-3.6.0.slim.js\" => {\n+            Ok(Content(ContentType::JavaScript, include_bytes!(\"../static/scripts/jquery-3.6.0.slim.js\")))\n         }\n         _ => err!(format!(\"Static file not found: {}\", filename)),\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "2cd17fe7afeaef2a29787999b1cb48a512811571",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add token with short expiration time to send url",
            "additions": 1,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -10,7 +10,7 @@ pub fn routes() -> Vec<Route> {\n     // If addding more routes here, consider also adding them to\n     // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n     if CONFIG.web_vault_enabled() {\n-        routes![web_index, app_id, web_files, attachments, sends, alive, static_files]\n+        routes![web_index, app_id, web_files, attachments, alive, static_files]\n     } else {\n         routes![attachments, alive, static_files]\n     }\n@@ -60,11 +60,6 @@ fn attachments(uuid: String, file_id: String) -> Option<NamedFile> {\n     NamedFile::open(Path::new(&CONFIG.attachments_folder()).join(uuid).join(file_id)).ok()\n }\n \n-#[get(\"/sends/<send_id>/<file_id>\")]\n-fn sends(send_id: String, file_id: String) -> Option<NamedFile> {\n-    NamedFile::open(Path::new(&CONFIG.sends_folder()).join(send_id).join(file_id)).ok()\n-}\n-\n #[get(\"/alive\")]\n fn alive() -> Json<String> {\n     use crate::util::format_date;\n",
            "comment_added_diff": []
        },
        {
            "commit": "e5ec245626e4a4d232b6a709338fe1e9811845e7",
            "timestamp": "2021-07-15T19:15:55+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Protect namedfile against path traversal, rocket only does it for pathbuf",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use rocket::{http::ContentType, response::content::Content, response::NamedFile,\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::{error::Error, util::Cached, CONFIG};\n+use crate::{CONFIG, error::Error, util::{Cached, SafeString}};\n \n pub fn routes() -> Vec<Route> {\n     // If addding more routes here, consider also adding them to\n@@ -56,7 +56,7 @@ fn web_files(p: PathBuf) -> Cached<Option<NamedFile>> {\n }\n \n #[get(\"/attachments/<uuid>/<file_id>\")]\n-fn attachments(uuid: String, file_id: String) -> Option<NamedFile> {\n+fn attachments(uuid: SafeString, file_id: SafeString) -> Option<NamedFile> {\n     NamedFile::open(Path::new(&CONFIG.attachments_folder()).join(uuid).join(file_id)).ok()\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "56ffec40f4cbc79afdeca13634d9b9f6fed04143",
            "timestamp": "2021-07-15T21:52:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,11 @@ use rocket::{http::ContentType, response::content::Content, response::NamedFile,\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::{CONFIG, error::Error, util::{Cached, SafeString}};\n+use crate::{\n+    error::Error,\n+    util::{Cached, SafeString},\n+    CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n     // If addding more routes here, consider also adding them to\n",
            "comment_added_diff": []
        }
    ],
    "hibp.png": [],
    "down.sql": [],
    "up.sql": [],
    "authenticator.rs": [
        {
            "commit": "ebf40099f2fc73cc5309ddd7fff6a679dc9ae839",
            "timestamp": "2019-10-10T17:32:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated authenticator TOTP\n\n- Added security check for previouse used codes\n- Allow TOTP codes with 1 step back and forward when there is a time\ndrift. This means in total 3 codes could be valid. But only newer codes\nthen the previouse used codes are excepted after that.",
            "additions": 51,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -77,7 +77,7 @@ fn activate_authenticator(data: JsonUpcase<EnableAuthenticatorData>, headers: He\n     let twofactor = TwoFactor::new(user.uuid.clone(), type_, key.to_uppercase());\n \n     // Validate the token provided with the key\n-    validate_totp_code(token, &twofactor.data)?;\n+    validate_totp_code(&user.uuid, token, &twofactor.data, &conn)?;\n \n     _generate_recover_code(&mut user, &conn);\n     twofactor.save(&conn)?;\n@@ -94,27 +94,69 @@ fn activate_authenticator_put(data: JsonUpcase<EnableAuthenticatorData>, headers\n     activate_authenticator(data, headers, conn)\n }\n \n-pub fn validate_totp_code_str(totp_code: &str, secret: &str) -> EmptyResult {\n+pub fn validate_totp_code_str(user_uuid: &str, totp_code: &str, secret: &str, conn: &DbConn) -> EmptyResult {\n     let totp_code: u64 = match totp_code.parse() {\n         Ok(code) => code,\n         _ => err!(\"TOTP code is not a number\"),\n     };\n \n-    validate_totp_code(totp_code, secret)\n+    validate_totp_code(user_uuid, totp_code, secret, &conn)\n }\n \n-pub fn validate_totp_code(totp_code: u64, secret: &str) -> EmptyResult {\n-    use oath::{totp_raw_now, HashType};\n+pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &DbConn) -> EmptyResult {\n+    use oath::{totp_raw_custom_time, HashType};\n+    use std::time::{UNIX_EPOCH, SystemTime};\n \n     let decoded_secret = match BASE32.decode(secret.as_bytes()) {\n         Ok(s) => s,\n         Err(_) => err!(\"Invalid TOTP secret\"),\n     };\n \n-    let generated = totp_raw_now(&decoded_secret, 6, 0, 30, &HashType::SHA1);\n-    if generated != totp_code {\n-        err!(\"Invalid TOTP code\");\n+    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Authenticator as i32, &conn)?;\n+\n+    // Get the current system time in UNIX Epoch (UTC)\n+    let current_time: u64 = SystemTime::now().duration_since(UNIX_EPOCH)\n+        .expect(\"Earlier than 1970-01-01 00:00:00 UTC\").as_secs();\n+\n+    // First check the current time for a valid token.\n+    let time_step_now = (current_time / 30) as i32;\n+    let generated_now = totp_raw_custom_time(&decoded_secret, 6, 0, 30, current_time, &HashType::SHA1);\n+    if generated_now == totp_code && time_step_now > twofactor.last_used {\n+        twofactor.last_used = time_step_now;\n+        twofactor.save(&conn)?;\n+        return Ok(());\n+    } else if generated_now == totp_code && time_step_now <= twofactor.last_used {\n+        warn!(\"This or a future TOTP code has already been used!\");\n+        err!(\"Invalid TOTP code!\");\n     }\n \n-    Ok(())\n+    // Check for time drifted codes\n+    // First check the previous TOTP code\n+    let time_step_prev = ((current_time - 30) / 30) as i32;\n+    let generated_prev = totp_raw_custom_time(&decoded_secret, 6, 0, 30, current_time - 30, &HashType::SHA1);\n+    if generated_prev == totp_code && time_step_prev > twofactor.last_used {\n+        info!(\"TOTP Time drift detected. Token is valide for one step on the past.\");\n+        twofactor.last_used = time_step_prev;\n+        twofactor.save(&conn)?;\n+        return Ok(());\n+    } else if generated_prev == totp_code && time_step_prev <= twofactor.last_used {\n+        warn!(\"This or a future TOTP code has already been used!\");\n+        err!(\"Invalid TOTP code!\");\n+    }\n+\n+    // Second check the next TOTP code\n+    let time_step_next = ((current_time + 30) / 30) as i32;\n+    let generated_next = totp_raw_custom_time(&decoded_secret, 6, 0, 30, current_time + 30, &HashType::SHA1);\n+    if generated_next == totp_code && time_step_next > twofactor.last_used {\n+        info!(\"TOTP Time drift detected. Token is valide for one step on the future.\");\n+        twofactor.last_used = time_step_next;\n+        twofactor.save(&conn)?;\n+        return Ok(());\n+    } else if generated_next == totp_code && time_step_next <= twofactor.last_used {\n+        warn!(\"This or a previous TOTP code has already been used!\");\n+        err!(\"Invalid TOTP code!\");\n+    }\n+\n+    // Else no valide code received, deny access\n+    err!(\"Invalid TOTP code!\");\n }\n",
            "comment_added_diff": [
                [
                    117,
                    "    // Get the current system time in UNIX Epoch (UTC)"
                ],
                [
                    121,
                    "    // First check the current time for a valid token."
                ],
                [
                    133,
                    "    // Check for time drifted codes"
                ],
                [
                    134,
                    "    // First check the previous TOTP code"
                ],
                [
                    147,
                    "    // Second check the next TOTP code"
                ],
                [
                    160,
                    "    // Else no valide code received, deny access"
                ]
            ]
        },
        {
            "commit": "9466f0269607098304c03f87e2ed116b93a2c01d",
            "timestamp": "2019-10-12T15:28:28+02:00",
            "author": "BlackDex",
            "commit_message": "Recoded TOTP time drift validation",
            "additions": 26,
            "deletions": 37,
            "change_type": "MODIFY",
            "diff": "@@ -118,43 +118,32 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n     let current_time: u64 = SystemTime::now().duration_since(UNIX_EPOCH)\n         .expect(\"Earlier than 1970-01-01 00:00:00 UTC\").as_secs();\n \n-    // First check the current time for a valid token.\n-    let time_step_now = (current_time / 30) as i32;\n-    let generated_now = totp_raw_custom_time(&decoded_secret, 6, 0, 30, current_time, &HashType::SHA1);\n-    if generated_now == totp_code && time_step_now > twofactor.last_used {\n-        twofactor.last_used = time_step_now;\n-        twofactor.save(&conn)?;\n-        return Ok(());\n-    } else if generated_now == totp_code && time_step_now <= twofactor.last_used {\n-        warn!(\"This or a future TOTP code has already been used!\");\n-        err!(\"Invalid TOTP code!\");\n-    }\n-\n-    // Check for time drifted codes\n-    // First check the previous TOTP code\n-    let time_step_prev = ((current_time - 30) / 30) as i32;\n-    let generated_prev = totp_raw_custom_time(&decoded_secret, 6, 0, 30, current_time - 30, &HashType::SHA1);\n-    if generated_prev == totp_code && time_step_prev > twofactor.last_used {\n-        info!(\"TOTP Time drift detected. Token is valide for one step on the past.\");\n-        twofactor.last_used = time_step_prev;\n-        twofactor.save(&conn)?;\n-        return Ok(());\n-    } else if generated_prev == totp_code && time_step_prev <= twofactor.last_used {\n-        warn!(\"This or a future TOTP code has already been used!\");\n-        err!(\"Invalid TOTP code!\");\n-    }\n-\n-    // Second check the next TOTP code\n-    let time_step_next = ((current_time + 30) / 30) as i32;\n-    let generated_next = totp_raw_custom_time(&decoded_secret, 6, 0, 30, current_time + 30, &HashType::SHA1);\n-    if generated_next == totp_code && time_step_next > twofactor.last_used {\n-        info!(\"TOTP Time drift detected. Token is valide for one step on the future.\");\n-        twofactor.last_used = time_step_next;\n-        twofactor.save(&conn)?;\n-        return Ok(());\n-    } else if generated_next == totp_code && time_step_next <= twofactor.last_used {\n-        warn!(\"This or a previous TOTP code has already been used!\");\n-        err!(\"Invalid TOTP code!\");\n+    // The amount of steps back and forward in time\n+    let steps = 1;\n+    for step in -steps..=steps {\n+\n+        let time_step = (current_time / 30) as i32 + step;\n+        // We need to calculate the time offsite and cast it as an i128.\n+        // Else we can't do math with it on a default u64 variable.\n+        let time_offset: i128 = (step * 30).into();\n+        let generated = totp_raw_custom_time(&decoded_secret, 6, 0, 30, (current_time as i128 + time_offset) as u64, &HashType::SHA1);\n+\n+        // Check the the given code equals the generated and if the time_step is larger then the one last used.\n+        if generated == totp_code && time_step > twofactor.last_used {\n+\n+            // If the step does not equals 0 the time is drifted either server or client side.\n+            if step != 0 {\n+                info!(\"TOTP Time drift detected. The step offset is {}\", step);\n+            }\n+\n+            // Save the last used time step so only totp time steps higher then this one are allowed.\n+            twofactor.last_used = time_step;\n+            twofactor.save(&conn)?;\n+            return Ok(());\n+        } else if generated == totp_code && time_step <= twofactor.last_used {\n+            warn!(\"This or a TOTP code within {} steps back and forward has already been used!\", steps);\n+            err!(\"Invalid TOTP Code!\");\n+        }\n     }\n \n     // Else no valide code received, deny access\n",
            "comment_added_diff": [
                [
                    121,
                    "    // The amount of steps back and forward in time"
                ],
                [
                    126,
                    "        // We need to calculate the time offsite and cast it as an i128."
                ],
                [
                    127,
                    "        // Else we can't do math with it on a default u64 variable."
                ],
                [
                    131,
                    "        // Check the the given code equals the generated and if the time_step is larger then the one last used."
                ],
                [
                    134,
                    "            // If the step does not equals 0 the time is drifted either server or client side."
                ],
                [
                    139,
                    "            // Save the last used time step so only totp time steps higher then this one are allowed."
                ]
            ]
        },
        {
            "commit": "603a964579fc56797d80d8681e0b98a2dfd46166",
            "timestamp": "2019-10-14T00:32:44+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #663.\n\nDuring the 2fa activation there is no twofactor record yet.\nChanged the layout a bit so that it will generate a new twofactor record\nwhen it does not exists yet. Else it will just update the already\nexisting record.",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -73,14 +73,10 @@ fn activate_authenticator(data: JsonUpcase<EnableAuthenticatorData>, headers: He\n         err!(\"Invalid key length\")\n     }\n \n-    let type_ = TwoFactorType::Authenticator;\n-    let twofactor = TwoFactor::new(user.uuid.clone(), type_, key.to_uppercase());\n-\n-    // Validate the token provided with the key\n-    validate_totp_code(&user.uuid, token, &twofactor.data, &conn)?;\n+    // Validate the token provided with the key, and save new twofactor\n+    validate_totp_code(&user.uuid, token, &key.to_uppercase(), &conn)?;\n \n     _generate_recover_code(&mut user, &conn);\n-    twofactor.save(&conn)?;\n \n     Ok(Json(json!({\n         \"Enabled\": true,\n@@ -112,7 +108,10 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n         Err(_) => err!(\"Invalid TOTP secret\"),\n     };\n \n-    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Authenticator as i32, &conn)?;\n+    let mut twofactor = match TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Authenticator as i32, &conn) {\n+        Some(tf) => tf,\n+        _ => TwoFactor::new(user_uuid.to_string(), TwoFactorType::Authenticator, secret.to_string()),\n+    };\n \n     // Get the current system time in UNIX Epoch (UTC)\n     let current_time: u64 = SystemTime::now().duration_since(UNIX_EPOCH)\n@@ -137,6 +136,7 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n             }\n \n             // Save the last used time step so only totp time steps higher then this one are allowed.\n+            // This will also save a newly created twofactor if the code is correct.\n             twofactor.last_used = time_step;\n             twofactor.save(&conn)?;\n             return Ok(());\n",
            "comment_added_diff": [
                [
                    76,
                    "    // Validate the token provided with the key, and save new twofactor"
                ],
                [
                    139,
                    "            // This will also save a newly created twofactor if the code is correct."
                ]
            ]
        },
        {
            "commit": "3f6809bcdf88268543c0ee75ae6c3a3fbcf23df8",
            "timestamp": "2019-11-07T17:11:29+01:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue/request #705\n\nAdded a config option to disable time drifted totp codes.\nDefault is false, since this is what the RFC recommends.",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -11,6 +11,8 @@ use crate::db::{\n     DbConn,\n };\n \n+pub use crate::config::CONFIG;\n+\n pub fn routes() -> Vec<Route> {\n     routes![\n         generate_authenticator,\n@@ -118,9 +120,11 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n         .expect(\"Earlier than 1970-01-01 00:00:00 UTC\").as_secs();\n \n     // The amount of steps back and forward in time\n-    let steps = 1;\n-    for step in -steps..=steps {\n+    // Also check if we need to disable time drifted TOTP codes.\n+    // If that is the case, we set the steps to 0 so only the current TOTP is valid.\n+    let steps = if CONFIG.authenticator_disable_time_drift() { 0 } else { 1 };\n \n+    for step in -steps..=steps {\n         let time_step = (current_time / 30) as i32 + step;\n         // We need to calculate the time offsite and cast it as an i128.\n         // Else we can't do math with it on a default u64 variable.\n",
            "comment_added_diff": [
                [
                    123,
                    "    // Also check if we need to disable time drifted TOTP codes."
                ],
                [
                    124,
                    "    // If that is the case, we set the steps to 0 so only the current TOTP is valid."
                ]
            ]
        },
        {
            "commit": "e274af6e3db0572bcd6acb8a89485e2fc4d9111b",
            "timestamp": "2019-12-27T18:42:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Print current server time when failing TOTP, and use chrono as the rest of the server",
            "additions": 11,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -103,7 +103,6 @@ pub fn validate_totp_code_str(user_uuid: &str, totp_code: &str, secret: &str, co\n \n pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &DbConn) -> EmptyResult {\n     use oath::{totp_raw_custom_time, HashType};\n-    use std::time::{UNIX_EPOCH, SystemTime};\n \n     let decoded_secret = match BASE32.decode(secret.as_bytes()) {\n         Ok(s) => s,\n@@ -116,24 +115,23 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n     };\n \n     // Get the current system time in UNIX Epoch (UTC)\n-    let current_time: u64 = SystemTime::now().duration_since(UNIX_EPOCH)\n-        .expect(\"Earlier than 1970-01-01 00:00:00 UTC\").as_secs();\n+    let current_time = chrono::Utc::now();\n+    let current_timestamp = current_time.timestamp();\n \n     // The amount of steps back and forward in time\n     // Also check if we need to disable time drifted TOTP codes.\n     // If that is the case, we set the steps to 0 so only the current TOTP is valid.\n-    let steps = if CONFIG.authenticator_disable_time_drift() { 0 } else { 1 };\n+    let steps: i64 = if CONFIG.authenticator_disable_time_drift() { 0 } else { 1 };\n \n     for step in -steps..=steps {\n-        let time_step = (current_time / 30) as i32 + step;\n+        let time_step = current_timestamp / 30i64 + step;\n         // We need to calculate the time offsite and cast it as an i128.\n         // Else we can't do math with it on a default u64 variable.\n-        let time_offset: i128 = (step * 30).into();\n-        let generated = totp_raw_custom_time(&decoded_secret, 6, 0, 30, (current_time as i128 + time_offset) as u64, &HashType::SHA1);\n+        let time = (current_timestamp + step * 30i64) as u64;\n+        let generated = totp_raw_custom_time(&decoded_secret, 6, 0, 30, time, &HashType::SHA1);\n \n         // Check the the given code equals the generated and if the time_step is larger then the one last used.\n-        if generated == totp_code && time_step > twofactor.last_used {\n-\n+        if generated == totp_code && time_step > twofactor.last_used as i64 {\n             // If the step does not equals 0 the time is drifted either server or client side.\n             if step != 0 {\n                 info!(\"TOTP Time drift detected. The step offset is {}\", step);\n@@ -141,15 +139,15 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n \n             // Save the last used time step so only totp time steps higher then this one are allowed.\n             // This will also save a newly created twofactor if the code is correct.\n-            twofactor.last_used = time_step;\n+            twofactor.last_used = time_step as i32;\n             twofactor.save(&conn)?;\n             return Ok(());\n-        } else if generated == totp_code && time_step <= twofactor.last_used {\n+        } else if generated == totp_code && time_step <= twofactor.last_used as i64 {\n             warn!(\"This or a TOTP code within {} steps back and forward has already been used!\", steps);\n-            err!(\"Invalid TOTP Code!\");\n+            err!(format!(\"Invalid TOTP code! Server time: {}\", current_time.format(\"%F %T UTC\")));\n         }\n     }\n \n     // Else no valide code received, deny access\n-    err!(\"Invalid TOTP code!\");\n+    err!(format!(\"Invalid TOTP code! Server time: {}\", current_time.format(\"%F %T UTC\")));\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "632f4d545367b5ab1cefce66bc526e5dc0a786de",
            "timestamp": "2020-05-07T18:02:37-04:00",
            "author": "theycallmesteve",
            "commit_message": "Whitespace fixes",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -20,6 +20,7 @@ pub fn routes() -> Vec<Route> {\n         activate_authenticator_put,\n     ]\n }\n+\n #[post(\"/two-factor/get-authenticator\", data = \"<data>\")]\n fn generate_authenticator(data: JsonUpcase<PasswordData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let data: PasswordData = data.into_inner().data;\n",
            "comment_added_diff": []
        },
        {
            "commit": "0807783388343a8ab4035e50f0a542fadfe03423",
            "timestamp": "2020-05-14T00:19:50+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add ip on totp miss",
            "additions": 38,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use rocket_contrib::json::Json;\n \n use crate::api::core::two_factor::_generate_recover_code;\n use crate::api::{EmptyResult, JsonResult, JsonUpcase, NumberOrString, PasswordData};\n-use crate::auth::Headers;\n+use crate::auth::{ClientIp, Headers};\n use crate::crypto;\n use crate::db::{\n     models::{TwoFactor, TwoFactorType},\n@@ -54,7 +54,12 @@ struct EnableAuthenticatorData {\n }\n \n #[post(\"/two-factor/authenticator\", data = \"<data>\")]\n-fn activate_authenticator(data: JsonUpcase<EnableAuthenticatorData>, headers: Headers, conn: DbConn) -> JsonResult {\n+fn activate_authenticator(\n+    data: JsonUpcase<EnableAuthenticatorData>,\n+    headers: Headers,\n+    ip: ClientIp,\n+    conn: DbConn,\n+) -> JsonResult {\n     let data: EnableAuthenticatorData = data.into_inner().data;\n     let password_hash = data.MasterPasswordHash;\n     let key = data.Key;\n@@ -77,7 +82,7 @@ fn activate_authenticator(data: JsonUpcase<EnableAuthenticatorData>, headers: He\n     }\n \n     // Validate the token provided with the key, and save new twofactor\n-    validate_totp_code(&user.uuid, token, &key.to_uppercase(), &conn)?;\n+    validate_totp_code(&user.uuid, token, &key.to_uppercase(), &ip, &conn)?;\n \n     _generate_recover_code(&mut user, &conn);\n \n@@ -89,20 +94,31 @@ fn activate_authenticator(data: JsonUpcase<EnableAuthenticatorData>, headers: He\n }\n \n #[put(\"/two-factor/authenticator\", data = \"<data>\")]\n-fn activate_authenticator_put(data: JsonUpcase<EnableAuthenticatorData>, headers: Headers, conn: DbConn) -> JsonResult {\n-    activate_authenticator(data, headers, conn)\n+fn activate_authenticator_put(\n+    data: JsonUpcase<EnableAuthenticatorData>,\n+    headers: Headers,\n+    ip: ClientIp,\n+    conn: DbConn,\n+) -> JsonResult {\n+    activate_authenticator(data, headers, ip, conn)\n }\n \n-pub fn validate_totp_code_str(user_uuid: &str, totp_code: &str, secret: &str, conn: &DbConn) -> EmptyResult {\n+pub fn validate_totp_code_str(\n+    user_uuid: &str,\n+    totp_code: &str,\n+    secret: &str,\n+    ip: &ClientIp,\n+    conn: &DbConn,\n+) -> EmptyResult {\n     let totp_code: u64 = match totp_code.parse() {\n         Ok(code) => code,\n         _ => err!(\"TOTP code is not a number\"),\n     };\n \n-    validate_totp_code(user_uuid, totp_code, secret, &conn)\n+    validate_totp_code(user_uuid, totp_code, secret, ip, &conn)\n }\n \n-pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &DbConn) -> EmptyResult {\n+pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &ClientIp, conn: &DbConn) -> EmptyResult {\n     use oath::{totp_raw_custom_time, HashType};\n \n     let decoded_secret = match BASE32.decode(secret.as_bytes()) {\n@@ -144,11 +160,22 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, conn: &\n             twofactor.save(&conn)?;\n             return Ok(());\n         } else if generated == totp_code && time_step <= twofactor.last_used as i64 {\n-            warn!(\"This or a TOTP code within {} steps back and forward has already been used!\", steps);\n-            err!(format!(\"Invalid TOTP code! Server time: {}\", current_time.format(\"%F %T UTC\")));\n+            warn!(\n+                \"This or a TOTP code within {} steps back and forward has already been used!\",\n+                steps\n+            );\n+            err!(format!(\n+                \"Invalid TOTP code! Server time: {} IP: {}\",\n+                current_time.format(\"%F %T UTC\"),\n+                ip.ip\n+            ));\n         }\n     }\n \n     // Else no valide code received, deny access\n-    err!(format!(\"Invalid TOTP code! Server time: {}\", current_time.format(\"%F %T UTC\")));\n+    err!(format!(\n+        \"Invalid TOTP code! Server time: {} IP: {}\",\n+        current_time.format(\"%F %T UTC\"),\n+        ip.ip\n+    ));\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 10,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -2,13 +2,16 @@ use data_encoding::BASE32;\n use rocket::Route;\n use rocket_contrib::json::Json;\n \n-use crate::api::core::two_factor::_generate_recover_code;\n-use crate::api::{EmptyResult, JsonResult, JsonUpcase, NumberOrString, PasswordData};\n-use crate::auth::{ClientIp, Headers};\n-use crate::crypto;\n-use crate::db::{\n-    models::{TwoFactor, TwoFactorType},\n-    DbConn,\n+use crate::{\n+    api::{\n+        core::two_factor::_generate_recover_code, EmptyResult, JsonResult, JsonUpcase, NumberOrString, PasswordData,\n+    },\n+    auth::{ClientIp, Headers},\n+    crypto,\n+    db::{\n+        models::{TwoFactor, TwoFactorType},\n+        DbConn,\n+    },\n };\n \n pub use crate::config::CONFIG;\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -141,7 +141,11 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n     // The amount of steps back and forward in time\n     // Also check if we need to disable time drifted TOTP codes.\n     // If that is the case, we set the steps to 0 so only the current TOTP is valid.\n-    let steps: i64 = if CONFIG.authenticator_disable_time_drift() { 0 } else { 1 };\n+    let steps: i64 = if CONFIG.authenticator_disable_time_drift() {\n+        0\n+    } else {\n+        1\n+    };\n \n     for step in -steps..=steps {\n         let time_step = current_timestamp / 30i64 + step;\n",
            "comment_added_diff": []
        },
        {
            "commit": "93c881a7a9abf30c1d2cfea961d5637de2757b86",
            "timestamp": "2021-03-31T21:45:05+01:00",
            "author": "Jake Howard",
            "commit_message": "Reflow some lines manually",
            "additions": 1,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -141,11 +141,7 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n     // The amount of steps back and forward in time\n     // Also check if we need to disable time drifted TOTP codes.\n     // If that is the case, we set the steps to 0 so only the current TOTP is valid.\n-    let steps: i64 = if CONFIG.authenticator_disable_time_drift() {\n-        0\n-    } else {\n-        1\n-    };\n+    let steps = !CONFIG.authenticator_disable_time_drift() as i64;\n \n     for step in -steps..=steps {\n         let time_step = current_timestamp / 30i64 + step;\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 4,
            "deletions": 19,
            "change_type": "MODIFY",
            "diff": "@@ -17,11 +17,7 @@ use crate::{\n pub use crate::config::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n-    routes![\n-        generate_authenticator,\n-        activate_authenticator,\n-        activate_authenticator_put,\n-    ]\n+    routes![generate_authenticator, activate_authenticator, activate_authenticator_put,]\n }\n \n #[post(\"/two-factor/get-authenticator\", data = \"<data>\")]\n@@ -163,22 +159,11 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n             twofactor.save(&conn)?;\n             return Ok(());\n         } else if generated == totp_code && time_step <= twofactor.last_used as i64 {\n-            warn!(\n-                \"This or a TOTP code within {} steps back and forward has already been used!\",\n-                steps\n-            );\n-            err!(format!(\n-                \"Invalid TOTP code! Server time: {} IP: {}\",\n-                current_time.format(\"%F %T UTC\"),\n-                ip.ip\n-            ));\n+            warn!(\"This or a TOTP code within {} steps back and forward has already been used!\", steps);\n+            err!(format!(\"Invalid TOTP code! Server time: {} IP: {}\", current_time.format(\"%F %T UTC\"), ip.ip));\n         }\n     }\n \n     // Else no valide code received, deny access\n-    err!(format!(\n-        \"Invalid TOTP code! Server time: {} IP: {}\",\n-        current_time.format(\"%F %T UTC\"),\n-        ip.ip\n-    ));\n+    err!(format!(\"Invalid TOTP code! Server time: {} IP: {}\", current_time.format(\"%F %T UTC\"), ip.ip));\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -114,7 +114,7 @@ pub fn validate_totp_code_str(\n         _ => err!(\"TOTP code is not a number\"),\n     };\n \n-    validate_totp_code(user_uuid, totp_code, secret, ip, &conn)\n+    validate_totp_code(user_uuid, totp_code, secret, ip, conn)\n }\n \n pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &ClientIp, conn: &DbConn) -> EmptyResult {\n@@ -125,7 +125,7 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n         Err(_) => err!(\"Invalid TOTP secret\"),\n     };\n \n-    let mut twofactor = match TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Authenticator as i32, &conn) {\n+    let mut twofactor = match TwoFactor::find_by_user_and_type(user_uuid, TwoFactorType::Authenticator as i32, conn) {\n         Some(tf) => tf,\n         _ => TwoFactor::new(user_uuid.to_string(), TwoFactorType::Authenticator, secret.to_string()),\n     };\n@@ -156,7 +156,7 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n             // Save the last used time step so only totp time steps higher then this one are allowed.\n             // This will also save a newly created twofactor if the code is correct.\n             twofactor.last_used = time_step as i32;\n-            twofactor.save(&conn)?;\n+            twofactor.save(conn)?;\n             return Ok(());\n         } else if generated == totp_code && time_step <= twofactor.last_used as i64 {\n             warn!(\"This or a TOTP code within {} steps back and forward has already been used!\", steps);\n",
            "comment_added_diff": []
        },
        {
            "commit": "89b5f7c98d0e655f712e8adc732b2cf32adc771d",
            "timestamp": "2021-08-22T13:46:48+02:00",
            "author": "BlackDex",
            "commit_message": "Dependency updates\n\nUpdated several dependencies and switch to different totp library.\n\n- Switch oath with totp-lite\n  oauth hasn't been updated in a long while and some dependencies could not be updated any more\n  It now also validates a preseeding 0, as the previous library returned an int instead of a str which stripped a leading 0\n- Updated rust to the current latest nightly (including build image)\n- Updated bootstrap css and js\n- Updated hadolint to latest version\n- Updated default rust image from v1.53 to v1.54\n- Updated new nightly build/clippy messages",
            "additions": 17,
            "deletions": 17,
            "change_type": "MODIFY",
            "diff": "@@ -62,7 +62,7 @@ fn activate_authenticator(\n     let data: EnableAuthenticatorData = data.into_inner().data;\n     let password_hash = data.MasterPasswordHash;\n     let key = data.Key;\n-    let token = data.Token.into_i32()? as u64;\n+    let token = data.Token.into_string();\n \n     let mut user = headers.user;\n \n@@ -81,7 +81,7 @@ fn activate_authenticator(\n     }\n \n     // Validate the token provided with the key, and save new twofactor\n-    validate_totp_code(&user.uuid, token, &key.to_uppercase(), &ip, &conn)?;\n+    validate_totp_code(&user.uuid, &token, &key.to_uppercase(), &ip, &conn)?;\n \n     _generate_recover_code(&mut user, &conn);\n \n@@ -109,16 +109,15 @@ pub fn validate_totp_code_str(\n     ip: &ClientIp,\n     conn: &DbConn,\n ) -> EmptyResult {\n-    let totp_code: u64 = match totp_code.parse() {\n-        Ok(code) => code,\n-        _ => err!(\"TOTP code is not a number\"),\n-    };\n+    if !totp_code.chars().all(char::is_numeric) {\n+        err!(\"TOTP code is not a number\");\n+    }\n \n     validate_totp_code(user_uuid, totp_code, secret, ip, conn)\n }\n \n-pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &ClientIp, conn: &DbConn) -> EmptyResult {\n-    use oath::{totp_raw_custom_time, HashType};\n+pub fn validate_totp_code(user_uuid: &str, totp_code: &str, secret: &str, ip: &ClientIp, conn: &DbConn) -> EmptyResult {\n+    use totp_lite::{totp_custom, Sha1};\n \n     let decoded_secret = match BASE32.decode(secret.as_bytes()) {\n         Ok(s) => s,\n@@ -130,27 +129,28 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n         _ => TwoFactor::new(user_uuid.to_string(), TwoFactorType::Authenticator, secret.to_string()),\n     };\n \n-    // Get the current system time in UNIX Epoch (UTC)\n-    let current_time = chrono::Utc::now();\n-    let current_timestamp = current_time.timestamp();\n-\n     // The amount of steps back and forward in time\n     // Also check if we need to disable time drifted TOTP codes.\n     // If that is the case, we set the steps to 0 so only the current TOTP is valid.\n     let steps = !CONFIG.authenticator_disable_time_drift() as i64;\n \n+    // Get the current system time in UNIX Epoch (UTC)\n+    let current_time = chrono::Utc::now();\n+    let current_timestamp = current_time.timestamp();\n+\n     for step in -steps..=steps {\n         let time_step = current_timestamp / 30i64 + step;\n-        // We need to calculate the time offsite and cast it as an i128.\n-        // Else we can't do math with it on a default u64 variable.\n+\n+        // We need to calculate the time offsite and cast it as an u64.\n+        // Since we only have times into the future and the totp generator needs an u64 instead of the default i64.\n         let time = (current_timestamp + step * 30i64) as u64;\n-        let generated = totp_raw_custom_time(&decoded_secret, 6, 0, 30, time, &HashType::SHA1);\n+        let generated = totp_custom::<Sha1>(30, 6, &decoded_secret, time);\n \n         // Check the the given code equals the generated and if the time_step is larger then the one last used.\n         if generated == totp_code && time_step > twofactor.last_used as i64 {\n             // If the step does not equals 0 the time is drifted either server or client side.\n             if step != 0 {\n-                info!(\"TOTP Time drift detected. The step offset is {}\", step);\n+                warn!(\"TOTP Time drift detected. The step offset is {}\", step);\n             }\n \n             // Save the last used time step so only totp time steps higher then this one are allowed.\n@@ -159,7 +159,7 @@ pub fn validate_totp_code(user_uuid: &str, totp_code: u64, secret: &str, ip: &Cl\n             twofactor.save(conn)?;\n             return Ok(());\n         } else if generated == totp_code && time_step <= twofactor.last_used as i64 {\n-            warn!(\"This or a TOTP code within {} steps back and forward has already been used!\", steps);\n+            warn!(\"This TOTP or a TOTP code within {} steps back or forward has already been used!\", steps);\n             err!(format!(\"Invalid TOTP code! Server time: {} IP: {}\", current_time.format(\"%F %T UTC\"), ip.ip));\n         }\n     }\n",
            "comment_added_diff": [
                [
                    137,
                    "    // Get the current system time in UNIX Epoch (UTC)"
                ],
                [
                    144,
                    "        // We need to calculate the time offsite and cast it as an u64."
                ],
                [
                    145,
                    "        // Since we only have times into the future and the totp generator needs an u64 instead of the default i64."
                ]
            ]
        }
    ],
    "identity.rs": [
        {
            "commit": "ebf40099f2fc73cc5309ddd7fff6a679dc9ae839",
            "timestamp": "2019-10-10T17:32:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated authenticator TOTP\n\n- Added security check for previouse used codes\n- Allow TOTP codes with 1 step back and forward when there is a time\ndrift. This means in total 3 codes could be valid. But only newer codes\nthen the previouse used codes are excepted after that.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -197,7 +197,7 @@ fn twofactor_auth(\n     let mut remember = data.two_factor_remember.unwrap_or(0);\n \n     match TwoFactorType::from_i32(selected_id) {\n-        Some(TwoFactorType::Authenticator) => _tf::authenticator::validate_totp_code_str(twofactor_code, &selected_data?)?,\n+        Some(TwoFactorType::Authenticator) => _tf::authenticator::validate_totp_code_str(user_uuid, twofactor_code, &selected_data?, conn)?,\n         Some(TwoFactorType::U2f) => _tf::u2f::validate_u2f_login(user_uuid, twofactor_code, conn)?,\n         Some(TwoFactorType::YubiKey) => _tf::yubikey::validate_yubikey_login(twofactor_code, &selected_data?)?,\n         Some(TwoFactorType::Duo) => _tf::duo::validate_duo_login(data.username.as_ref().unwrap(), twofactor_code, conn)?,\n",
            "comment_added_diff": []
        },
        {
            "commit": "18bc8331f9a27421b3913af4a8f070255cf3caba",
            "timestamp": "2019-10-15T21:19:49+02:00",
            "author": "vpl",
            "commit_message": "Send email when preparing 2FA JsonError",
            "additions": 8,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -293,13 +293,19 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n             }\n \n             Some(tf_type @ TwoFactorType::Email) => {\n-                let twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, &conn) {\n+                use crate::api::core::two_factor as _tf;\n+\n+                let mut twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, &conn) {\n                     Some(tf) => tf,\n                     None => err!(\"No twofactor email registered\"),\n                 };\n \n-                let email_data = EmailTokenData::from_json(&twofactor.data)?;\n+                // Send email immediately if email is the only 2FA option\n+                if providers.len() == 1 {\n+                    _tf::email::prepare_send_token(&mut twofactor, &conn)?\n+                }\n \n+                let email_data = EmailTokenData::from_json(&twofactor.data)?;\n                 result[\"TwoFactorProviders2\"][provider.to_string()] = json!({\n                     \"Email\": email::obscure_email(&email_data.email),\n                 })\n",
            "comment_added_diff": [
                [
                    303,
                    "                // Send email immediately if email is the only 2FA option"
                ]
            ]
        },
        {
            "commit": "2edecf34fff71ec1c89c05b5f6c5b6121eed715d",
            "timestamp": "2019-10-15T21:20:19+02:00",
            "author": "vpl",
            "commit_message": "Use user_uuid instead of mut twofactor",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -295,14 +295,14 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n             Some(tf_type @ TwoFactorType::Email) => {\n                 use crate::api::core::two_factor as _tf;\n \n-                let mut twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, &conn) {\n+                let twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, &conn) {\n                     Some(tf) => tf,\n                     None => err!(\"No twofactor email registered\"),\n                 };\n \n                 // Send email immediately if email is the only 2FA option\n                 if providers.len() == 1 {\n-                    _tf::email::prepare_send_token(&mut twofactor, &conn)?\n+                    _tf::email::send_token(&user_uuid, &conn)?\n                 }\n \n                 let email_data = EmailTokenData::from_json(&twofactor.data)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 29,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -3,6 +3,7 @@ use rocket::request::{Form, FormItems, FromForm};\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n+use chrono::Utc;\n \n use crate::api::core::two_factor::email::EmailTokenData;\n use crate::api::core::two_factor::{duo, email, yubikey};\n@@ -96,6 +97,34 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: ClientIp) -> JsonResult\n         )\n     }\n \n+    if !user.verified_at.is_some() && CONFIG.mail_enabled() && CONFIG.signups_verify() {\n+        let now = Utc::now().naive_utc();\n+        if user.last_verifying_at.is_none() || now.signed_duration_since(user.last_verifying_at.unwrap()).num_seconds() > CONFIG.signups_verify_resend_time() as i64 {\n+            let resend_limit = CONFIG.signups_verify_resend_limit() as i32;\n+            if resend_limit == 0 || user.login_verify_count < resend_limit {\n+                // We want to send another email verification if we require signups to verify\n+                // their email address, and we haven't sent them a reminder in a while...\n+                let mut user = user;\n+                user.last_verifying_at = Some(now);\n+                user.login_verify_count = user.login_verify_count + 1;\n+\n+                if let Err(e) = user.save(&conn) {\n+                    error!(\"Error updating user: {:#?}\", e);\n+                }\n+\n+                if let Err(e) = mail::send_verify_email(&user.email, &user.uuid) {\n+                    error!(\"Error auto-sending email verification email: {:#?}\", e);\n+                }\n+            }\n+        }\n+\n+        // We still want the login to fail until they actually verified the email address\n+        err!(\n+            \"Please verify your email before trying again.\",\n+            format!(\"IP: {}. Username: {}.\", ip.ip, username)\n+        )\n+    }\n+\n     let (mut device, new_device) = get_device(&data, &conn, &user);\n \n     let twofactor_token = twofactor_auth(&user.uuid, &data, &mut device, &conn)?;\n",
            "comment_added_diff": [
                [
                    105,
                    "                // We want to send another email verification if we require signups to verify"
                ],
                [
                    106,
                    "                // their email address, and we haven't sent them a reminder in a while..."
                ],
                [
                    121,
                    "        // We still want the login to fail until they actually verified the email address"
                ]
            ]
        },
        {
            "commit": "912e1f93b78625e5cfc1e53b5d8cd265b728dfc2",
            "timestamp": "2019-12-06T22:12:41+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix some lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -1,9 +1,9 @@\n+use chrono::Utc;\n use num_traits::FromPrimitive;\n use rocket::request::{Form, FormItems, FromForm};\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n-use chrono::Utc;\n \n use crate::api::core::two_factor::email::EmailTokenData;\n use crate::api::core::two_factor::{duo, email, yubikey};\n@@ -97,7 +97,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: ClientIp) -> JsonResult\n         )\n     }\n \n-    if !user.verified_at.is_some() && CONFIG.mail_enabled() && CONFIG.signups_verify() {\n+    if user.verified_at.is_none() && CONFIG.mail_enabled() && CONFIG.signups_verify() {\n         let now = Utc::now().naive_utc();\n         if user.last_verifying_at.is_none() || now.signed_duration_since(user.last_verifying_at.unwrap()).num_seconds() > CONFIG.signups_verify_resend_time() as i64 {\n             let resend_limit = CONFIG.signups_verify_resend_limit() as i32;\n@@ -106,7 +106,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: ClientIp) -> JsonResult\n                 // their email address, and we haven't sent them a reminder in a while...\n                 let mut user = user;\n                 user.last_verifying_at = Some(now);\n-                user.login_verify_count = user.login_verify_count + 1;\n+                user.login_verify_count += 1;\n \n                 if let Err(e) = user.save(&conn) {\n                     error!(\"Error updating user: {:#?}\", e);\n",
            "comment_added_diff": []
        },
        {
            "commit": "5cabf4d0400e0db3dffabc2cdafb803d811a01de",
            "timestamp": "2019-12-07T14:38:32+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix IP not shown when failed login (Fixes #761)",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -211,7 +211,7 @@ fn twofactor_auth(\n \n     let twofactor_code = match data.two_factor_token {\n         Some(ref code) => code,\n-        None => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?),\n+        None => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?, \"2FA token not provided\"),\n     };\n \n     let selected_twofactor = twofactors\n@@ -237,7 +237,7 @@ fn twofactor_auth(\n                 Some(ref code) if !CONFIG.disable_2fa_remember() && ct_eq(code, twofactor_code) => {\n                     remember = 1; // Make sure we also return the token here, otherwise it will only remember the first time\n                 }\n-                _ => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?),\n+                _ => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?, \"2FA Remember token not provided\"),\n             }\n         }\n         _ => err!(\"Invalid two factor provider\"),\n",
            "comment_added_diff": []
        },
        {
            "commit": "c06162b22fdf8f2cfa96b38ab1e679d1ed332b94",
            "timestamp": "2020-03-22T15:04:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Handle `devicePushToken`\n\nMobile push isn't currently supported, but this should get rid of spurious\n`Detected unexpected parameter during login: devicepushtoken` warnings.",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -347,6 +347,7 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n     Ok(result)\n }\n \n+// https://github.com/bitwarden/mobile/blob/master/src/Core/Models/Request/TokenRequest.cs\n #[derive(Debug, Clone, Default)]\n #[allow(non_snake_case)]\n struct ConnectData {\n@@ -364,6 +365,7 @@ struct ConnectData {\n     device_identifier: Option<String>,\n     device_name: Option<String>,\n     device_type: Option<String>,\n+    device_push_token: Option<String>, // Unused; mobile device push not yet supported.\n \n     // Needed for two-factor auth\n     two_factor_provider: Option<i32>,\n@@ -391,6 +393,7 @@ impl<'f> FromForm<'f> for ConnectData {\n                 \"deviceidentifier\" => form.device_identifier = Some(value),\n                 \"devicename\" => form.device_name = Some(value),\n                 \"devicetype\" => form.device_type = Some(value),\n+                \"devicepushtoken\" => form.device_push_token = Some(value),\n                 \"twofactorprovider\" => form.two_factor_provider = value.parse().ok(),\n                 \"twofactortoken\" => form.two_factor_token = Some(value),\n                 \"twofactorremember\" => form.two_factor_remember = value.parse().ok(),\n",
            "comment_added_diff": [
                [
                    350,
                    "// https://github.com/bitwarden/mobile/blob/master/src/Core/Models/Request/TokenRequest.cs"
                ],
                [
                    368,
                    "    device_push_token: Option<String>, // Unused; mobile device push not yet supported."
                ]
            ]
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -216,8 +216,7 @@ fn twofactor_auth(\n \n     let selected_twofactor = twofactors\n         .into_iter()\n-        .filter(|tf| tf.atype == selected_id && tf.enabled)\n-        .nth(0);\n+        .find(|tf| tf.atype == selected_id && tf.enabled);\n \n     use crate::api::core::two_factor as _tf;\n     use crate::crypto::ct_eq;\n",
            "comment_added_diff": []
        },
        {
            "commit": "0807783388343a8ab4035e50f0a542fadfe03423",
            "timestamp": "2020-05-14T00:19:50+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add ip on totp miss",
            "additions": 5,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -38,7 +38,7 @@ fn login(data: Form<ConnectData>, conn: DbConn, ip: ClientIp) -> JsonResult {\n             _check_is_some(&data.device_name, \"device_name cannot be blank\")?;\n             _check_is_some(&data.device_type, \"device_type cannot be blank\")?;\n \n-            _password_login(data, conn, ip)\n+            _password_login(data, conn, &ip)\n         }\n         t => err!(\"Invalid type\", t),\n     }\n@@ -71,7 +71,7 @@ fn _refresh_login(data: ConnectData, conn: DbConn) -> JsonResult {\n     })))\n }\n \n-fn _password_login(data: ConnectData, conn: DbConn, ip: ClientIp) -> JsonResult {\n+fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult {\n     // Validate scope\n     let scope = data.scope.as_ref().unwrap();\n     if scope != \"api offline_access\" {\n@@ -127,7 +127,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: ClientIp) -> JsonResult\n \n     let (mut device, new_device) = get_device(&data, &conn, &user);\n \n-    let twofactor_token = twofactor_auth(&user.uuid, &data, &mut device, &conn)?;\n+    let twofactor_token = twofactor_auth(&user.uuid, &data, &mut device, &ip, &conn)?;\n \n     if CONFIG.mail_enabled() && new_device {\n         if let Err(e) = mail::send_new_device_logged_in(&user.email, &ip.ip.to_string(), &device.updated_at, &device.name) {\n@@ -197,6 +197,7 @@ fn twofactor_auth(\n     user_uuid: &str,\n     data: &ConnectData,\n     device: &mut Device,\n+    ip: &ClientIp,\n     conn: &DbConn,\n ) -> ApiResult<Option<String>> {\n     let twofactors = TwoFactor::find_by_user(user_uuid, conn);\n@@ -225,7 +226,7 @@ fn twofactor_auth(\n     let mut remember = data.two_factor_remember.unwrap_or(0);\n \n     match TwoFactorType::from_i32(selected_id) {\n-        Some(TwoFactorType::Authenticator) => _tf::authenticator::validate_totp_code_str(user_uuid, twofactor_code, &selected_data?, conn)?,\n+        Some(TwoFactorType::Authenticator) => _tf::authenticator::validate_totp_code_str(user_uuid, twofactor_code, &selected_data?, ip, conn)?,\n         Some(TwoFactorType::U2f) => _tf::u2f::validate_u2f_login(user_uuid, twofactor_code, conn)?,\n         Some(TwoFactorType::YubiKey) => _tf::yubikey::validate_yubikey_login(twofactor_code, &selected_data?)?,\n         Some(TwoFactorType::Duo) => _tf::duo::validate_duo_login(data.username.as_ref().unwrap(), twofactor_code, conn)?,\n",
            "comment_added_diff": []
        },
        {
            "commit": "a28ebcb401be9a2b0c052d1db319a0c5d6622a3d",
            "timestamp": "2020-07-07T21:30:18-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Use local time in email notifications for new device logins\n\nIn this implementation, the `TZ` environment variable must be set\nin order for the formatted output to use a more user-friendly\ntime zone abbreviation (e.g., `UTC`). Otherwise, the output uses\nthe time zone's UTC offset (e.g., `+00:00`).",
            "additions": 5,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,4 @@\n-use chrono::Utc;\n+use chrono::Local;\n use num_traits::FromPrimitive;\n use rocket::request::{Form, FormItems, FromForm};\n use rocket::Route;\n@@ -97,8 +97,10 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n         )\n     }\n \n+    let now = Local::now();\n+\n     if user.verified_at.is_none() && CONFIG.mail_enabled() && CONFIG.signups_verify() {\n-        let now = Utc::now().naive_utc();\n+        let now = now.naive_utc();\n         if user.last_verifying_at.is_none() || now.signed_duration_since(user.last_verifying_at.unwrap()).num_seconds() > CONFIG.signups_verify_resend_time() as i64 {\n             let resend_limit = CONFIG.signups_verify_resend_limit() as i32;\n             if resend_limit == 0 || user.login_verify_count < resend_limit {\n@@ -130,7 +132,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n     let twofactor_token = twofactor_auth(&user.uuid, &data, &mut device, &ip, &conn)?;\n \n     if CONFIG.mail_enabled() && new_device {\n-        if let Err(e) = mail::send_new_device_logged_in(&user.email, &ip.ip.to_string(), &device.updated_at, &device.name) {\n+        if let Err(e) = mail::send_new_device_logged_in(&user.email, &ip.ip.to_string(), &now, &device.name) {\n             error!(\"Error sending new device email: {:#?}\", e);\n \n             if CONFIG.require_device_email() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 16,
            "deletions": 19,
            "change_type": "MODIFY",
            "diff": "@@ -1,19 +1,22 @@\n use chrono::Local;\n use num_traits::FromPrimitive;\n-use rocket::request::{Form, FormItems, FromForm};\n-use rocket::Route;\n+use rocket::{\n+    request::{Form, FormItems, FromForm},\n+    Route,\n+};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::api::core::two_factor::email::EmailTokenData;\n-use crate::api::core::two_factor::{duo, email, yubikey};\n-use crate::api::{ApiResult, EmptyResult, JsonResult};\n-use crate::auth::ClientIp;\n-use crate::db::models::*;\n-use crate::db::DbConn;\n-use crate::mail;\n-use crate::util;\n-use crate::CONFIG;\n+use crate::{\n+    api::{\n+        core::two_factor::{duo, email, email::EmailTokenData, yubikey},\n+        ApiResult, EmptyResult, JsonResult,\n+    },\n+    auth::ClientIp,\n+    db::{models::*, DbConn},\n+    error::MapResult,\n+    mail, util, CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n     routes![login]\n@@ -49,10 +52,7 @@ fn _refresh_login(data: ConnectData, conn: DbConn) -> JsonResult {\n     let token = data.refresh_token.unwrap();\n \n     // Get device by refresh token\n-    let mut device = match Device::find_by_refresh_token(&token, &conn) {\n-        Some(device) => device,\n-        None => err!(\"Invalid refresh token\"),\n-    };\n+    let mut device = Device::find_by_refresh_token(&token, &conn).map_res(\"Invalid refresh token\")?;\n \n     // COMMON\n     let user = User::find_by_uuid(&device.user_uuid, &conn).unwrap();\n@@ -254,10 +254,7 @@ fn twofactor_auth(\n }\n \n fn _selected_data(tf: Option<TwoFactor>) -> ApiResult<String> {\n-    match tf {\n-        Some(tf) => Ok(tf.data),\n-        None => err!(\"Two factor doesn't exist\"),\n-    }\n+    tf.map(|t| t.data).map_res(\"Two factor doesn't exist\")\n }\n \n fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> ApiResult<Value> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "ad48e9ed0f91a1a7b38a032b2a538d4c9725f31c",
            "timestamp": "2020-08-04T15:12:04+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix unlock on desktop clients",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -68,6 +68,11 @@ fn _refresh_login(data: ConnectData, conn: DbConn) -> JsonResult {\n         \"refresh_token\": device.refresh_token,\n         \"Key\": user.akey,\n         \"PrivateKey\": user.private_key,\n+\n+        \"Kdf\": user.client_kdf_type,\n+        \"KdfIterations\": user.client_kdf_iter,\n+        \"ResetMasterPassword\": false, // TODO: according to official server seems something like: user.password_hash.is_empty(), but would need testing\n+        \"scope\": \"api offline_access\"\n     })))\n }\n \n@@ -156,6 +161,11 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n         \"Key\": user.akey,\n         \"PrivateKey\": user.private_key,\n         //\"TwoFactorToken\": \"11122233333444555666777888999\"\n+        \n+        \"Kdf\": user.client_kdf_type,\n+        \"KdfIterations\": user.client_kdf_iter,\n+        \"ResetMasterPassword\": false,// TODO: Same as above\n+        \"scope\": \"api offline_access\"\n     });\n \n     if let Some(token) = twofactor_token {\n",
            "comment_added_diff": [
                [
                    74,
                    "        \"ResetMasterPassword\": false, // TODO: according to official server seems something like: user.password_hash.is_empty(), but would need testing"
                ],
                [
                    167,
                    "        \"ResetMasterPassword\": false,// TODO: Same as above"
                ]
            ]
        },
        {
            "commit": "29c6b145ca40e5bc125f2fb7f00b3ef5dca90d87",
            "timestamp": "2020-08-11T16:48:15+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove redundant user fetching from login",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -147,7 +147,6 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n     }\n \n     // Common\n-    let user = User::find_by_uuid(&device.user_uuid, &conn).unwrap();\n     let orgs = UserOrganization::find_by_user(&user.uuid, &conn);\n \n     let (access_token, expires_in) = device.refresh_tokens(&user, orgs);\n",
            "comment_added_diff": []
        },
        {
            "commit": "043aa27aa36f3918ad273eb67068cc0dc925dfb4",
            "timestamp": "2020-11-30T23:12:56+01:00",
            "author": "janost",
            "commit_message": "Implement admin ability to enable/disable users",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -102,6 +102,14 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n         )\n     }\n \n+    // Check if the user is disabled\n+    if !user.enabled {\n+        err!(\n+            \"This user has been disabled\",\n+            format!(\"IP: {}. Username: {}.\", ip.ip, username)\n+        )\n+    }\n+\n     let now = Local::now();\n \n     if user.verified_at.is_none() && CONFIG.mail_enabled() && CONFIG.signups_verify() {\n",
            "comment_added_diff": [
                [
                    105,
                    "    // Check if the user is disabled"
                ]
            ]
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 23,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -114,7 +114,10 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n \n     if user.verified_at.is_none() && CONFIG.mail_enabled() && CONFIG.signups_verify() {\n         let now = now.naive_utc();\n-        if user.last_verifying_at.is_none() || now.signed_duration_since(user.last_verifying_at.unwrap()).num_seconds() > CONFIG.signups_verify_resend_time() as i64 {\n+        if user.last_verifying_at.is_none()\n+            || now.signed_duration_since(user.last_verifying_at.unwrap()).num_seconds()\n+                > CONFIG.signups_verify_resend_time() as i64\n+        {\n             let resend_limit = CONFIG.signups_verify_resend_limit() as i32;\n             if resend_limit == 0 || user.login_verify_count < resend_limit {\n                 // We want to send another email verification if we require signups to verify\n@@ -168,7 +171,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n         \"Key\": user.akey,\n         \"PrivateKey\": user.private_key,\n         //\"TwoFactorToken\": \"11122233333444555666777888999\"\n-        \n+\n         \"Kdf\": user.client_kdf_type,\n         \"KdfIterations\": user.client_kdf_iter,\n         \"ResetMasterPassword\": false,// TODO: Same as above\n@@ -231,12 +234,13 @@ fn twofactor_auth(\n \n     let twofactor_code = match data.two_factor_token {\n         Some(ref code) => code,\n-        None => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?, \"2FA token not provided\"),\n+        None => err_json!(\n+            _json_err_twofactor(&twofactor_ids, user_uuid, conn)?,\n+            \"2FA token not provided\"\n+        ),\n     };\n \n-    let selected_twofactor = twofactors\n-        .into_iter()\n-        .find(|tf| tf.atype == selected_id && tf.enabled);\n+    let selected_twofactor = twofactors.into_iter().find(|tf| tf.atype == selected_id && tf.enabled);\n \n     use crate::api::core::two_factor as _tf;\n     use crate::crypto::ct_eq;\n@@ -245,18 +249,27 @@ fn twofactor_auth(\n     let mut remember = data.two_factor_remember.unwrap_or(0);\n \n     match TwoFactorType::from_i32(selected_id) {\n-        Some(TwoFactorType::Authenticator) => _tf::authenticator::validate_totp_code_str(user_uuid, twofactor_code, &selected_data?, ip, conn)?,\n+        Some(TwoFactorType::Authenticator) => {\n+            _tf::authenticator::validate_totp_code_str(user_uuid, twofactor_code, &selected_data?, ip, conn)?\n+        }\n         Some(TwoFactorType::U2f) => _tf::u2f::validate_u2f_login(user_uuid, twofactor_code, conn)?,\n         Some(TwoFactorType::YubiKey) => _tf::yubikey::validate_yubikey_login(twofactor_code, &selected_data?)?,\n-        Some(TwoFactorType::Duo) => _tf::duo::validate_duo_login(data.username.as_ref().unwrap(), twofactor_code, conn)?,\n-        Some(TwoFactorType::Email) => _tf::email::validate_email_code_str(user_uuid, twofactor_code, &selected_data?, conn)?,\n+        Some(TwoFactorType::Duo) => {\n+            _tf::duo::validate_duo_login(data.username.as_ref().unwrap(), twofactor_code, conn)?\n+        }\n+        Some(TwoFactorType::Email) => {\n+            _tf::email::validate_email_code_str(user_uuid, twofactor_code, &selected_data?, conn)?\n+        }\n \n         Some(TwoFactorType::Remember) => {\n             match device.twofactor_remember {\n                 Some(ref code) if !CONFIG.disable_2fa_remember() && ct_eq(code, twofactor_code) => {\n                     remember = 1; // Make sure we also return the token here, otherwise it will only remember the first time\n                 }\n-                _ => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?, \"2FA Remember token not provided\"),\n+                _ => err_json!(\n+                    _json_err_twofactor(&twofactor_ids, user_uuid, conn)?,\n+                    \"2FA Remember token not provided\"\n+                ),\n             }\n         }\n         _ => err!(\"Invalid two factor provider\"),\n",
            "comment_added_diff": []
        },
        {
            "commit": "b268c3dd1cfda78f113cc5c3bf06e08324590379",
            "timestamp": "2021-04-06T20:38:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update web vault and add unnoficialserver response",
            "additions": 4,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -72,7 +72,8 @@ fn _refresh_login(data: ConnectData, conn: DbConn) -> JsonResult {\n         \"Kdf\": user.client_kdf_type,\n         \"KdfIterations\": user.client_kdf_iter,\n         \"ResetMasterPassword\": false, // TODO: according to official server seems something like: user.password_hash.is_empty(), but would need testing\n-        \"scope\": \"api offline_access\"\n+        \"scope\": \"api offline_access\",\n+        \"unofficialServer\": true,\n     })))\n }\n \n@@ -172,7 +173,8 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n         \"Kdf\": user.client_kdf_type,\n         \"KdfIterations\": user.client_kdf_iter,\n         \"ResetMasterPassword\": false,// TODO: Same as above\n-        \"scope\": \"api offline_access\"\n+        \"scope\": \"api offline_access\",\n+        \"unofficialServer\": true,\n     });\n \n     if let Some(token) = twofactor_token {\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 8,
            "deletions": 24,
            "change_type": "MODIFY",
            "diff": "@@ -87,27 +87,18 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n     let username = data.username.as_ref().unwrap();\n     let user = match User::find_by_mail(username, &conn) {\n         Some(user) => user,\n-        None => err!(\n-            \"Username or password is incorrect. Try again\",\n-            format!(\"IP: {}. Username: {}.\", ip.ip, username)\n-        ),\n+        None => err!(\"Username or password is incorrect. Try again\", format!(\"IP: {}. Username: {}.\", ip.ip, username)),\n     };\n \n     // Check password\n     let password = data.password.as_ref().unwrap();\n     if !user.check_valid_password(password) {\n-        err!(\n-            \"Username or password is incorrect. Try again\",\n-            format!(\"IP: {}. Username: {}.\", ip.ip, username)\n-        )\n+        err!(\"Username or password is incorrect. Try again\", format!(\"IP: {}. Username: {}.\", ip.ip, username))\n     }\n \n     // Check if the user is disabled\n     if !user.enabled {\n-        err!(\n-            \"This user has been disabled\",\n-            format!(\"IP: {}. Username: {}.\", ip.ip, username)\n-        )\n+        err!(\"This user has been disabled\", format!(\"IP: {}. Username: {}.\", ip.ip, username))\n     }\n \n     let now = Local::now();\n@@ -137,10 +128,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n         }\n \n         // We still want the login to fail until they actually verified the email address\n-        err!(\n-            \"Please verify your email before trying again.\",\n-            format!(\"IP: {}. Username: {}.\", ip.ip, username)\n-        )\n+        err!(\"Please verify your email before trying again.\", format!(\"IP: {}. Username: {}.\", ip.ip, username))\n     }\n \n     let (mut device, new_device) = get_device(&data, &conn, &user);\n@@ -234,10 +222,7 @@ fn twofactor_auth(\n \n     let twofactor_code = match data.two_factor_token {\n         Some(ref code) => code,\n-        None => err_json!(\n-            _json_err_twofactor(&twofactor_ids, user_uuid, conn)?,\n-            \"2FA token not provided\"\n-        ),\n+        None => err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?, \"2FA token not provided\"),\n     };\n \n     let selected_twofactor = twofactors.into_iter().find(|tf| tf.atype == selected_id && tf.enabled);\n@@ -266,10 +251,9 @@ fn twofactor_auth(\n                 Some(ref code) if !CONFIG.disable_2fa_remember() && ct_eq(code, twofactor_code) => {\n                     remember = 1; // Make sure we also return the token here, otherwise it will only remember the first time\n                 }\n-                _ => err_json!(\n-                    _json_err_twofactor(&twofactor_ids, user_uuid, conn)?,\n-                    \"2FA Remember token not provided\"\n-                ),\n+                _ => {\n+                    err_json!(_json_err_twofactor(&twofactor_ids, user_uuid, conn)?, \"2FA Remember token not provided\")\n+                }\n             }\n         }\n         _ => err!(\"Invalid two factor provider\"),\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 6,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -240,6 +240,7 @@ fn twofactor_auth(\n             _tf::authenticator::validate_totp_code_str(user_uuid, twofactor_code, &selected_data?, ip, conn)?\n         }\n         Some(TwoFactorType::U2f) => _tf::u2f::validate_u2f_login(user_uuid, twofactor_code, conn)?,\n+        Some(TwoFactorType::Webauthn) => _tf::webauthn::validate_webauthn_login(user_uuid, twofactor_code, conn)?,\n         Some(TwoFactorType::YubiKey) => _tf::yubikey::validate_yubikey_login(twofactor_code, &selected_data?)?,\n         Some(TwoFactorType::Duo) => {\n             _tf::duo::validate_duo_login(data.username.as_ref().unwrap(), twofactor_code, conn)?\n@@ -309,6 +310,11 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n                 });\n             }\n \n+            Some(TwoFactorType::Webauthn) if CONFIG.domain_set() => {\n+                let request = two_factor::webauthn::generate_webauthn_login(user_uuid, conn)?;\n+                result[\"TwoFactorProviders2\"][provider.to_string()] = request.0;\n+            }\n+\n             Some(TwoFactorType::Duo) => {\n                 let email = match User::find_by_uuid(user_uuid, &conn) {\n                     Some(u) => u.email,\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 6,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -134,7 +134,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n \n     let (mut device, new_device) = get_device(&data, &conn, &user);\n \n-    let twofactor_token = twofactor_auth(&user.uuid, &data, &mut device, &ip, &conn)?;\n+    let twofactor_token = twofactor_auth(&user.uuid, &data, &mut device, ip, &conn)?;\n \n     if CONFIG.mail_enabled() && new_device {\n         if let Err(e) = mail::send_new_device_logged_in(&user.email, &ip.ip.to_string(), &now, &device.name) {\n@@ -185,7 +185,7 @@ fn get_device(data: &ConnectData, conn: &DbConn, user: &User) -> (Device, bool)\n \n     let mut new_device = false;\n     // Find device or create new\n-    let device = match Device::find_by_uuid(&device_id, &conn) {\n+    let device = match Device::find_by_uuid(&device_id, conn) {\n         Some(device) => {\n             // Check if owned device, and recreate if not\n             if device.user_uuid != user.uuid {\n@@ -316,7 +316,7 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n             }\n \n             Some(TwoFactorType::Duo) => {\n-                let email = match User::find_by_uuid(user_uuid, &conn) {\n+                let email = match User::find_by_uuid(user_uuid, conn) {\n                     Some(u) => u.email,\n                     None => err!(\"User does not exist\"),\n                 };\n@@ -330,7 +330,7 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n             }\n \n             Some(tf_type @ TwoFactorType::YubiKey) => {\n-                let twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, &conn) {\n+                let twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, conn) {\n                     Some(tf) => tf,\n                     None => err!(\"No YubiKey devices registered\"),\n                 };\n@@ -345,14 +345,14 @@ fn _json_err_twofactor(providers: &[i32], user_uuid: &str, conn: &DbConn) -> Api\n             Some(tf_type @ TwoFactorType::Email) => {\n                 use crate::api::core::two_factor as _tf;\n \n-                let twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, &conn) {\n+                let twofactor = match TwoFactor::find_by_user_and_type(user_uuid, tf_type as i32, conn) {\n                     Some(tf) => tf,\n                     None => err!(\"No twofactor email registered\"),\n                 };\n \n                 // Send email immediately if email is the only 2FA option\n                 if providers.len() == 1 {\n-                    _tf::email::send_token(&user_uuid, &conn)?\n+                    _tf::email::send_token(user_uuid, conn)?\n                 }\n \n                 let email_data = EmailTokenData::from_json(&twofactor.data)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -56,7 +56,7 @@ fn _refresh_login(data: ConnectData, conn: DbConn) -> JsonResult {\n \n     // COMMON\n     let user = User::find_by_uuid(&device.user_uuid, &conn).unwrap();\n-    let orgs = UserOrganization::find_by_user(&user.uuid, &conn);\n+    let orgs = UserOrganization::find_confirmed_by_user(&user.uuid, &conn);\n \n     let (access_token, expires_in) = device.refresh_tokens(&user, orgs);\n \n@@ -147,7 +147,7 @@ fn _password_login(data: ConnectData, conn: DbConn, ip: &ClientIp) -> JsonResult\n     }\n \n     // Common\n-    let orgs = UserOrganization::find_by_user(&user.uuid, &conn);\n+    let orgs = UserOrganization::find_confirmed_by_user(&user.uuid, &conn);\n \n     let (access_token, expires_in) = device.refresh_tokens(&user, orgs);\n     device.save(&conn)?;\n",
            "comment_added_diff": []
        }
    ],
    "two_factor.rs": [
        {
            "commit": "ebf40099f2fc73cc5309ddd7fff6a679dc9ae839",
            "timestamp": "2019-10-10T17:32:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated authenticator TOTP\n\n- Added security check for previouse used codes\n- Allow TOTP codes with 1 step back and forward when there is a time\ndrift. This means in total 3 codes could be valid. But only newer codes\nthen the previouse used codes are excepted after that.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -19,6 +19,7 @@ pub struct TwoFactor {\n     pub atype: i32,\n     pub enabled: bool,\n     pub data: String,\n+    pub last_used: i32,\n }\n \n #[allow(dead_code)]\n@@ -47,6 +48,7 @@ impl TwoFactor {\n             atype: atype as i32,\n             enabled: true,\n             data,\n+            last_used: 0,\n         }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "76743aee48263f459ad4c8f3fc6a77bd2e482f35",
            "timestamp": "2020-01-13T21:53:57-05:00",
            "author": "Michael Powers",
            "commit_message": "Fixes #635 - Unique constraint violation when using U2F tokens on PostgreSQL\nBecause of differences in how .on_conflict() works compared to .replace_into() the PostgreSQL backend wasn't correctly ensuring the unique constraint on user_uuid and atype wasn't getting violated.\n\nThis change simply issues a DELETE on the unique constraint prior to the insert to ensure uniqueness. PostgreSQL does not support multiple constraints in ON CONFLICT clauses.",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -73,6 +73,16 @@ impl TwoFactor {\n impl TwoFactor {\n     #[cfg(feature = \"postgresql\")]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n+        // We need to make sure we're not going to violate the unique constraint on user_uuid and atype.\n+        // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n+        // not support multiple constraints on ON CONFLICT clauses.\n+        let result: EmptyResult = diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(&self.user_uuid)).filter(twofactor::atype.eq(&self.atype)))\n+            .execute(&**conn)\n+            .map_res(\"Error deleting twofactor for insert\");\n+        if result.is_err() {\n+            return result;\n+        }\n+\n         diesel::insert_into(twofactor::table)\n             .values(self)\n             .on_conflict(twofactor::uuid)\n",
            "comment_added_diff": [
                [
                    76,
                    "        // We need to make sure we're not going to violate the unique constraint on user_uuid and atype."
                ],
                [
                    77,
                    "        // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does"
                ],
                [
                    78,
                    "        // not support multiple constraints on ON CONFLICT clauses."
                ]
            ]
        },
        {
            "commit": "e196ba6e869793a37f0f5fa79f0f46c12ec3b40a",
            "timestamp": "2020-01-16T08:14:25-05:00",
            "author": "Michael Powers",
            "commit_message": "Switch error handling to ? operator instead of explicit handling.",
            "additions": 2,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -76,12 +76,9 @@ impl TwoFactor {\n         // We need to make sure we're not going to violate the unique constraint on user_uuid and atype.\n         // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n         // not support multiple constraints on ON CONFLICT clauses.\n-        let result: EmptyResult = diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(&self.user_uuid)).filter(twofactor::atype.eq(&self.atype)))\n+        diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(&self.user_uuid)).filter(twofactor::atype.eq(&self.atype)))\n             .execute(&**conn)\n-            .map_res(\"Error deleting twofactor for insert\");\n-        if result.is_err() {\n-            return result;\n-        }\n+            .map_res(\"Error deleting twofactor for insert\")?;\n \n         diesel::insert_into(twofactor::table)\n             .values(self)\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,3 @@\n-use diesel;\n use diesel::prelude::*;\n use serde_json::Value;\n \n@@ -23,7 +22,7 @@ pub struct TwoFactor {\n }\n \n #[allow(dead_code)]\n-#[derive(FromPrimitive)]\n+#[derive(num_derive::FromPrimitive)]\n pub enum TwoFactorType {\n     Authenticator = 0,\n     Email = 1,\n",
            "comment_added_diff": []
        },
        {
            "commit": "dfdf4473ea89087a5d055a7d9fdcda62fa727c58",
            "timestamp": "2020-05-08T13:36:35-04:00",
            "author": "theycallmesteve",
            "commit_message": "Rename to_json_list to to_json_provder to reflect the response model",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -59,7 +59,7 @@ impl TwoFactor {\n         })\n     }\n \n-    pub fn to_json_list(&self) -> Value {\n+    pub fn to_json_provider(&self) -> Value {\n         json!({\n             \"Enabled\": self.enabled,\n             \"Type\": self.atype,\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 63,
            "deletions": 51,
            "change_type": "MODIFY",
            "diff": "@@ -1,24 +1,24 @@\n-use diesel::prelude::*;\n use serde_json::Value;\n \n use crate::api::EmptyResult;\n-use crate::db::schema::twofactor;\n use crate::db::DbConn;\n use crate::error::MapResult;\n \n use super::User;\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"twofactor\"]\n-#[belongs_to(User, foreign_key = \"user_uuid\")]\n-#[primary_key(uuid)]\n-pub struct TwoFactor {\n-    pub uuid: String,\n-    pub user_uuid: String,\n-    pub atype: i32,\n-    pub enabled: bool,\n-    pub data: String,\n-    pub last_used: i32,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"twofactor\"]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct TwoFactor {\n+        pub uuid: String,\n+        pub user_uuid: String,\n+        pub atype: i32,\n+        pub enabled: bool,\n+        pub data: String,\n+        pub last_used: i32,\n+    }\n }\n \n #[allow(dead_code)]\n@@ -70,57 +70,69 @@ impl TwoFactor {\n \n /// Database methods\n impl TwoFactor {\n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        // We need to make sure we're not going to violate the unique constraint on user_uuid and atype.\n-        // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n-        // not support multiple constraints on ON CONFLICT clauses.\n-        diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(&self.user_uuid)).filter(twofactor::atype.eq(&self.atype)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting twofactor for insert\")?;\n-\n-        diesel::insert_into(twofactor::table)\n-            .values(self)\n-            .on_conflict(twofactor::uuid)\n-            .do_update()\n-            .set(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving twofactor\")\n-    }\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(twofactor::table)\n+                    .values(TwoFactorDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving twofactor\")        \n+            }\n+            postgresql {\n+                let value = TwoFactorDb::to_db(self);\n+                // We need to make sure we're not going to violate the unique constraint on user_uuid and atype.\n+                // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n+                // not support multiple constraints on ON CONFLICT clauses.\n+                diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(&self.user_uuid)).filter(twofactor::atype.eq(&self.atype)))\n+                    .execute(conn)\n+                    .map_res(\"Error deleting twofactor for insert\")?;\n \n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        diesel::replace_into(twofactor::table)\n-            .values(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving twofactor\")\n+                diesel::insert_into(twofactor::table)\n+                    .values(&value)\n+                    .on_conflict(twofactor::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving twofactor\")            \n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(twofactor::table.filter(twofactor::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting twofactor\")\n+        db_run! { conn: {\n+            diesel::delete(twofactor::table.filter(twofactor::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting twofactor\")\n+        }}\n     }\n \n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        twofactor::table\n-            .filter(twofactor::user_uuid.eq(user_uuid))\n-            .filter(twofactor::atype.lt(1000)) // Filter implementation types\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading twofactor\")\n+        db_run! { conn: {\n+            twofactor::table\n+                .filter(twofactor::user_uuid.eq(user_uuid))\n+                .filter(twofactor::atype.lt(1000)) // Filter implementation types\n+                .load::<TwoFactorDb>(conn)\n+                .expect(\"Error loading twofactor\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_user_and_type(user_uuid: &str, atype: i32, conn: &DbConn) -> Option<Self> {\n-        twofactor::table\n-            .filter(twofactor::user_uuid.eq(user_uuid))\n-            .filter(twofactor::atype.eq(atype))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            twofactor::table\n+                .filter(twofactor::user_uuid.eq(user_uuid))\n+                .filter(twofactor::atype.eq(atype))\n+                .first::<TwoFactorDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting twofactors\")\n+        db_run! { conn: {\n+            diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting twofactors\")\n+        }}\n     }\n }\n",
            "comment_added_diff": [
                [
                    83,
                    "                // We need to make sure we're not going to violate the unique constraint on user_uuid and atype."
                ],
                [
                    84,
                    "                // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does"
                ],
                [
                    85,
                    "                // not support multiple constraints on ON CONFLICT clauses."
                ],
                [
                    113,
                    "                .filter(twofactor::atype.lt(1000)) // Filter implementation types"
                ]
            ]
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 15,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -71,12 +71,23 @@ impl TwoFactor {\n /// Database methods\n impl TwoFactor {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(twofactor::table)\n+                match diesel::replace_into(twofactor::table)\n                     .values(TwoFactorDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving twofactor\")        \n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(twofactor::table)\n+                            .filter(twofactor::uuid.eq(&self.uuid))\n+                            .set(TwoFactorDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving twofactor\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving twofactor\")\n             }\n             postgresql {\n                 let value = TwoFactorDb::to_db(self);\n@@ -93,7 +104,7 @@ impl TwoFactor {\n                     .do_update()\n                     .set(&value)\n                     .execute(conn)\n-                    .map_res(\"Error saving twofactor\")            \n+                    .map_res(\"Error saving twofactor\")\n             }\n         }\n     }\n",
            "comment_added_diff": [
                [
                    81,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -7,7 +7,7 @@ use crate::error::MapResult;\n use super::User;\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"twofactor\"]\n     #[belongs_to(User, foreign_key = \"user_uuid\")]\n     #[primary_key(uuid)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 72,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -31,11 +31,14 @@ pub enum TwoFactorType {\n     U2f = 4,\n     Remember = 5,\n     OrganizationDuo = 6,\n+    Webauthn = 7,\n \n     // These are implementation details\n     U2fRegisterChallenge = 1000,\n     U2fLoginChallenge = 1001,\n     EmailVerificationChallenge = 1002,\n+    WebauthnRegisterChallenge = 1003,\n+    WebauthnLoginChallenge = 1004,\n }\n \n /// Local methods\n@@ -146,4 +149,73 @@ impl TwoFactor {\n                 .map_res(\"Error deleting twofactors\")\n         }}\n     }\n+\n+    pub fn migrate_u2f_to_webauthn(conn: &DbConn) -> EmptyResult {\n+        let u2f_factors = db_run! { conn: {\n+            twofactor::table\n+                .filter(twofactor::atype.eq(TwoFactorType::U2f as i32))\n+                .load::<TwoFactorDb>(conn)\n+                .expect(\"Error loading twofactor\")\n+                .from_db()\n+        }};\n+\n+        use crate::api::core::two_factor::u2f::U2FRegistration;\n+        use crate::api::core::two_factor::webauthn::{get_webauthn_registrations, WebauthnRegistration};\n+        use std::convert::TryInto;\n+        use webauthn_rs::proto::*;\n+\n+        for mut u2f in u2f_factors {\n+            let mut regs: Vec<U2FRegistration> = serde_json::from_str(&u2f.data)?;\n+            // If there are no registrations or they are migrated (we do the migration in batch so we can consider them all migrated when the first one is)\n+            if regs.is_empty() || regs[0].migrated == Some(true) {\n+                continue;\n+            }\n+\n+            let (_, mut webauthn_regs) = get_webauthn_registrations(&u2f.user_uuid, &conn)?;\n+\n+            // If the user already has webauthn registrations saved, don't overwrite them\n+            if !webauthn_regs.is_empty() {\n+                continue;\n+            }\n+\n+            for reg in &mut regs {\n+                let x: [u8; 32] = reg.reg.pub_key[1..33].try_into().unwrap();\n+                let y: [u8; 32] = reg.reg.pub_key[33..65].try_into().unwrap();\n+\n+                let key = COSEKey {\n+                    type_: COSEAlgorithm::ES256,\n+                    key: COSEKeyType::EC_EC2(COSEEC2Key {\n+                        curve: ECDSACurve::SECP256R1,\n+                        x,\n+                        y,\n+                    }),\n+                };\n+\n+                let new_reg = WebauthnRegistration {\n+                    id: reg.id,\n+                    migrated: true,\n+                    name: reg.name.clone(),\n+                    credential: Credential {\n+                        counter: reg.counter,\n+                        verified: false,\n+                        cred: key,\n+                        cred_id: reg.reg.key_handle.clone(),\n+                        registration_policy: UserVerificationPolicy::Discouraged,\n+                    },\n+                };\n+\n+                webauthn_regs.push(new_reg);\n+\n+                reg.migrated = Some(true);\n+            }\n+\n+            u2f.data = serde_json::to_string(&regs)?;\n+            u2f.save(&conn)?;\n+\n+            TwoFactor::new(u2f.user_uuid.clone(), TwoFactorType::Webauthn, serde_json::to_string(&webauthn_regs)?)\n+                .save(&conn)?;\n+        }\n+\n+        Ok(())\n+    }\n }\n",
            "comment_added_diff": [
                [
                    169,
                    "            // If there are no registrations or they are migrated (we do the migration in batch so we can consider them all migrated when the first one is)"
                ],
                [
                    176,
                    "            // If the user already has webauthn registrations saved, don't overwrite them"
                ]
            ]
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -171,7 +171,7 @@ impl TwoFactor {\n                 continue;\n             }\n \n-            let (_, mut webauthn_regs) = get_webauthn_registrations(&u2f.user_uuid, &conn)?;\n+            let (_, mut webauthn_regs) = get_webauthn_registrations(&u2f.user_uuid, conn)?;\n \n             // If the user already has webauthn registrations saved, don't overwrite them\n             if !webauthn_regs.is_empty() {\n@@ -210,10 +210,10 @@ impl TwoFactor {\n             }\n \n             u2f.data = serde_json::to_string(&regs)?;\n-            u2f.save(&conn)?;\n+            u2f.save(conn)?;\n \n             TwoFactor::new(u2f.user_uuid.clone(), TwoFactorType::Webauthn, serde_json::to_string(&webauthn_regs)?)\n-                .save(&conn)?;\n+                .save(conn)?;\n         }\n \n         Ok(())\n",
            "comment_added_diff": []
        }
    ],
    "schema.rs": [
        {
            "commit": "ebf40099f2fc73cc5309ddd7fff6a679dc9ae839",
            "timestamp": "2019-10-10T17:32:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated authenticator TOTP\n\n- Added security check for previouse used codes\n- Allow TOTP codes with 1 step back and forward when there is a time\ndrift. This means in total 3 codes could be valid. But only newer codes\nthen the previouse used codes are excepted after that.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -92,6 +92,7 @@ table! {\n         atype -> Integer,\n         enabled -> Bool,\n         data -> Text,\n+        last_used -> Integer,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "ebf40099f2fc73cc5309ddd7fff6a679dc9ae839",
            "timestamp": "2019-10-10T17:32:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated authenticator TOTP\n\n- Added security check for previouse used codes\n- Allow TOTP codes with 1 step back and forward when there is a time\ndrift. This means in total 3 codes could be valid. But only newer codes\nthen the previouse used codes are excepted after that.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -92,6 +92,7 @@ table! {\n         atype -> Integer,\n         enabled -> Bool,\n         data -> Text,\n+        last_used -> Integer,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "ebf40099f2fc73cc5309ddd7fff6a679dc9ae839",
            "timestamp": "2019-10-10T17:32:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated authenticator TOTP\n\n- Added security check for previouse used codes\n- Allow TOTP codes with 1 step back and forward when there is a time\ndrift. This means in total 3 codes could be valid. But only newer codes\nthen the previouse used codes are excepted after that.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -92,6 +92,7 @@ table! {\n         atype -> Integer,\n         enabled -> Bool,\n         data -> Text,\n+        last_used -> Integer,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 5,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -101,7 +101,12 @@ table! {\n         uuid -> Varchar,\n         created_at -> Datetime,\n         updated_at -> Datetime,\n+        verified_at -> Nullable<Datetime>,\n+        last_verifying_at -> Nullable<Datetime>,\n+        login_verify_count -> Integer,\n         email -> Varchar,\n+        email_new -> Nullable<Varchar>,\n+        email_new_token -> Nullable<Varchar>,\n         name -> Text,\n         password_hash -> Blob,\n         salt -> Blob,\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -101,7 +101,12 @@ table! {\n         uuid -> Text,\n         created_at -> Timestamp,\n         updated_at -> Timestamp,\n+        verified_at -> Nullable<Timestamp>,\n+        last_verifying_at -> Nullable<Timestamp>,\n+        login_verify_count -> Integer,\n         email -> Text,\n+        email_new -> Nullable<Text>,\n+        email_new_token -> Nullable<Text>,\n         name -> Text,\n         password_hash -> Binary,\n         salt -> Binary,\n@@ -170,4 +175,4 @@ allow_tables_to_appear_in_same_query!(\n     users,\n     users_collections,\n     users_organizations,\n-);\n\\ No newline at end of file\n+);\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 5,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -101,7 +101,12 @@ table! {\n         uuid -> Text,\n         created_at -> Timestamp,\n         updated_at -> Timestamp,\n+        verified_at -> Nullable<Timestamp>,\n+        last_verifying_at -> Nullable<Timestamp>,\n+        login_verify_count -> Integer,\n         email -> Text,\n+        email_new -> Nullable<Text>,\n+        email_new_token -> Nullable<Text>,\n         name -> Text,\n         password_hash -> Binary,\n         salt -> Binary,\n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -77,6 +77,16 @@ table! {\n     }\n }\n \n+table! {\n+    org_policies (uuid) {\n+        uuid -> Varchar,\n+        org_uuid -> Varchar,\n+        atype -> Integer,\n+        enabled -> Bool,\n+        data -> Text,\n+    }\n+}\n+\n table! {\n     organizations (uuid) {\n         uuid -> Varchar,\n@@ -155,6 +165,7 @@ joinable!(devices -> users (user_uuid));\n joinable!(folders -> users (user_uuid));\n joinable!(folders_ciphers -> ciphers (cipher_uuid));\n joinable!(folders_ciphers -> folders (folder_uuid));\n+joinable!(org_policies -> organizations (org_uuid));\n joinable!(twofactor -> users (user_uuid));\n joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n@@ -170,6 +181,7 @@ allow_tables_to_appear_in_same_query!(\n     folders,\n     folders_ciphers,\n     invitations,\n+    org_policies,\n     organizations,\n     twofactor,\n     users,\n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -77,6 +77,16 @@ table! {\n     }\n }\n \n+table! {\n+    org_policies (uuid) {\n+        uuid -> Text,\n+        org_uuid -> Text,\n+        atype -> Integer,\n+        enabled -> Bool,\n+        data -> Text,\n+    }\n+}\n+\n table! {\n     organizations (uuid) {\n         uuid -> Text,\n@@ -155,6 +165,7 @@ joinable!(devices -> users (user_uuid));\n joinable!(folders -> users (user_uuid));\n joinable!(folders_ciphers -> ciphers (cipher_uuid));\n joinable!(folders_ciphers -> folders (folder_uuid));\n+joinable!(org_policies -> organizations (org_uuid));\n joinable!(twofactor -> users (user_uuid));\n joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n@@ -170,6 +181,7 @@ allow_tables_to_appear_in_same_query!(\n     folders,\n     folders_ciphers,\n     invitations,\n+    org_policies,\n     organizations,\n     twofactor,\n     users,\n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -77,6 +77,16 @@ table! {\n     }\n }\n \n+table! {\n+    org_policies (uuid) {\n+        uuid -> Text,\n+        org_uuid -> Text,\n+        atype -> Integer,\n+        enabled -> Bool,\n+        data -> Text,\n+    }\n+}\n+\n table! {\n     organizations (uuid) {\n         uuid -> Text,\n@@ -155,6 +165,7 @@ joinable!(devices -> users (user_uuid));\n joinable!(folders -> users (user_uuid));\n joinable!(folders_ciphers -> ciphers (cipher_uuid));\n joinable!(folders_ciphers -> folders (folder_uuid));\n+joinable!(org_policies -> organizations (org_uuid));\n joinable!(twofactor -> users (user_uuid));\n joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n@@ -170,6 +181,7 @@ allow_tables_to_appear_in_same_query!(\n     folders,\n     folders_ciphers,\n     invitations,\n+    org_policies,\n     organizations,\n     twofactor,\n     users,\n",
            "comment_added_diff": []
        },
        {
            "commit": "e3b00b59a7db760848f6b357fc4328081574aeac",
            "timestamp": "2020-04-17T22:35:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial support for soft deletes",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ table! {\n         data -> Text,\n         favorite -> Bool,\n         password_history -> Nullable<Text>,\n+        deleted_at -> Nullable<Datetime>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "e3b00b59a7db760848f6b357fc4328081574aeac",
            "timestamp": "2020-04-17T22:35:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial support for soft deletes",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ table! {\n         data -> Text,\n         favorite -> Bool,\n         password_history -> Nullable<Text>,\n+        deleted_at -> Nullable<Timestamp>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "e3b00b59a7db760848f6b357fc4328081574aeac",
            "timestamp": "2020-04-17T22:35:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial support for soft deletes",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ table! {\n         data -> Text,\n         favorite -> Bool,\n         password_history -> Nullable<Text>,\n+        deleted_at -> Nullable<Timestamp>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -141,6 +141,7 @@ table! {\n         user_uuid -> Varchar,\n         collection_uuid -> Varchar,\n         read_only -> Bool,\n+        hide_passwords -> Bool,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -141,6 +141,7 @@ table! {\n         user_uuid -> Text,\n         collection_uuid -> Text,\n         read_only -> Bool,\n+        hide_passwords -> Bool,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -141,6 +141,7 @@ table! {\n         user_uuid -> Text,\n         collection_uuid -> Text,\n         read_only -> Bool,\n+        hide_passwords -> Bool,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0e9eba8c8b7e2b3b3ea4793ed71c6c52c6606a96",
            "timestamp": "2020-08-19T02:32:56-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Maximize similarity between MySQL and SQLite/PostgreSQL schemas\n\nIn particular, Diesel aliases `Varchar` to `Text`, and `Blob` to `Binary`:\n\n* https://docs.diesel.rs/diesel/sql_types/struct.Text.html\n* https://docs.diesel.rs/diesel/sql_types/struct.Binary.html",
            "additions": 32,
            "deletions": 32,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,7 @@\n table! {\n     attachments (id) {\n-        id -> Varchar,\n-        cipher_uuid -> Varchar,\n+        id -> Text,\n+        cipher_uuid -> Text,\n         file_name -> Text,\n         file_size -> Integer,\n         akey -> Nullable<Text>,\n@@ -10,11 +10,11 @@ table! {\n \n table! {\n     ciphers (uuid) {\n-        uuid -> Varchar,\n+        uuid -> Text,\n         created_at -> Datetime,\n         updated_at -> Datetime,\n-        user_uuid -> Nullable<Varchar>,\n-        organization_uuid -> Nullable<Varchar>,\n+        user_uuid -> Nullable<Text>,\n+        organization_uuid -> Nullable<Text>,\n         atype -> Integer,\n         name -> Text,\n         notes -> Nullable<Text>,\n@@ -28,25 +28,25 @@ table! {\n \n table! {\n     ciphers_collections (cipher_uuid, collection_uuid) {\n-        cipher_uuid -> Varchar,\n-        collection_uuid -> Varchar,\n+        cipher_uuid -> Text,\n+        collection_uuid -> Text,\n     }\n }\n \n table! {\n     collections (uuid) {\n-        uuid -> Varchar,\n-        org_uuid -> Varchar,\n+        uuid -> Text,\n+        org_uuid -> Text,\n         name -> Text,\n     }\n }\n \n table! {\n     devices (uuid) {\n-        uuid -> Varchar,\n+        uuid -> Text,\n         created_at -> Datetime,\n         updated_at -> Datetime,\n-        user_uuid -> Varchar,\n+        user_uuid -> Text,\n         name -> Text,\n         atype -> Integer,\n         push_token -> Nullable<Text>,\n@@ -57,31 +57,31 @@ table! {\n \n table! {\n     folders (uuid) {\n-        uuid -> Varchar,\n+        uuid -> Text,\n         created_at -> Datetime,\n         updated_at -> Datetime,\n-        user_uuid -> Varchar,\n+        user_uuid -> Text,\n         name -> Text,\n     }\n }\n \n table! {\n     folders_ciphers (cipher_uuid, folder_uuid) {\n-        cipher_uuid -> Varchar,\n-        folder_uuid -> Varchar,\n+        cipher_uuid -> Text,\n+        folder_uuid -> Text,\n     }\n }\n \n table! {\n     invitations (email) {\n-        email -> Varchar,\n+        email -> Text,\n     }\n }\n \n table! {\n     org_policies (uuid) {\n-        uuid -> Varchar,\n-        org_uuid -> Varchar,\n+        uuid -> Text,\n+        org_uuid -> Text,\n         atype -> Integer,\n         enabled -> Bool,\n         data -> Text,\n@@ -90,7 +90,7 @@ table! {\n \n table! {\n     organizations (uuid) {\n-        uuid -> Varchar,\n+        uuid -> Text,\n         name -> Text,\n         billing_email -> Text,\n     }\n@@ -98,8 +98,8 @@ table! {\n \n table! {\n     twofactor (uuid) {\n-        uuid -> Varchar,\n-        user_uuid -> Varchar,\n+        uuid -> Text,\n+        user_uuid -> Text,\n         atype -> Integer,\n         enabled -> Bool,\n         data -> Text,\n@@ -109,18 +109,18 @@ table! {\n \n table! {\n     users (uuid) {\n-        uuid -> Varchar,\n+        uuid -> Text,\n         created_at -> Datetime,\n         updated_at -> Datetime,\n         verified_at -> Nullable<Datetime>,\n         last_verifying_at -> Nullable<Datetime>,\n         login_verify_count -> Integer,\n-        email -> Varchar,\n-        email_new -> Nullable<Varchar>,\n-        email_new_token -> Nullable<Varchar>,\n+        email -> Text,\n+        email_new -> Nullable<Text>,\n+        email_new_token -> Nullable<Text>,\n         name -> Text,\n-        password_hash -> Blob,\n-        salt -> Blob,\n+        password_hash -> Binary,\n+        salt -> Binary,\n         password_iterations -> Integer,\n         password_hint -> Nullable<Text>,\n         akey -> Text,\n@@ -138,8 +138,8 @@ table! {\n \n table! {\n     users_collections (user_uuid, collection_uuid) {\n-        user_uuid -> Varchar,\n-        collection_uuid -> Varchar,\n+        user_uuid -> Text,\n+        collection_uuid -> Text,\n         read_only -> Bool,\n         hide_passwords -> Bool,\n     }\n@@ -147,9 +147,9 @@ table! {\n \n table! {\n     users_organizations (uuid) {\n-        uuid -> Varchar,\n-        user_uuid -> Varchar,\n-        org_uuid -> Varchar,\n+        uuid -> Text,\n+        user_uuid -> Text,\n+        org_uuid -> Text,\n         access_all -> Bool,\n         akey -> Text,\n         status -> Integer,\n",
            "comment_added_diff": []
        },
        {
            "commit": "f83a8a36d16eb14c4d2f68f7edf7989bbf7973cb",
            "timestamp": "2020-08-19T02:32:58-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Track favorites on a per-user basis\n\nCurrently, favorites are tracked at the cipher level. For org-owned ciphers,\nthis means that if one user sets it as a favorite, it automatically becomes a\nfavorite for all other users that the cipher has been shared with.",
            "additions": 7,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -20,7 +20,6 @@ table! {\n         notes -> Nullable<Text>,\n         fields -> Nullable<Text>,\n         data -> Text,\n-        favorite -> Bool,\n         password_history -> Nullable<Text>,\n         deleted_at -> Nullable<Datetime>,\n     }\n@@ -55,6 +54,13 @@ table! {\n     }\n }\n \n+table! {\n+    favorites (user_uuid, cipher_uuid) {\n+        user_uuid -> Text,\n+        cipher_uuid -> Text,\n+    }\n+}\n+\n table! {\n     folders (uuid) {\n         uuid -> Text,\n",
            "comment_added_diff": []
        },
        {
            "commit": "f83a8a36d16eb14c4d2f68f7edf7989bbf7973cb",
            "timestamp": "2020-08-19T02:32:58-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Track favorites on a per-user basis\n\nCurrently, favorites are tracked at the cipher level. For org-owned ciphers,\nthis means that if one user sets it as a favorite, it automatically becomes a\nfavorite for all other users that the cipher has been shared with.",
            "additions": 7,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -20,7 +20,6 @@ table! {\n         notes -> Nullable<Text>,\n         fields -> Nullable<Text>,\n         data -> Text,\n-        favorite -> Bool,\n         password_history -> Nullable<Text>,\n         deleted_at -> Nullable<Timestamp>,\n     }\n@@ -55,6 +54,13 @@ table! {\n     }\n }\n \n+table! {\n+    favorites (user_uuid, cipher_uuid) {\n+        user_uuid -> Text,\n+        cipher_uuid -> Text,\n+    }\n+}\n+\n table! {\n     folders (uuid) {\n         uuid -> Text,\n",
            "comment_added_diff": []
        },
        {
            "commit": "f83a8a36d16eb14c4d2f68f7edf7989bbf7973cb",
            "timestamp": "2020-08-19T02:32:58-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Track favorites on a per-user basis\n\nCurrently, favorites are tracked at the cipher level. For org-owned ciphers,\nthis means that if one user sets it as a favorite, it automatically becomes a\nfavorite for all other users that the cipher has been shared with.",
            "additions": 7,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -20,7 +20,6 @@ table! {\n         notes -> Nullable<Text>,\n         fields -> Nullable<Text>,\n         data -> Text,\n-        favorite -> Bool,\n         password_history -> Nullable<Text>,\n         deleted_at -> Nullable<Timestamp>,\n     }\n@@ -55,6 +54,13 @@ table! {\n     }\n }\n \n+table! {\n+    favorites (user_uuid, cipher_uuid) {\n+        user_uuid -> Text,\n+        cipher_uuid -> Text,\n+    }\n+}\n+\n table! {\n     folders (uuid) {\n         uuid -> Text,\n",
            "comment_added_diff": []
        },
        {
            "commit": "043aa27aa36f3918ad273eb67068cc0dc925dfb4",
            "timestamp": "2020-11-30T23:12:56+01:00",
            "author": "janost",
            "commit_message": "Implement admin ability to enable/disable users",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -116,6 +116,7 @@ table! {\n table! {\n     users (uuid) {\n         uuid -> Text,\n+        enabled -> Bool,\n         created_at -> Datetime,\n         updated_at -> Datetime,\n         verified_at -> Nullable<Datetime>,\n",
            "comment_added_diff": []
        },
        {
            "commit": "043aa27aa36f3918ad273eb67068cc0dc925dfb4",
            "timestamp": "2020-11-30T23:12:56+01:00",
            "author": "janost",
            "commit_message": "Implement admin ability to enable/disable users",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -116,6 +116,7 @@ table! {\n table! {\n     users (uuid) {\n         uuid -> Text,\n+        enabled -> Bool,\n         created_at -> Timestamp,\n         updated_at -> Timestamp,\n         verified_at -> Nullable<Timestamp>,\n",
            "comment_added_diff": []
        },
        {
            "commit": "043aa27aa36f3918ad273eb67068cc0dc925dfb4",
            "timestamp": "2020-11-30T23:12:56+01:00",
            "author": "janost",
            "commit_message": "Implement admin ability to enable/disable users",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -116,6 +116,7 @@ table! {\n table! {\n     users (uuid) {\n         uuid -> Text,\n+        enabled -> Bool,\n         created_at -> Timestamp,\n         updated_at -> Timestamp,\n         verified_at -> Nullable<Timestamp>,\n",
            "comment_added_diff": []
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -136,6 +136,7 @@ table! {\n         totp_secret -> Nullable<Text>,\n         totp_recover -> Nullable<Text>,\n         security_stamp -> Text,\n+        stamp_exception -> Nullable<Text>,\n         equivalent_domains -> Text,\n         excluded_globals -> Text,\n         client_kdf_type -> Integer,\n",
            "comment_added_diff": []
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -136,6 +136,7 @@ table! {\n         totp_secret -> Nullable<Text>,\n         totp_recover -> Nullable<Text>,\n         security_stamp -> Text,\n+        stamp_exception -> Nullable<Text>,\n         equivalent_domains -> Text,\n         excluded_globals -> Text,\n         client_kdf_type -> Integer,\n",
            "comment_added_diff": []
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -136,6 +136,7 @@ table! {\n         totp_secret -> Nullable<Text>,\n         totp_recover -> Nullable<Text>,\n         security_stamp -> Text,\n+        stamp_exception -> Nullable<Text>,\n         equivalent_domains -> Text,\n         excluded_globals -> Text,\n         client_kdf_type -> Integer,\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 26,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -102,6 +102,29 @@ table! {\n     }\n }\n \n+table! {\n+    sends (uuid) {\n+        uuid -> Text,\n+        user_uuid -> Nullable<Text>,\n+        organization_uuid -> Nullable<Text>,\n+        name -> Text,\n+        notes -> Nullable<Text>,\n+        atype -> Integer,\n+        data -> Text,\n+        key -> Text,\n+        password_hash -> Nullable<Binary>,\n+        password_salt -> Nullable<Binary>,\n+        password_iter -> Nullable<Integer>,\n+        max_access_count -> Nullable<Integer>,\n+        access_count -> Integer,\n+        creation_date -> Datetime,\n+        revision_date -> Datetime,\n+        expiration_date -> Nullable<Datetime>,\n+        deletion_date -> Datetime,\n+        disabled -> Bool,\n+    }\n+}\n+\n table! {\n     twofactor (uuid) {\n         uuid -> Text,\n@@ -176,6 +199,8 @@ joinable!(folders -> users (user_uuid));\n joinable!(folders_ciphers -> ciphers (cipher_uuid));\n joinable!(folders_ciphers -> folders (folder_uuid));\n joinable!(org_policies -> organizations (org_uuid));\n+joinable!(sends -> organizations (organization_uuid));\n+joinable!(sends -> users (user_uuid));\n joinable!(twofactor -> users (user_uuid));\n joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n@@ -193,6 +218,7 @@ allow_tables_to_appear_in_same_query!(\n     invitations,\n     org_policies,\n     organizations,\n+    sends,\n     twofactor,\n     users,\n     users_collections,\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 26,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -102,6 +102,29 @@ table! {\n     }\n }\n \n+table! {\n+    sends (uuid) {\n+        uuid -> Text,\n+        user_uuid -> Nullable<Text>,\n+        organization_uuid -> Nullable<Text>,\n+        name -> Text,\n+        notes -> Nullable<Text>,\n+        atype -> Integer,\n+        data -> Text,\n+        key -> Text,\n+        password_hash -> Nullable<Binary>,\n+        password_salt -> Nullable<Binary>,\n+        password_iter -> Nullable<Integer>,\n+        max_access_count -> Nullable<Integer>,\n+        access_count -> Integer,\n+        creation_date -> Timestamp,\n+        revision_date -> Timestamp,\n+        expiration_date -> Nullable<Timestamp>,\n+        deletion_date -> Timestamp,\n+        disabled -> Bool,\n+    }\n+}\n+\n table! {\n     twofactor (uuid) {\n         uuid -> Text,\n@@ -176,6 +199,8 @@ joinable!(folders -> users (user_uuid));\n joinable!(folders_ciphers -> ciphers (cipher_uuid));\n joinable!(folders_ciphers -> folders (folder_uuid));\n joinable!(org_policies -> organizations (org_uuid));\n+joinable!(sends -> organizations (organization_uuid));\n+joinable!(sends -> users (user_uuid));\n joinable!(twofactor -> users (user_uuid));\n joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n@@ -193,6 +218,7 @@ allow_tables_to_appear_in_same_query!(\n     invitations,\n     org_policies,\n     organizations,\n+    sends,\n     twofactor,\n     users,\n     users_collections,\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 26,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -102,6 +102,29 @@ table! {\n     }\n }\n \n+table! {\n+    sends (uuid) {\n+        uuid -> Text,\n+        user_uuid -> Nullable<Text>,\n+        organization_uuid -> Nullable<Text>,\n+        name -> Text,\n+        notes -> Nullable<Text>,\n+        atype -> Integer,\n+        data -> Text,\n+        key -> Text,\n+        password_hash -> Nullable<Binary>,\n+        password_salt -> Nullable<Binary>,\n+        password_iter -> Nullable<Integer>,\n+        max_access_count -> Nullable<Integer>,\n+        access_count -> Integer,\n+        creation_date -> Timestamp,\n+        revision_date -> Timestamp,\n+        expiration_date -> Nullable<Timestamp>,\n+        deletion_date -> Timestamp,\n+        disabled -> Bool,\n+    }\n+}\n+\n table! {\n     twofactor (uuid) {\n         uuid -> Text,\n@@ -176,6 +199,8 @@ joinable!(folders -> users (user_uuid));\n joinable!(folders_ciphers -> ciphers (cipher_uuid));\n joinable!(folders_ciphers -> folders (folder_uuid));\n joinable!(org_policies -> organizations (org_uuid));\n+joinable!(sends -> organizations (organization_uuid));\n+joinable!(sends -> users (user_uuid));\n joinable!(twofactor -> users (user_uuid));\n joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n@@ -193,6 +218,7 @@ allow_tables_to_appear_in_same_query!(\n     invitations,\n     org_policies,\n     organizations,\n+    sends,\n     twofactor,\n     users,\n     users_collections,\n",
            "comment_added_diff": []
        },
        {
            "commit": "95e24ffc51db2f6834142ec86568c2d244562006",
            "timestamp": "2021-03-15T16:42:20+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "rename send key -> akey",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -111,7 +111,7 @@ table! {\n         notes -> Nullable<Text>,\n         atype -> Integer,\n         data -> Text,\n-        key -> Text,\n+        akey -> Text,\n         password_hash -> Nullable<Binary>,\n         password_salt -> Nullable<Binary>,\n         password_iter -> Nullable<Integer>,\n",
            "comment_added_diff": []
        },
        {
            "commit": "95e24ffc51db2f6834142ec86568c2d244562006",
            "timestamp": "2021-03-15T16:42:20+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "rename send key -> akey",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -111,7 +111,7 @@ table! {\n         notes -> Nullable<Text>,\n         atype -> Integer,\n         data -> Text,\n-        key -> Text,\n+        akey -> Text,\n         password_hash -> Nullable<Binary>,\n         password_salt -> Nullable<Binary>,\n         password_iter -> Nullable<Integer>,\n",
            "comment_added_diff": []
        },
        {
            "commit": "95e24ffc51db2f6834142ec86568c2d244562006",
            "timestamp": "2021-03-15T16:42:20+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "rename send key -> akey",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -111,7 +111,7 @@ table! {\n         notes -> Nullable<Text>,\n         atype -> Integer,\n         data -> Text,\n-        key -> Text,\n+        akey -> Text,\n         password_hash -> Nullable<Binary>,\n         password_salt -> Nullable<Binary>,\n         password_iter -> Nullable<Integer>,\n",
            "comment_added_diff": []
        },
        {
            "commit": "a9a5706764a98fbcda1bc6ac2e0ef5f78ea6c202",
            "timestamp": "2021-05-11T20:09:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for password reprompt\n\nUpstream PR: https://github.com/bitwarden/server/pull/1269",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ table! {\n         data -> Text,\n         password_history -> Nullable<Text>,\n         deleted_at -> Nullable<Datetime>,\n+        reprompt -> Nullable<Integer>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "a9a5706764a98fbcda1bc6ac2e0ef5f78ea6c202",
            "timestamp": "2021-05-11T20:09:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for password reprompt\n\nUpstream PR: https://github.com/bitwarden/server/pull/1269",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ table! {\n         data -> Text,\n         password_history -> Nullable<Text>,\n         deleted_at -> Nullable<Timestamp>,\n+        reprompt -> Nullable<Integer>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "a9a5706764a98fbcda1bc6ac2e0ef5f78ea6c202",
            "timestamp": "2021-05-11T20:09:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for password reprompt\n\nUpstream PR: https://github.com/bitwarden/server/pull/1269",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ table! {\n         data -> Text,\n         password_history -> Nullable<Text>,\n         deleted_at -> Nullable<Timestamp>,\n+        reprompt -> Nullable<Integer>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "d3449bfa00cff40dc1f9ef349c9c6524e78f64e1",
            "timestamp": "2021-05-11T22:51:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding the sender's email address in Bitwarden Sends\n\nNote: The original Vaultwarden implementation of Bitwarden Send would always\nhide the email address, while the upstream implementation would always show it.\n\nUpstream PR: https://github.com/bitwarden/server/pull/1234",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -122,6 +122,7 @@ table! {\n         expiration_date -> Nullable<Datetime>,\n         deletion_date -> Datetime,\n         disabled -> Bool,\n+        hide_email -> Nullable<Bool>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "d3449bfa00cff40dc1f9ef349c9c6524e78f64e1",
            "timestamp": "2021-05-11T22:51:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding the sender's email address in Bitwarden Sends\n\nNote: The original Vaultwarden implementation of Bitwarden Send would always\nhide the email address, while the upstream implementation would always show it.\n\nUpstream PR: https://github.com/bitwarden/server/pull/1234",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -122,6 +122,7 @@ table! {\n         expiration_date -> Nullable<Timestamp>,\n         deletion_date -> Timestamp,\n         disabled -> Bool,\n+        hide_email -> Nullable<Bool>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "d3449bfa00cff40dc1f9ef349c9c6524e78f64e1",
            "timestamp": "2021-05-11T22:51:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding the sender's email address in Bitwarden Sends\n\nNote: The original Vaultwarden implementation of Bitwarden Send would always\nhide the email address, while the upstream implementation would always show it.\n\nUpstream PR: https://github.com/bitwarden/server/pull/1234",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -122,6 +122,7 @@ table! {\n         expiration_date -> Nullable<Timestamp>,\n         deletion_date -> Timestamp,\n         disabled -> Bool,\n+        hide_email -> Nullable<Bool>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -100,6 +100,8 @@ table! {\n         uuid -> Text,\n         name -> Text,\n         billing_email -> Text,\n+        private_key -> Nullable<Text>,\n+        public_key -> Nullable<Text>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -100,6 +100,8 @@ table! {\n         uuid -> Text,\n         name -> Text,\n         billing_email -> Text,\n+        private_key -> Nullable<Text>,\n+        public_key -> Nullable<Text>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -100,6 +100,8 @@ table! {\n         uuid -> Text,\n         name -> Text,\n         billing_email -> Text,\n+        private_key -> Nullable<Text>,\n+        public_key -> Nullable<Text>,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 19,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -192,6 +192,23 @@ table! {\n     }\n }\n \n+table! {\n+    emergency_access (uuid) {\n+        uuid -> Text,\n+        grantor_uuid -> Text,\n+        grantee_uuid -> Nullable<Text>,\n+        email -> Nullable<Text>,\n+        key_encrypted -> Nullable<Text>,\n+        atype -> Integer,\n+        status -> Integer,\n+        wait_time_days -> Integer,\n+        recovery_initiated_at -> Nullable<Timestamp>,\n+        last_notification_at -> Nullable<Timestamp>,\n+        updated_at -> Timestamp,\n+        created_at -> Timestamp,\n+    }\n+}\n+\n joinable!(attachments -> ciphers (cipher_uuid));\n joinable!(ciphers -> organizations (organization_uuid));\n joinable!(ciphers -> users (user_uuid));\n@@ -210,6 +227,7 @@ joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n joinable!(users_organizations -> organizations (org_uuid));\n joinable!(users_organizations -> users (user_uuid));\n+joinable!(emergency_access -> users (grantor_uuid));\n \n allow_tables_to_appear_in_same_query!(\n     attachments,\n@@ -227,4 +245,5 @@ allow_tables_to_appear_in_same_query!(\n     users,\n     users_collections,\n     users_organizations,\n+    emergency_access,\n );\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 19,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -192,6 +192,23 @@ table! {\n     }\n }\n \n+table! {\n+    emergency_access (uuid) {\n+        uuid -> Text,\n+        grantor_uuid -> Text,\n+        grantee_uuid -> Nullable<Text>,\n+        email -> Nullable<Text>,\n+        key_encrypted -> Nullable<Text>,\n+        atype -> Integer,\n+        status -> Integer,\n+        wait_time_days -> Integer,\n+        recovery_initiated_at -> Nullable<Timestamp>,\n+        last_notification_at -> Nullable<Timestamp>,\n+        updated_at -> Timestamp,\n+        created_at -> Timestamp,\n+    }\n+}\n+\n joinable!(attachments -> ciphers (cipher_uuid));\n joinable!(ciphers -> organizations (organization_uuid));\n joinable!(ciphers -> users (user_uuid));\n@@ -210,6 +227,7 @@ joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n joinable!(users_organizations -> organizations (org_uuid));\n joinable!(users_organizations -> users (user_uuid));\n+joinable!(emergency_access -> users (grantor_uuid));\n \n allow_tables_to_appear_in_same_query!(\n     attachments,\n@@ -227,4 +245,5 @@ allow_tables_to_appear_in_same_query!(\n     users,\n     users_collections,\n     users_organizations,\n+    emergency_access,\n );\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 19,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -192,6 +192,23 @@ table! {\n     }\n }\n \n+table! {\n+    emergency_access (uuid) {\n+        uuid -> Text,\n+        grantor_uuid -> Text,\n+        grantee_uuid -> Nullable<Text>,\n+        email -> Nullable<Text>,\n+        key_encrypted -> Nullable<Text>,\n+        atype -> Integer,\n+        status -> Integer,\n+        wait_time_days -> Integer,\n+        recovery_initiated_at -> Nullable<Timestamp>,\n+        last_notification_at -> Nullable<Timestamp>,\n+        updated_at -> Timestamp,\n+        created_at -> Timestamp,\n+    }\n+}\n+\n joinable!(attachments -> ciphers (cipher_uuid));\n joinable!(ciphers -> organizations (organization_uuid));\n joinable!(ciphers -> users (user_uuid));\n@@ -210,6 +227,7 @@ joinable!(users_collections -> collections (collection_uuid));\n joinable!(users_collections -> users (user_uuid));\n joinable!(users_organizations -> organizations (org_uuid));\n joinable!(users_organizations -> users (user_uuid));\n+joinable!(emergency_access -> users (grantor_uuid));\n \n allow_tables_to_appear_in_same_query!(\n     attachments,\n@@ -227,4 +245,5 @@ allow_tables_to_appear_in_same_query!(\n     users,\n     users_collections,\n     users_organizations,\n+    emergency_access,\n );\n",
            "comment_added_diff": []
        }
    ],
    "icons.rs": [
        {
            "commit": "d292269ea069af7ebd342548d42bb7810848eca2",
            "timestamp": "2019-10-10T23:21:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Make the blacklist logic be cached",
            "additions": 5,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -61,14 +61,7 @@ fn icon(domain: String) -> Content<Vec<u8>> {\n         return Content(icon_type, FALLBACK_ICON.to_vec());\n     }\n \n-    if check_icon_domain_is_blacklisted(&domain) {\n-        warn!(\"Domain is blacklisted: {:#?}\", domain);\n-        return Content(icon_type, FALLBACK_ICON.to_vec());\n-    }\n-\n-    let icon = get_icon(&domain);\n-\n-    Content(icon_type, icon)\n+    Content(icon_type, get_icon(&domain))\n }\n \n fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n@@ -380,6 +373,10 @@ fn parse_sizes(sizes: Option<String>) -> (u16, u16) {\n }\n \n fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n+    if check_icon_domain_is_blacklisted(domain) {\n+        err!(\"Domain is blacklisted\", domain)\n+    }\n+\n     let (iconlist, cookie_str) = get_icon_url(&domain)?;\n \n     let mut buffer = Vec::new();\n",
            "comment_added_diff": []
        },
        {
            "commit": "ee550be80cb3ee6d1c64fcd30f8a49008167c2f4",
            "timestamp": "2019-10-29T14:24:01+01:00",
            "author": "BlackDex",
            "commit_message": "Added http favicon url when response failed",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -259,6 +259,7 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n     } else {\n         // Add the default favicon.ico to the list with just the given domain\n         iconlist.push(Icon::new(35, format!(\"{}/favicon.ico\", ssldomain)));\n+        iconlist.push(Icon::new(35, format!(\"{}/favicon.ico\", httpdomain)));\n     }\n \n     // Sort the iconlist by priority\n",
            "comment_added_diff": []
        },
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 3,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -65,9 +65,8 @@ fn icon(domain: String) -> Content<Vec<u8>> {\n }\n \n fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n-    let mut is_blacklisted = false;\n-    if CONFIG.icon_blacklist_non_global_ips() {\n-        is_blacklisted = (domain, 0)\n+    let mut is_blacklisted = CONFIG.icon_blacklist_non_global_ips()\n+        && (domain, 0)\n             .to_socket_addrs()\n             .map(|x| {\n                 for ip_port in x {\n@@ -79,7 +78,6 @@ fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n                 false\n             })\n             .unwrap_or(false);\n-    }\n \n     // Skip the regex check if the previous one is true already\n     if !is_blacklisted {\n@@ -279,11 +277,7 @@ fn get_page_with_cookies(url: &str, cookie_str: &str) -> Result<Response, Error>\n     }\n \n     if cookie_str.is_empty() {\n-        CLIENT\n-            .get(url)\n-            .send()?\n-            .error_for_status()\n-            .map_err(Into::into)\n+        CLIENT.get(url).send()?.error_for_status().map_err(Into::into)\n     } else {\n         CLIENT\n             .get(url)\n",
            "comment_added_diff": []
        },
        {
            "commit": "ca7c5129b2eadabed826cd82b6c291c0cb68cda9",
            "timestamp": "2019-11-06T15:47:56+01:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #709 creating icon_cache directory.\n\nWhen the icon_cache directory doesn't exists yet, and the first icon\ncatched is a miss this .miss file was not able to be created since the\ndirectory was only created during a valid icon download.",
            "additions": 3,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -104,6 +104,9 @@ fn get_icon(domain: &str) -> Vec<u8> {\n         return FALLBACK_ICON.to_vec();\n     }\n \n+    // Create icon_cache_folder before fetching\n+    create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache\");\n+\n     // Get the icon, or fallback in case of error\n     match download_icon(&domain) {\n         Ok(icon) => {\n@@ -395,8 +398,6 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n }\n \n fn save_icon(path: &str, icon: &[u8]) {\n-    create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache\");\n-\n     if let Ok(mut f) = File::create(path) {\n         f.write_all(icon).expect(\"Error writing icon file\");\n     };\n",
            "comment_added_diff": [
                [
                    107,
                    "    // Create icon_cache_folder before fetching"
                ]
            ]
        },
        {
            "commit": "0ff7fd939e9afe2197bb53eb37bce7d2b62f0b7f",
            "timestamp": "2019-11-06T20:21:47+01:00",
            "author": "BlackDex",
            "commit_message": "Next attempt for issue #709 fix\n\nNow creates icon cache directory at startup.\nAnd it also creates the directory if it went missing during runtime.\nAlso modified the icon_save/mark_negcache to be one.",
            "additions": 14,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -104,9 +104,6 @@ fn get_icon(domain: &str) -> Vec<u8> {\n         return FALLBACK_ICON.to_vec();\n     }\n \n-    // Create icon_cache_folder before fetching\n-    create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache\");\n-\n     // Get the icon, or fallback in case of error\n     match download_icon(&domain) {\n         Ok(icon) => {\n@@ -115,7 +112,9 @@ fn get_icon(domain: &str) -> Vec<u8> {\n         }\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n-            mark_negcache(&path);\n+            let miss_indicator = path.to_owned() + \".miss\";\n+            let empty_icon = Vec::new();\n+            save_icon(&miss_indicator, &empty_icon);\n             FALLBACK_ICON.to_vec()\n         }\n     }\n@@ -171,11 +170,6 @@ fn icon_is_negcached(path: &str) -> bool {\n     }\n }\n \n-fn mark_negcache(path: &str) {\n-    let miss_indicator = path.to_owned() + \".miss\";\n-    File::create(&miss_indicator).expect(\"Error creating negative cache marker\");\n-}\n-\n fn icon_is_expired(path: &str) -> bool {\n     let expired = file_is_expired(path, CONFIG.icon_cache_ttl());\n     expired.unwrap_or(true)\n@@ -398,9 +392,17 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n }\n \n fn save_icon(path: &str, icon: &[u8]) {\n-    if let Ok(mut f) = File::create(path) {\n-        f.write_all(icon).expect(\"Error writing icon file\");\n-    };\n+    match File::create(path) {\n+        Ok(mut f) => {\n+            f.write_all(icon).expect(\"Error writing icon file\");\n+        }\n+        Err(ref e) if e.kind() == std::io::ErrorKind::NotFound => {\n+            create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache\");\n+        }\n+        Err(e) => {\n+            info!(\"Icon save error: {:?}\", e);\n+        }\n+    }\n }\n \n fn _header_map() -> HeaderMap {\n",
            "comment_added_diff": []
        },
        {
            "commit": "2ffc3eac4da67c82db0d7dbc361295a047139499",
            "timestamp": "2019-11-06T20:34:52+01:00",
            "author": "BlackDex",
            "commit_message": "Clippy fix",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -112,7 +112,7 @@ fn get_icon(domain: &str) -> Vec<u8> {\n         }\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n-            let miss_indicator = path.to_owned() + \".miss\";\n+            let miss_indicator = path + \".miss\";\n             let empty_icon = Vec::new();\n             save_icon(&miss_indicator, &empty_icon);\n             FALLBACK_ICON.to_vec()\n",
            "comment_added_diff": []
        },
        {
            "commit": "b209c1bc4d3f31a9b7061ee2b4aef276faaef3f8",
            "timestamp": "2019-11-22T13:16:12+01:00",
            "author": "BlackDex",
            "commit_message": "Add an option to fetch and parse href=\"data:image\"\n\nSome sites are using base64 encoded inline images for favicons.\nThis will try to match those with some sane checks and return that.\nThese icons will have lower prio then the icons with a normal URL.",
            "additions": 26,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -238,7 +238,7 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n         let favicons = soup\n             .tag(\"link\")\n             .attr(\"rel\", Regex::new(r\"icon$|apple.*icon\")?) // Only use icon rels\n-            .attr(\"href\", Regex::new(r\"(?i)\\w+\\.(jpg|jpeg|png|ico)(\\?.*)?$\")?) // Only allow specific extensions\n+            .attr(\"href\", Regex::new(r\"(?i)\\w+\\.(jpg|jpeg|png|ico)(\\?.*)?$|^data:image.*base64\")?) // Only allow specific extensions\n             .find_all();\n \n         // Loop through all the found icons and determine it's priority\n@@ -373,15 +373,32 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n \n     let mut buffer = Vec::new();\n \n+    use data_url::DataUrl;\n+\n     for icon in iconlist.iter().take(5) {\n-        match get_page_with_cookies(&icon.href, &cookie_str) {\n-            Ok(mut res) => {\n-                info!(\"Downloaded icon from {}\", icon.href);\n-                res.copy_to(&mut buffer)?;\n-                break;\n-            }\n-            Err(_) => info!(\"Download failed for {}\", icon.href),\n-        };\n+        if icon.href.starts_with(\"data:image\") {\n+            let datauri = DataUrl::process(&icon.href).unwrap();\n+            // Check if we are able to decode the data uri\n+            match datauri.decode_to_vec() {\n+                Ok((body, _fragment)) => {\n+                    // Also check if the size is atleast 67 bytes, which seems to be the smallest png i could create\n+                    if body.len() >= 67 {\n+                        buffer = body;\n+                        break;\n+                    }\n+                }\n+                _ => warn!(\"data uri is invalid\")\n+            };\n+        } else {\n+            match get_page_with_cookies(&icon.href, &cookie_str) {\n+                Ok(mut res) => {\n+                    info!(\"Downloaded icon from {}\", icon.href);\n+                    res.copy_to(&mut buffer)?;\n+                    break;\n+                }\n+                Err(_) => info!(\"Download failed for {}\", icon.href),\n+            };\n+        }\n     }\n \n     if buffer.is_empty() {\n",
            "comment_added_diff": [
                [
                    241,
                    "            .attr(\"href\", Regex::new(r\"(?i)\\w+\\.(jpg|jpeg|png|ico)(\\?.*)?$|^data:image.*base64\")?) // Only allow specific extensions"
                ],
                [
                    381,
                    "            // Check if we are able to decode the data uri"
                ],
                [
                    384,
                    "                    // Also check if the size is atleast 67 bytes, which seems to be the smallest png i could create"
                ]
            ]
        },
        {
            "commit": "25454697130a2bcbb76f7f29cdf8d1d382de96c7",
            "timestamp": "2019-12-19T00:37:16+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix crash when page URL points to huge file",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -213,7 +213,7 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n     let mut cookie_str = String::new();\n \n     let resp = get_page(&ssldomain).or_else(|_| get_page(&httpdomain));\n-    if let Ok(content) = resp {\n+    if let Ok(mut content) = resp {\n         // Extract the URL from the respose in case redirects occured (like @ gitlab.com)\n         let url = content.url().clone();\n \n@@ -233,7 +233,11 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n         // Add the default favicon.ico to the list with the domain the content responded from.\n         iconlist.push(Icon::new(35, url.join(\"/favicon.ico\").unwrap().into_string()));\n \n-        let soup = Soup::from_reader(content)?;\n+        // 512KB should be more than enough for the HTML, though as we only really need\n+        // the HTML header, it could potentially be reduced even further\n+        let limited_reader = crate::util::LimitedReader::new(&mut content, 512 * 1024);\n+\n+        let soup = Soup::from_reader(limited_reader)?;\n         // Search for and filter\n         let favicons = soup\n             .tag(\"link\")\n",
            "comment_added_diff": [
                [
                    236,
                    "        // 512KB should be more than enough for the HTML, though as we only really need"
                ],
                [
                    237,
                    "        // the HTML header, it could potentially be reduced even further"
                ]
            ]
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -391,7 +391,7 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n                         break;\n                     }\n                 }\n-                _ => warn!(\"data uri is invalid\")\n+                _ => warn!(\"data uri is invalid\"),\n             };\n         } else {\n             match get_page_with_cookies(&icon.href, &cookie_str) {\n",
            "comment_added_diff": []
        },
        {
            "commit": "ebb36235a70a2c539a7656454de3478ae776aa22",
            "timestamp": "2020-01-30T22:30:57+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Cache icons in the clients",
            "additions": 4,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -16,6 +16,7 @@ use soup::prelude::*;\n \n use crate::error::Error;\n use crate::CONFIG;\n+use crate::util::Cached;\n \n pub fn routes() -> Vec<Route> {\n     routes![icon]\n@@ -53,15 +54,15 @@ fn is_valid_domain(domain: &str) -> bool {\n }\n \n #[get(\"/<domain>/icon.png\")]\n-fn icon(domain: String) -> Content<Vec<u8>> {\n+fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n     let icon_type = ContentType::new(\"image\", \"x-icon\");\n \n     if !is_valid_domain(&domain) {\n         warn!(\"Invalid domain: {:#?}\", domain);\n-        return Content(icon_type, FALLBACK_ICON.to_vec());\n+        return Cached::long(Content(icon_type, FALLBACK_ICON.to_vec()));\n     }\n \n-    Content(icon_type, get_icon(&domain))\n+    Cached::long(Content(icon_type, get_icon(&domain)))\n }\n \n fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n",
            "comment_added_diff": []
        },
        {
            "commit": "70f3ab8ec3d6ccfd8ec8c71c888459de484d9b43",
            "timestamp": "2020-03-09T22:04:03+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Migrate lazy_static to once_cell, less macro magic and slightly faster",
            "additions": 5,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -1,3 +1,4 @@\n+use once_cell::sync::Lazy;\n use std::fs::{create_dir_all, remove_file, symlink_metadata, File};\n use std::io::prelude::*;\n use std::net::ToSocketAddrs;\n@@ -26,16 +27,16 @@ const FALLBACK_ICON: &[u8; 344] = include_bytes!(\"../static/fallback-icon.png\");\n \n const ALLOWED_CHARS: &str = \"_-.\";\n \n-lazy_static! {\n+static CLIENT: Lazy<Client> = Lazy::new(|| {\n     // Reuse the client between requests\n-    static ref CLIENT: Client = Client::builder()\n+    Client::builder()\n         .use_sys_proxy()\n         .gzip(true)\n         .timeout(Duration::from_secs(CONFIG.icon_download_timeout()))\n         .default_headers(_header_map())\n         .build()\n-        .unwrap();\n-}\n+        .unwrap()\n+});\n \n fn is_valid_domain(domain: &str) -> bool {\n     // Don't allow empty or too big domains or path traversal\n",
            "comment_added_diff": []
        },
        {
            "commit": "1b4b40c95dab106a5b06b8b1685004b59abf21dd",
            "timestamp": "2020-03-14T23:12:45+01:00",
            "author": "BlackDex",
            "commit_message": "Updated reqwest to the latest version.\n\n- Use the blocking client (no async).\n- Disabled gzip.\n- use_sys_proxy is now default.",
            "additions": 1,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -8,7 +8,7 @@ use rocket::http::ContentType;\n use rocket::response::Content;\n use rocket::Route;\n \n-use reqwest::{header::HeaderMap, Client, Response, Url};\n+use reqwest::{Url, header::HeaderMap, blocking::Client, blocking::Response};\n \n use rocket::http::Cookie;\n \n@@ -30,8 +30,6 @@ const ALLOWED_CHARS: &str = \"_-.\";\n static CLIENT: Lazy<Client> = Lazy::new(|| {\n     // Reuse the client between requests\n     Client::builder()\n-        .use_sys_proxy()\n-        .gzip(true)\n         .timeout(Duration::from_secs(CONFIG.icon_download_timeout()))\n         .default_headers(_header_map())\n         .build()\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -182,7 +182,7 @@ struct Icon {\n }\n \n impl Icon {\n-    fn new(priority: u8, href: String) -> Self {\n+    const fn new(priority: u8, href: String) -> Self {\n         Self { href, priority }\n     }\n }\n@@ -213,7 +213,7 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n     let mut cookie_str = String::new();\n \n     let resp = get_page(&ssldomain).or_else(|_| get_page(&httpdomain));\n-    if let Ok(mut content) = resp {\n+    if let Ok(content) = resp {\n         // Extract the URL from the respose in case redirects occured (like @ gitlab.com)\n         let url = content.url().clone();\n \n@@ -235,7 +235,7 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n \n         // 512KB should be more than enough for the HTML, though as we only really need\n         // the HTML header, it could potentially be reduced even further\n-        let limited_reader = crate::util::LimitedReader::new(&mut content, 512 * 1024);\n+        let limited_reader = content.take(512 * 1024);\n \n         let soup = Soup::from_reader(limited_reader)?;\n         // Search for and filter\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 10,
            "deletions": 16,
            "change_type": "MODIFY",
            "diff": "@@ -1,23 +1,17 @@\n-use once_cell::sync::Lazy;\n-use std::fs::{create_dir_all, remove_file, symlink_metadata, File};\n-use std::io::prelude::*;\n-use std::net::ToSocketAddrs;\n-use std::time::{Duration, SystemTime};\n-\n-use rocket::http::ContentType;\n-use rocket::response::Content;\n-use rocket::Route;\n-\n-use reqwest::{Url, header::HeaderMap, blocking::Client, blocking::Response};\n-\n-use rocket::http::Cookie;\n+use std::{\n+    fs::{create_dir_all, remove_file, symlink_metadata, File},\n+    io::prelude::*,\n+    net::ToSocketAddrs,\n+    time::{Duration, SystemTime},\n+};\n \n+use once_cell::sync::Lazy;\n use regex::Regex;\n+use reqwest::{blocking::Client, blocking::Response, header::HeaderMap, Url};\n+use rocket::{http::ContentType, http::Cookie, response::Content, Route};\n use soup::prelude::*;\n \n-use crate::error::Error;\n-use crate::CONFIG;\n-use crate::util::Cached;\n+use crate::{error::Error, util::Cached, CONFIG};\n \n pub fn routes() -> Vec<Route> {\n     routes![icon]\n",
            "comment_added_diff": []
        },
        {
            "commit": "f14e19a3d82c0171a85b5909e97f733a4615597c",
            "timestamp": "2020-07-14T21:58:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Don't compile the regexes each time",
            "additions": 8,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -30,6 +30,11 @@ static CLIENT: Lazy<Client> = Lazy::new(|| {\n         .unwrap()\n });\n \n+static ICON_REL_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"icon$|apple.*icon\").unwrap());\n+static ICON_HREF_REGEX: Lazy<Regex> =\n+    Lazy::new(|| Regex::new(r\"(?i)\\w+\\.(jpg|jpeg|png|ico)(\\?.*)?$|^data:image.*base64\").unwrap());\n+static ICON_SIZE_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?x)(\\d+)\\D*(\\d+)\").unwrap());\n+\n fn is_valid_domain(domain: &str) -> bool {\n     // Don't allow empty or too big domains or path traversal\n     if domain.is_empty() || domain.len() > 255 || domain.contains(\"..\") {\n@@ -235,8 +240,8 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n         // Search for and filter\n         let favicons = soup\n             .tag(\"link\")\n-            .attr(\"rel\", Regex::new(r\"icon$|apple.*icon\")?) // Only use icon rels\n-            .attr(\"href\", Regex::new(r\"(?i)\\w+\\.(jpg|jpeg|png|ico)(\\?.*)?$|^data:image.*base64\")?) // Only allow specific extensions\n+            .attr(\"rel\", ICON_REL_REGEX.clone()) // Only use icon rels\n+            .attr(\"href\", ICON_HREF_REGEX.clone()) // Only allow specific extensions\n             .find_all();\n \n         // Loop through all the found icons and determine it's priority\n@@ -348,7 +353,7 @@ fn parse_sizes(sizes: Option<String>) -> (u16, u16) {\n     let mut height: u16 = 0;\n \n     if let Some(sizes) = sizes {\n-        match Regex::new(r\"(?x)(\\d+)\\D*(\\d+)\").unwrap().captures(sizes.trim()) {\n+        match ICON_SIZE_REGEX.captures(sizes.trim()) {\n             None => {}\n             Some(dimensions) => {\n                 if dimensions.len() >= 3 {\n",
            "comment_added_diff": [
                [
                    243,
                    "            .attr(\"rel\", ICON_REL_REGEX.clone()) // Only use icon rels"
                ],
                [
                    244,
                    "            .attr(\"href\", ICON_HREF_REGEX.clone()) // Only allow specific extensions"
                ]
            ]
        },
        {
            "commit": "1e950c7dbc8bfaca0df4fd2d97d12e8b7d1fbc55",
            "timestamp": "2020-07-15T00:00:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Replace IP support in preparation for compiling on stable, included some tests to check that the code matches the unstable implementation",
            "additions": 100,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,7 @@\n use std::{\n     fs::{create_dir_all, remove_file, symlink_metadata, File},\n     io::prelude::*,\n-    net::ToSocketAddrs,\n+    net::{IpAddr, ToSocketAddrs},\n     time::{Duration, SystemTime},\n };\n \n@@ -63,13 +63,111 @@ fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n     Cached::long(Content(icon_type, get_icon(&domain)))\n }\n \n+/// TODO: This is extracted from IpAddr::is_global, which is unstable:\n+/// https://doc.rust-lang.org/nightly/std/net/enum.IpAddr.html#method.is_global\n+/// Remove once https://github.com/rust-lang/rust/issues/27709 is merged\n+#[cfg(not(feature = \"unstable\"))]\n+fn is_global(ip: IpAddr) -> bool {\n+    match ip {\n+        IpAddr::V4(ip) => {\n+            // check if this address is 192.0.0.9 or 192.0.0.10. These addresses are the only two\n+            // globally routable addresses in the 192.0.0.0/24 range.\n+            if u32::from(ip) == 0xc0000009 || u32::from(ip) == 0xc000000a {\n+                return true;\n+            }\n+            !ip.is_private()\n+            && !ip.is_loopback()\n+            && !ip.is_link_local()\n+            && !ip.is_broadcast()\n+            && !ip.is_documentation()\n+            && !(ip.octets()[0] == 100 && (ip.octets()[1] & 0b1100_0000 == 0b0100_0000))\n+            && !(ip.octets()[0] == 192 && ip.octets()[1] == 0 && ip.octets()[2] == 0)\n+            && !(ip.octets()[0] & 240 == 240 && !ip.is_broadcast())\n+            && !(ip.octets()[0] == 198 && (ip.octets()[1] & 0xfe) == 18)\n+            // Make sure the address is not in 0.0.0.0/8\n+            && ip.octets()[0] != 0\n+        }\n+        IpAddr::V6(ip) => {\n+            if ip.is_multicast() && ip.segments()[0] & 0x000f == 14 {\n+                true\n+            } else {\n+                !ip.is_multicast()\n+                    && !ip.is_loopback()\n+                    && !((ip.segments()[0] & 0xffc0) == 0xfe80)\n+                    && !((ip.segments()[0] & 0xfe00) == 0xfc00)\n+                    && !ip.is_unspecified()\n+                    && !((ip.segments()[0] == 0x2001) && (ip.segments()[1] == 0xdb8))\n+            }\n+        }\n+    }\n+}\n+\n+#[cfg(feature = \"unstable\")]\n+fn is_global(ip: IpAddr) -> bool {\n+    ip.is_global()\n+}\n+\n+/// These are some tests to check that the implementations match\n+/// The IPv4 can be all checked in 5 mins or so and they are correct as of nightly 2020-07-11\n+/// The IPV6 can't be checked in a reasonable time, so we check  about ten billion random ones, so far correct\n+/// Note that the is_global implementation is subject to change as new IP RFCs are created\n+///\n+/// To run while showing progress output:\n+/// cargo test --features sqlite,unstable -- --nocapture --ignored\n+#[cfg(test)]\n+#[cfg(feature = \"unstable\")]\n+mod tests {\n+    use super::*;\n+\n+    #[test]\n+    #[ignore]\n+    fn test_ipv4_global() {\n+        for a in 0..u8::MAX {\n+            println!(\"Iter: {}/255\", a);\n+            for b in 0..u8::MAX {\n+                for c in 0..u8::MAX {\n+                    for d in 0..u8::MAX {\n+                        let ip = IpAddr::V4(std::net::Ipv4Addr::new(a, b, c, d));\n+                        assert_eq!(ip.is_global(), is_global(ip))\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    #[ignore]\n+    fn test_ipv6_global() {\n+        use ring::rand::{SecureRandom, SystemRandom};\n+        let mut v = [0u8; 16];\n+        let rand = SystemRandom::new();\n+        for i in 0..1_000 {\n+            println!(\"Iter: {}/1_000\", i);\n+            for _ in 0..10_000_000 {\n+                rand.fill(&mut v).expect(\"Error generating random values\");\n+                let ip = IpAddr::V6(std::net::Ipv6Addr::new(\n+                    (v[14] as u16) << 8 | v[15] as u16,\n+                    (v[12] as u16) << 8 | v[13] as u16,\n+                    (v[10] as u16) << 8 | v[11] as u16,\n+                    (v[8] as u16) << 8 | v[9] as u16,\n+                    (v[6] as u16) << 8 | v[7] as u16,\n+                    (v[4] as u16) << 8 | v[5] as u16,\n+                    (v[2] as u16) << 8 | v[3] as u16,\n+                    (v[0] as u16) << 8 | v[1] as u16,\n+                ));\n+                assert_eq!(ip.is_global(), is_global(ip))\n+            }\n+        }\n+    }\n+}\n+\n fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n     let mut is_blacklisted = CONFIG.icon_blacklist_non_global_ips()\n         && (domain, 0)\n             .to_socket_addrs()\n             .map(|x| {\n                 for ip_port in x {\n-                    if !ip_port.ip().is_global() {\n+                    if !is_global(ip_port.ip()) {\n                         warn!(\"IP {} for domain '{}' is not a global IP!\", ip_port.ip(), domain);\n                         return true;\n                     }\n",
            "comment_added_diff": [
                [
                    66,
                    "/// TODO: This is extracted from IpAddr::is_global, which is unstable:"
                ],
                [
                    67,
                    "/// https://doc.rust-lang.org/nightly/std/net/enum.IpAddr.html#method.is_global"
                ],
                [
                    68,
                    "/// Remove once https://github.com/rust-lang/rust/issues/27709 is merged"
                ],
                [
                    73,
                    "            // check if this address is 192.0.0.9 or 192.0.0.10. These addresses are the only two"
                ],
                [
                    74,
                    "            // globally routable addresses in the 192.0.0.0/24 range."
                ],
                [
                    87,
                    "            // Make sure the address is not in 0.0.0.0/8"
                ],
                [
                    110,
                    "/// These are some tests to check that the implementations match"
                ],
                [
                    111,
                    "/// The IPv4 can be all checked in 5 mins or so and they are correct as of nightly 2020-07-11"
                ],
                [
                    112,
                    "/// The IPV6 can't be checked in a reasonable time, so we check  about ten billion random ones, so far correct"
                ],
                [
                    113,
                    "/// Note that the is_global implementation is subject to change as new IP RFCs are created"
                ],
                [
                    114,
                    "///"
                ],
                [
                    115,
                    "/// To run while showing progress output:"
                ],
                [
                    116,
                    "/// cargo test --features sqlite,unstable -- --nocapture --ignored"
                ]
            ]
        },
        {
            "commit": "ed70b07d8184a6e5c3bb048af15386fb68b647c6",
            "timestamp": "2020-11-09T20:47:26-05:00",
            "author": "James Hurst",
            "commit_message": "Return 404 instead of fallback icon",
            "additions": 12,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -17,8 +17,6 @@ pub fn routes() -> Vec<Route> {\n     routes![icon]\n }\n \n-const FALLBACK_ICON: &[u8; 344] = include_bytes!(\"../static/fallback-icon.png\");\n-\n const ALLOWED_CHARS: &str = \"_-.\";\n \n static CLIENT: Lazy<Client> = Lazy::new(|| {\n@@ -52,15 +50,15 @@ fn is_valid_domain(domain: &str) -> bool {\n }\n \n #[get(\"/<domain>/icon.png\")]\n-fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n-    let icon_type = ContentType::new(\"image\", \"x-icon\");\n-\n+fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n     if !is_valid_domain(&domain) {\n         warn!(\"Invalid domain: {:#?}\", domain);\n-        return Cached::long(Content(icon_type, FALLBACK_ICON.to_vec()));\n+        return None;\n     }\n \n-    Cached::long(Content(icon_type, get_icon(&domain)))\n+    get_icon(&domain).map(|icon| {\n+        Cached::long(Content(ContentType::new(\"image\", \"x-icon\"), icon))\n+    })\n }\n \n /// TODO: This is extracted from IpAddr::is_global, which is unstable:\n@@ -190,29 +188,29 @@ fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n     is_blacklisted\n }\n \n-fn get_icon(domain: &str) -> Vec<u8> {\n+fn get_icon(domain: &str) -> Option<Vec<u8>> {\n     let path = format!(\"{}/{}.png\", CONFIG.icon_cache_folder(), domain);\n \n     if let Some(icon) = get_cached_icon(&path) {\n-        return icon;\n+        return Some(icon);\n     }\n \n     if CONFIG.disable_icon_download() {\n-        return FALLBACK_ICON.to_vec();\n+        return None;\n     }\n \n-    // Get the icon, or fallback in case of error\n+    // Get the icon, or None in case of error\n     match download_icon(&domain) {\n         Ok(icon) => {\n             save_icon(&path, &icon);\n-            icon\n+            Some(icon)\n         }\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n             let miss_indicator = path + \".miss\";\n             let empty_icon = Vec::new();\n             save_icon(&miss_indicator, &empty_icon);\n-            FALLBACK_ICON.to_vec()\n+            None\n         }\n     }\n }\n@@ -220,7 +218,7 @@ fn get_icon(domain: &str) -> Vec<u8> {\n fn get_cached_icon(path: &str) -> Option<Vec<u8>> {\n     // Check for expiration of negatively cached copy\n     if icon_is_negcached(path) {\n-        return Some(FALLBACK_ICON.to_vec());\n+        return None;\n     }\n \n     // Check for expiration of successfully cached copy\n",
            "comment_added_diff": [
                [
                    202,
                    "    // Get the icon, or None in case of error"
                ]
            ]
        },
        {
            "commit": "771233176fd108e0537c5dc5456c5c09cd8d1ef8",
            "timestamp": "2020-11-09T22:06:11-05:00",
            "author": "James Hurst",
            "commit_message": "Fix for negcached icons",
            "additions": 5,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -191,6 +191,11 @@ fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n fn get_icon(domain: &str) -> Option<Vec<u8>> {\n     let path = format!(\"{}/{}.png\", CONFIG.icon_cache_folder(), domain);\n \n+    // Check for expiration of negatively cached copy\n+    if icon_is_negcached(&path) {\n+        return None;\n+    }\n+\n     if let Some(icon) = get_cached_icon(&path) {\n         return Some(icon);\n     }\n@@ -216,11 +221,6 @@ fn get_icon(domain: &str) -> Option<Vec<u8>> {\n }\n \n fn get_cached_icon(path: &str) -> Option<Vec<u8>> {\n-    // Check for expiration of negatively cached copy\n-    if icon_is_negcached(path) {\n-        return None;\n-    }\n-\n     // Check for expiration of successfully cached copy\n     if icon_is_expired(path) {\n         return None;\n",
            "comment_added_diff": [
                [
                    194,
                    "    // Check for expiration of negatively cached copy"
                ]
            ]
        },
        {
            "commit": "48baf723a422f0a4964807b12b002a589799d6ee",
            "timestamp": "2020-12-08T17:34:18+01:00",
            "author": "BlackDex",
            "commit_message": "Updated icon downloading\n\n- Added more checks to prevent panics (Removed unwrap)\n- Try do download from base domain or add www when the provided domain\n  fails\n- Added some more domain validation checks to prevent errors\n- Added the ICON_BLACKLIST_REGEX to a Lazy Static HashMap which\n  speeds-up the checks!\n- Validate the Regex before starting/config change.\n- Some cleanups\n- Disabled some noisy debugging from 2 crates.",
            "additions": 123,
            "deletions": 39,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,9 @@\n use std::{\n+    collections::HashMap,\n     fs::{create_dir_all, remove_file, symlink_metadata, File},\n     io::prelude::*,\n     net::{IpAddr, ToSocketAddrs},\n+    sync::RwLock,\n     time::{Duration, SystemTime},\n };\n \n@@ -28,20 +30,48 @@ static CLIENT: Lazy<Client> = Lazy::new(|| {\n         .unwrap()\n });\n \n-static ICON_REL_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"icon$|apple.*icon\").unwrap());\n-static ICON_HREF_REGEX: Lazy<Regex> =\n-    Lazy::new(|| Regex::new(r\"(?i)\\w+\\.(jpg|jpeg|png|ico)(\\?.*)?$|^data:image.*base64\").unwrap());\n+// Build Regex only once since this takes a lot of time.\n+static ICON_REL_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?i)icon$|apple.*icon\").unwrap());\n static ICON_SIZE_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?x)(\\d+)\\D*(\\d+)\").unwrap());\n \n+// Special HashMap which holds the user defined Regex to speedup matching the regex.\n+static ICON_BLACKLIST_REGEX: Lazy<RwLock<HashMap<String, Regex>>> = Lazy::new(|| RwLock::new(HashMap::new()));\n+\n+#[get(\"/<domain>/icon.png\")]\n+fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n+    if !is_valid_domain(&domain) {\n+        warn!(\"Invalid domain: {}\", domain);\n+        return None;\n+    }\n+\n+    get_icon(&domain).map(|icon| Cached::long(Content(ContentType::new(\"image\", \"x-icon\"), icon)))\n+}\n+\n+/// Returns if the domain provided is valid or not.\n+///\n+/// This does some manual checks and makes use of Url to do some basic checking.\n+/// domains can't be larger then 63 characters (not counting multiple subdomains) according to the RFC's, but we limit the total size to 255.\n fn is_valid_domain(domain: &str) -> bool {\n-    // Don't allow empty or too big domains or path traversal\n-    if domain.is_empty() || domain.len() > 255 || domain.contains(\"..\") {\n+    // If parsing the domain fails using Url, it will not work with reqwest.\n+    if let Err(parse_error) = Url::parse(format!(\"https://{}\", domain).as_str()) {\n+        debug!(\"Domain parse error: '{}' - {:?}\", domain, parse_error);\n+        return false;\n+    } else if domain.is_empty()\n+        || domain.contains(\"..\")\n+        || domain.starts_with('.')\n+        || domain.starts_with('-')\n+        || domain.ends_with('-')\n+    {\n+        debug!(\"Domain validation error: '{}' is either empty, contains '..', starts with an '.', starts or ends with a '-'\", domain);\n+        return false;\n+    } else if domain.len() > 255 {\n+        debug!(\"Domain validation error: '{}' exceeds 255 characters\", domain);\n         return false;\n     }\n \n-    // Only alphanumeric or specific characters\n     for c in domain.chars() {\n         if !c.is_alphanumeric() && !ALLOWED_CHARS.contains(c) {\n+            debug!(\"Domain validation error: '{}' contains an invalid character '{}'\", domain, c);\n             return false;\n         }\n     }\n@@ -49,21 +79,10 @@ fn is_valid_domain(domain: &str) -> bool {\n     true\n }\n \n-#[get(\"/<domain>/icon.png\")]\n-fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n-    if !is_valid_domain(&domain) {\n-        warn!(\"Invalid domain: {:#?}\", domain);\n-        return None;\n-    }\n-\n-    get_icon(&domain).map(|icon| {\n-        Cached::long(Content(ContentType::new(\"image\", \"x-icon\"), icon))\n-    })\n-}\n-\n /// TODO: This is extracted from IpAddr::is_global, which is unstable:\n /// https://doc.rust-lang.org/nightly/std/net/enum.IpAddr.html#method.is_global\n /// Remove once https://github.com/rust-lang/rust/issues/27709 is merged\n+#[allow(clippy::nonminimal_bool)]\n #[cfg(not(feature = \"unstable\"))]\n fn is_global(ip: IpAddr) -> bool {\n     match ip {\n@@ -159,7 +178,7 @@ mod tests {\n     }\n }\n \n-fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n+fn is_domain_blacklisted(domain: &str) -> bool {\n     let mut is_blacklisted = CONFIG.icon_blacklist_non_global_ips()\n         && (domain, 0)\n             .to_socket_addrs()\n@@ -177,7 +196,31 @@ fn check_icon_domain_is_blacklisted(domain: &str) -> bool {\n     // Skip the regex check if the previous one is true already\n     if !is_blacklisted {\n         if let Some(blacklist) = CONFIG.icon_blacklist_regex() {\n-            let regex = Regex::new(&blacklist).expect(\"Valid Regex\");\n+            let mut regex_hashmap = ICON_BLACKLIST_REGEX.read().unwrap();\n+\n+            // Use the pre-generate Regex stored in a Lazy HashMap if there's one, else generate it.\n+            let regex = if let Some(regex) = regex_hashmap.get(&blacklist) {\n+                regex\n+            } else {\n+                drop(regex_hashmap);\n+\n+                let mut regex_hashmap_write = ICON_BLACKLIST_REGEX.write().unwrap();\n+                // Clear the current list if the previous key doesn't exists.\n+                // To prevent growing of the HashMap after someone has changed it via the admin interface.\n+                if regex_hashmap_write.len() >= 1 {\n+                    regex_hashmap_write.clear();\n+                }\n+\n+                // Generate the regex to store in too the Lazy Static HashMap.\n+                let blacklist_regex = Regex::new(&blacklist).unwrap();\n+                regex_hashmap_write.insert(blacklist.to_string(), blacklist_regex);\n+                drop(regex_hashmap_write);\n+\n+                regex_hashmap = ICON_BLACKLIST_REGEX.read().unwrap();\n+                regex_hashmap.get(&blacklist).unwrap()\n+            };\n+\n+            // Use the pre-generate Regex stored in a Lazy HashMap.\n             if regex.is_match(&domain) {\n                 warn!(\"Blacklisted domain: {:#?} matched {:#?}\", domain, blacklist);\n                 is_blacklisted = true;\n@@ -213,8 +256,7 @@ fn get_icon(domain: &str) -> Option<Vec<u8>> {\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n             let miss_indicator = path + \".miss\";\n-            let empty_icon = Vec::new();\n-            save_icon(&miss_indicator, &empty_icon);\n+            save_icon(&miss_indicator, &[]);\n             None\n         }\n     }\n@@ -307,11 +349,51 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n     // Some sites have extra security in place with for example XSRF Tokens.\n     let mut cookie_str = String::new();\n \n-    let resp = get_page(&ssldomain).or_else(|_| get_page(&httpdomain));\n+    // First check the domain as given during the request for both HTTPS and HTTP.\n+    let resp = match get_page(&ssldomain).or_else(|_| get_page(&httpdomain)) {\n+        Ok(c) => Ok(c),\n+        Err(e) => {\n+            let mut sub_resp = Err(e);\n+\n+            // When the domain is not an IP, and has more then one dot, remove all subdomains.\n+            let is_ip = domain.parse::<IpAddr>();\n+            if is_ip.is_err() && domain.matches('.').count() > 1 {\n+                let mut domain_parts = domain.split('.');\n+                let base_domain = format!(\n+                    \"{base}.{tld}\",\n+                    tld = domain_parts.next_back().unwrap(),\n+                    base = domain_parts.next_back().unwrap()\n+                );\n+                if is_valid_domain(&base_domain) {\n+                    let sslbase = format!(\"https://{}\", base_domain);\n+                    let httpbase = format!(\"http://{}\", base_domain);\n+                    debug!(\"[get_icon_url]: Trying without subdomains '{}'\", base_domain);\n+\n+                    sub_resp = get_page(&sslbase).or_else(|_| get_page(&httpbase));\n+                }\n+\n+            // When the domain is not an IP, and has less then 2 dots, try to add www. infront of it.\n+            } else if is_ip.is_err() && domain.matches('.').count() < 2 {\n+                let www_domain = format!(\"www.{}\", domain);\n+                if is_valid_domain(&www_domain) {\n+                    let sslwww = format!(\"https://{}\", www_domain);\n+                    let httpwww = format!(\"http://{}\", www_domain);\n+                    debug!(\"[get_icon_url]: Trying with www. prefix '{}'\", www_domain);\n+\n+                    sub_resp = get_page(&sslwww).or_else(|_| get_page(&httpwww));\n+                }\n+            }\n+\n+            sub_resp\n+        }\n+    };\n+\n     if let Ok(content) = resp {\n         // Extract the URL from the respose in case redirects occured (like @ gitlab.com)\n         let url = content.url().clone();\n \n+        // Get all the cookies and pass it on to the next function.\n+        // Needed for XSRF Cookies for example (like @ mijn.ing.nl)\n         let raw_cookies = content.headers().get_all(\"set-cookie\");\n         cookie_str = raw_cookies\n             .iter()\n@@ -337,14 +419,18 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n         let favicons = soup\n             .tag(\"link\")\n             .attr(\"rel\", ICON_REL_REGEX.clone()) // Only use icon rels\n-            .attr(\"href\", ICON_HREF_REGEX.clone()) // Only allow specific extensions\n+            .attr_name(\"href\") // Make sure there is a href\n             .find_all();\n \n         // Loop through all the found icons and determine it's priority\n         for favicon in favicons {\n             let sizes = favicon.get(\"sizes\");\n-            let href = favicon.get(\"href\").expect(\"Missing href\");\n-            let full_href = url.join(&href).unwrap().into_string();\n+            let href = favicon.get(\"href\").unwrap();\n+            // Skip invalid url's\n+            let full_href = match url.join(&href) {\n+                Ok(h) => h.into_string(),\n+                _ => continue,\n+            };\n \n             let priority = get_icon_priority(&full_href, sizes);\n \n@@ -368,20 +454,18 @@ fn get_page(url: &str) -> Result<Response, Error> {\n }\n \n fn get_page_with_cookies(url: &str, cookie_str: &str) -> Result<Response, Error> {\n-    if check_icon_domain_is_blacklisted(Url::parse(url).unwrap().host_str().unwrap_or_default()) {\n-        err!(\"Favicon rel linked to a non blacklisted domain!\");\n+    if is_domain_blacklisted(Url::parse(url).unwrap().host_str().unwrap_or_default()) {\n+        err!(\"Favicon rel linked to a blacklisted domain!\");\n     }\n \n-    if cookie_str.is_empty() {\n-        CLIENT.get(url).send()?.error_for_status().map_err(Into::into)\n-    } else {\n-        CLIENT\n-            .get(url)\n-            .header(\"cookie\", cookie_str)\n-            .send()?\n-            .error_for_status()\n-            .map_err(Into::into)\n+    let mut client = CLIENT.get(url);\n+    if !cookie_str.is_empty() {\n+        client = client.header(\"cookie\", cookie_str)\n     }\n+\n+    client.send()?\n+        .error_for_status()\n+        .map_err(Into::into)\n }\n \n /// Returns a Integer with the priority of the type of the icon which to prefer.\n@@ -464,7 +548,7 @@ fn parse_sizes(sizes: Option<String>) -> (u16, u16) {\n }\n \n fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n-    if check_icon_domain_is_blacklisted(domain) {\n+    if is_domain_blacklisted(domain) {\n         err!(\"Domain is blacklisted\", domain)\n     }\n \n@@ -495,7 +579,7 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n                     res.copy_to(&mut buffer)?;\n                     break;\n                 }\n-                Err(_) => info!(\"Download failed for {}\", icon.href),\n+                Err(_) => warn!(\"Download failed for {}\", icon.href),\n             };\n         }\n     }\n",
            "comment_added_diff": [
                [
                    33,
                    "// Build Regex only once since this takes a lot of time."
                ],
                [
                    37,
                    "// Special HashMap which holds the user defined Regex to speedup matching the regex."
                ],
                [
                    50,
                    "/// Returns if the domain provided is valid or not."
                ],
                [
                    51,
                    "///"
                ],
                [
                    52,
                    "/// This does some manual checks and makes use of Url to do some basic checking."
                ],
                [
                    53,
                    "/// domains can't be larger then 63 characters (not counting multiple subdomains) according to the RFC's, but we limit the total size to 255."
                ],
                [
                    55,
                    "    // If parsing the domain fails using Url, it will not work with reqwest."
                ],
                [
                    56,
                    "    if let Err(parse_error) = Url::parse(format!(\"https://{}\", domain).as_str()) {"
                ],
                [
                    201,
                    "            // Use the pre-generate Regex stored in a Lazy HashMap if there's one, else generate it."
                ],
                [
                    208,
                    "                // Clear the current list if the previous key doesn't exists."
                ],
                [
                    209,
                    "                // To prevent growing of the HashMap after someone has changed it via the admin interface."
                ],
                [
                    214,
                    "                // Generate the regex to store in too the Lazy Static HashMap."
                ],
                [
                    223,
                    "            // Use the pre-generate Regex stored in a Lazy HashMap."
                ],
                [
                    352,
                    "    // First check the domain as given during the request for both HTTPS and HTTP."
                ],
                [
                    358,
                    "            // When the domain is not an IP, and has more then one dot, remove all subdomains."
                ],
                [
                    368,
                    "                    let sslbase = format!(\"https://{}\", base_domain);"
                ],
                [
                    369,
                    "                    let httpbase = format!(\"http://{}\", base_domain);"
                ],
                [
                    375,
                    "            // When the domain is not an IP, and has less then 2 dots, try to add www. infront of it."
                ],
                [
                    379,
                    "                    let sslwww = format!(\"https://{}\", www_domain);"
                ],
                [
                    380,
                    "                    let httpwww = format!(\"http://{}\", www_domain);"
                ],
                [
                    395,
                    "        // Get all the cookies and pass it on to the next function."
                ],
                [
                    396,
                    "        // Needed for XSRF Cookies for example (like @ mijn.ing.nl)"
                ],
                [
                    422,
                    "            .attr_name(\"href\") // Make sure there is a href"
                ],
                [
                    429,
                    "            // Skip invalid url's"
                ]
            ]
        },
        {
            "commit": "1a8ec047335756ac24830f0fb51a0e2cf5b05264",
            "timestamp": "2020-12-10T23:13:24+01:00",
            "author": "BlackDex",
            "commit_message": "Small update on favicon downloading\n\n- Changed the user-agent, which caused at least one site to stall the\n  connection (Same happens on icons.bitwarden.com)\n- Added default_header creation to the lazy static CLIENT\n- Added referer passing, which is checked by some sites\n- Some small other changes",
            "additions": 47,
            "deletions": 43,
            "change_type": "MODIFY",
            "diff": "@@ -9,7 +9,7 @@ use std::{\n \n use once_cell::sync::Lazy;\n use regex::Regex;\n-use reqwest::{blocking::Client, blocking::Response, header::HeaderMap, Url};\n+use reqwest::{blocking::Client, blocking::Response, header, Url};\n use rocket::{http::ContentType, http::Cookie, response::Content, Route};\n use soup::prelude::*;\n \n@@ -22,10 +22,18 @@ pub fn routes() -> Vec<Route> {\n const ALLOWED_CHARS: &str = \"_-.\";\n \n static CLIENT: Lazy<Client> = Lazy::new(|| {\n+    // Generate the default headers\n+    let mut default_headers = header::HeaderMap::new();\n+    default_headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\"));\n+    default_headers.insert(header::ACCEPT_LANGUAGE, header::HeaderValue::from_static(\"en-US,en;q=0.8\"));\n+    default_headers.insert(header::CACHE_CONTROL, header::HeaderValue::from_static(\"no-cache\"));\n+    default_headers.insert(header::PRAGMA, header::HeaderValue::from_static(\"no-cache\"));\n+    default_headers.insert(header::ACCEPT, header::HeaderValue::from_static(\"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\"));\n+\n     // Reuse the client between requests\n     Client::builder()\n         .timeout(Duration::from_secs(CONFIG.icon_download_timeout()))\n-        .default_headers(_header_map())\n+        .default_headers(default_headers)\n         .build()\n         .unwrap()\n });\n@@ -324,6 +332,12 @@ impl Icon {\n     }\n }\n \n+struct IconUrlResult {\n+    iconlist: Vec<Icon>,\n+    cookies: String,\n+    referer: String,\n+}\n+\n /// Returns a Result/Tuple which holds a Vector IconList and a string which holds the cookies from the last response.\n /// There will always be a result with a string which will contain https://example.com/favicon.ico and an empty string for the cookies.\n /// This does not mean that that location does exists, but it is the default location browser use.\n@@ -336,19 +350,11 @@ impl Icon {\n /// let (mut iconlist, cookie_str) = get_icon_url(\"github.com\")?;\n /// let (mut iconlist, cookie_str) = get_icon_url(\"gitlab.com\")?;\n /// ```\n-fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n+fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n     // Default URL with secure and insecure schemes\n     let ssldomain = format!(\"https://{}\", domain);\n     let httpdomain = format!(\"http://{}\", domain);\n \n-    // Create the iconlist\n-    let mut iconlist: Vec<Icon> = Vec::new();\n-\n-    // Create the cookie_str to fill it all the cookies from the response\n-    // These cookies can be used to request/download the favicon image.\n-    // Some sites have extra security in place with for example XSRF Tokens.\n-    let mut cookie_str = String::new();\n-\n     // First check the domain as given during the request for both HTTPS and HTTP.\n     let resp = match get_page(&ssldomain).or_else(|_| get_page(&httpdomain)) {\n         Ok(c) => Ok(c),\n@@ -388,6 +394,15 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n         }\n     };\n \n+    // Create the iconlist\n+    let mut iconlist: Vec<Icon> = Vec::new();\n+\n+    // Create the cookie_str to fill it all the cookies from the response\n+    // These cookies can be used to request/download the favicon image.\n+    // Some sites have extra security in place with for example XSRF Tokens.\n+    let mut cookie_str = \"\".to_string();\n+    let mut referer = \"\".to_string();\n+\n     if let Ok(content) = resp {\n         // Extract the URL from the respose in case redirects occured (like @ gitlab.com)\n         let url = content.url().clone();\n@@ -407,6 +422,10 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n             })\n             .collect::<String>();\n \n+        // Set the referer to be used on the final request, some sites check this.\n+        // Mostly used to prevent direct linking and other security resons.\n+        referer = url.as_str().to_string();\n+\n         // Add the default favicon.ico to the list with the domain the content responded from.\n         iconlist.push(Icon::new(35, url.join(\"/favicon.ico\").unwrap().into_string()));\n \n@@ -446,21 +465,28 @@ fn get_icon_url(domain: &str) -> Result<(Vec<Icon>, String), Error> {\n     iconlist.sort_by_key(|x| x.priority);\n \n     // There always is an icon in the list, so no need to check if it exists, and just return the first one\n-    Ok((iconlist, cookie_str))\n+    Ok(IconUrlResult{\n+        iconlist,\n+        cookies: cookie_str,\n+        referer\n+    })\n }\n \n fn get_page(url: &str) -> Result<Response, Error> {\n-    get_page_with_cookies(url, \"\")\n+    get_page_with_cookies(url, \"\", \"\")\n }\n \n-fn get_page_with_cookies(url: &str, cookie_str: &str) -> Result<Response, Error> {\n+fn get_page_with_cookies(url: &str, cookie_str: &str, referer: &str) -> Result<Response, Error> {\n     if is_domain_blacklisted(Url::parse(url).unwrap().host_str().unwrap_or_default()) {\n         err!(\"Favicon rel linked to a blacklisted domain!\");\n     }\n \n     let mut client = CLIENT.get(url);\n     if !cookie_str.is_empty() {\n-        client = client.header(\"cookie\", cookie_str)\n+        client = client.header(\"Cookie\", cookie_str)\n+    }\n+    if !referer.is_empty() {\n+        client = client.header(\"Referer\", referer)\n     }\n \n     client.send()?\n@@ -493,7 +519,7 @@ fn get_icon_priority(href: &str, sizes: Option<String>) -> u8 {\n                 1\n             } else if width == 64 {\n                 2\n-            } else if width >= 24 && width <= 128 {\n+            } else if (24..=128).contains(&width) {\n                 3\n             } else if width == 16 {\n                 4\n@@ -552,13 +578,13 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n         err!(\"Domain is blacklisted\", domain)\n     }\n \n-    let (iconlist, cookie_str) = get_icon_url(&domain)?;\n+    let icon_result = get_icon_url(&domain)?;\n \n     let mut buffer = Vec::new();\n \n     use data_url::DataUrl;\n \n-    for icon in iconlist.iter().take(5) {\n+    for icon in icon_result.iconlist.iter().take(5) {\n         if icon.href.starts_with(\"data:image\") {\n             let datauri = DataUrl::process(&icon.href).unwrap();\n             // Check if we are able to decode the data uri\n@@ -573,13 +599,13 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n                 _ => warn!(\"data uri is invalid\"),\n             };\n         } else {\n-            match get_page_with_cookies(&icon.href, &cookie_str) {\n+            match get_page_with_cookies(&icon.href, &icon_result.cookies, &icon_result.referer) {\n                 Ok(mut res) => {\n                     info!(\"Downloaded icon from {}\", icon.href);\n                     res.copy_to(&mut buffer)?;\n                     break;\n-                }\n-                Err(_) => warn!(\"Download failed for {}\", icon.href),\n+                },\n+                _ => warn!(\"Download failed for {}\", icon.href),\n             };\n         }\n     }\n@@ -604,25 +630,3 @@ fn save_icon(path: &str, icon: &[u8]) {\n         }\n     }\n }\n-\n-fn _header_map() -> HeaderMap {\n-    // Set some default headers for the request.\n-    // Use a browser like user-agent to make sure most websites will return there correct website.\n-    use reqwest::header::*;\n-\n-    macro_rules! headers {\n-        ($( $name:ident : $value:literal),+ $(,)? ) => {\n-            let mut headers = HeaderMap::new();\n-            $( headers.insert($name, HeaderValue::from_static($value)); )+\n-            headers\n-        };\n-    }\n-\n-    headers! {\n-        USER_AGENT: \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\",\n-        ACCEPT_LANGUAGE: \"en-US,en;q=0.8\",\n-        CACHE_CONTROL: \"no-cache\",\n-        PRAGMA: \"no-cache\",\n-        ACCEPT: \"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\",\n-    }\n-}\n",
            "comment_added_diff": [
                [
                    25,
                    "    // Generate the default headers"
                ],
                [
                    397,
                    "    // Create the iconlist"
                ],
                [
                    400,
                    "    // Create the cookie_str to fill it all the cookies from the response"
                ],
                [
                    401,
                    "    // These cookies can be used to request/download the favicon image."
                ],
                [
                    402,
                    "    // Some sites have extra security in place with for example XSRF Tokens."
                ],
                [
                    425,
                    "        // Set the referer to be used on the final request, some sites check this."
                ],
                [
                    426,
                    "        // Mostly used to prevent direct linking and other security resons."
                ]
            ]
        },
        {
            "commit": "c836f88ff2a7f94ee7427ae04b91e702a31ab52a",
            "timestamp": "2021-02-07T22:28:02+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove soup and use a newer html5ever directly",
            "additions": 46,
            "deletions": 27,
            "change_type": "MODIFY",
            "diff": "@@ -11,7 +11,6 @@ use once_cell::sync::Lazy;\n use regex::Regex;\n use reqwest::{blocking::Client, blocking::Response, header, Url};\n use rocket::{http::ContentType, http::Cookie, response::Content, Route};\n-use soup::prelude::*;\n \n use crate::{error::Error, util::Cached, CONFIG};\n \n@@ -332,6 +331,42 @@ impl Icon {\n     }\n }\n \n+fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Vec<Icon>, url: &Url) {\n+    if let markup5ever_rcdom::NodeData::Element { name, attrs, .. } = &node.data {\n+        if name.local.as_ref() == \"link\" {\n+            let mut has_rel = false;\n+            let mut href = None;\n+            let mut sizes = None;\n+\n+            let attrs = attrs.borrow();\n+            for attr in attrs.iter() {\n+                let attr_name = attr.name.local.as_ref();\n+                let attr_value = attr.value.as_ref();\n+\n+                if attr_name == \"rel\" && ICON_REL_REGEX.is_match(attr_value) {\n+                    has_rel = true;\n+                } else if attr_name == \"href\" {\n+                    href = Some(attr_value);\n+                } else if attr_name == \"sizes\" {\n+                    sizes = Some(attr_value);\n+                }\n+            }\n+\n+            if has_rel && href.is_some() {\n+                if let Ok(full_href) = url.join(&href.unwrap()).map(|h| h.into_string()) {\n+                    let priority = get_icon_priority(&full_href, sizes);\n+                    icons.push(Icon::new(priority, full_href));\n+                }\n+            }\n+        }\n+    }\n+\n+    // TODO: Might want to limit the recursion depth?\n+    for child in node.children.borrow().iter() {\n+        get_favicons_node(child, icons, url);\n+    }\n+}\n+\n struct IconUrlResult {\n     iconlist: Vec<Icon>,\n     cookies: String,\n@@ -431,30 +466,14 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n \n         // 512KB should be more than enough for the HTML, though as we only really need\n         // the HTML header, it could potentially be reduced even further\n-        let limited_reader = content.take(512 * 1024);\n-\n-        let soup = Soup::from_reader(limited_reader)?;\n-        // Search for and filter\n-        let favicons = soup\n-            .tag(\"link\")\n-            .attr(\"rel\", ICON_REL_REGEX.clone()) // Only use icon rels\n-            .attr_name(\"href\") // Make sure there is a href\n-            .find_all();\n-\n-        // Loop through all the found icons and determine it's priority\n-        for favicon in favicons {\n-            let sizes = favicon.get(\"sizes\");\n-            let href = favicon.get(\"href\").unwrap();\n-            // Skip invalid url's\n-            let full_href = match url.join(&href) {\n-                Ok(h) => h.into_string(),\n-                _ => continue,\n-            };\n-\n-            let priority = get_icon_priority(&full_href, sizes);\n-\n-            iconlist.push(Icon::new(priority, full_href))\n-        }\n+        let mut limited_reader = content.take(512 * 1024);\n+\n+        use html5ever::tendril::TendrilSink;\n+        let dom = html5ever::parse_document(markup5ever_rcdom::RcDom::default(), Default::default())\n+            .from_utf8()\n+            .read_from(&mut limited_reader)?;\n+    \n+        get_favicons_node(&dom.document, &mut iconlist, &url);\n     } else {\n         // Add the default favicon.ico to the list with just the given domain\n         iconlist.push(Icon::new(35, format!(\"{}/favicon.ico\", ssldomain)));\n@@ -506,7 +525,7 @@ fn get_page_with_cookies(url: &str, cookie_str: &str, referer: &str) -> Result<R\n /// priority1 = get_icon_priority(\"http://example.com/path/to/a/favicon.png\", \"32x32\");\n /// priority2 = get_icon_priority(\"https://example.com/path/to/a/favicon.ico\", \"\");\n /// ```\n-fn get_icon_priority(href: &str, sizes: Option<String>) -> u8 {\n+fn get_icon_priority(href: &str, sizes: Option<&str>) -> u8 {\n     // Check if there is a dimension set\n     let (width, height) = parse_sizes(sizes);\n \n@@ -554,7 +573,7 @@ fn get_icon_priority(href: &str, sizes: Option<String>) -> u8 {\n /// let (width, height) = parse_sizes(\"x128x128\"); // (128, 128)\n /// let (width, height) = parse_sizes(\"32\"); // (0, 0)\n /// ```\n-fn parse_sizes(sizes: Option<String>) -> (u16, u16) {\n+fn parse_sizes(sizes: Option<&str>) -> (u16, u16) {\n     let mut width: u16 = 0;\n     let mut height: u16 = 0;\n \n",
            "comment_added_diff": [
                [
                    364,
                    "    // TODO: Might want to limit the recursion depth?"
                ]
            ]
        },
        {
            "commit": "b22564cb000febe9a871f2121d96993ff5569c7b",
            "timestamp": "2021-03-27T13:30:40+00:00",
            "author": "Jake Howard",
            "commit_message": "Cache icons on the client\n\nThis should make the vault pages load much faster, and massively reduce the number of requests.",
            "additions": 8,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -51,7 +51,10 @@ fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n         return None;\n     }\n \n-    get_icon(&domain).map(|icon| Cached::long(Content(ContentType::new(\"image\", \"x-icon\"), icon)))\n+    get_icon(&domain).map(|(icon, cached)| {\n+        let cache_ttl = if cached {CONFIG.icon_cache_ttl()} else {CONFIG.icon_cache_negttl()};\n+        Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), icon), cache_ttl)\n+    })\n }\n \n /// Returns if the domain provided is valid or not.\n@@ -238,7 +241,7 @@ fn is_domain_blacklisted(domain: &str) -> bool {\n     is_blacklisted\n }\n \n-fn get_icon(domain: &str) -> Option<Vec<u8>> {\n+fn get_icon(domain: &str) -> Option<(Vec<u8>, bool)> {\n     let path = format!(\"{}/{}.png\", CONFIG.icon_cache_folder(), domain);\n \n     // Check for expiration of negatively cached copy\n@@ -247,7 +250,7 @@ fn get_icon(domain: &str) -> Option<Vec<u8>> {\n     }\n \n     if let Some(icon) = get_cached_icon(&path) {\n-        return Some(icon);\n+        return Some((icon, true));\n     }\n \n     if CONFIG.disable_icon_download() {\n@@ -258,7 +261,7 @@ fn get_icon(domain: &str) -> Option<Vec<u8>> {\n     match download_icon(&domain) {\n         Ok(icon) => {\n             save_icon(&path, &icon);\n-            Some(icon)\n+            Some((icon, false))\n         }\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n@@ -472,7 +475,7 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n         let dom = html5ever::parse_document(markup5ever_rcdom::RcDom::default(), Default::default())\n             .from_utf8()\n             .read_from(&mut limited_reader)?;\n-    \n+\n         get_favicons_node(&dom.document, &mut iconlist, &url);\n     } else {\n         // Add the default favicon.ico to the list with just the given domain\n",
            "comment_added_diff": []
        },
        {
            "commit": "a8138be69b0c051da9f97827a9f5427c98dd3051",
            "timestamp": "2021-03-27T14:03:31+00:00",
            "author": "Jake Howard",
            "commit_message": "Use `if let` more",
            "additions": 7,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -352,10 +352,12 @@ fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Ve\n                 }\n             }\n \n-            if has_rel && href.is_some() {\n-                if let Ok(full_href) = url.join(&href.unwrap()).map(|h| h.into_string()) {\n-                    let priority = get_icon_priority(&full_href, sizes);\n-                    icons.push(Icon::new(priority, full_href));\n+            if has_rel {\n+                if let Some(inner_href) = href {\n+                    if let Ok(full_href) = url.join(&inner_href).map(|h| h.into_string()) {\n+                        let priority = get_icon_priority(&full_href, sizes);\n+                        icons.push(Icon::new(priority, full_href));\n+                    }\n                 }\n             }\n         }\n@@ -472,7 +474,7 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n         let dom = html5ever::parse_document(markup5ever_rcdom::RcDom::default(), Default::default())\n             .from_utf8()\n             .read_from(&mut limited_reader)?;\n-    \n+\n         get_favicons_node(&dom.document, &mut iconlist, &url);\n     } else {\n         // Add the default favicon.ico to the list with just the given domain\n",
            "comment_added_diff": []
        },
        {
            "commit": "6209e778e59c44d38288579a105c9e46c829c405",
            "timestamp": "2021-03-28T10:39:12+01:00",
            "author": "Jake Howard",
            "commit_message": "Icons should always be cached using full TTL",
            "additions": 4,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -51,10 +51,7 @@ fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n         return None;\n     }\n \n-    get_icon(&domain).map(|(icon, cached)| {\n-        let cache_ttl = if cached {CONFIG.icon_cache_ttl()} else {CONFIG.icon_cache_negttl()};\n-        Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), icon), cache_ttl)\n-    })\n+    get_icon(&domain).map(|icon| Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), icon), CONFIG.icon_cache_ttl()))\n }\n \n /// Returns if the domain provided is valid or not.\n@@ -241,7 +238,7 @@ fn is_domain_blacklisted(domain: &str) -> bool {\n     is_blacklisted\n }\n \n-fn get_icon(domain: &str) -> Option<(Vec<u8>, bool)> {\n+fn get_icon(domain: &str) -> Option<Vec<u8>> {\n     let path = format!(\"{}/{}.png\", CONFIG.icon_cache_folder(), domain);\n \n     // Check for expiration of negatively cached copy\n@@ -250,7 +247,7 @@ fn get_icon(domain: &str) -> Option<(Vec<u8>, bool)> {\n     }\n \n     if let Some(icon) = get_cached_icon(&path) {\n-        return Some((icon, true));\n+        return Some(icon);\n     }\n \n     if CONFIG.disable_icon_download() {\n@@ -261,7 +258,7 @@ fn get_icon(domain: &str) -> Option<(Vec<u8>, bool)> {\n     match download_icon(&domain) {\n         Ok(icon) => {\n             save_icon(&path, &icon);\n-            Some((icon, false))\n+            Some(icon)\n         }\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n",
            "comment_added_diff": []
        },
        {
            "commit": "3a3390963c91566e1b60ee4bb3d0f7fea5a950a6",
            "timestamp": "2021-03-29T10:27:58+02:00",
            "author": "BlackDex",
            "commit_message": "Icon and SMTP Debug fixes.\n\n- We need to add some feature to enable smtp debugging again. See: https://github.com/lettre/lettre/pull/584\n- Upstream added the fallback icon again, probably because of caching ;). See: https://github.com/bitwarden/server/pull/1149\n- Enabled gzip and brotli compression support with reqwest. Some sites seem to force this, or assume that because of the User-Agent string it is supported. This caused some failed icons.\n\nFixes #1540",
            "additions": 14,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -18,8 +18,6 @@ pub fn routes() -> Vec<Route> {\n     routes![icon]\n }\n \n-const ALLOWED_CHARS: &str = \"_-.\";\n-\n static CLIENT: Lazy<Client> = Lazy::new(|| {\n     // Generate the default headers\n     let mut default_headers = header::HeaderMap::new();\n@@ -45,13 +43,18 @@ static ICON_SIZE_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?x)(\\d+)\\D*(\\d+\n static ICON_BLACKLIST_REGEX: Lazy<RwLock<HashMap<String, Regex>>> = Lazy::new(|| RwLock::new(HashMap::new()));\n \n #[get(\"/<domain>/icon.png\")]\n-fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n+fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n+    const FALLBACK_ICON: &[u8] = include_bytes!(\"../static/images/fallback-icon.png\");\n+\n     if !is_valid_domain(&domain) {\n         warn!(\"Invalid domain: {}\", domain);\n-        return None;\n+        return Cached::ttl(Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()), CONFIG.icon_cache_negttl());\n     }\n \n-    get_icon(&domain).map(|icon| Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), icon), CONFIG.icon_cache_ttl()))\n+    match get_icon(&domain) {\n+        Some(i) => Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), i), CONFIG.icon_cache_ttl()),\n+        _ => Cached::ttl(Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()), CONFIG.icon_cache_negttl()),\n+    }\n }\n \n /// Returns if the domain provided is valid or not.\n@@ -59,6 +62,8 @@ fn icon(domain: String) -> Option<Cached<Content<Vec<u8>>>> {\n /// This does some manual checks and makes use of Url to do some basic checking.\n /// domains can't be larger then 63 characters (not counting multiple subdomains) according to the RFC's, but we limit the total size to 255.\n fn is_valid_domain(domain: &str) -> bool {\n+    const ALLOWED_CHARS: &str = \"_-.\";\n+\n     // If parsing the domain fails using Url, it will not work with reqwest.\n     if let Err(parse_error) = Url::parse(format!(\"https://{}\", domain).as_str()) {\n         debug!(\"Domain parse error: '{}' - {:?}\", domain, parse_error);\n@@ -486,10 +491,10 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n     iconlist.sort_by_key(|x| x.priority);\n \n     // There always is an icon in the list, so no need to check if it exists, and just return the first one\n-    Ok(IconUrlResult{\n+    Ok(IconUrlResult {\n         iconlist,\n         cookies: cookie_str,\n-        referer\n+        referer,\n     })\n }\n \n@@ -510,9 +515,7 @@ fn get_page_with_cookies(url: &str, cookie_str: &str, referer: &str) -> Result<R\n         client = client.header(\"Referer\", referer)\n     }\n \n-    client.send()?\n-        .error_for_status()\n-        .map_err(Into::into)\n+    client.send()?.error_for_status().map_err(Into::into)\n }\n \n /// Returns a Integer with the priority of the type of the icon which to prefer.\n@@ -625,7 +628,7 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n                     info!(\"Downloaded icon from {}\", icon.href);\n                     res.copy_to(&mut buffer)?;\n                     break;\n-                },\n+                }\n                 _ => warn!(\"Download failed for {}\", icon.href),\n             };\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 26,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -22,10 +22,18 @@ static CLIENT: Lazy<Client> = Lazy::new(|| {\n     // Generate the default headers\n     let mut default_headers = header::HeaderMap::new();\n     default_headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\"));\n-    default_headers.insert(header::ACCEPT_LANGUAGE, header::HeaderValue::from_static(\"en-US,en;q=0.8\"));\n+    default_headers.insert(\n+        header::ACCEPT_LANGUAGE,\n+        header::HeaderValue::from_static(\"en-US,en;q=0.8\"),\n+    );\n     default_headers.insert(header::CACHE_CONTROL, header::HeaderValue::from_static(\"no-cache\"));\n     default_headers.insert(header::PRAGMA, header::HeaderValue::from_static(\"no-cache\"));\n-    default_headers.insert(header::ACCEPT, header::HeaderValue::from_static(\"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\"));\n+    default_headers.insert(\n+        header::ACCEPT,\n+        header::HeaderValue::from_static(\n+            \"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\",\n+        ),\n+    );\n \n     // Reuse the client between requests\n     Client::builder()\n@@ -48,12 +56,18 @@ fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n \n     if !is_valid_domain(&domain) {\n         warn!(\"Invalid domain: {}\", domain);\n-        return Cached::ttl(Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()), CONFIG.icon_cache_negttl());\n+        return Cached::ttl(\n+            Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()),\n+            CONFIG.icon_cache_negttl(),\n+        );\n     }\n \n     match get_icon(&domain) {\n         Some(i) => Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), i), CONFIG.icon_cache_ttl()),\n-        _ => Cached::ttl(Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()), CONFIG.icon_cache_negttl()),\n+        _ => Cached::ttl(\n+            Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()),\n+            CONFIG.icon_cache_negttl(),\n+        ),\n     }\n }\n \n@@ -74,7 +88,10 @@ fn is_valid_domain(domain: &str) -> bool {\n         || domain.starts_with('-')\n         || domain.ends_with('-')\n     {\n-        debug!(\"Domain validation error: '{}' is either empty, contains '..', starts with an '.', starts or ends with a '-'\", domain);\n+        debug!(\n+            \"Domain validation error: '{}' is either empty, contains '..', starts with an '.', starts or ends with a '-'\",\n+            domain\n+        );\n         return false;\n     } else if domain.len() > 255 {\n         debug!(\"Domain validation error: '{}' exceeds 255 characters\", domain);\n@@ -83,7 +100,10 @@ fn is_valid_domain(domain: &str) -> bool {\n \n     for c in domain.chars() {\n         if !c.is_alphanumeric() && !ALLOWED_CHARS.contains(c) {\n-            debug!(\"Domain validation error: '{}' contains an invalid character '{}'\", domain, c);\n+            debug!(\n+                \"Domain validation error: '{}' contains an invalid character '{}'\",\n+                domain, c\n+            );\n             return false;\n         }\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "1d0eaac260d251abed23106e6356cb07e5b6e994",
            "timestamp": "2021-04-03T22:51:44+02:00",
            "author": "BlackDex",
            "commit_message": "Updated icon fetching.\n\n- Added image type checking, and prevent downloading non images.\n  We didn't checked this before, which could in turn could allow someone\nto download an arbitrary file.\n- This also prevents SVG images from being used, while they work on the\n  web-vault and desktop client, they didn't on the mobile versions.\n- Because of this image type checking we can return a valid file type\n  instead of only 'x-icon' (which is still used as a fallback).\n- Prevent rel values with `icon-mask`, these are not valid favicons.",
            "additions": 45,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -37,6 +37,7 @@ static CLIENT: Lazy<Client> = Lazy::new(|| {\n \n // Build Regex only once since this takes a lot of time.\n static ICON_REL_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?i)icon$|apple.*icon\").unwrap());\n+static ICON_REL_BLACKLIST: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?i)mask-icon\").unwrap());\n static ICON_SIZE_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r\"(?x)(\\d+)\\D*(\\d+)\").unwrap());\n \n // Special HashMap which holds the user defined Regex to speedup matching the regex.\n@@ -52,7 +53,9 @@ fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n     }\n \n     match get_icon(&domain) {\n-        Some(i) => Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), i), CONFIG.icon_cache_ttl()),\n+        Some((icon, icon_type)) => {\n+            Cached::ttl(Content(ContentType::new(\"image\", icon_type), icon), CONFIG.icon_cache_ttl())\n+        },\n         _ => Cached::ttl(Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()), CONFIG.icon_cache_negttl()),\n     }\n }\n@@ -243,7 +246,7 @@ fn is_domain_blacklisted(domain: &str) -> bool {\n     is_blacklisted\n }\n \n-fn get_icon(domain: &str) -> Option<Vec<u8>> {\n+fn get_icon(domain: &str) -> Option<(Vec<u8>, String)> {\n     let path = format!(\"{}/{}.png\", CONFIG.icon_cache_folder(), domain);\n \n     // Check for expiration of negatively cached copy\n@@ -252,7 +255,11 @@ fn get_icon(domain: &str) -> Option<Vec<u8>> {\n     }\n \n     if let Some(icon) = get_cached_icon(&path) {\n-        return Some(icon);\n+        let icon_type =  match get_icon_type(&icon) {\n+            Some(x) => x,\n+            _ => \"x-icon\",\n+        };\n+        return Some((icon, icon_type.to_string()));\n     }\n \n     if CONFIG.disable_icon_download() {\n@@ -261,9 +268,9 @@ fn get_icon(domain: &str) -> Option<Vec<u8>> {\n \n     // Get the icon, or None in case of error\n     match download_icon(&domain) {\n-        Ok(icon) => {\n+        Ok((icon, icon_type)) => {\n             save_icon(&path, &icon);\n-            Some(icon)\n+            Some((icon, icon_type.unwrap_or(\"x-icon\").to_string()))\n         }\n         Err(e) => {\n             error!(\"Error downloading icon: {:?}\", e);\n@@ -324,7 +331,6 @@ fn icon_is_expired(path: &str) -> bool {\n     expired.unwrap_or(true)\n }\n \n-#[derive(Debug)]\n struct Icon {\n     priority: u8,\n     href: String,\n@@ -348,7 +354,7 @@ fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Ve\n                 let attr_name = attr.name.local.as_ref();\n                 let attr_value = attr.value.as_ref();\n \n-                if attr_name == \"rel\" && ICON_REL_REGEX.is_match(attr_value) {\n+                if attr_name == \"rel\" && ICON_REL_REGEX.is_match(attr_value) && !ICON_REL_BLACKLIST.is_match(attr_value) {\n                     has_rel = true;\n                 } else if attr_name == \"href\" {\n                     href = Some(attr_value);\n@@ -597,7 +603,7 @@ fn parse_sizes(sizes: Option<&str>) -> (u16, u16) {\n     (width, height)\n }\n \n-fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n+fn download_icon(domain: &str) -> Result<(Vec<u8>, Option<&str>), Error> {\n     if is_domain_blacklisted(domain) {\n         err!(\"Domain is blacklisted\", domain)\n     }\n@@ -605,6 +611,7 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n     let icon_result = get_icon_url(&domain)?;\n \n     let mut buffer = Vec::new();\n+    let mut icon_type: Option<&str> = None;\n \n     use data_url::DataUrl;\n \n@@ -616,17 +623,31 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n                 Ok((body, _fragment)) => {\n                     // Also check if the size is atleast 67 bytes, which seems to be the smallest png i could create\n                     if body.len() >= 67 {\n+                        // Check if the icon type is allowed, else try an icon from the list.\n+                        icon_type = get_icon_type(&body);\n+                        if icon_type.is_none() {\n+                            debug!(\"Icon from {} data:image uri, is not a valid image type\", domain);\n+                            continue;\n+                        }\n+                        info!(\"Extracted icon from data:image uri for {}\", domain);\n                         buffer = body;\n                         break;\n                     }\n                 }\n-                _ => warn!(\"data uri is invalid\"),\n+                _ => warn!(\"Extracted icon from data:image uri is invalid\"),\n             };\n         } else {\n             match get_page_with_cookies(&icon.href, &icon_result.cookies, &icon_result.referer) {\n                 Ok(mut res) => {\n-                    info!(\"Downloaded icon from {}\", icon.href);\n                     res.copy_to(&mut buffer)?;\n+                    // Check if the icon type is allowed, else try an icon from the list.\n+                    icon_type = get_icon_type(&buffer);\n+                    if icon_type.is_none() {\n+                        buffer.clear();\n+                        debug!(\"Icon from {}, is not a valid image type\", icon.href);\n+                        continue;\n+                    }\n+                    info!(\"Downloaded icon from {}\", icon.href);\n                     break;\n                 }\n                 _ => warn!(\"Download failed for {}\", icon.href),\n@@ -635,10 +656,10 @@ fn download_icon(domain: &str) -> Result<Vec<u8>, Error> {\n     }\n \n     if buffer.is_empty() {\n-        err!(\"Empty response\")\n+        err!(\"Empty response downloading icon\")\n     }\n \n-    Ok(buffer)\n+    Ok((buffer, icon_type))\n }\n \n fn save_icon(path: &str, icon: &[u8]) {\n@@ -650,7 +671,18 @@ fn save_icon(path: &str, icon: &[u8]) {\n             create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache\");\n         }\n         Err(e) => {\n-            info!(\"Icon save error: {:?}\", e);\n+            warn!(\"Icon save error: {:?}\", e);\n         }\n     }\n }\n+\n+fn get_icon_type(bytes: &[u8]) -> Option<&'static str> {\n+    match bytes {\n+        [137, 80, 78, 71, ..] => Some(\"png\"),\n+        [0, 0, 1, 0, ..] => Some(\"x-icon\"),\n+        [82, 73, 70, 70, ..] => Some(\"webp\"),\n+        [255, 216, 255, ..] => Some(\"jpeg\"),\n+        [66, 77, ..] => Some(\"bmp\"),\n+        _ => None\n+    }\n+}\n",
            "comment_added_diff": [
                [
                    626,
                    "                        // Check if the icon type is allowed, else try an icon from the list."
                ],
                [
                    643,
                    "                    // Check if the icon type is allowed, else try an icon from the list."
                ]
            ]
        },
        {
            "commit": "155109dea120e109e1e027d4e1312b6adad4c231",
            "timestamp": "2021-04-06T21:04:37+01:00",
            "author": "Jake Howard",
            "commit_message": "Extract client creation to a single place",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -12,7 +12,7 @@ use regex::Regex;\n use reqwest::{blocking::Client, blocking::Response, header, Url};\n use rocket::{http::ContentType, http::Cookie, response::Content, Route};\n \n-use crate::{error::Error, util::Cached, CONFIG};\n+use crate::{error::Error, util::{Cached, get_reqwest_client_builder}, CONFIG};\n \n pub fn routes() -> Vec<Route> {\n     routes![icon]\n@@ -28,11 +28,11 @@ static CLIENT: Lazy<Client> = Lazy::new(|| {\n     default_headers.insert(header::ACCEPT, header::HeaderValue::from_static(\"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\"));\n \n     // Reuse the client between requests\n-    Client::builder()\n+    get_reqwest_client_builder()\n         .timeout(Duration::from_secs(CONFIG.icon_download_timeout()))\n         .default_headers(default_headers)\n         .build()\n-        .unwrap()\n+        .expect(\"Failed to build icon client\")\n });\n \n // Build Regex only once since this takes a lot of time.\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 13,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -22,10 +22,7 @@ static CLIENT: Lazy<Client> = Lazy::new(|| {\n     // Generate the default headers\n     let mut default_headers = header::HeaderMap::new();\n     default_headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\"));\n-    default_headers.insert(\n-        header::ACCEPT_LANGUAGE,\n-        header::HeaderValue::from_static(\"en-US,en;q=0.8\"),\n-    );\n+    default_headers.insert(header::ACCEPT_LANGUAGE, header::HeaderValue::from_static(\"en-US,en;q=0.8\"));\n     default_headers.insert(header::CACHE_CONTROL, header::HeaderValue::from_static(\"no-cache\"));\n     default_headers.insert(header::PRAGMA, header::HeaderValue::from_static(\"no-cache\"));\n     default_headers.insert(\n@@ -64,10 +61,7 @@ fn icon(domain: String) -> Cached<Content<Vec<u8>>> {\n \n     match get_icon(&domain) {\n         Some(i) => Cached::ttl(Content(ContentType::new(\"image\", \"x-icon\"), i), CONFIG.icon_cache_ttl()),\n-        _ => Cached::ttl(\n-            Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()),\n-            CONFIG.icon_cache_negttl(),\n-        ),\n+        _ => Cached::ttl(Content(ContentType::new(\"image\", \"png\"), FALLBACK_ICON.to_vec()), CONFIG.icon_cache_negttl()),\n     }\n }\n \n@@ -100,10 +94,7 @@ fn is_valid_domain(domain: &str) -> bool {\n \n     for c in domain.chars() {\n         if !c.is_alphanumeric() && !ALLOWED_CHARS.contains(c) {\n-            debug!(\n-                \"Domain validation error: '{}' contains an invalid character '{}'\",\n-                domain, c\n-            );\n+            debug!(\"Domain validation error: '{}' contains an invalid character '{}'\", domain, c);\n             return false;\n         }\n     }\n@@ -352,12 +343,20 @@ struct Icon {\n \n impl Icon {\n     const fn new(priority: u8, href: String) -> Self {\n-        Self { href, priority }\n+        Self {\n+            href,\n+            priority,\n+        }\n     }\n }\n \n fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Vec<Icon>, url: &Url) {\n-    if let markup5ever_rcdom::NodeData::Element { name, attrs, .. } = &node.data {\n+    if let markup5ever_rcdom::NodeData::Element {\n+        name,\n+        attrs,\n+        ..\n+    } = &node.data\n+    {\n         if name.local.as_ref() == \"link\" {\n             let mut has_rel = false;\n             let mut href = None;\n",
            "comment_added_diff": []
        },
        {
            "commit": "305de2e2cd820ae6651a6442d88f5ca637263fae",
            "timestamp": "2021-04-15T18:30:23+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Format the changes from merge to master",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -12,7 +12,11 @@ use regex::Regex;\n use reqwest::{blocking::Client, blocking::Response, header, Url};\n use rocket::{http::ContentType, http::Cookie, response::Content, Route};\n \n-use crate::{error::Error, util::{Cached, get_reqwest_client_builder}, CONFIG};\n+use crate::{\n+    error::Error,\n+    util::{get_reqwest_client_builder, Cached},\n+    CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n     routes![icon]\n",
            "comment_added_diff": []
        },
        {
            "commit": "b8010be26b4e2d489f55ba01622f9b6e1685b3b1",
            "timestamp": "2021-05-02T17:49:25+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Extract some FromDb trait impls outside the macros so they aren't repeated, and fix some clippy lints",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -354,8 +354,8 @@ struct Icon {\n impl Icon {\n     const fn new(priority: u8, href: String) -> Self {\n         Self {\n-            href,\n             priority,\n+            href,\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "7cb19ef767142b773ab44a457940844589432a74",
            "timestamp": "2021-05-08T17:46:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated branding, email and crates\n\n- Updated branding for admin and emails\n- Updated crates and some deprications\n- Removed newline-converter because this is built-in into lettre\n- Updated email templates to use a shared header and footer template\n- Also trigger SMTP SSL When TLS is selected without SSL\n  Resolves #1641",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -389,7 +389,7 @@ fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Ve\n \n             if has_rel {\n                 if let Some(inner_href) = href {\n-                    if let Ok(full_href) = url.join(&inner_href).map(|h| h.into_string()) {\n+                    if let Ok(full_href) = url.join(&inner_href).map(String::from) {\n                         let priority = get_icon_priority(&full_href, sizes);\n                         icons.push(Icon::new(priority, full_href));\n                     }\n@@ -499,7 +499,7 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n         referer = url.as_str().to_string();\n \n         // Add the default favicon.ico to the list with the domain the content responded from.\n-        iconlist.push(Icon::new(35, url.join(\"/favicon.ico\").unwrap().into_string()));\n+        iconlist.push(Icon::new(35, String::from(url.join(\"/favicon.ico\").unwrap())));\n \n         // 512KB should be more than enough for the HTML, though as we only really need\n         // the HTML header, it could potentially be reduced even further\n",
            "comment_added_diff": []
        },
        {
            "commit": "f270f2ed652459cec2d5251b998eef17a88ea49e",
            "timestamp": "2021-05-16T15:29:13+02:00",
            "author": "BlackDex",
            "commit_message": "Updated icon fetching and crates.\n\n- Updated some crates\n- Updated icon fetching code:\n  + Use a cookie jar and set Max-Age to 2 minutes for all cookies\n  + Locate the base href tag to fix some locations\n  + Changed User-Agent (Helps on some sites to get HTML instead of JS)\n  + Reduced HTML code limit from 512KB to 384KB\n  + Allow some large icons higer-up in the sort\n  + Allow GIF images\n  + Ignore cookie_store and hyper::client debug messages",
            "additions": 117,
            "deletions": 52,
            "change_type": "MODIFY",
            "diff": "@@ -3,14 +3,14 @@ use std::{\n     fs::{create_dir_all, remove_file, symlink_metadata, File},\n     io::prelude::*,\n     net::{IpAddr, ToSocketAddrs},\n-    sync::RwLock,\n+    sync::{Arc, RwLock},\n     time::{Duration, SystemTime},\n };\n \n use once_cell::sync::Lazy;\n use regex::Regex;\n-use reqwest::{blocking::Client, blocking::Response, header, Url};\n-use rocket::{http::ContentType, http::Cookie, response::Content, Route};\n+use reqwest::{blocking::Client, blocking::Response, header};\n+use rocket::{http::ContentType, response::Content, Route};\n \n use crate::{\n     error::Error,\n@@ -25,19 +25,17 @@ pub fn routes() -> Vec<Route> {\n static CLIENT: Lazy<Client> = Lazy::new(|| {\n     // Generate the default headers\n     let mut default_headers = header::HeaderMap::new();\n-    default_headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\"));\n-    default_headers.insert(header::ACCEPT_LANGUAGE, header::HeaderValue::from_static(\"en-US,en;q=0.8\"));\n+    default_headers\n+        .insert(header::USER_AGENT, header::HeaderValue::from_static(\"Links (2.22; Linux X86_64; GNU C; text)\"));\n+    default_headers\n+        .insert(header::ACCEPT, header::HeaderValue::from_static(\"text/html, text/*;q=0.5, image/*, */*;q=0.1\"));\n+    default_headers.insert(header::ACCEPT_LANGUAGE, header::HeaderValue::from_static(\"en,*;q=0.1\"));\n     default_headers.insert(header::CACHE_CONTROL, header::HeaderValue::from_static(\"no-cache\"));\n     default_headers.insert(header::PRAGMA, header::HeaderValue::from_static(\"no-cache\"));\n-    default_headers.insert(\n-        header::ACCEPT,\n-        header::HeaderValue::from_static(\n-            \"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\",\n-        ),\n-    );\n \n     // Reuse the client between requests\n     get_reqwest_client_builder()\n+        .cookie_provider(Arc::new(Jar::default()))\n         .timeout(Duration::from_secs(CONFIG.icon_download_timeout()))\n         .default_headers(default_headers)\n         .build()\n@@ -80,7 +78,7 @@ fn is_valid_domain(domain: &str) -> bool {\n     const ALLOWED_CHARS: &str = \"_-.\";\n \n     // If parsing the domain fails using Url, it will not work with reqwest.\n-    if let Err(parse_error) = Url::parse(format!(\"https://{}\", domain).as_str()) {\n+    if let Err(parse_error) = url::Url::parse(format!(\"https://{}\", domain).as_str()) {\n         debug!(\"Domain parse error: '{}' - {:?}\", domain, parse_error);\n         return false;\n     } else if domain.is_empty()\n@@ -360,7 +358,51 @@ impl Icon {\n     }\n }\n \n-fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Vec<Icon>, url: &Url) {\n+/// Iterates over the HTML document to find <base href=\"http://domain.tld\">\n+/// When found it will stop the iteration and the found base href will be shared deref via `base_href`.\n+///\n+/// # Arguments\n+/// * `node` - A Parsed HTML document via html5ever::parse_document()\n+/// * `base_href` - a mutable url::Url which will be overwritten when a base href tag has been found.\n+///\n+fn get_base_href(node: &std::rc::Rc<markup5ever_rcdom::Node>, base_href: &mut url::Url) -> bool {\n+    if let markup5ever_rcdom::NodeData::Element {\n+        name,\n+        attrs,\n+        ..\n+    } = &node.data\n+    {\n+        if name.local.as_ref() == \"base\" {\n+            let attrs = attrs.borrow();\n+            for attr in attrs.iter() {\n+                let attr_name = attr.name.local.as_ref();\n+                let attr_value = attr.value.as_ref();\n+\n+                if attr_name == \"href\" {\n+                    debug!(\"Found base href: {}\", attr_value);\n+                    *base_href = match base_href.join(attr_value) {\n+                        Ok(href) => href,\n+                        _ => base_href.clone(),\n+                    };\n+                    return true;\n+                }\n+            }\n+            return true;\n+        }\n+    }\n+\n+    // TODO: Might want to limit the recursion depth?\n+    for child in node.children.borrow().iter() {\n+        // Check if we got a true back and stop the iter.\n+        // This means we found a <base> tag and can stop processing the html.\n+        if get_base_href(child, base_href) {\n+            return true;\n+        }\n+    }\n+    false\n+}\n+\n+fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Vec<Icon>, url: &url::Url) {\n     if let markup5ever_rcdom::NodeData::Element {\n         name,\n         attrs,\n@@ -406,12 +448,11 @@ fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Ve\n \n struct IconUrlResult {\n     iconlist: Vec<Icon>,\n-    cookies: String,\n     referer: String,\n }\n \n-/// Returns a Result/Tuple which holds a Vector IconList and a string which holds the cookies from the last response.\n-/// There will always be a result with a string which will contain https://example.com/favicon.ico and an empty string for the cookies.\n+/// Returns a IconUrlResult which holds a Vector IconList and a string which holds the referer.\n+/// There will always two items within the iconlist which holds http(s)://domain.tld/favicon.ico.\n /// This does not mean that that location does exists, but it is the default location browser use.\n ///\n /// # Argument\n@@ -419,8 +460,8 @@ struct IconUrlResult {\n ///\n /// # Example\n /// ```\n-/// let (mut iconlist, cookie_str) = get_icon_url(\"github.com\")?;\n-/// let (mut iconlist, cookie_str) = get_icon_url(\"gitlab.com\")?;\n+/// let icon_result = get_icon_url(\"github.com\")?;\n+/// let icon_result = get_icon_url(\"vaultwarden.discourse.group\")?;\n /// ```\n fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n     // Default URL with secure and insecure schemes\n@@ -468,32 +509,12 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n \n     // Create the iconlist\n     let mut iconlist: Vec<Icon> = Vec::new();\n-\n-    // Create the cookie_str to fill it all the cookies from the response\n-    // These cookies can be used to request/download the favicon image.\n-    // Some sites have extra security in place with for example XSRF Tokens.\n-    let mut cookie_str = \"\".to_string();\n-    let mut referer = \"\".to_string();\n+    let mut referer = String::from(\"\");\n \n     if let Ok(content) = resp {\n         // Extract the URL from the respose in case redirects occured (like @ gitlab.com)\n         let url = content.url().clone();\n \n-        // Get all the cookies and pass it on to the next function.\n-        // Needed for XSRF Cookies for example (like @ mijn.ing.nl)\n-        let raw_cookies = content.headers().get_all(\"set-cookie\");\n-        cookie_str = raw_cookies\n-            .iter()\n-            .filter_map(|raw_cookie| raw_cookie.to_str().ok())\n-            .map(|cookie_str| {\n-                if let Ok(cookie) = Cookie::parse(cookie_str) {\n-                    format!(\"{}={}; \", cookie.name(), cookie.value())\n-                } else {\n-                    String::new()\n-                }\n-            })\n-            .collect::<String>();\n-\n         // Set the referer to be used on the final request, some sites check this.\n         // Mostly used to prevent direct linking and other security resons.\n         referer = url.as_str().to_string();\n@@ -501,16 +522,17 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n         // Add the default favicon.ico to the list with the domain the content responded from.\n         iconlist.push(Icon::new(35, String::from(url.join(\"/favicon.ico\").unwrap())));\n \n-        // 512KB should be more than enough for the HTML, though as we only really need\n-        // the HTML header, it could potentially be reduced even further\n-        let mut limited_reader = content.take(512 * 1024);\n+        // 384KB should be more than enough for the HTML, though as we only really need the HTML header.\n+        let mut limited_reader = content.take(384 * 1024);\n \n         use html5ever::tendril::TendrilSink;\n         let dom = html5ever::parse_document(markup5ever_rcdom::RcDom::default(), Default::default())\n             .from_utf8()\n             .read_from(&mut limited_reader)?;\n \n-        get_favicons_node(&dom.document, &mut iconlist, &url);\n+        let mut base_url: url::Url = url;\n+        get_base_href(&dom.document, &mut base_url);\n+        get_favicons_node(&dom.document, &mut iconlist, &base_url);\n     } else {\n         // Add the default favicon.ico to the list with just the given domain\n         iconlist.push(Icon::new(35, format!(\"{}/favicon.ico\", ssldomain)));\n@@ -523,24 +545,20 @@ fn get_icon_url(domain: &str) -> Result<IconUrlResult, Error> {\n     // There always is an icon in the list, so no need to check if it exists, and just return the first one\n     Ok(IconUrlResult {\n         iconlist,\n-        cookies: cookie_str,\n         referer,\n     })\n }\n \n fn get_page(url: &str) -> Result<Response, Error> {\n-    get_page_with_cookies(url, \"\", \"\")\n+    get_page_with_referer(url, \"\")\n }\n \n-fn get_page_with_cookies(url: &str, cookie_str: &str, referer: &str) -> Result<Response, Error> {\n-    if is_domain_blacklisted(Url::parse(url).unwrap().host_str().unwrap_or_default()) {\n+fn get_page_with_referer(url: &str, referer: &str) -> Result<Response, Error> {\n+    if is_domain_blacklisted(url::Url::parse(url).unwrap().host_str().unwrap_or_default()) {\n         err!(\"Favicon rel linked to a blacklisted domain!\");\n     }\n \n     let mut client = CLIENT.get(url);\n-    if !cookie_str.is_empty() {\n-        client = client.header(\"Cookie\", cookie_str)\n-    }\n     if !referer.is_empty() {\n         client = client.header(\"Referer\", referer)\n     }\n@@ -573,7 +591,7 @@ fn get_icon_priority(href: &str, sizes: Option<&str>) -> u8 {\n                 1\n             } else if width == 64 {\n                 2\n-            } else if (24..=128).contains(&width) {\n+            } else if (24..=192).contains(&width) {\n                 3\n             } else if width == 16 {\n                 4\n@@ -661,7 +679,7 @@ fn download_icon(domain: &str) -> Result<(Vec<u8>, Option<&str>), Error> {\n                 _ => warn!(\"Extracted icon from data:image uri is invalid\"),\n             };\n         } else {\n-            match get_page_with_cookies(&icon.href, &icon_result.cookies, &icon_result.referer) {\n+            match get_page_with_referer(&icon.href, &icon_result.referer) {\n                 Ok(mut res) => {\n                     res.copy_to(&mut buffer)?;\n                     // Check if the icon type is allowed, else try an icon from the list.\n@@ -706,7 +724,54 @@ fn get_icon_type(bytes: &[u8]) -> Option<&'static str> {\n         [0, 0, 1, 0, ..] => Some(\"x-icon\"),\n         [82, 73, 70, 70, ..] => Some(\"webp\"),\n         [255, 216, 255, ..] => Some(\"jpeg\"),\n+        [71, 73, 70, 56, ..] => Some(\"gif\"),\n         [66, 77, ..] => Some(\"bmp\"),\n         _ => None,\n     }\n }\n+\n+/// This is an implementation of the default Cookie Jar from Reqwest and reqwest_cookie_store build by pfernie.\n+/// The default cookie jar used by Reqwest keeps all the cookies based upon the Max-Age or Expires which could be a long time.\n+/// That could be used for tracking, to prevent this we force the lifespan of the cookies to always be max two minutes.\n+/// A Cookie Jar is needed because some sites force a redirect with cookies to verify if a request uses cookies or not.\n+use cookie_store::CookieStore;\n+#[derive(Default)]\n+pub struct Jar(RwLock<CookieStore>);\n+\n+impl reqwest::cookie::CookieStore for Jar {\n+    fn set_cookies(&self, cookie_headers: &mut dyn Iterator<Item = &header::HeaderValue>, url: &url::Url) {\n+        use cookie::{Cookie as RawCookie, ParseError as RawCookieParseError};\n+        use time::Duration;\n+\n+        let mut cookie_store = self.0.write().unwrap();\n+        let cookies = cookie_headers.filter_map(|val| {\n+            std::str::from_utf8(val.as_bytes())\n+                .map_err(RawCookieParseError::from)\n+                .and_then(RawCookie::parse)\n+                .map(|mut c| {\n+                    c.set_expires(None);\n+                    c.set_max_age(Some(Duration::minutes(2)));\n+                    c.into_owned()\n+                })\n+                .ok()\n+        });\n+        cookie_store.store_response_cookies(cookies, url);\n+    }\n+\n+    fn cookies(&self, url: &url::Url) -> Option<header::HeaderValue> {\n+        use bytes::Bytes;\n+\n+        let cookie_store = self.0.read().unwrap();\n+        let s = cookie_store\n+            .get_request_values(url)\n+            .map(|(name, value)| format!(\"{}={}\", name, value))\n+            .collect::<Vec<_>>()\n+            .join(\"; \");\n+\n+        if s.is_empty() {\n+            return None;\n+        }\n+\n+        header::HeaderValue::from_maybe_shared(Bytes::from(s)).ok()\n+    }\n+}\n",
            "comment_added_diff": [
                [
                    81,
                    "    if let Err(parse_error) = url::Url::parse(format!(\"https://{}\", domain).as_str()) {"
                ],
                [
                    361,
                    "/// Iterates over the HTML document to find <base href=\"http://domain.tld\">"
                ],
                [
                    362,
                    "/// When found it will stop the iteration and the found base href will be shared deref via `base_href`."
                ],
                [
                    363,
                    "///"
                ],
                [
                    364,
                    "/// # Arguments"
                ],
                [
                    365,
                    "/// * `node` - A Parsed HTML document via html5ever::parse_document()"
                ],
                [
                    366,
                    "/// * `base_href` - a mutable url::Url which will be overwritten when a base href tag has been found."
                ],
                [
                    367,
                    "///"
                ],
                [
                    394,
                    "    // TODO: Might want to limit the recursion depth?"
                ],
                [
                    396,
                    "        // Check if we got a true back and stop the iter."
                ],
                [
                    397,
                    "        // This means we found a <base> tag and can stop processing the html."
                ],
                [
                    454,
                    "/// Returns a IconUrlResult which holds a Vector IconList and a string which holds the referer."
                ],
                [
                    455,
                    "/// There will always two items within the iconlist which holds http(s)://domain.tld/favicon.ico."
                ],
                [
                    463,
                    "/// let icon_result = get_icon_url(\"github.com\")?;"
                ],
                [
                    464,
                    "/// let icon_result = get_icon_url(\"vaultwarden.discourse.group\")?;"
                ],
                [
                    525,
                    "        // 384KB should be more than enough for the HTML, though as we only really need the HTML header."
                ],
                [
                    733,
                    "/// This is an implementation of the default Cookie Jar from Reqwest and reqwest_cookie_store build by pfernie."
                ],
                [
                    734,
                    "/// The default cookie jar used by Reqwest keeps all the cookies based upon the Max-Age or Expires which could be a long time."
                ],
                [
                    735,
                    "/// That could be used for tracking, to prevent this we force the lifespan of the cookies to always be max two minutes."
                ],
                [
                    736,
                    "/// A Cookie Jar is needed because some sites force a redirect with cookies to verify if a request uses cookies or not."
                ]
            ]
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -249,7 +249,7 @@ fn is_domain_blacklisted(domain: &str) -> bool {\n             };\n \n             // Use the pre-generate Regex stored in a Lazy HashMap.\n-            if regex.is_match(&domain) {\n+            if regex.is_match(domain) {\n                 warn!(\"Blacklisted domain: {:#?} matched {:#?}\", domain, blacklist);\n                 is_blacklisted = true;\n             }\n@@ -280,7 +280,7 @@ fn get_icon(domain: &str) -> Option<(Vec<u8>, String)> {\n     }\n \n     // Get the icon, or None in case of error\n-    match download_icon(&domain) {\n+    match download_icon(domain) {\n         Ok((icon, icon_type)) => {\n             save_icon(&path, &icon);\n             Some((icon, icon_type.unwrap_or(\"x-icon\").to_string()))\n@@ -431,7 +431,7 @@ fn get_favicons_node(node: &std::rc::Rc<markup5ever_rcdom::Node>, icons: &mut Ve\n \n             if has_rel {\n                 if let Some(inner_href) = href {\n-                    if let Ok(full_href) = url.join(&inner_href).map(String::from) {\n+                    if let Ok(full_href) = url.join(inner_href).map(String::from) {\n                         let priority = get_icon_priority(&full_href, sizes);\n                         icons.push(Icon::new(priority, full_href));\n                     }\n@@ -650,7 +650,7 @@ fn download_icon(domain: &str) -> Result<(Vec<u8>, Option<&str>), Error> {\n         err!(\"Domain is blacklisted\", domain)\n     }\n \n-    let icon_result = get_icon_url(&domain)?;\n+    let icon_result = get_icon_url(domain)?;\n \n     let mut buffer = Vec::new();\n     let mut icon_type: Option<&str> = None;\n",
            "comment_added_diff": []
        },
        {
            "commit": "9375d5b8c212956f3469b86e62e5d7f057194ea2",
            "timestamp": "2021-09-24T18:27:52+02:00",
            "author": "BlackDex",
            "commit_message": "Updated icon downloading\n\n- Unicode websites could break (www.post.japanpost.jp for example).\n  regex would fail because it was missing the unicode-perl feature.\n- Be less verbose in logging with icon downloads\n- Removed duplicate info/error messages\n- Added err_silent! macro to help with the less verbose error/info messages.",
            "additions": 10,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -250,7 +250,7 @@ fn is_domain_blacklisted(domain: &str) -> bool {\n \n             // Use the pre-generate Regex stored in a Lazy HashMap.\n             if regex.is_match(domain) {\n-                warn!(\"Blacklisted domain: {:#?} matched {:#?}\", domain, blacklist);\n+                warn!(\"Blacklisted domain: {} matched ICON_BLACKLIST_REGEX\", domain);\n                 is_blacklisted = true;\n             }\n         }\n@@ -555,7 +555,7 @@ fn get_page(url: &str) -> Result<Response, Error> {\n \n fn get_page_with_referer(url: &str, referer: &str) -> Result<Response, Error> {\n     if is_domain_blacklisted(url::Url::parse(url).unwrap().host_str().unwrap_or_default()) {\n-        err!(\"Favicon rel linked to a blacklisted domain!\");\n+        err!(\"Favicon resolves to a blacklisted domain or IP!\", url);\n     }\n \n     let mut client = CLIENT.get(url);\n@@ -563,7 +563,10 @@ fn get_page_with_referer(url: &str, referer: &str) -> Result<Response, Error> {\n         client = client.header(\"Referer\", referer)\n     }\n \n-    client.send()?.error_for_status().map_err(Into::into)\n+    match client.send() {\n+        Ok(c) => c.error_for_status().map_err(Into::into),\n+        Err(e) => err_silent!(format!(\"{}\", e)),\n+    }\n }\n \n /// Returns a Integer with the priority of the type of the icon which to prefer.\n@@ -647,7 +650,7 @@ fn parse_sizes(sizes: Option<&str>) -> (u16, u16) {\n \n fn download_icon(domain: &str) -> Result<(Vec<u8>, Option<&str>), Error> {\n     if is_domain_blacklisted(domain) {\n-        err!(\"Domain is blacklisted\", domain)\n+        err_silent!(\"Domain is blacklisted\", domain)\n     }\n \n     let icon_result = get_icon_url(domain)?;\n@@ -676,7 +679,7 @@ fn download_icon(domain: &str) -> Result<(Vec<u8>, Option<&str>), Error> {\n                         break;\n                     }\n                 }\n-                _ => warn!(\"Extracted icon from data:image uri is invalid\"),\n+                _ => debug!(\"Extracted icon from data:image uri is invalid\"),\n             };\n         } else {\n             match get_page_with_referer(&icon.href, &icon_result.referer) {\n@@ -692,13 +695,13 @@ fn download_icon(domain: &str) -> Result<(Vec<u8>, Option<&str>), Error> {\n                     info!(\"Downloaded icon from {}\", icon.href);\n                     break;\n                 }\n-                _ => warn!(\"Download failed for {}\", icon.href),\n+                Err(e) => debug!(\"{:?}\", e),\n             };\n         }\n     }\n \n     if buffer.is_empty() {\n-        err!(\"Empty response downloading icon\")\n+        err_silent!(\"Empty response or unable find a valid icon\", domain);\n     }\n \n     Ok((buffer, icon_type))\n",
            "comment_added_diff": []
        }
    ],
    "email.rs": [
        {
            "commit": "18bc8331f9a27421b3913af4a8f070255cf3caba",
            "timestamp": "2019-10-15T21:19:49+02:00",
            "author": "vpl",
            "commit_message": "Send email when preparing 2FA JsonError",
            "additions": 7,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -58,6 +58,13 @@ fn send_email_login(data: JsonUpcase<SendEmailLoginData>, conn: DbConn) -> Empty\n     let type_ = TwoFactorType::Email as i32;\n     let mut twofactor = TwoFactor::find_by_user_and_type(&user.uuid, type_, &conn)?;\n \n+    prepare_send_token(&mut twofactor, &conn)?;\n+\n+    Ok(())\n+}\n+\n+/// Generate the token, save the data for later verification and send email to user\n+pub fn prepare_send_token(twofactor: &mut TwoFactor, conn: &DbConn) -> EmptyResult {\n     let generated_token = generate_token(CONFIG.email_token_size())?;\n     let mut twofactor_data = EmailTokenData::from_json(&twofactor.data)?;\n     twofactor_data.set_token(generated_token);\n",
            "comment_added_diff": [
                [
                    66,
                    "/// Generate the token, save the data for later verification and send email to user"
                ]
            ]
        },
        {
            "commit": "2edecf34fff71ec1c89c05b5f6c5b6121eed715d",
            "timestamp": "2019-10-15T21:20:19+02:00",
            "author": "vpl",
            "commit_message": "Use user_uuid instead of mut twofactor",
            "additions": 6,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -55,17 +55,18 @@ fn send_email_login(data: JsonUpcase<SendEmailLoginData>, conn: DbConn) -> Empty\n         err!(\"Email 2FA is disabled\")\n     }\n \n-    let type_ = TwoFactorType::Email as i32;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(&user.uuid, type_, &conn)?;\n-\n-    prepare_send_token(&mut twofactor, &conn)?;\n+    send_token(&user.uuid, &conn)?;\n \n     Ok(())\n }\n \n /// Generate the token, save the data for later verification and send email to user\n-pub fn prepare_send_token(twofactor: &mut TwoFactor, conn: &DbConn) -> EmptyResult {\n+pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+    let type_ = TwoFactorType::Email as i32;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, type_, &conn)?;\n+\n     let generated_token = generate_token(CONFIG.email_token_size())?;\n+\n     let mut twofactor_data = EmailTokenData::from_json(&twofactor.data)?;\n     twofactor_data.set_token(generated_token);\n     twofactor.data = twofactor_data.to_json();\n",
            "comment_added_diff": []
        },
        {
            "commit": "e449912f05d63a3499609ae00184796dd7390bf0",
            "timestamp": "2019-11-02T18:31:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Generate recovery codes for email and duo",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -2,6 +2,7 @@ use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json;\n \n+use crate::api::core::two_factor::_generate_recover_code;\n use crate::api::{EmptyResult, JsonResult, JsonUpcase, PasswordData};\n use crate::auth::Headers;\n use crate::crypto;\n@@ -172,7 +173,7 @@ struct EmailData {\n #[put(\"/two-factor/email\", data = \"<data>\")]\n fn email(data: JsonUpcase<EmailData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let data: EmailData = data.into_inner().data;\n-    let user = headers.user;\n+    let mut user = headers.user;\n \n     if !user.check_valid_password(&data.MasterPasswordHash) {\n         err!(\"Invalid password\");\n@@ -197,6 +198,8 @@ fn email(data: JsonUpcase<EmailData>, headers: Headers, conn: DbConn) -> JsonRes\n     twofactor.data = email_data.to_json();\n     twofactor.save(&conn)?;\n \n+    _generate_recover_code(&mut user, &conn);\n+\n     Ok(Json(json!({\n         \"Email\": email_data.email,\n         \"Enabled\": \"true\",\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 2,
            "deletions": 18,
            "change_type": "MODIFY",
            "diff": "@@ -66,7 +66,7 @@ pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n     let type_ = TwoFactorType::Email as i32;\n     let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, type_, &conn)?;\n \n-    let generated_token = generate_token(CONFIG.email_token_size())?;\n+    let generated_token = crypto::generate_token(CONFIG.email_token_size())?;\n \n     let mut twofactor_data = EmailTokenData::from_json(&twofactor.data)?;\n     twofactor_data.set_token(generated_token);\n@@ -109,22 +109,6 @@ struct SendEmailData {\n     MasterPasswordHash: String,\n }\n \n-\n-fn generate_token(token_size: u32) -> Result<String, Error> {\n-    if token_size > 19 {\n-        err!(\"Generating token failed\")\n-    }\n-\n-    // 8 bytes to create an u64 for up to 19 token digits\n-    let bytes = crypto::get_random(vec![0; 8]);\n-    let mut bytes_array = [0u8; 8];\n-    bytes_array.copy_from_slice(&bytes);\n-\n-    let number = u64::from_be_bytes(bytes_array) % 10u64.pow(token_size);\n-    let token = format!(\"{:0size$}\", number, size = token_size as usize);\n-    Ok(token)\n-}\n-\n /// Send a verification email to the specified email address to check whether it exists/belongs to user.\n #[post(\"/two-factor/send-email\", data = \"<data>\")]\n fn send_email(data: JsonUpcase<SendEmailData>, headers: Headers, conn: DbConn) -> EmptyResult {\n@@ -145,7 +129,7 @@ fn send_email(data: JsonUpcase<SendEmailData>, headers: Headers, conn: DbConn) -\n         tf.delete(&conn)?;\n     }\n \n-    let generated_token = generate_token(CONFIG.email_token_size())?;\n+    let generated_token = crypto::generate_token(CONFIG.email_token_size())?;\n     let twofactor_data = EmailTokenData::new(data.Email, generated_token);\n \n     // Uses EmailVerificationChallenge as type to show that it's not verified yet.\n",
            "comment_added_diff": []
        },
        {
            "commit": "12928b832c8354a9d81fe984e378f60353cca3b3",
            "timestamp": "2019-11-30T23:30:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix broken tests",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -321,14 +321,14 @@ mod tests {\n \n     #[test]\n     fn test_token() {\n-        let result = generate_token(19).unwrap();\n+        let result = crypto::generate_token(19).unwrap();\n \n         assert_eq!(result.chars().count(), 19);\n     }\n \n     #[test]\n     fn test_token_too_large() {\n-        let result = generate_token(20);\n+        let result = crypto::generate_token(20);\n \n         assert!(result.is_err(), \"too large token should give an error\");\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 1,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -18,12 +18,7 @@ use chrono::{Duration, NaiveDateTime, Utc};\n use std::ops::Add;\n \n pub fn routes() -> Vec<Route> {\n-    routes![\n-        get_email,\n-        send_email_login,\n-        send_email,\n-        email,\n-    ]\n+    routes![get_email, send_email_login, send_email, email,]\n }\n \n #[derive(Deserialize)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "def174a517716967b80d5ecb8407772668bfd631",
            "timestamp": "2020-01-30T22:11:53+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Convert email domains to punycode",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -271,7 +271,7 @@ impl EmailTokenData {\n \n /// Takes an email address and obscures it by replacing it with asterisks except two characters.\n pub fn obscure_email(email: &str) -> String {\n-    let split: Vec<&str> = email.split('@').collect();\n+    let split: Vec<&str> = email.rsplitn(2, '@').collect();\n \n     let mut name = split[0].to_string();\n     let domain = &split[1];\n",
            "comment_added_diff": []
        },
        {
            "commit": "f5916ec396329a1239641944ebcf2b9e42656179",
            "timestamp": "2020-01-30T22:33:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix backwards indices",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -273,8 +273,8 @@ impl EmailTokenData {\n pub fn obscure_email(email: &str) -> String {\n     let split: Vec<&str> = email.rsplitn(2, '@').collect();\n \n-    let mut name = split[0].to_string();\n-    let domain = &split[1];\n+    let mut name = split[1].to_string();\n+    let domain = &split[0];\n \n     let name_size = name.chars().count();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,5 @@\n use rocket::Route;\n use rocket_contrib::json::Json;\n-use serde_json;\n \n use crate::api::core::two_factor::_generate_recover_code;\n use crate::api::{EmptyResult, JsonResult, JsonUpcase, PasswordData};\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 17,
            "deletions": 19,
            "change_type": "MODIFY",
            "diff": "@@ -1,20 +1,18 @@\n+use chrono::{Duration, NaiveDateTime, Utc};\n use rocket::Route;\n use rocket_contrib::json::Json;\n \n-use crate::api::core::two_factor::_generate_recover_code;\n-use crate::api::{EmptyResult, JsonResult, JsonUpcase, PasswordData};\n-use crate::auth::Headers;\n-use crate::crypto;\n-use crate::db::{\n-    models::{TwoFactor, TwoFactorType},\n-    DbConn,\n+use crate::{\n+    api::{core::two_factor::_generate_recover_code, EmptyResult, JsonResult, JsonUpcase, PasswordData},\n+    auth::Headers,\n+    crypto,\n+    db::{\n+        models::{TwoFactor, TwoFactorType},\n+        DbConn,\n+    },\n+    error::{Error, MapResult},\n+    mail, CONFIG,\n };\n-use crate::error::Error;\n-use crate::mail;\n-use crate::CONFIG;\n-\n-use chrono::{Duration, NaiveDateTime, Utc};\n-use std::ops::Add;\n \n pub fn routes() -> Vec<Route> {\n     routes![get_email, send_email_login, send_email, email,]\n@@ -58,7 +56,7 @@ fn send_email_login(data: JsonUpcase<SendEmailLoginData>, conn: DbConn) -> Empty\n /// Generate the token, save the data for later verification and send email to user\n pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n     let type_ = TwoFactorType::Email as i32;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, type_, &conn)?;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, type_, &conn).map_res(\"Two factor not found\")?;\n \n     let generated_token = crypto::generate_token(CONFIG.email_token_size())?;\n \n@@ -67,7 +65,7 @@ pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n     twofactor.data = twofactor_data.to_json();\n     twofactor.save(&conn)?;\n \n-    mail::send_token(&twofactor_data.email, &twofactor_data.last_token?)?;\n+    mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n \n     Ok(())\n }\n@@ -134,7 +132,7 @@ fn send_email(data: JsonUpcase<SendEmailData>, headers: Headers, conn: DbConn) -\n     );\n     twofactor.save(&conn)?;\n \n-    mail::send_token(&twofactor_data.email, &twofactor_data.last_token?)?;\n+    mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n \n     Ok(())\n }\n@@ -158,7 +156,7 @@ fn email(data: JsonUpcase<EmailData>, headers: Headers, conn: DbConn) -> JsonRes\n     }\n \n     let type_ = TwoFactorType::EmailVerificationChallenge as i32;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(&user.uuid, type_, &conn)?;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(&user.uuid, type_, &conn).map_res(\"Two factor not found\")?;\n \n     let mut email_data = EmailTokenData::from_json(&twofactor.data)?;\n \n@@ -188,7 +186,7 @@ fn email(data: JsonUpcase<EmailData>, headers: Headers, conn: DbConn) -> JsonRes\n /// Validate the email code when used as TwoFactor token mechanism\n pub fn validate_email_code_str(user_uuid: &str, token: &str, data: &str, conn: &DbConn) -> EmptyResult {\n     let mut email_data = EmailTokenData::from_json(&data)?;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Email as i32, &conn)?;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Email as i32, &conn).map_res(\"Two factor not found\")?;\n     let issued_token = match &email_data.last_token {\n         Some(t) => t,\n         _ => err!(\"No token available\"),\n@@ -211,7 +209,7 @@ pub fn validate_email_code_str(user_uuid: &str, token: &str, data: &str, conn: &\n \n     let date = NaiveDateTime::from_timestamp(email_data.token_sent, 0);\n     let max_time = CONFIG.email_expiration_time() as i64;\n-    if date.add(Duration::seconds(max_time)) < Utc::now().naive_utc() {\n+    if date + Duration::seconds(max_time) < Utc::now().naive_utc() {\n         err!(\"Token has expired\")\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 10,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -65,7 +65,10 @@ pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n     twofactor.data = twofactor_data.to_json();\n     twofactor.save(&conn)?;\n \n-    mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n+    mail::send_token(\n+        &twofactor_data.email,\n+        &twofactor_data.last_token.map_res(\"Token is empty\")?,\n+    )?;\n \n     Ok(())\n }\n@@ -132,7 +135,10 @@ fn send_email(data: JsonUpcase<SendEmailData>, headers: Headers, conn: DbConn) -\n     );\n     twofactor.save(&conn)?;\n \n-    mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n+    mail::send_token(\n+        &twofactor_data.email,\n+        &twofactor_data.last_token.map_res(\"Token is empty\")?,\n+    )?;\n \n     Ok(())\n }\n@@ -186,7 +192,8 @@ fn email(data: JsonUpcase<EmailData>, headers: Headers, conn: DbConn) -> JsonRes\n /// Validate the email code when used as TwoFactor token mechanism\n pub fn validate_email_code_str(user_uuid: &str, token: &str, data: &str, conn: &DbConn) -> EmptyResult {\n     let mut email_data = EmailTokenData::from_json(&data)?;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Email as i32, &conn).map_res(\"Two factor not found\")?;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Email as i32, &conn)\n+        .map_res(\"Two factor not found\")?;\n     let issued_token = match &email_data.last_token {\n         Some(t) => t,\n         _ => err!(\"No token available\"),\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 3,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -65,10 +65,7 @@ pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n     twofactor.data = twofactor_data.to_json();\n     twofactor.save(&conn)?;\n \n-    mail::send_token(\n-        &twofactor_data.email,\n-        &twofactor_data.last_token.map_res(\"Token is empty\")?,\n-    )?;\n+    mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n \n     Ok(())\n }\n@@ -128,17 +125,10 @@ fn send_email(data: JsonUpcase<SendEmailData>, headers: Headers, conn: DbConn) -\n     let twofactor_data = EmailTokenData::new(data.Email, generated_token);\n \n     // Uses EmailVerificationChallenge as type to show that it's not verified yet.\n-    let twofactor = TwoFactor::new(\n-        user.uuid,\n-        TwoFactorType::EmailVerificationChallenge,\n-        twofactor_data.to_json(),\n-    );\n+    let twofactor = TwoFactor::new(user.uuid, TwoFactorType::EmailVerificationChallenge, twofactor_data.to_json());\n     twofactor.save(&conn)?;\n \n-    mail::send_token(\n-        &twofactor_data.email,\n-        &twofactor_data.last_token.map_res(\"Token is empty\")?,\n-    )?;\n+    mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n \n     Ok(())\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 9,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -56,14 +56,14 @@ fn send_email_login(data: JsonUpcase<SendEmailLoginData>, conn: DbConn) -> Empty\n /// Generate the token, save the data for later verification and send email to user\n pub fn send_token(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n     let type_ = TwoFactorType::Email as i32;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, type_, &conn).map_res(\"Two factor not found\")?;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, type_, conn).map_res(\"Two factor not found\")?;\n \n     let generated_token = crypto::generate_token(CONFIG.email_token_size())?;\n \n     let mut twofactor_data = EmailTokenData::from_json(&twofactor.data)?;\n     twofactor_data.set_token(generated_token);\n     twofactor.data = twofactor_data.to_json();\n-    twofactor.save(&conn)?;\n+    twofactor.save(conn)?;\n \n     mail::send_token(&twofactor_data.email, &twofactor_data.last_token.map_res(\"Token is empty\")?)?;\n \n@@ -181,8 +181,8 @@ fn email(data: JsonUpcase<EmailData>, headers: Headers, conn: DbConn) -> JsonRes\n \n /// Validate the email code when used as TwoFactor token mechanism\n pub fn validate_email_code_str(user_uuid: &str, token: &str, data: &str, conn: &DbConn) -> EmptyResult {\n-    let mut email_data = EmailTokenData::from_json(&data)?;\n-    let mut twofactor = TwoFactor::find_by_user_and_type(&user_uuid, TwoFactorType::Email as i32, &conn)\n+    let mut email_data = EmailTokenData::from_json(data)?;\n+    let mut twofactor = TwoFactor::find_by_user_and_type(user_uuid, TwoFactorType::Email as i32, conn)\n         .map_res(\"Two factor not found\")?;\n     let issued_token = match &email_data.last_token {\n         Some(t) => t,\n@@ -195,14 +195,14 @@ pub fn validate_email_code_str(user_uuid: &str, token: &str, data: &str, conn: &\n             email_data.reset_token();\n         }\n         twofactor.data = email_data.to_json();\n-        twofactor.save(&conn)?;\n+        twofactor.save(conn)?;\n \n         err!(\"Token is invalid\")\n     }\n \n     email_data.reset_token();\n     twofactor.data = email_data.to_json();\n-    twofactor.save(&conn)?;\n+    twofactor.save(conn)?;\n \n     let date = NaiveDateTime::from_timestamp(email_data.token_sent, 0);\n     let max_time = CONFIG.email_expiration_time() as i64;\n@@ -255,7 +255,7 @@ impl EmailTokenData {\n     }\n \n     pub fn from_json(string: &str) -> Result<EmailTokenData, Error> {\n-        let res: Result<EmailTokenData, crate::serde_json::Error> = serde_json::from_str(&string);\n+        let res: Result<EmailTokenData, crate::serde_json::Error> = serde_json::from_str(string);\n         match res {\n             Ok(x) => Ok(x),\n             Err(_) => err!(\"Could not decode EmailTokenData from string\"),\n@@ -292,7 +292,7 @@ mod tests {\n     fn test_obscure_email_long() {\n         let email = \"bytes@example.ext\";\n \n-        let result = obscure_email(&email);\n+        let result = obscure_email(email);\n \n         // Only first two characters should be visible.\n         assert_eq!(result, \"by***@example.ext\");\n@@ -302,7 +302,7 @@ mod tests {\n     fn test_obscure_email_short() {\n         let email = \"byt@example.ext\";\n \n-        let result = obscure_email(&email);\n+        let result = obscure_email(email);\n \n         // If it's smaller than 3 characters it should only show asterisks.\n         assert_eq!(result, \"***@example.ext\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "881d1f43340b16cfa6b9836b520537461397c1d3",
            "timestamp": "2021-08-19T09:25:34+02:00",
            "author": "BlackDex",
            "commit_message": "Fix wrong display of MFA email.\n\nThere was some wrong logic regarding the display of which email is\nconfigured to be used for the email MFA. This is now fixed.\n\nResolves #1878",
            "additions": 7,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -80,14 +80,16 @@ fn get_email(data: JsonUpcase<PasswordData>, headers: Headers, conn: DbConn) ->\n         err!(\"Invalid password\");\n     }\n \n-    let type_ = TwoFactorType::Email as i32;\n-    let enabled = match TwoFactor::find_by_user_and_type(&user.uuid, type_, &conn) {\n-        Some(x) => x.enabled,\n-        _ => false,\n+    let (enabled, mfa_email) = match TwoFactor::find_by_user_and_type(&user.uuid, TwoFactorType::Email as i32, &conn) {\n+        Some(x) => {\n+            let twofactor_data = EmailTokenData::from_json(&x.data)?;\n+            (true, json!(twofactor_data.email))\n+        }\n+        _ => (false, json!(null)),\n     };\n \n     Ok(Json(json!({\n-        \"Email\": user.email,\n+        \"Email\": mfa_email,\n         \"Enabled\": enabled,\n         \"Object\": \"twoFactorEmail\"\n     })))\n",
            "comment_added_diff": []
        }
    ],
    "notifications.rs": [
        {
            "commit": "ebc47dc161405518c4a88d1ac006b8def1677ad8",
            "timestamp": "2019-10-17T17:15:11+02:00",
            "author": "Jellyfrog",
            "commit_message": "Remove unneeded WS logging",
            "additions": 0,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -157,8 +157,6 @@ impl Handler for WSHandler {\n     }\n \n     fn on_message(&mut self, msg: Message) -> ws::Result<()> {\n-        info!(\"Server got message '{}'. \", msg);\n-\n         if let Message::Text(text) = msg.clone() {\n             let json = &text[..text.len() - 1]; // Remove last char\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "8d1b72b9512b90775e671b7ba08cd552a0aabd13",
            "timestamp": "2019-12-06T22:46:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Collapsed log messages from 3 lines per request to 2 and hidden the ones valued as less informative.\nUse LOG_LEVEL debug or trace to recover them.\n\nRemoved LOG_MOUNTS and bundled it with LOG_LEVEL debug and trace.\n\nRemoved duplicate error messages\n\nMade websocket not proxied message more prominent, but only print it once.",
            "additions": 15,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -1,20 +1,31 @@\n+use std::sync::atomic::{AtomicBool, Ordering};\n+\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value as JsonValue;\n \n-use crate::api::JsonResult;\n+use crate::api::{EmptyResult, JsonResult};\n use crate::auth::Headers;\n use crate::db::DbConn;\n \n-use crate::CONFIG;\n+use crate::{Error, CONFIG};\n \n pub fn routes() -> Vec<Route> {\n     routes![negotiate, websockets_err]\n }\n \n+static SHOW_WEBSOCKETS_MSG: AtomicBool = AtomicBool::new(true);\n+\n #[get(\"/hub\")]\n-fn websockets_err() -> JsonResult {\n-    err!(\"'/notifications/hub' should be proxied to the websocket server or notifications won't work. Go to the README for more info.\")\n+fn websockets_err() -> EmptyResult {\n+    if CONFIG.websocket_enabled() && SHOW_WEBSOCKETS_MSG.compare_and_swap(true, false, Ordering::Relaxed) {\n+        err!(\"###########################################################\n+    '/notifications/hub' should be proxied to the websocket server or notifications won't work.\n+    Go to the Wiki for more info, or disable WebSockets setting WEBSOCKET_ENABLED=false.\n+    ###########################################################################################\")\n+    } else {\n+        Err(Error::empty())\n+    }\n }\n \n #[post(\"/hub/negotiate\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "8c229920ad6bdccbb81110d88ccc139a09d65784",
            "timestamp": "2020-01-04T23:52:38+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Protect websocket server against panics",
            "additions": 48,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -54,10 +54,11 @@ fn negotiate(_headers: Headers, _conn: DbConn) -> JsonResult {\n //\n // Websockets server\n //\n+use std::io;\n use std::sync::Arc;\n use std::thread;\n \n-use ws::{self, util::Token, Factory, Handler, Handshake, Message, Sender, WebSocket};\n+use ws::{self, util::Token, Factory, Handler, Handshake, Message, Sender};\n \n use chashmap::CHashMap;\n use chrono::NaiveDateTime;\n@@ -135,20 +136,51 @@ struct InitialMessage {\n const PING_MS: u64 = 15_000;\n const PING: Token = Token(1);\n \n+const ID_KEY: &str = \"id=\";\n+const ACCESS_TOKEN_KEY: &str = \"access_token=\";\n+\n+impl WSHandler {\n+    fn err(&self, msg: &'static str) -> ws::Result<()> {\n+        self.out.close(ws::CloseCode::Invalid)?;\n+\n+        // We need to specifically return an IO error so ws closes the connection\n+        let io_error = io::Error::from(io::ErrorKind::InvalidData);\n+        Err(ws::Error::new(ws::ErrorKind::Io(io_error), msg))\n+    }\n+}\n+\n impl Handler for WSHandler {\n     fn on_open(&mut self, hs: Handshake) -> ws::Result<()> {\n-        // TODO: Improve this split\n+        // Path == \"/notifications/hub?id=<id>==&access_token=<access_token>\"\n         let path = hs.request.resource();\n-        let mut query_split: Vec<_> = path.split('?').nth(1).unwrap().split('&').collect();\n-        query_split.sort();\n-        let access_token = &query_split[0][13..];\n-        let _id = &query_split[1][3..];\n+\n+        let (_id, access_token) = match path.split('?').nth(1) {\n+            Some(params) => {\n+                let mut params_iter = params.split('&').take(2);\n+\n+                let mut id = None;\n+                let mut access_token = None;\n+                while let Some(val) = params_iter.next() {\n+                    if val.starts_with(ID_KEY) {\n+                        id = Some(&val[ID_KEY.len()..]);\n+                    } else if val.starts_with(ACCESS_TOKEN_KEY) {\n+                        access_token = Some(&val[ACCESS_TOKEN_KEY.len()..]);\n+                    }\n+                }\n+\n+                match (id, access_token) {\n+                    (Some(a), Some(b)) => (a, b),\n+                    _ => return self.err(\"Missing id or access token\"),\n+                }\n+            }\n+            None => return self.err(\"Missing query path\"),\n+        };\n \n         // Validate the user\n         use crate::auth;\n         let claims = match auth::decode_login(access_token) {\n             Ok(claims) => claims,\n-            Err(_) => return Err(ws::Error::new(ws::ErrorKind::Internal, \"Invalid access token provided\")),\n+            Err(_) => return self.err(\"Invalid access token provided\"),\n         };\n \n         // Assign the user to the handler\n@@ -190,10 +222,7 @@ impl Handler for WSHandler {\n             // reschedule the timeout\n             self.out.timeout(PING_MS, PING)\n         } else {\n-            Err(ws::Error::new(\n-                ws::ErrorKind::Internal,\n-                \"Invalid timeout token provided\",\n-            ))\n+            Ok(())\n         }\n     }\n }\n@@ -362,7 +391,14 @@ pub fn start_notification_server() -> WebSocketUsers {\n \n     if CONFIG.websocket_enabled() {\n         thread::spawn(move || {\n-            WebSocket::new(factory)\n+            let mut settings = ws::Settings::default();\n+            settings.max_connections = 500;\n+            settings.queue_size = 2;\n+            settings.panic_on_internal = false;\n+\n+            ws::Builder::new()\n+                .with_settings(settings)\n+                .build(factory)\n                 .unwrap()\n                 .listen((CONFIG.websocket_address().as_str(), CONFIG.websocket_port()))\n                 .unwrap();\n",
            "comment_added_diff": [
                [
                    146,
                    "        // We need to specifically return an IO error so ws closes the connection"
                ],
                [
                    154,
                    "        // Path == \"/notifications/hub?id=<id>==&access_token=<access_token>\""
                ]
            ]
        },
        {
            "commit": "862d4010770766285f63924d74a1e919707ce6be",
            "timestamp": "2020-03-26T19:26:44-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix WebSocket notifications\n\nIgnore a missing `id` query param; it's unclear what this ID represents,\nbut it wasn't being used in the existing bitwarden_rs code, and no longer\nseems to be sent in the latest versions of the official clients.",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -152,6 +152,9 @@ impl WSHandler {\n impl Handler for WSHandler {\n     fn on_open(&mut self, hs: Handshake) -> ws::Result<()> {\n         // Path == \"/notifications/hub?id=<id>==&access_token=<access_token>\"\n+        //\n+        // We don't use `id`, and as of around 2020-03-25, the official clients\n+        // no longer seem to pass `id` (only `access_token`).\n         let path = hs.request.resource();\n \n         let (_id, access_token) = match path.split('?').nth(1) {\n@@ -170,10 +173,11 @@ impl Handler for WSHandler {\n \n                 match (id, access_token) {\n                     (Some(a), Some(b)) => (a, b),\n-                    _ => return self.err(\"Missing id or access token\"),\n+                    (None, Some(b)) => (\"\", b), // Ignore missing `id`.\n+                    _ => return self.err(\"Missing access token\"),\n                 }\n             }\n-            None => return self.err(\"Missing query path\"),\n+            None => return self.err(\"Missing query parameters\"),\n         };\n \n         // Validate the user\n",
            "comment_added_diff": [
                [
                    155,
                    "        //"
                ],
                [
                    156,
                    "        // We don't use `id`, and as of around 2020-03-25, the official clients"
                ],
                [
                    157,
                    "        // no longer seem to pass `id` (only `access_token`)."
                ],
                [
                    176,
                    "                    (None, Some(b)) => (\"\", b), // Ignore missing `id`."
                ]
            ]
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 6,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -159,11 +159,12 @@ impl Handler for WSHandler {\n \n         let (_id, access_token) = match path.split('?').nth(1) {\n             Some(params) => {\n-                let mut params_iter = params.split('&').take(2);\n+                let params_iter = params.split('&').take(2);\n \n                 let mut id = None;\n                 let mut access_token = None;\n-                while let Some(val) = params_iter.next() {\n+                \n+                for val in params_iter {\n                     if val.starts_with(ID_KEY) {\n                         id = Some(&val[ID_KEY.len()..]);\n                     } else if val.starts_with(ACCESS_TOKEN_KEY) {\n@@ -260,7 +261,9 @@ impl Factory for WSFactory {\n         // Remove handler\n         if let Some(user_uuid) = &handler.user_uuid {\n             if let Some(mut user_conn) = self.users.map.get_mut(user_uuid) {\n-                user_conn.remove_item(&handler.out);\n+                if let Some(pos) = user_conn.iter().position(|x| x == &handler.out) {\n+                    user_conn.remove(pos);\n+                }\n             }\n         }\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 7,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -4,11 +4,12 @@ use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value as JsonValue;\n \n-use crate::api::{EmptyResult, JsonResult};\n-use crate::auth::Headers;\n-use crate::db::DbConn;\n-\n-use crate::{Error, CONFIG};\n+use crate::{\n+    api::{EmptyResult, JsonResult},\n+    auth::Headers,\n+    db::DbConn,\n+    Error, CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n     routes![negotiate, websockets_err]\n@@ -163,7 +164,7 @@ impl Handler for WSHandler {\n \n                 let mut id = None;\n                 let mut access_token = None;\n-                \n+\n                 for val in params_iter {\n                     if val.starts_with(ID_KEY) {\n                         id = Some(&val[ID_KEY.len()..]);\n",
            "comment_added_diff": []
        },
        {
            "commit": "c59cfe33717c19caef913d35181bf3108b7b93f3",
            "timestamp": "2020-08-31T19:05:07+02:00",
            "author": "aaxdev",
            "commit_message": "Fix MsgPack headers and support mobile SignalR",
            "additions": 43,
            "deletions": 29,
            "change_type": "MODIFY",
            "diff": "@@ -20,10 +20,12 @@ static SHOW_WEBSOCKETS_MSG: AtomicBool = AtomicBool::new(true);\n #[get(\"/hub\")]\n fn websockets_err() -> EmptyResult {\n     if CONFIG.websocket_enabled() && SHOW_WEBSOCKETS_MSG.compare_and_swap(true, false, Ordering::Relaxed) {\n-        err!(\"###########################################################\n+        err!(\n+            \"###########################################################\n     '/notifications/hub' should be proxied to the websocket server or notifications won't work.\n     Go to the Wiki for more info, or disable WebSockets setting WEBSOCKET_ENABLED=false.\n-    ###########################################################################################\")\n+    ###########################################################################################\"\n+        )\n     } else {\n         Err(Error::empty())\n     }\n@@ -148,6 +150,39 @@ impl WSHandler {\n         let io_error = io::Error::from(io::ErrorKind::InvalidData);\n         Err(ws::Error::new(ws::ErrorKind::Io(io_error), msg))\n     }\n+\n+    fn get_request_token(&self, hs: Handshake, token: &mut String) {\n+        let path = hs.request.resource();\n+\n+        match hs.request.header(\"Authorization\") {\n+            Some(header_value) => match std::str::from_utf8(header_value) {\n+                Ok(converted) => match converted.split(\"Bearer \").nth(1) {\n+                    Some(token_part) => token.push_str(token_part),\n+                    _ => (),\n+                },\n+                _ => (),\n+            },\n+            _ => (),\n+        };\n+\n+        match token.is_empty() {\n+            true => {\n+                match path.split('?').nth(1) {\n+                    Some(params) => {\n+                        let params_iter = params.split('&').take(2);\n+                        for val in params_iter {\n+                            if val.starts_with(ACCESS_TOKEN_KEY) {\n+                                token.push_str(&val[ACCESS_TOKEN_KEY.len()..]);\n+                                break;\n+                            }\n+                        }\n+                    }\n+                    _ => (),\n+                };\n+            }\n+            false => (),\n+        }\n+    }\n }\n \n impl Handler for WSHandler {\n@@ -156,35 +191,14 @@ impl Handler for WSHandler {\n         //\n         // We don't use `id`, and as of around 2020-03-25, the official clients\n         // no longer seem to pass `id` (only `access_token`).\n-        let path = hs.request.resource();\n-\n-        let (_id, access_token) = match path.split('?').nth(1) {\n-            Some(params) => {\n-                let params_iter = params.split('&').take(2);\n-\n-                let mut id = None;\n-                let mut access_token = None;\n \n-                for val in params_iter {\n-                    if val.starts_with(ID_KEY) {\n-                        id = Some(&val[ID_KEY.len()..]);\n-                    } else if val.starts_with(ACCESS_TOKEN_KEY) {\n-                        access_token = Some(&val[ACCESS_TOKEN_KEY.len()..]);\n-                    }\n-                }\n-\n-                match (id, access_token) {\n-                    (Some(a), Some(b)) => (a, b),\n-                    (None, Some(b)) => (\"\", b), // Ignore missing `id`.\n-                    _ => return self.err(\"Missing access token\"),\n-                }\n-            }\n-            None => return self.err(\"Missing query parameters\"),\n-        };\n+        // Get user token from header or query parameter\n+        let mut access_token = \"\".into();\n+        self.get_request_token(hs, &mut access_token);\n \n         // Validate the user\n         use crate::auth;\n-        let claims = match auth::decode_login(access_token) {\n+        let claims = match auth::decode_login(&mut access_token.as_str()) {\n             Ok(claims) => claims,\n             Err(_) => return self.err(\"Invalid access token provided\"),\n         };\n@@ -335,7 +349,7 @@ impl WebSocketUsers {\n /* Message Structure\n [\n     1, // MessageType.Invocation\n-    {}, // Headers\n+    {}, // Headers (map)\n     null, // InvocationId\n     \"ReceiveMessage\", // Target\n     [ // Arguments\n@@ -352,7 +366,7 @@ fn create_update(payload: Vec<(Value, Value)>, ut: UpdateType) -> Vec<u8> {\n \n     let value = V::Array(vec![\n         1.into(),\n-        V::Array(vec![]),\n+        V::Map(vec![]),\n         V::Nil,\n         \"ReceiveMessage\".into(),\n         V::Array(vec![V::Map(vec![\n",
            "comment_added_diff": [
                [
                    195,
                    "        // Get user token from header or query parameter"
                ],
                [
                    352,
                    "    {}, // Headers (map)"
                ]
            ]
        },
        {
            "commit": "260ffee093b8c7bea084a338ec8abb4544d0086d",
            "timestamp": "2020-08-31T22:20:21+02:00",
            "author": "aaxdev",
            "commit_message": "Improving code",
            "additions": 27,
            "deletions": 33,
            "change_type": "MODIFY",
            "diff": "@@ -21,7 +21,7 @@ static SHOW_WEBSOCKETS_MSG: AtomicBool = AtomicBool::new(true);\n fn websockets_err() -> EmptyResult {\n     if CONFIG.websocket_enabled() && SHOW_WEBSOCKETS_MSG.compare_and_swap(true, false, Ordering::Relaxed) {\n         err!(\n-            \"###########################################################\n+    \"###########################################################\n     '/notifications/hub' should be proxied to the websocket server or notifications won't work.\n     Go to the Wiki for more info, or disable WebSockets setting WEBSOCKET_ENABLED=false.\n     ###########################################################################################\"\n@@ -139,7 +139,6 @@ struct InitialMessage {\n const PING_MS: u64 = 15_000;\n const PING: Token = Token(1);\n \n-const ID_KEY: &str = \"id=\";\n const ACCESS_TOKEN_KEY: &str = \"access_token=\";\n \n impl WSHandler {\n@@ -151,37 +150,30 @@ impl WSHandler {\n         Err(ws::Error::new(ws::ErrorKind::Io(io_error), msg))\n     }\n \n-    fn get_request_token(&self, hs: Handshake, token: &mut String) {\n-        let path = hs.request.resource();\n+    fn get_request_token(&self, hs: Handshake) -> Option<String> {\n+        use std::str::from_utf8;\n \n-        match hs.request.header(\"Authorization\") {\n-            Some(header_value) => match std::str::from_utf8(header_value) {\n-                Ok(converted) => match converted.split(\"Bearer \").nth(1) {\n-                    Some(token_part) => token.push_str(token_part),\n-                    _ => (),\n-                },\n-                _ => (),\n-            },\n-            _ => (),\n+        // Verify we have a token header\n+        if let Some(header_value) = hs.request.header(\"Authorization\") {\n+            if let Ok(converted) = from_utf8(header_value) {\n+                if let Some(token_part) = converted.split(\"Bearer \").nth(1) {\n+                    return Some(token_part.into());\n+                }\n+            }\n         };\n-\n-        match token.is_empty() {\n-            true => {\n-                match path.split('?').nth(1) {\n-                    Some(params) => {\n-                        let params_iter = params.split('&').take(2);\n-                        for val in params_iter {\n-                            if val.starts_with(ACCESS_TOKEN_KEY) {\n-                                token.push_str(&val[ACCESS_TOKEN_KEY.len()..]);\n-                                break;\n-                            }\n-                        }\n-                    }\n-                    _ => (),\n-                };\n+        \n+        // Otherwise verify the query parameter value\n+        let path = hs.request.resource();\n+        if let Some(params) = path.split('?').nth(1) {\n+            let params_iter = params.split('&').take(1);\n+            for val in params_iter {\n+                if val.starts_with(ACCESS_TOKEN_KEY) {\n+                    return Some(val[ACCESS_TOKEN_KEY.len()..].into());\n+                }\n             }\n-            false => (),\n-        }\n+        };\n+\n+        None\n     }\n }\n \n@@ -193,12 +185,14 @@ impl Handler for WSHandler {\n         // no longer seem to pass `id` (only `access_token`).\n \n         // Get user token from header or query parameter\n-        let mut access_token = \"\".into();\n-        self.get_request_token(hs, &mut access_token);\n+        let access_token = match self.get_request_token(hs) {\n+            Some(token) => token,\n+            _ => return self.err(\"Missing access token\"),\n+        };\n \n         // Validate the user\n         use crate::auth;\n-        let claims = match auth::decode_login(&mut access_token.as_str()) {\n+        let claims = match auth::decode_login(access_token.as_str()) {\n             Ok(claims) => claims,\n             Err(_) => return self.err(\"Invalid access token provided\"),\n         };\n",
            "comment_added_diff": [
                [
                    156,
                    "        // Verify we have a token header"
                ],
                [
                    165,
                    "        // Otherwise verify the query parameter value"
                ]
            ]
        },
        {
            "commit": "58606796246110b8d49deb69e7d2ec352041bd94",
            "timestamp": "2021-01-31T20:07:42+01:00",
            "author": "BlackDex",
            "commit_message": "Updated dependencies and small mail fixes\n\n- Updated rust nightly\n- Updated depenencies\n- Removed unicode support for regex (less dependencies)\n- Fixed dependency and nightly changes/deprications\n- Some mail changes for less spam point triggering",
            "additions": 5,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -19,13 +19,12 @@ static SHOW_WEBSOCKETS_MSG: AtomicBool = AtomicBool::new(true);\n \n #[get(\"/hub\")]\n fn websockets_err() -> EmptyResult {\n-    if CONFIG.websocket_enabled() && SHOW_WEBSOCKETS_MSG.compare_and_swap(true, false, Ordering::Relaxed) {\n-        err!(\n-    \"###########################################################\n+    if CONFIG.websocket_enabled() && SHOW_WEBSOCKETS_MSG.compare_exchange(true, false, Ordering::Relaxed, Ordering::Relaxed).is_ok() {\n+        err!(\"\n+    ###########################################################\n     '/notifications/hub' should be proxied to the websocket server or notifications won't work.\n     Go to the Wiki for more info, or disable WebSockets setting WEBSOCKET_ENABLED=false.\n-    ###########################################################################################\"\n-        )\n+    ###########################################################################################\\n\")\n     } else {\n         Err(Error::empty())\n     }\n@@ -161,7 +160,7 @@ impl WSHandler {\n                 }\n             }\n         };\n-        \n+\n         // Otherwise verify the query parameter value\n         let path = hs.request.resource();\n         if let Some(params) = path.split('?').nth(1) {\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -394,6 +394,10 @@ pub enum UpdateType {\n \n     LogOut = 11,\n \n+    SyncSendCreate = 12,\n+    SyncSendUpdate = 13,\n+    SyncSendDelete = 14,\n+\n     None = 100,\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "a8138be69b0c051da9f97827a9f5427c98dd3051",
            "timestamp": "2021-03-27T14:03:31+00:00",
            "author": "Jake Howard",
            "commit_message": "Use `if let` more",
            "additions": 8,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -166,8 +166,8 @@ impl WSHandler {\n         if let Some(params) = path.split('?').nth(1) {\n             let params_iter = params.split('&').take(1);\n             for val in params_iter {\n-                if val.starts_with(ACCESS_TOKEN_KEY) {\n-                    return Some(val[ACCESS_TOKEN_KEY.len()..].into());\n+                if let Some(stripped) = val.strip_prefix(ACCESS_TOKEN_KEY) {\n+                    return Some(stripped.into());\n                 }\n             }\n         };\n@@ -410,10 +410,12 @@ pub fn start_notification_server() -> WebSocketUsers {\n \n     if CONFIG.websocket_enabled() {\n         thread::spawn(move || {\n-            let mut settings = ws::Settings::default();\n-            settings.max_connections = 500;\n-            settings.queue_size = 2;\n-            settings.panic_on_internal = false;\n+            let settings = ws::Settings {\n+                max_connections: 500,\n+                queue_size: 2,\n+                panic_on_internal: false,\n+                ..Default::default()\n+            };\n \n             ws::Builder::new()\n                 .with_settings(settings)\n",
            "comment_added_diff": []
        },
        {
            "commit": "49af9cf4f5f8264384c7fa9063299f44e7536068",
            "timestamp": "2021-03-27T14:26:32+00:00",
            "author": "Jake Howard",
            "commit_message": "Correctly camelCase acronyms\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#upper_case_acronyms",
            "additions": 10,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -120,7 +120,7 @@ fn convert_option<T: Into<Value>>(option: Option<T>) -> Value {\n }\n \n // Server WebSocket handler\n-pub struct WSHandler {\n+pub struct WsHandler {\n     out: Sender,\n     user_uuid: Option<String>,\n     users: WebSocketUsers,\n@@ -140,7 +140,7 @@ const PING: Token = Token(1);\n \n const ACCESS_TOKEN_KEY: &str = \"access_token=\";\n \n-impl WSHandler {\n+impl WsHandler {\n     fn err(&self, msg: &'static str) -> ws::Result<()> {\n         self.out.close(ws::CloseCode::Invalid)?;\n \n@@ -176,7 +176,7 @@ impl WSHandler {\n     }\n }\n \n-impl Handler for WSHandler {\n+impl Handler for WsHandler {\n     fn on_open(&mut self, hs: Handshake) -> ws::Result<()> {\n         // Path == \"/notifications/hub?id=<id>==&access_token=<access_token>\"\n         //\n@@ -240,13 +240,13 @@ impl Handler for WSHandler {\n     }\n }\n \n-struct WSFactory {\n+struct WsFactory {\n     pub users: WebSocketUsers,\n }\n \n-impl WSFactory {\n+impl WsFactory {\n     pub fn init() -> Self {\n-        WSFactory {\n+        WsFactory {\n             users: WebSocketUsers {\n                 map: Arc::new(CHashMap::new()),\n             },\n@@ -254,11 +254,11 @@ impl WSFactory {\n     }\n }\n \n-impl Factory for WSFactory {\n-    type Handler = WSHandler;\n+impl Factory for WsFactory {\n+    type Handler = WsHandler;\n \n     fn connection_made(&mut self, out: Sender) -> Self::Handler {\n-        WSHandler {\n+        WsHandler {\n             out,\n             user_uuid: None,\n             users: self.users.clone(),\n@@ -405,7 +405,7 @@ use rocket::State;\n pub type Notify<'a> = State<'a, WebSocketUsers>;\n \n pub fn start_notification_server() -> WebSocketUsers {\n-    let factory = WSFactory::init();\n+    let factory = WsFactory::init();\n     let users = factory.users.clone();\n \n     if CONFIG.websocket_enabled() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ use rocket_contrib::json::Json;\n use serde_json::Value as JsonValue;\n \n use crate::{\n-    api::{EmptyResult, JsonResult},\n+    api::EmptyResult,\n     auth::Headers,\n     db::DbConn,\n     Error, CONFIG,\n@@ -31,7 +31,7 @@ fn websockets_err() -> EmptyResult {\n }\n \n #[post(\"/hub/negotiate\")]\n-fn negotiate(_headers: Headers, _conn: DbConn) -> JsonResult {\n+fn negotiate(_headers: Headers, _conn: DbConn) -> Json<JsonValue> {\n     use crate::crypto;\n     use data_encoding::BASE64URL;\n \n@@ -47,10 +47,10 @@ fn negotiate(_headers: Headers, _conn: DbConn) -> JsonResult {\n     // Rocket SSE support: https://github.com/SergioBenitez/Rocket/issues/33\n     // {\"transport\":\"ServerSentEvents\", \"transferFormats\":[\"Text\"]},\n     // {\"transport\":\"LongPolling\", \"transferFormats\":[\"Text\",\"Binary\"]}\n-    Ok(Json(json!({\n+    Json(json!({\n         \"connectionId\": conn_id,\n         \"availableTransports\": available_transports\n-    })))\n+    }))\n }\n \n //\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 10,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -4,12 +4,7 @@ use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value as JsonValue;\n \n-use crate::{\n-    api::EmptyResult,\n-    auth::Headers,\n-    db::DbConn,\n-    Error, CONFIG,\n-};\n+use crate::{api::EmptyResult, auth::Headers, db::DbConn, Error, CONFIG};\n \n pub fn routes() -> Vec<Route> {\n     routes![negotiate, websockets_err]\n@@ -19,12 +14,18 @@ static SHOW_WEBSOCKETS_MSG: AtomicBool = AtomicBool::new(true);\n \n #[get(\"/hub\")]\n fn websockets_err() -> EmptyResult {\n-    if CONFIG.websocket_enabled() && SHOW_WEBSOCKETS_MSG.compare_exchange(true, false, Ordering::Relaxed, Ordering::Relaxed).is_ok() {\n-        err!(\"\n+    if CONFIG.websocket_enabled()\n+        && SHOW_WEBSOCKETS_MSG\n+            .compare_exchange(true, false, Ordering::Relaxed, Ordering::Relaxed)\n+            .is_ok()\n+    {\n+        err!(\n+            \"\n     ###########################################################\n     '/notifications/hub' should be proxied to the websocket server or notifications won't work.\n     Go to the Wiki for more info, or disable WebSockets setting WEBSOCKET_ENABLED=false.\n-    ###########################################################################################\\n\")\n+    ###########################################################################################\\n\"\n+        )\n     } else {\n         Err(Error::empty())\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 8,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -15,9 +15,7 @@ static SHOW_WEBSOCKETS_MSG: AtomicBool = AtomicBool::new(true);\n #[get(\"/hub\")]\n fn websockets_err() -> EmptyResult {\n     if CONFIG.websocket_enabled()\n-        && SHOW_WEBSOCKETS_MSG\n-            .compare_exchange(true, false, Ordering::Relaxed, Ordering::Relaxed)\n-            .is_ok()\n+        && SHOW_WEBSOCKETS_MSG.compare_exchange(true, false, Ordering::Relaxed, Ordering::Relaxed).is_ok()\n     {\n         err!(\n             \"\n@@ -205,9 +203,7 @@ impl Handler for WsHandler {\n         let handler_insert = self.out.clone();\n         let handler_update = self.out.clone();\n \n-        self.users\n-            .map\n-            .upsert(user_uuid, || vec![handler_insert], |ref mut v| v.push(handler_update));\n+        self.users.map.upsert(user_uuid, || vec![handler_insert], |ref mut v| v.push(handler_update));\n \n         // Schedule a ping to keep the connection alive\n         self.out.timeout(PING_MS, PING)\n@@ -217,7 +213,11 @@ impl Handler for WsHandler {\n         if let Message::Text(text) = msg.clone() {\n             let json = &text[..text.len() - 1]; // Remove last char\n \n-            if let Ok(InitialMessage { protocol, version }) = from_str::<InitialMessage>(json) {\n+            if let Ok(InitialMessage {\n+                protocol,\n+                version,\n+            }) = from_str::<InitialMessage>(json)\n+            {\n                 if &protocol == \"messagepack\" && version == 1 {\n                     return self.out.send(&INITIAL_RESPONSE[..]); // Respond to initial message\n                 }\n@@ -296,10 +296,7 @@ impl WebSocketUsers {\n     // NOTE: The last modified date needs to be updated before calling these methods\n     pub fn send_user_update(&self, ut: UpdateType, user: &User) {\n         let data = create_update(\n-            vec![\n-                (\"UserId\".into(), user.uuid.clone().into()),\n-                (\"Date\".into(), serialize_date(user.updated_at)),\n-            ],\n+            vec![(\"UserId\".into(), user.uuid.clone().into()), (\"Date\".into(), serialize_date(user.updated_at))],\n             ut,\n         );\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -332,7 +332,7 @@ impl WebSocketUsers {\n         );\n \n         for uuid in user_uuids {\n-            self.send_update(&uuid, &data).ok();\n+            self.send_update(uuid, &data).ok();\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "ffdcafa0446aa110e27266a920b4497490cddb6f",
            "timestamp": "2021-07-25T14:49:55+02:00",
            "author": "BlackDex",
            "commit_message": "Fix WebAuthn issues and some small updates\n\n- Updated some packages\n- Updated code related to package updates.\n- Disabled User Verification enforcement when WebAuthn Key sends UV=1\n  This makes it compatible with upstream and resolves #1840\n- Fixed a bug where removing an individual WebAuthn key deleted the wrong key.",
            "additions": 4,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -408,12 +408,10 @@ pub fn start_notification_server() -> WebSocketUsers {\n \n     if CONFIG.websocket_enabled() {\n         thread::spawn(move || {\n-            let settings = ws::Settings {\n-                max_connections: 500,\n-                queue_size: 2,\n-                panic_on_internal: false,\n-                ..Default::default()\n-            };\n+            let mut settings = ws::Settings::default();\n+            settings.max_connections = 500;\n+            settings.queue_size = 2;\n+            settings.panic_on_internal = false;\n \n             ws::Builder::new()\n                 .with_settings(settings)\n",
            "comment_added_diff": []
        },
        {
            "commit": "dd98fe860b33f8e34c161f49e3f6b07908d1dc3e",
            "timestamp": "2021-08-03T17:39:38+02:00",
            "author": "Fabian Thies",
            "commit_message": "Send create, update and delete notifications for `Send`s in the correct format.\nAdd endpoints to get all sends or a specific send by its uuid.",
            "additions": 18,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -65,7 +65,7 @@ use chashmap::CHashMap;\n use chrono::NaiveDateTime;\n use serde_json::from_str;\n \n-use crate::db::models::{Cipher, Folder, User};\n+use crate::db::models::{Cipher, Folder, User, Send};\n \n use rmpv::Value;\n \n@@ -335,6 +335,23 @@ impl WebSocketUsers {\n             self.send_update(uuid, &data).ok();\n         }\n     }\n+\n+    pub fn send_send_update(&self, ut: UpdateType, send: &Send, user_uuids: &[String]) {\n+        let user_uuid = convert_option(send.user_uuid.clone());\n+\n+        let data = create_update(\n+            vec![\n+                (\"Id\".into(), send.uuid.clone().into()),\n+                (\"UserId\".into(), user_uuid),\n+                (\"RevisionDate\".into(), serialize_date(send.revision_date)),\n+            ],\n+            ut,\n+        );\n+\n+        for uuid in user_uuids {\n+            self.send_update(uuid, &data).ok();\n+        }\n+    }\n }\n \n /* Message Structure\n",
            "comment_added_diff": []
        },
        {
            "commit": "1f0f64d961cd8839bcd5be6336f68d44b40aaa21",
            "timestamp": "2021-08-04T16:56:43+02:00",
            "author": "Fabian Thies",
            "commit_message": "Sort the imports in notifications.rs alphabetically",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -65,7 +65,7 @@ use chashmap::CHashMap;\n use chrono::NaiveDateTime;\n use serde_json::from_str;\n \n-use crate::db::models::{Cipher, Folder, User, Send};\n+use crate::db::models::{Cipher, Folder, Send, User};\n \n use rmpv::Value;\n \n",
            "comment_added_diff": []
        }
    ],
    "Dockerfile": [],
    "Dockerfile.alpine": [],
    "rust-toolchain": [],
    "main.rs": [
        {
            "commit": "fccc0a4b05323bed8d9dd1a1b2ceee85c4aa5593",
            "timestamp": "2019-10-25T21:48:10+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update rocket to latest master\nDowngrade rust version to fix cargo issue\nSet rustup profile to minimal",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,4 @@\n-#![feature(proc_macro_hygiene, decl_macro, vec_remove_item, try_trait, ip)]\n+#![feature(proc_macro_hygiene, vec_remove_item, try_trait, ip)]\n #![recursion_limit = \"256\"]\n \n #[cfg(feature = \"openssl\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0ff7fd939e9afe2197bb53eb37bce7d2b62f0b7f",
            "timestamp": "2019-11-06T20:21:47+01:00",
            "author": "BlackDex",
            "commit_message": "Next attempt for issue #709 fix\n\nNow creates icon cache directory at startup.\nAnd it also creates the directory if it went missing during runtime.\nAlso modified the icon_save/mark_negcache to be one.",
            "additions": 9,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -25,6 +25,7 @@ extern crate num_derive;\n use std::{\n     path::Path,\n     process::{exit, Command},\n+    fs::create_dir_all,\n };\n \n #[macro_use]\n@@ -52,6 +53,8 @@ fn main() {\n     check_web_vault();\n     migrations::run_migrations();\n \n+    create_icon_cache_folder();\n+\n     launch_rocket();\n }\n \n@@ -129,8 +132,7 @@ fn check_db() {\n         let path = Path::new(&url);\n \n         if let Some(parent) = path.parent() {\n-            use std::fs;\n-            if fs::create_dir_all(parent).is_err() {\n+            if create_dir_all(parent).is_err() {\n                 error!(\"Error creating database directory\");\n                 exit(1);\n             }\n@@ -148,6 +150,11 @@ fn check_db() {\n     db::get_connection().expect(\"Can't connect to DB\");\n }\n \n+fn create_icon_cache_folder() {\n+    // Try to create the icon cache folder, and generate an error if it could not.\n+    create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache directory\");\n+}\n+\n fn check_rsa_keys() {\n     // If the RSA keys don't exist, try to create them\n     if !util::file_exists(&CONFIG.private_rsa_key()) || !util::file_exists(&CONFIG.public_rsa_key()) {\n",
            "comment_added_diff": [
                [
                    154,
                    "    // Try to create the icon cache folder, and generate an error if it could not."
                ]
            ]
        },
        {
            "commit": "8d1b72b9512b90775e671b7ba08cd552a0aabd13",
            "timestamp": "2019-12-06T22:46:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Collapsed log messages from 3 lines per request to 2 and hidden the ones valued as less informative.\nUse LOG_LEVEL debug or trace to recover them.\n\nRemoved LOG_MOUNTS and bundled it with LOG_LEVEL debug and trace.\n\nRemoved duplicate error messages\n\nMade websocket not proxied message more prominent, but only print it once.",
            "additions": 37,
            "deletions": 30,
            "change_type": "MODIFY",
            "diff": "@@ -23,9 +23,10 @@ extern crate derive_more;\n extern crate num_derive;\n \n use std::{\n+    fs::create_dir_all,\n     path::Path,\n     process::{exit, Command},\n-    fs::create_dir_all,\n+    str::FromStr,\n };\n \n #[macro_use]\n@@ -44,9 +45,14 @@ pub use error::{Error, MapResult};\n fn main() {\n     launch_info();\n \n-    if CONFIG.extended_logging() {\n-        init_logging().ok();\n-    }\n+    use log::LevelFilter as LF;\n+    let level = LF::from_str(&CONFIG.log_level()).expect(\"Valid log level\");\n+    init_logging(level).ok();\n+\n+    let extra_debug = match level {\n+        LF::Trace | LF::Debug => true,\n+        _ => false,\n+    };\n \n     check_db();\n     check_rsa_keys();\n@@ -55,7 +61,7 @@ fn main() {\n \n     create_icon_cache_folder();\n \n-    launch_rocket();\n+    launch_rocket(extra_debug);\n }\n \n fn launch_info() {\n@@ -73,10 +79,23 @@ fn launch_info() {\n     println!(\"\\\\--------------------------------------------------------------------/\\n\");\n }\n \n-fn init_logging() -> Result<(), fern::InitError> {\n-    use std::str::FromStr;\n+fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n     let mut logger = fern::Dispatch::new()\n-        .format(|out, message, record| {\n+        .level(level)\n+        // Hide unknown certificate errors if using self-signed\n+        .level_for(\"rustls::session\", log::LevelFilter::Off)\n+        // Hide failed to close stream messages\n+        .level_for(\"hyper::server\", log::LevelFilter::Warn)\n+        // Silence rocket logs\n+        .level_for(\"_\", log::LevelFilter::Off)\n+        .level_for(\"launch\", log::LevelFilter::Off)\n+        .level_for(\"launch_\", log::LevelFilter::Off)\n+        .level_for(\"rocket::rocket\", log::LevelFilter::Off)\n+        .level_for(\"rocket::fairing\", log::LevelFilter::Off)\n+        .chain(std::io::stdout());\n+\n+    if CONFIG.extended_logging() {\n+        logger = logger.format(|out, message, record| {\n             out.finish(format_args!(\n                 \"{}[{}][{}] {}\",\n                 chrono::Local::now().format(\"[%Y-%m-%d %H:%M:%S]\"),\n@@ -84,13 +103,10 @@ fn init_logging() -> Result<(), fern::InitError> {\n                 record.level(),\n                 message\n             ))\n-        })\n-        .level(log::LevelFilter::from_str(&CONFIG.log_level()).expect(\"Valid log level\"))\n-        // Hide unknown certificate errors if using self-signed\n-        .level_for(\"rustls::session\", log::LevelFilter::Off)\n-        // Hide failed to close stream messages\n-        .level_for(\"hyper::server\", log::LevelFilter::Warn)\n-        .chain(std::io::stdout());\n+        });\n+    } else {\n+        logger = logger.format(|out, message, _| out.finish(format_args!(\"{}\", message)));\n+    }\n \n     if let Some(log_file) = CONFIG.log_file() {\n         logger = logger.chain(fern::log_file(log_file)?);\n@@ -236,33 +252,24 @@ mod migrations {\n     }\n }\n \n-fn launch_rocket() {\n+fn launch_rocket(extra_debug: bool) {\n     // Create Rocket object, this stores current log level and sets it's own\n     let rocket = rocket::ignite();\n \n-    // If we aren't logging the mounts, we force the logging level down\n-    if !CONFIG.log_mounts() {\n-        log::set_max_level(log::LevelFilter::Warn);\n-    }\n-\n+    // If addding more base paths here, consider also adding them to\n+    // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n     let rocket = rocket\n         .mount(\"/\", api::web_routes())\n         .mount(\"/api\", api::core_routes())\n         .mount(\"/admin\", api::admin_routes())\n         .mount(\"/identity\", api::identity_routes())\n         .mount(\"/icons\", api::icons_routes())\n-        .mount(\"/notifications\", api::notifications_routes());\n-\n-    // Force the level up for the fairings, managed state and lauch\n-    if !CONFIG.log_mounts() {\n-        log::set_max_level(log::LevelFilter::max());\n-    }\n-\n-    let rocket = rocket\n+        .mount(\"/notifications\", api::notifications_routes())\n         .manage(db::init_pool())\n         .manage(api::start_notification_server())\n         .attach(util::AppHeaders())\n-        .attach(util::CORS());\n+        .attach(util::CORS())\n+        .attach(util::BetterLogging(extra_debug));\n \n     // Launch and print error if there is one\n     // The launch will restore the original logging level\n",
            "comment_added_diff": [
                [
                    85,
                    "        // Hide unknown certificate errors if using self-signed"
                ],
                [
                    87,
                    "        // Hide failed to close stream messages"
                ],
                [
                    89,
                    "        // Silence rocket logs"
                ],
                [
                    259,
                    "    // If addding more base paths here, consider also adding them to"
                ],
                [
                    260,
                    "    // crate::utils::LOGGED_ROUTES to make sure they appear in the log"
                ]
            ]
        },
        {
            "commit": "36ae946655ac0e885268bd7502738412508d9ce2",
            "timestamp": "2019-12-29T15:34:22+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Avoid some to_string in the request logging and include message to disable web vault when not found.",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -225,7 +225,9 @@ fn check_web_vault() {\n     let index_path = Path::new(&CONFIG.web_vault_folder()).join(\"index.html\");\n \n     if !index_path.exists() {\n-        error!(\"Web vault is not found. To install it, please follow the steps in https://github.com/dani-garcia/bitwarden_rs/wiki/Building-binary#install-the-web-vault\");\n+        error!(\"Web vault is not found. To install it, please follow the steps in: \");\n+        error!(\"https://github.com/dani-garcia/bitwarden_rs/wiki/Building-binary#install-the-web-vault\");\n+        error!(\"You can also set the environment variable 'WEB_VAULT_ENABLED=false' to disable it\");\n         exit(1);\n     }\n }\n",
            "comment_added_diff": [
                [
                    229,
                    "        error!(\"https://github.com/dani-garcia/bitwarden_rs/wiki/Building-binary#install-the-web-vault\");"
                ]
            ]
        },
        {
            "commit": "d592323e390db4007711c8b7bcdbeec2a8ed2271",
            "timestamp": "2020-01-04T14:37:29-08:00",
            "author": "Richard Huang",
            "commit_message": "minor typo conect -> connect",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -157,7 +157,7 @@ fn check_db() {\n         // Turn on WAL in SQLite\n         if CONFIG.enable_db_wal() {\n             use diesel::RunQueryDsl;\n-            let connection = db::get_connection().expect(\"Can't conect to DB\");\n+            let connection = db::get_connection().expect(\"Can't connect to DB\");\n             diesel::sql_query(\"PRAGMA journal_mode=wal\")\n                 .execute(&connection)\n                 .expect(\"Failed to turn on WAL\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 10,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -255,18 +255,20 @@ mod migrations {\n }\n \n fn launch_rocket(extra_debug: bool) {\n-    // Create Rocket object, this stores current log level and sets it's own\n+    // Create Rocket object, this stores current log level and sets its own\n     let rocket = rocket::ignite();\n \n-    // If addding more base paths here, consider also adding them to\n+    let basepath = &CONFIG.domain_path();\n+\n+    // If adding more paths here, consider also adding them to\n     // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n     let rocket = rocket\n-        .mount(\"/\", api::web_routes())\n-        .mount(\"/api\", api::core_routes())\n-        .mount(\"/admin\", api::admin_routes())\n-        .mount(\"/identity\", api::identity_routes())\n-        .mount(\"/icons\", api::icons_routes())\n-        .mount(\"/notifications\", api::notifications_routes())\n+        .mount(&[basepath, \"/\"].concat(), api::web_routes())\n+        .mount(&[basepath, \"/api\"].concat(), api::core_routes())\n+        .mount(&[basepath, \"/admin\"].concat(), api::admin_routes())\n+        .mount(&[basepath, \"/identity\"].concat(), api::identity_routes())\n+        .mount(&[basepath, \"/icons\"].concat(), api::icons_routes())\n+        .mount(&[basepath, \"/notifications\"].concat(), api::notifications_routes())\n         .manage(db::init_pool())\n         .manage(api::start_notification_server())\n         .attach(util::AppHeaders())\n",
            "comment_added_diff": [
                [
                    258,
                    "    // Create Rocket object, this stores current log level and sets its own"
                ],
                [
                    263,
                    "    // If adding more paths here, consider also adding them to"
                ]
            ]
        },
        {
            "commit": "7439aeb63ef692510c121a0e9f090d58de8d87e2",
            "timestamp": "2020-02-25T14:10:52+01:00",
            "author": "BlackDex",
            "commit_message": "Make panics logable (as warn)\n\npanic!()'s only appear on stderr, this makes tracking down some strange\nissues harder with the usage of docker since stderr does not get logged\ninto the bitwarden.log file. This change logs the message to stdout and\nthe logfile when activated.",
            "additions": 6,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -27,6 +27,7 @@ use std::{\n     path::Path,\n     process::{exit, Command},\n     str::FromStr,\n+    panic,\n };\n \n #[macro_use]\n@@ -121,6 +122,11 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n \n     logger.apply()?;\n \n+    // Catch panics and log them instead of default output to StdErr\n+    panic::set_hook(Box::new(|info| {\n+        warn!(\"[PANIC] {}\", info);\n+    }));\n+\n     Ok(())\n }\n \n",
            "comment_added_diff": [
                [
                    125,
                    "    // Catch panics and log them instead of default output to StdErr"
                ]
            ]
        },
        {
            "commit": "cc404b4edc392fc141c941da10e411d8e98a817e",
            "timestamp": "2020-03-02T15:51:57-05:00",
            "author": "zethra",
            "commit_message": "Added command line flags for help and version\n\nSigned-off-by: zethra <benaagoldberg@gmail.com>",
            "additions": 26,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -42,7 +42,18 @@ mod util;\n pub use config::CONFIG;\n pub use error::{Error, MapResult};\n \n+use structopt::StructOpt;\n+\n+#[derive(Debug, StructOpt)]\n+#[structopt(name = \"bitwarden_rs\", about = \"A Bitwarden API server written in Rust\")]\n+struct Opt {\n+    /// Prints the app version\n+    #[structopt(short, long)]\n+    version: bool,\n+}\n+\n fn main() {\n+    parse_args();\n     launch_info();\n \n     use log::LevelFilter as LF;\n@@ -64,6 +75,18 @@ fn main() {\n     launch_rocket(extra_debug);\n }\n \n+fn parse_args() {\n+    let opt = Opt::from_args();\n+    if opt.version {\n+        if let Some(version) = option_env!(\"GIT_VERSION\") {\n+            println!(\"bitwarden_rs {}\", version);\n+        } else {\n+            println!(\"bitwarden_rs (Version info from Git not present)\");\n+        }\n+        exit(0);\n+    }\n+}\n+\n fn launch_info() {\n     println!(\"/--------------------------------------------------------------------\\\\\");\n     println!(\"|                       Starting Bitwarden_RS                        |\");\n@@ -177,7 +200,9 @@ fn check_rsa_keys() {\n         info!(\"JWT keys don't exist, checking if OpenSSL is available...\");\n \n         Command::new(\"openssl\").arg(\"version\").status().unwrap_or_else(|_| {\n-            info!(\"Can't create keys because OpenSSL is not available, make sure it's installed and available on the PATH\");\n+            info!(\n+                \"Can't create keys because OpenSSL is not available, make sure it's installed and available on the PATH\"\n+            );\n             exit(1);\n         });\n \n",
            "comment_added_diff": [
                [
                    50,
                    "    /// Prints the app version"
                ]
            ]
        },
        {
            "commit": "70f3ab8ec3d6ccfd8ec8c71c888459de484d9b43",
            "timestamp": "2020-03-09T22:04:03+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Migrate lazy_static to once_cell, less macro magic and slightly faster",
            "additions": 0,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -16,8 +16,6 @@ extern crate diesel;\n #[macro_use]\n extern crate diesel_migrations;\n #[macro_use]\n-extern crate lazy_static;\n-#[macro_use]\n extern crate derive_more;\n #[macro_use]\n extern crate num_derive;\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd09fe1a3d9b7f31644fb5fb9f9c38a30c893dac",
            "timestamp": "2020-03-16T17:53:22+01:00",
            "author": "BlackDex",
            "commit_message": "Updated code so backtraces are logged also.",
            "additions": 47,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -20,12 +20,14 @@ extern crate derive_more;\n #[macro_use]\n extern crate num_derive;\n \n+extern crate backtrace;\n+\n use std::{\n     fs::create_dir_all,\n     path::Path,\n     process::{exit, Command},\n     str::FromStr,\n-    panic,\n+    panic, thread, fmt // For panic logging\n };\n \n #[macro_use]\n@@ -43,6 +45,16 @@ pub use error::{Error, MapResult};\n \n use structopt::StructOpt;\n \n+// Used for catching panics and log them to file instead of stderr\n+use backtrace::Backtrace;\n+struct Shim(Backtrace);\n+\n+impl fmt::Debug for Shim {\n+    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n+        write!(fmt, \"\\n{:?}\", self.0)\n+    }\n+}\n+\n #[derive(Debug, StructOpt)]\n #[structopt(name = \"bitwarden_rs\", about = \"A Bitwarden API server written in Rust\")]\n struct Opt {\n@@ -145,7 +157,40 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n \n     // Catch panics and log them instead of default output to StdErr\n     panic::set_hook(Box::new(|info| {\n-        warn!(\"[PANIC] {}\", info);\n+        let backtrace = Backtrace::new();\n+\n+        let thread = thread::current();\n+        let thread = thread.name().unwrap_or(\"unnamed\");\n+\n+        let msg = match info.payload().downcast_ref::<&'static str>() {\n+            Some(s) => *s,\n+            None => match info.payload().downcast_ref::<String>() {\n+                Some(s) => &**s,\n+                None => \"Box<Any>\",\n+            },\n+        };\n+\n+        match info.location() {\n+            Some(location) => {\n+                error!(\n+                    target: \"panic\", \"thread '{}' panicked at '{}': {}:{}{:?}\",\n+                    thread,\n+                    msg,\n+                    location.file(),\n+                    location.line(),\n+                    Shim(backtrace)\n+                );\n+            }\n+            None => {\n+                error!(\n+                    target: \"panic\",\n+                    \"thread '{}' panicked at '{}'{:?}\",\n+                    thread,\n+                    msg,\n+                    Shim(backtrace)\n+                )\n+            }\n+        }\n     }));\n \n     Ok(())\n",
            "comment_added_diff": [
                [
                    30,
                    "    panic, thread, fmt // For panic logging"
                ],
                [
                    48,
                    "// Used for catching panics and log them to file instead of stderr"
                ]
            ]
        },
        {
            "commit": "ba725e1c256464620def3146cf3167b37292de0d",
            "timestamp": "2020-03-16T22:39:10+01:00",
            "author": "Ymage",
            "commit_message": "Make openssl crate as default (non feature-flipped)",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,6 @@\n #![feature(proc_macro_hygiene, vec_remove_item, try_trait, ip)]\n #![recursion_limit = \"256\"]\n \n-#[cfg(feature = \"openssl\")]\n extern crate openssl;\n #[macro_use]\n extern crate rocket;\n",
            "comment_added_diff": []
        },
        {
            "commit": "35f30088b2fd4f97c39b4af6c4aadecaecffe5a4",
            "timestamp": "2020-03-18T18:11:11+01:00",
            "author": "BlackDex",
            "commit_message": "Fixing issue #759 by disabling Foreign Key Checks.\n\nDuring migrations some queries are out of order regarding to foreign\nkeys.\nBecause of this the migrations fail when the sql database has this\nenforced by default.\nTurning of this check during the migrations will fix this and this is\nonly per session.",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -323,6 +323,16 @@ mod migrations {\n         let connection = crate::db::get_connection().expect(\"Can't connect to DB\");\n \n         use std::io::stdout;\n+\n+        // Disable Foreign Key Checks during migration\n+        use diesel::RunQueryDsl;\n+        #[cfg(feature = \"postgres\")]\n+        diesel::sql_query(\"SET CONSTRAINTS ALL DEFERRED\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n+        #[cfg(feature = \"mysql\")]\n+        diesel::sql_query(\"SET FOREIGN_KEY_CHECKS = 0\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n+        #[cfg(feature = \"sqlite\")]\n+        diesel::sql_query(\"PRAGMA defer_foreign_keys = ON\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n+\n         embedded_migrations::run_with_output(&connection, &mut stdout()).expect(\"Can't run migrations\");\n     }\n }\n",
            "comment_added_diff": [
                [
                    327,
                    "        // Disable Foreign Key Checks during migration"
                ]
            ]
        },
        {
            "commit": "7a6a3e4160d2a472febd2122248f21ae7dfb0c90",
            "timestamp": "2020-03-22T16:13:34+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Set the cargo version and allow changing it during build time with BWRS_VERSION.\nAlso renamed GIT_VERSION because that's not the only source anymore.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -88,7 +88,7 @@ fn main() {\n fn parse_args() {\n     let opt = Opt::from_args();\n     if opt.version {\n-        if let Some(version) = option_env!(\"GIT_VERSION\") {\n+        if let Some(version) = option_env!(\"BWRS_VERSION\") {\n             println!(\"bitwarden_rs {}\", version);\n         } else {\n             println!(\"bitwarden_rs (Version info from Git not present)\");\n@@ -101,7 +101,7 @@ fn launch_info() {\n     println!(\"/--------------------------------------------------------------------\\\\\");\n     println!(\"|                       Starting Bitwarden_RS                        |\");\n \n-    if let Some(version) = option_env!(\"GIT_VERSION\") {\n+    if let Some(version) = option_env!(\"BWRS_VERSION\") {\n         println!(\"|{:^68}|\", format!(\"Version {}\", version));\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 2,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,7 @@\n-#![feature(proc_macro_hygiene, vec_remove_item, try_trait, ip)]\n+#![forbid(unsafe_code)]\n+#![feature(proc_macro_hygiene, try_trait, ip)]\n #![recursion_limit = \"256\"]\n \n-extern crate openssl;\n #[macro_use]\n extern crate rocket;\n #[macro_use]\n@@ -14,12 +14,6 @@ extern crate log;\n extern crate diesel;\n #[macro_use]\n extern crate diesel_migrations;\n-#[macro_use]\n-extern crate derive_more;\n-#[macro_use]\n-extern crate num_derive;\n-\n-extern crate backtrace;\n \n use std::{\n     fs::create_dir_all,\n",
            "comment_added_diff": []
        },
        {
            "commit": "322a08edfb3f6dc2958025ddbe33f5d71463c133",
            "timestamp": "2020-05-13T12:29:47-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Update startup banner to direct usage/config questions to the forum",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -102,7 +102,10 @@ fn launch_info() {\n     println!(\"|--------------------------------------------------------------------|\");\n     println!(\"| This is an *unofficial* Bitwarden implementation, DO NOT use the   |\");\n     println!(\"| official channels to report bugs/features, regardless of client.   |\");\n-    println!(\"| Report URL: https://github.com/dani-garcia/bitwarden_rs/issues/new |\");\n+    println!(\"| Send usage/configuration questions or feature requests to:         |\");\n+    println!(\"|   https://bitwardenrs.discourse.group/                             |\");\n+    println!(\"| Report suspected bugs/issues in the software itself at:            |\");\n+    println!(\"|   https://github.com/dani-garcia/bitwarden_rs/issues/new           |\");\n     println!(\"\\\\--------------------------------------------------------------------/\\n\");\n }\n \n",
            "comment_added_diff": [
                [
                    106,
                    "    println!(\"|   https://bitwardenrs.discourse.group/                             |\");"
                ],
                [
                    108,
                    "    println!(\"|   https://github.com/dani-garcia/bitwarden_rs/issues/new           |\");"
                ]
            ]
        },
        {
            "commit": "afbf1db331d99ab1bbc9413e1e3e167be3e69728",
            "timestamp": "2020-06-04T01:21:30+02:00",
            "author": "Robert Kaussow",
            "commit_message": "add back openssl crate",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -2,6 +2,7 @@\n #![feature(proc_macro_hygiene, try_trait, ip)]\n #![recursion_limit = \"256\"]\n \n+extern crate openssl;\n #[macro_use]\n extern crate rocket;\n #[macro_use]\n",
            "comment_added_diff": []
        },
        {
            "commit": "a87646b8cb3260d7abf407e137aa3825296fab6c",
            "timestamp": "2020-06-15T23:40:39+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Some format changes to main.rs",
            "additions": 14,
            "deletions": 16,
            "change_type": "MODIFY",
            "diff": "@@ -17,11 +17,13 @@ extern crate diesel;\n extern crate diesel_migrations;\n \n use std::{\n+    fmt, // For panic logging\n     fs::create_dir_all,\n+    panic,\n     path::Path,\n     process::{exit, Command},\n     str::FromStr,\n-    panic, thread, fmt // For panic logging\n+    thread,\n };\n \n #[macro_use]\n@@ -178,15 +180,13 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n                     Shim(backtrace)\n                 );\n             }\n-            None => {\n-                error!(\n-                    target: \"panic\",\n-                    \"thread '{}' panicked at '{}'{:?}\",\n-                    thread,\n-                    msg,\n-                    Shim(backtrace)\n-                )\n-            }\n+            None => error!(\n+                target: \"panic\",\n+                \"thread '{}' panicked at '{}'{:?}\",\n+                thread,\n+                msg,\n+                Shim(backtrace)\n+            ),\n         }\n     }));\n \n@@ -336,14 +336,11 @@ mod migrations {\n }\n \n fn launch_rocket(extra_debug: bool) {\n-    // Create Rocket object, this stores current log level and sets its own\n-    let rocket = rocket::ignite();\n-\n     let basepath = &CONFIG.domain_path();\n \n     // If adding more paths here, consider also adding them to\n     // crate::utils::LOGGED_ROUTES to make sure they appear in the log\n-    let rocket = rocket\n+    let result = rocket::ignite()\n         .mount(&[basepath, \"/\"].concat(), api::web_routes())\n         .mount(&[basepath, \"/api\"].concat(), api::core_routes())\n         .mount(&[basepath, \"/admin\"].concat(), api::admin_routes())\n@@ -354,9 +351,10 @@ fn launch_rocket(extra_debug: bool) {\n         .manage(api::start_notification_server())\n         .attach(util::AppHeaders())\n         .attach(util::CORS())\n-        .attach(util::BetterLogging(extra_debug));\n+        .attach(util::BetterLogging(extra_debug))\n+        .launch();\n \n     // Launch and print error if there is one\n     // The launch will restore the original logging level\n-    error!(\"Launch error {:#?}\", rocket.launch());\n+    error!(\"Launch error {:#?}\", result);\n }\n",
            "comment_added_diff": [
                [
                    20,
                    "    fmt, // For panic logging"
                ]
            ]
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,5 @@\n #![forbid(unsafe_code)]\n-#![feature(proc_macro_hygiene, try_trait, ip)]\n+#![feature(proc_macro_hygiene, ip)]\n #![recursion_limit = \"256\"]\n \n extern crate openssl;\n",
            "comment_added_diff": []
        },
        {
            "commit": "1e950c7dbc8bfaca0df4fd2d97d12e8b7d1fbc55",
            "timestamp": "2020-07-15T00:00:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Replace IP support in preparation for compiling on stable, included some tests to check that the code matches the unstable implementation",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,5 @@\n #![forbid(unsafe_code)]\n-#![feature(proc_macro_hygiene, ip)]\n+#![cfg_attr(feature = \"unstable\", feature(ip))]\n #![recursion_limit = \"256\"]\n \n extern crate openssl;\n",
            "comment_added_diff": []
        },
        {
            "commit": "d348f12a0e7f9a6e4d1193324a0d6446fa943d00",
            "timestamp": "2020-07-22T21:50:49-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add config option for log timestamp format",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -130,8 +130,8 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n     if CONFIG.extended_logging() {\n         logger = logger.format(|out, message, record| {\n             out.finish(format_args!(\n-                \"{}[{}][{}] {}\",\n-                chrono::Local::now().format(\"[%Y-%m-%d %H:%M:%S]\"),\n+                \"[{}][{}][{}] {}\",\n+                chrono::Local::now().format(&CONFIG.log_timestamp_format()),\n                 record.target(),\n                 record.level(),\n                 message\n",
            "comment_added_diff": []
        },
        {
            "commit": "93b7ded1e6d34c42e756fdc80a629f76db5f0c47",
            "timestamp": "2020-08-12T18:45:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unneccessary shim for backtrace",
            "additions": 8,
            "deletions": 19,
            "change_type": "MODIFY",
            "diff": "@@ -17,7 +17,6 @@ extern crate diesel;\n extern crate diesel_migrations;\n \n use std::{\n-    fmt, // For panic logging\n     fs::create_dir_all,\n     panic,\n     path::Path,\n@@ -26,6 +25,8 @@ use std::{\n     thread,\n };\n \n+use structopt::StructOpt;\n+\n #[macro_use]\n mod error;\n mod api;\n@@ -39,18 +40,6 @@ mod util;\n pub use config::CONFIG;\n pub use error::{Error, MapResult};\n \n-use structopt::StructOpt;\n-\n-// Used for catching panics and log them to file instead of stderr\n-use backtrace::Backtrace;\n-struct Shim(Backtrace);\n-\n-impl fmt::Debug for Shim {\n-    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n-        write!(fmt, \"\\n{:?}\", self.0)\n-    }\n-}\n-\n #[derive(Debug, StructOpt)]\n #[structopt(name = \"bitwarden_rs\", about = \"A Bitwarden API server written in Rust\")]\n struct Opt {\n@@ -156,8 +145,6 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n \n     // Catch panics and log them instead of default output to StdErr\n     panic::set_hook(Box::new(|info| {\n-        let backtrace = Backtrace::new();\n-\n         let thread = thread::current();\n         let thread = thread.name().unwrap_or(\"unnamed\");\n \n@@ -169,23 +156,25 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n             },\n         };\n \n+        let backtrace = backtrace::Backtrace::new();\n+\n         match info.location() {\n             Some(location) => {\n                 error!(\n-                    target: \"panic\", \"thread '{}' panicked at '{}': {}:{}{:?}\",\n+                    target: \"panic\", \"thread '{}' panicked at '{}': {}:{}\\n{:?}\",\n                     thread,\n                     msg,\n                     location.file(),\n                     location.line(),\n-                    Shim(backtrace)\n+                    backtrace\n                 );\n             }\n             None => error!(\n                 target: \"panic\",\n-                \"thread '{}' panicked at '{}'{:?}\",\n+                \"thread '{}' panicked at '{}'\\n{:?}\",\n                 thread,\n                 msg,\n-                Shim(backtrace)\n+                backtrace\n             ),\n         }\n     }));\n",
            "comment_added_diff": []
        },
        {
            "commit": "f83a8a36d16eb14c4d2f68f7edf7989bbf7973cb",
            "timestamp": "2020-08-19T02:32:58-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Track favorites on a per-user basis\n\nCurrently, favorites are tracked at the cipher level. For org-owned ciphers,\nthis means that if one user sets it as a favorite, it automatically becomes a\nfavorite for all other users that the cipher has been shared with.",
            "additions": 12,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -313,12 +313,23 @@ mod migrations {\n \n         // Disable Foreign Key Checks during migration\n         use diesel::RunQueryDsl;\n+\n+        // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,\n+        // \"SET CONSTRAINTS sets the behavior of constraint checking within the\n+        // current transaction\", so this setting probably won't take effect for\n+        // any of the migrations since it's being run outside of a transaction.\n+        // Migrations that need to disable foreign key checks should run this\n+        // from within the migration script itself.\n         #[cfg(feature = \"postgres\")]\n         diesel::sql_query(\"SET CONSTRAINTS ALL DEFERRED\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n+\n+        // Scoped to a connection/session.\n         #[cfg(feature = \"mysql\")]\n         diesel::sql_query(\"SET FOREIGN_KEY_CHECKS = 0\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n+\n+        // Scoped to a connection.\n         #[cfg(feature = \"sqlite\")]\n-        diesel::sql_query(\"PRAGMA defer_foreign_keys = ON\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n+        diesel::sql_query(\"PRAGMA foreign_keys = OFF\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n \n         embedded_migrations::run_with_output(&connection, &mut stdout()).expect(\"Can't run migrations\");\n     }\n",
            "comment_added_diff": [
                [
                    317,
                    "        // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,"
                ],
                [
                    318,
                    "        // \"SET CONSTRAINTS sets the behavior of constraint checking within the"
                ],
                [
                    319,
                    "        // current transaction\", so this setting probably won't take effect for"
                ],
                [
                    320,
                    "        // any of the migrations since it's being run outside of a transaction."
                ],
                [
                    321,
                    "        // Migrations that need to disable foreign key checks should run this"
                ],
                [
                    322,
                    "        // from within the migration script itself."
                ],
                [
                    326,
                    "        // Scoped to a connection/session."
                ],
                [
                    330,
                    "        // Scoped to a connection."
                ]
            ]
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 11,
            "deletions": 71,
            "change_type": "MODIFY",
            "diff": "@@ -33,6 +33,7 @@ mod api;\n mod auth;\n mod config;\n mod crypto;\n+#[macro_use]\n mod db;\n mod mail;\n mod util;\n@@ -61,10 +62,8 @@ fn main() {\n         _ => false,\n     };\n \n-    check_db();\n     check_rsa_keys();\n     check_web_vault();\n-    migrations::run_migrations();\n \n     create_icon_cache_folder();\n \n@@ -200,30 +199,6 @@ fn chain_syslog(logger: fern::Dispatch) -> fern::Dispatch {\n     }\n }\n \n-fn check_db() {\n-    if cfg!(feature = \"sqlite\") {\n-        let url = CONFIG.database_url();\n-        let path = Path::new(&url);\n-\n-        if let Some(parent) = path.parent() {\n-            if create_dir_all(parent).is_err() {\n-                error!(\"Error creating database directory\");\n-                exit(1);\n-            }\n-        }\n-\n-        // Turn on WAL in SQLite\n-        if CONFIG.enable_db_wal() {\n-            use diesel::RunQueryDsl;\n-            let connection = db::get_connection().expect(\"Can't connect to DB\");\n-            diesel::sql_query(\"PRAGMA journal_mode=wal\")\n-                .execute(&connection)\n-                .expect(\"Failed to turn on WAL\");\n-        }\n-    }\n-    db::get_connection().expect(\"Can't connect to DB\");\n-}\n-\n fn create_icon_cache_folder() {\n     // Try to create the icon cache folder, and generate an error if it could not.\n     create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache directory\");\n@@ -285,57 +260,22 @@ fn check_web_vault() {\n     let index_path = Path::new(&CONFIG.web_vault_folder()).join(\"index.html\");\n \n     if !index_path.exists() {\n-        error!(\"Web vault is not found. To install it, please follow the steps in: \");\n+        error!(\"Web vault is not found at '{}'. To install it, please follow the steps in: \", CONFIG.web_vault_folder());\n         error!(\"https://github.com/dani-garcia/bitwarden_rs/wiki/Building-binary#install-the-web-vault\");\n         error!(\"You can also set the environment variable 'WEB_VAULT_ENABLED=false' to disable it\");\n         exit(1);\n     }\n }\n \n-// Embed the migrations from the migrations folder into the application\n-// This way, the program automatically migrates the database to the latest version\n-// https://docs.rs/diesel_migrations/*/diesel_migrations/macro.embed_migrations.html\n-#[allow(unused_imports)]\n-mod migrations {\n-\n-    #[cfg(feature = \"sqlite\")]\n-    embed_migrations!(\"migrations/sqlite\");\n-    #[cfg(feature = \"mysql\")]\n-    embed_migrations!(\"migrations/mysql\");\n-    #[cfg(feature = \"postgresql\")]\n-    embed_migrations!(\"migrations/postgresql\");\n-\n-    pub fn run_migrations() {\n-        // Make sure the database is up to date (create if it doesn't exist, or run the migrations)\n-        let connection = crate::db::get_connection().expect(\"Can't connect to DB\");\n-\n-        use std::io::stdout;\n-\n-        // Disable Foreign Key Checks during migration\n-        use diesel::RunQueryDsl;\n-\n-        // FIXME: Per https://www.postgresql.org/docs/12/sql-set-constraints.html,\n-        // \"SET CONSTRAINTS sets the behavior of constraint checking within the\n-        // current transaction\", so this setting probably won't take effect for\n-        // any of the migrations since it's being run outside of a transaction.\n-        // Migrations that need to disable foreign key checks should run this\n-        // from within the migration script itself.\n-        #[cfg(feature = \"postgres\")]\n-        diesel::sql_query(\"SET CONSTRAINTS ALL DEFERRED\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n-\n-        // Scoped to a connection/session.\n-        #[cfg(feature = \"mysql\")]\n-        diesel::sql_query(\"SET FOREIGN_KEY_CHECKS = 0\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n-\n-        // Scoped to a connection.\n-        #[cfg(feature = \"sqlite\")]\n-        diesel::sql_query(\"PRAGMA foreign_keys = OFF\").execute(&connection).expect(\"Failed to disable Foreign Key Checks during migrations\");\n-\n-        embedded_migrations::run_with_output(&connection, &mut stdout()).expect(\"Can't run migrations\");\n-    }\n-}\n-\n fn launch_rocket(extra_debug: bool) {\n+    let pool = match db::DbPool::from_config() {\n+        Ok(p) => p,\n+        Err(e) => {\n+            error!(\"Error creating database pool: {:?}\", e);\n+            exit(1);\n+        }\n+    };\n+\n     let basepath = &CONFIG.domain_path();\n \n     // If adding more paths here, consider also adding them to\n@@ -347,7 +287,7 @@ fn launch_rocket(extra_debug: bool) {\n         .mount(&[basepath, \"/identity\"].concat(), api::identity_routes())\n         .mount(&[basepath, \"/icons\"].concat(), api::icons_routes())\n         .mount(&[basepath, \"/notifications\"].concat(), api::notifications_routes())\n-        .manage(db::init_pool())\n+        .manage(pool)\n         .manage(api::start_notification_server())\n         .attach(util::AppHeaders())\n         .attach(util::CORS())\n",
            "comment_added_diff": []
        },
        {
            "commit": "729c9cff41cc74055f8397fae7f60084dcf4b71b",
            "timestamp": "2020-10-03T22:32:00+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Retry initial db connection, with adjustable option",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -268,7 +268,7 @@ fn check_web_vault() {\n }\n \n fn launch_rocket(extra_debug: bool) {\n-    let pool = match db::DbPool::from_config() {\n+    let pool = match util::retry_db(db::DbPool::from_config, CONFIG.db_connection_retries()) {\n         Ok(p) => p,\n         Err(e) => {\n             error!(\"Error creating database pool: {:?}\", e);\n",
            "comment_added_diff": []
        },
        {
            "commit": "6faaeaae6649ddfa9a1b4b424a27e6792b1f90b3",
            "timestamp": "2020-11-18T12:07:08+01:00",
            "author": "BlackDex",
            "commit_message": "Updated email processing.\n\n- Added an option to enable smtp debugging via SMTP_DEBUG. This will\n  trigger a trace of the smtp commands sent/received to/from the mail\nserver. Useful when troubleshooting.\n- Added two options to ignore invalid certificates which either do not\n  match at all, or only doesn't match the hostname.\n- Updated lettre to the latest alpha.4 version.",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -115,6 +115,16 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n         .level_for(\"rocket::fairing\", log::LevelFilter::Off)\n         .chain(std::io::stdout());\n \n+    // Enable smtp debug logging only specifically for smtp when need.\n+    // This can contain sensitive information we do not want in the default debug/trace logging.\n+    if CONFIG.smtp_debug() {\n+        println!(\"[WARNING] SMTP Debugging is enabled (SMTP_DEBUG=true). Sensitive information could be disclosed via logs!\");\n+        println!(\"[WARNING] Only enable SMTP_DEBUG during troubleshooting!\\n\");\n+        logger = logger.level_for(\"lettre::transport::smtp\", log::LevelFilter::Debug)\n+    } else {\n+        logger = logger.level_for(\"lettre::transport::smtp\", log::LevelFilter::Off)\n+    }\n+\n     if CONFIG.extended_logging() {\n         logger = logger.format(|out, message, record| {\n             out.finish(format_args!(\n",
            "comment_added_diff": [
                [
                    118,
                    "    // Enable smtp debug logging only specifically for smtp when need."
                ],
                [
                    119,
                    "    // This can contain sensitive information we do not want in the default debug/trace logging."
                ]
            ]
        },
        {
            "commit": "48baf723a422f0a4964807b12b002a589799d6ee",
            "timestamp": "2020-12-08T17:34:18+01:00",
            "author": "BlackDex",
            "commit_message": "Updated icon downloading\n\n- Added more checks to prevent panics (Removed unwrap)\n- Try do download from base domain or add www when the provided domain\n  fails\n- Added some more domain validation checks to prevent errors\n- Added the ICON_BLACKLIST_REGEX to a Lazy Static HashMap which\n  speeds-up the checks!\n- Validate the Regex before starting/config change.\n- Some cleanups\n- Disabled some noisy debugging from 2 crates.",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -113,6 +113,9 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n         .level_for(\"launch_\", log::LevelFilter::Off)\n         .level_for(\"rocket::rocket\", log::LevelFilter::Off)\n         .level_for(\"rocket::fairing\", log::LevelFilter::Off)\n+        // Never show html5ever and hyper::proto logs, too noisy\n+        .level_for(\"html5ever\", log::LevelFilter::Off)\n+        .level_for(\"hyper::proto\", log::LevelFilter::Off)\n         .chain(std::io::stdout());\n \n     // Enable smtp debug logging only specifically for smtp when need.\n",
            "comment_added_diff": [
                [
                    116,
                    "        // Never show html5ever and hyper::proto logs, too noisy"
                ]
            ]
        },
        {
            "commit": "235ff447367ec37adcef52921350271b3c5b9378",
            "timestamp": "2021-01-19T17:55:21+01:00",
            "author": "BlackDex",
            "commit_message": "Updated the admin interface\n\nMostly updated the admin interface, also some small other items.\n\n- Added more diagnostic information to (hopefully) decrease issue\n  reporting, or at least solve them quicker.\n- Added an option to generate a support string which can be used to\n  copy/paste on the forum or during the creation of an issue. It will\ntry to hide the sensitive information automatically.\n- Changed the `Created At` and `Last Active` info to be in a column and\n  able to sort them in the users overview.\n- Some small layout changes.\n- Updated javascript and css files to the latest versions available.\n- Decreased the png file sizes using `oxipng`\n- Updated target='_blank' links to have rel='noreferrer' to prevent\n  javascript window.opener modifications.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,6 @@\n #![forbid(unsafe_code)]\n #![cfg_attr(feature = \"unstable\", feature(ip))]\n-#![recursion_limit = \"256\"]\n+#![recursion_limit = \"512\"]\n \n extern crate openssl;\n #[macro_use]\n",
            "comment_added_diff": []
        },
        {
            "commit": "58606796246110b8d49deb69e7d2ec352041bd94",
            "timestamp": "2021-01-31T20:07:42+01:00",
            "author": "BlackDex",
            "commit_message": "Updated dependencies and small mail fixes\n\n- Updated rust nightly\n- Updated depenencies\n- Removed unicode support for regex (less dependencies)\n- Fixed dependency and nightly changes/deprications\n- Some mail changes for less spam point triggering",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -6,7 +6,7 @@ extern crate openssl;\n #[macro_use]\n extern crate rocket;\n #[macro_use]\n-extern crate serde_derive;\n+extern crate serde;\n #[macro_use]\n extern crate serde_json;\n #[macro_use]\n",
            "comment_added_diff": []
        },
        {
            "commit": "8b660ae090179248544c9dc713a5ae2d896aad37",
            "timestamp": "2021-02-07T20:10:40+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Swap structopt for a simpler alternative",
            "additions": 20,
            "deletions": 17,
            "change_type": "MODIFY",
            "diff": "@@ -25,8 +25,6 @@ use std::{\n     thread,\n };\n \n-use structopt::StructOpt;\n-\n #[macro_use]\n mod error;\n mod api;\n@@ -41,14 +39,6 @@ mod util;\n pub use config::CONFIG;\n pub use error::{Error, MapResult};\n \n-#[derive(Debug, StructOpt)]\n-#[structopt(name = \"bitwarden_rs\", about = \"A Bitwarden API server written in Rust\")]\n-struct Opt {\n-    /// Prints the app version\n-    #[structopt(short, long)]\n-    version: bool,\n-}\n-\n fn main() {\n     parse_args();\n     launch_info();\n@@ -70,14 +60,27 @@ fn main() {\n     launch_rocket(extra_debug);\n }\n \n+const HELP: &str = \"\\\n+        A Bitwarden API server written in Rust\n+        \n+        USAGE:\n+            bitwarden_rs\n+        \n+        FLAGS:\n+            -h, --help       Prints help information\n+            -v, --version    Prints the app version\n+\";\n+\n fn parse_args() {\n-    let opt = Opt::from_args();\n-    if opt.version {\n-        if let Some(version) = option_env!(\"BWRS_VERSION\") {\n-            println!(\"bitwarden_rs {}\", version);\n-        } else {\n-            println!(\"bitwarden_rs (Version info from Git not present)\");\n-        }\n+    const NO_VERSION: &str = \"(Version info from Git not present)\";\n+    let mut pargs = pico_args::Arguments::from_env();\n+\n+    if pargs.contains([\"-h\", \"--help\"]) {\n+        println!(\"bitwarden_rs {}\", option_env!(\"BWRS_VERSION\").unwrap_or(NO_VERSION));\n+        print!(\"{}\", HELP);\n+        exit(0);\n+    } else if pargs.contains([\"-v\", \"--version\"]) {\n+        println!(\"bitwarden_rs {}\", option_env!(\"BWRS_VERSION\").unwrap_or(NO_VERSION));\n         exit(0);\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "513056f7118da82c8011710b65c569080e1fc2ca",
            "timestamp": "2021-02-28T01:45:05-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Check for data folder on startup\n\nCurrently, when starting up for the first time (running standalone, outside\nof Docker), bitwarden_rs panics when the `openssl` tool isn't able to create\n`data/rsa_key.pem` due to the `data` dir not existing. Instead, print a more\nhelpful error message telling the user to create the directory.",
            "additions": 23,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -38,6 +38,7 @@ mod util;\n \n pub use config::CONFIG;\n pub use error::{Error, MapResult};\n+pub use util::is_running_in_docker;\n \n fn main() {\n     parse_args();\n@@ -52,6 +53,7 @@ fn main() {\n         _ => false,\n     };\n \n+    check_data_folder();\n     check_rsa_keys();\n     check_web_vault();\n \n@@ -215,9 +217,28 @@ fn chain_syslog(logger: fern::Dispatch) -> fern::Dispatch {\n     }\n }\n \n+fn create_dir(path: &str, description: &str) {\n+    // Try to create the specified dir, if it doesn't already exist.\n+    let err_msg = format!(\"Error creating {} directory '{}'\", description, path);\n+    create_dir_all(path).expect(&err_msg);\n+}\n+\n fn create_icon_cache_folder() {\n-    // Try to create the icon cache folder, and generate an error if it could not.\n-    create_dir_all(&CONFIG.icon_cache_folder()).expect(\"Error creating icon cache directory\");\n+    create_dir(&CONFIG.icon_cache_folder(), \"icon cache\");\n+}\n+\n+fn check_data_folder() {\n+    let data_folder = &CONFIG.data_folder();\n+    let path = Path::new(data_folder);\n+    if !path.exists() {\n+        error!(\"Data folder '{}' doesn't exist.\", data_folder);\n+        if is_running_in_docker() {\n+            error!(\"Verify that your data volume is mounted at the correct location.\");\n+        } else {\n+            error!(\"Create the data folder and try again.\");\n+        }\n+        exit(1);\n+    }\n }\n \n fn check_rsa_keys() {\n",
            "comment_added_diff": [
                [
                    221,
                    "    // Try to create the specified dir, if it doesn't already exist."
                ]
            ]
        },
        {
            "commit": "1fc6c30652b59a9dd7495393075df2a22246fa02",
            "timestamp": "2021-03-22T19:57:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send deletion thread and updated users revision",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -313,6 +313,8 @@ fn launch_rocket(extra_debug: bool) {\n         }\n     };\n \n+    api::start_send_deletion_scheduler(pool.clone());\n+\n     let basepath = &CONFIG.domain_path();\n \n     // If adding more paths here, consider also adding them to\n",
            "comment_added_diff": []
        },
        {
            "commit": "ea57dc3bc9253b8db8e0815bac344f2cf981894b",
            "timestamp": "2021-03-27T14:03:07+00:00",
            "author": "Jake Howard",
            "commit_message": "Use `matches` macro",
            "additions": 3,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -48,10 +48,7 @@ fn main() {\n     let level = LF::from_str(&CONFIG.log_level()).expect(\"Valid log level\");\n     init_logging(level).ok();\n \n-    let extra_debug = match level {\n-        LF::Trace | LF::Debug => true,\n-        _ => false,\n-    };\n+    let extra_debug = matches!(level, LF::Trace | LF::Debug);\n \n     check_data_folder();\n     check_rsa_keys();\n@@ -64,10 +61,10 @@ fn main() {\n \n const HELP: &str = \"\\\n         A Bitwarden API server written in Rust\n-        \n+\n         USAGE:\n             bitwarden_rs\n-        \n+\n         FLAGS:\n             -h, --help       Prints help information\n             -v, --version    Prints the app version\n",
            "comment_added_diff": []
        },
        {
            "commit": "49af9cf4f5f8264384c7fa9063299f44e7536068",
            "timestamp": "2021-03-27T14:26:32+00:00",
            "author": "Jake Howard",
            "commit_message": "Correctly camelCase acronyms\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#upper_case_acronyms",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -326,7 +326,7 @@ fn launch_rocket(extra_debug: bool) {\n         .manage(pool)\n         .manage(api::start_notification_server())\n         .attach(util::AppHeaders())\n-        .attach(util::CORS())\n+        .attach(util::Cors())\n         .attach(util::BetterLogging(extra_debug))\n         .launch();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 7,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -123,7 +123,9 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n     // Enable smtp debug logging only specifically for smtp when need.\n     // This can contain sensitive information we do not want in the default debug/trace logging.\n     if CONFIG.smtp_debug() {\n-        println!(\"[WARNING] SMTP Debugging is enabled (SMTP_DEBUG=true). Sensitive information could be disclosed via logs!\");\n+        println!(\n+            \"[WARNING] SMTP Debugging is enabled (SMTP_DEBUG=true). Sensitive information could be disclosed via logs!\"\n+        );\n         println!(\"[WARNING] Only enable SMTP_DEBUG during troubleshooting!\\n\");\n         logger = logger.level_for(\"lettre::transport::smtp\", log::LevelFilter::Debug)\n     } else {\n@@ -294,7 +296,10 @@ fn check_web_vault() {\n     let index_path = Path::new(&CONFIG.web_vault_folder()).join(\"index.html\");\n \n     if !index_path.exists() {\n-        error!(\"Web vault is not found at '{}'. To install it, please follow the steps in: \", CONFIG.web_vault_folder());\n+        error!(\n+            \"Web vault is not found at '{}'. To install it, please follow the steps in: \",\n+            CONFIG.web_vault_folder()\n+        );\n         error!(\"https://github.com/dani-garcia/bitwarden_rs/wiki/Building-binary#install-the-web-vault\");\n         error!(\"You can also set the environment variable 'WEB_VAULT_ENABLED=false' to disable it\");\n         exit(1);\n",
            "comment_added_diff": []
        },
        {
            "commit": "73ff8d79f70b36483d1d33587cdc9549c8e472bd",
            "timestamp": "2021-04-05T23:07:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add a generic job scheduler\n\nAlso rewrite deletion of old sends using the job scheduler.",
            "additions": 37,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -16,6 +16,7 @@ extern crate diesel;\n #[macro_use]\n extern crate diesel_migrations;\n \n+use job_scheduler::{JobScheduler, Job};\n use std::{\n     fs::create_dir_all,\n     panic,\n@@ -23,6 +24,7 @@ use std::{\n     process::{exit, Command},\n     str::FromStr,\n     thread,\n+    time::Duration,\n };\n \n #[macro_use]\n@@ -56,7 +58,9 @@ fn main() {\n \n     create_icon_cache_folder();\n \n-    launch_rocket(extra_debug);\n+    let pool = create_db_pool();\n+    schedule_jobs(pool.clone());\n+    launch_rocket(pool, extra_debug); // Blocks until program termination.\n }\n \n const HELP: &str = \"\\\n@@ -301,17 +305,17 @@ fn check_web_vault() {\n     }\n }\n \n-fn launch_rocket(extra_debug: bool) {\n-    let pool = match util::retry_db(db::DbPool::from_config, CONFIG.db_connection_retries()) {\n+fn create_db_pool() -> db::DbPool {\n+    match util::retry_db(db::DbPool::from_config, CONFIG.db_connection_retries()) {\n         Ok(p) => p,\n         Err(e) => {\n             error!(\"Error creating database pool: {:?}\", e);\n             exit(1);\n         }\n-    };\n-\n-    api::start_send_deletion_scheduler(pool.clone());\n+    }\n+}\n \n+fn launch_rocket(pool: db::DbPool, extra_debug: bool) {\n     let basepath = &CONFIG.domain_path();\n \n     // If adding more paths here, consider also adding them to\n@@ -334,3 +338,30 @@ fn launch_rocket(extra_debug: bool) {\n     // The launch will restore the original logging level\n     error!(\"Launch error {:#?}\", result);\n }\n+\n+fn schedule_jobs(pool: db::DbPool) {\n+    if CONFIG.job_poll_interval_ms() == 0 {\n+        info!(\"Job scheduler disabled.\");\n+        return;\n+    }\n+    thread::Builder::new().name(\"job-scheduler\".to_string()).spawn(move || {\n+        let mut sched = JobScheduler::new();\n+\n+        // Purge sends that are past their deletion date.\n+        if !CONFIG.send_purge_schedule().is_empty() {\n+            sched.add(Job::new(CONFIG.send_purge_schedule().parse().unwrap(), || {\n+                api::purge_sends(pool.clone());\n+            }));\n+        }\n+\n+        // Periodically check for jobs to run. We probably won't need any\n+        // jobs that run more often than once a minute, so a default poll\n+        // interval of 30 seconds should be sufficient. Users who want to\n+        // schedule jobs to run more frequently for some reason can reduce\n+        // the poll interval accordingly.\n+        loop {\n+            sched.tick();\n+            thread::sleep(Duration::from_millis(CONFIG.job_poll_interval_ms()));\n+        }\n+    }).expect(\"Error spawning job scheduler thread\");\n+}\n",
            "comment_added_diff": [
                [
                    63,
                    "    launch_rocket(pool, extra_debug); // Blocks until program termination."
                ],
                [
                    350,
                    "        // Purge sends that are past their deletion date."
                ],
                [
                    357,
                    "        // Periodically check for jobs to run. We probably won't need any"
                ],
                [
                    358,
                    "        // jobs that run more often than once a minute, so a default poll"
                ],
                [
                    359,
                    "        // interval of 30 seconds should be sufficient. Users who want to"
                ],
                [
                    360,
                    "        // schedule jobs to run more frequently for some reason can reduce"
                ],
                [
                    361,
                    "        // the poll interval accordingly."
                ]
            ]
        },
        {
            "commit": "d77333576b1268cd24f17348ffe6d72e07855f54",
            "timestamp": "2021-04-05T23:07:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for auto-deleting trashed items\n\nUpstream will soon auto-delete trashed items after 30 days, but some people\nuse the trash as an archive folder, so to avoid unexpected data loss, this\nimplementation requires the user to explicitly enable auto-deletion.",
            "additions": 7,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -354,6 +354,13 @@ fn schedule_jobs(pool: db::DbPool) {\n             }));\n         }\n \n+        // Purge trashed items that are old enough to be auto-deleted.\n+        if !CONFIG.trash_purge_schedule().is_empty() {\n+            sched.add(Job::new(CONFIG.trash_purge_schedule().parse().unwrap(), || {\n+                api::purge_trashed_ciphers(pool.clone());\n+            }));\n+        }\n+\n         // Periodically check for jobs to run. We probably won't need any\n         // jobs that run more often than once a minute, so a default poll\n         // interval of 30 seconds should be sufficient. Users who want to\n",
            "comment_added_diff": [
                [
                    357,
                    "        // Purge trashed items that are old enough to be auto-deleted."
                ]
            ]
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 8,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -64,10 +64,10 @@ fn main() {\n }\n \n const HELP: &str = \"\\\n-        A Bitwarden API server written in Rust\n+        Alternative implementation of the Bitwarden server API written in Rust\n \n         USAGE:\n-            bitwarden_rs\n+            vaultwarden\n \n         FLAGS:\n             -h, --help       Prints help information\n@@ -79,18 +79,18 @@ fn parse_args() {\n     let mut pargs = pico_args::Arguments::from_env();\n \n     if pargs.contains([\"-h\", \"--help\"]) {\n-        println!(\"bitwarden_rs {}\", option_env!(\"BWRS_VERSION\").unwrap_or(NO_VERSION));\n+        println!(\"vaultwarden {}\", option_env!(\"BWRS_VERSION\").unwrap_or(NO_VERSION));\n         print!(\"{}\", HELP);\n         exit(0);\n     } else if pargs.contains([\"-v\", \"--version\"]) {\n-        println!(\"bitwarden_rs {}\", option_env!(\"BWRS_VERSION\").unwrap_or(NO_VERSION));\n+        println!(\"vaultwarden {}\", option_env!(\"BWRS_VERSION\").unwrap_or(NO_VERSION));\n         exit(0);\n     }\n }\n \n fn launch_info() {\n     println!(\"/--------------------------------------------------------------------\\\\\");\n-    println!(\"|                       Starting Bitwarden_RS                        |\");\n+    println!(\"|                        Starting Vaultwarden                        |\");\n \n     if let Some(version) = option_env!(\"BWRS_VERSION\") {\n         println!(\"|{:^68}|\", format!(\"Version {}\", version));\n@@ -102,7 +102,7 @@ fn launch_info() {\n     println!(\"| Send usage/configuration questions or feature requests to:         |\");\n     println!(\"|   https://bitwardenrs.discourse.group/                             |\");\n     println!(\"| Report suspected bugs/issues in the software itself at:            |\");\n-    println!(\"|   https://github.com/dani-garcia/bitwarden_rs/issues/new           |\");\n+    println!(\"|   https://github.com/dani-garcia/vaultwarden/issues/new            |\");\n     println!(\"\\\\--------------------------------------------------------------------/\\n\");\n }\n \n@@ -207,7 +207,7 @@ fn chain_syslog(logger: fern::Dispatch) -> fern::Dispatch {\n     let syslog_fmt = syslog::Formatter3164 {\n         facility: syslog::Facility::LOG_USER,\n         hostname: None,\n-        process: \"bitwarden_rs\".into(),\n+        process: \"vaultwarden\".into(),\n         pid: 0,\n     };\n \n@@ -304,7 +304,7 @@ fn check_web_vault() {\n             \"Web vault is not found at '{}'. To install it, please follow the steps in: \",\n             CONFIG.web_vault_folder()\n         );\n-        error!(\"https://github.com/dani-garcia/bitwarden_rs/wiki/Building-binary#install-the-web-vault\");\n+        error!(\"https://github.com/dani-garcia/vaultwarden/wiki/Building-binary#install-the-web-vault\");\n         error!(\"You can also set the environment variable 'WEB_VAULT_ENABLED=false' to disable it\");\n         exit(1);\n     }\n",
            "comment_added_diff": [
                [
                    105,
                    "    println!(\"|   https://github.com/dani-garcia/vaultwarden/issues/new            |\");"
                ],
                [
                    307,
                    "        error!(\"https://github.com/dani-garcia/vaultwarden/wiki/Building-binary#install-the-web-vault\");"
                ]
            ]
        },
        {
            "commit": "7b5d5d1302858fd3bbf5395dafba7bef0fe45bfa",
            "timestamp": "2021-04-30T22:40:12+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Rename references to the discourse forum",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -100,7 +100,7 @@ fn launch_info() {\n     println!(\"| This is an *unofficial* Bitwarden implementation, DO NOT use the   |\");\n     println!(\"| official channels to report bugs/features, regardless of client.   |\");\n     println!(\"| Send usage/configuration questions or feature requests to:         |\");\n-    println!(\"|   https://bitwardenrs.discourse.group/                             |\");\n+    println!(\"|   https://vaultwarden.discourse.group/                             |\");\n     println!(\"| Report suspected bugs/issues in the software itself at:            |\");\n     println!(\"|   https://github.com/dani-garcia/vaultwarden/issues/new            |\");\n     println!(\"\\\\--------------------------------------------------------------------/\\n\");\n",
            "comment_added_diff": [
                [
                    103,
                    "    println!(\"|   https://vaultwarden.discourse.group/                             |\");"
                ]
            ]
        },
        {
            "commit": "f270f2ed652459cec2d5251b998eef17a88ea49e",
            "timestamp": "2021-05-16T15:29:13+02:00",
            "author": "BlackDex",
            "commit_message": "Updated icon fetching and crates.\n\n- Updated some crates\n- Updated icon fetching code:\n  + Use a cookie jar and set Max-Age to 2 minutes for all cookies\n  + Locate the base href tag to fix some locations\n  + Changed User-Agent (Helps on some sites to get HTML instead of JS)\n  + Reduced HTML code limit from 512KB to 384KB\n  + Allow some large icons higer-up in the sort\n  + Allow GIF images\n  + Ignore cookie_store and hyper::client debug messages",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -122,6 +122,9 @@ fn init_logging(level: log::LevelFilter) -> Result<(), fern::InitError> {\n         // Never show html5ever and hyper::proto logs, too noisy\n         .level_for(\"html5ever\", log::LevelFilter::Off)\n         .level_for(\"hyper::proto\", log::LevelFilter::Off)\n+        .level_for(\"hyper::client\", log::LevelFilter::Off)\n+        // Prevent cookie_store logs\n+        .level_for(\"cookie_store\", log::LevelFilter::Off)\n         .chain(std::io::stdout());\n \n     // Enable smtp debug logging only specifically for smtp when need.\n",
            "comment_added_diff": [
                [
                    126,
                    "        // Prevent cookie_store logs"
                ]
            ]
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -60,6 +60,8 @@ fn main() {\n \n     let pool = create_db_pool();\n     schedule_jobs(pool.clone());\n+    crate::db::models::TwoFactor::migrate_u2f_to_webauthn(&pool.get().unwrap()).unwrap();\n+\n     launch_rocket(pool, extra_debug); // Blocks until program termination.\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 22,
            "deletions": 42,
            "change_type": "MODIFY",
            "diff": "@@ -21,7 +21,7 @@ use std::{\n     fs::create_dir_all,\n     panic,\n     path::Path,\n-    process::{exit, Command},\n+    process::exit,\n     str::FromStr,\n     thread,\n     time::Duration,\n@@ -53,7 +53,10 @@ fn main() {\n     let extra_debug = matches!(level, LF::Trace | LF::Debug);\n \n     check_data_folder();\n-    check_rsa_keys();\n+    check_rsa_keys().unwrap_or_else(|_| {\n+        error!(\"Error creating keys, exiting...\");\n+        exit(1);\n+    });\n     check_web_vault();\n \n     create_icon_cache_folder();\n@@ -249,52 +252,29 @@ fn check_data_folder() {\n     }\n }\n \n-fn check_rsa_keys() {\n+fn check_rsa_keys()-> Result<(), crate::error::Error> {\n     // If the RSA keys don't exist, try to create them\n-    if !util::file_exists(&CONFIG.private_rsa_key()) || !util::file_exists(&CONFIG.public_rsa_key()) {\n-        info!(\"JWT keys don't exist, checking if OpenSSL is available...\");\n-\n-        Command::new(\"openssl\").arg(\"version\").status().unwrap_or_else(|_| {\n-            info!(\n-                \"Can't create keys because OpenSSL is not available, make sure it's installed and available on the PATH\"\n-            );\n-            exit(1);\n-        });\n-\n-        info!(\"OpenSSL detected, creating keys...\");\n-\n-        let key = CONFIG.rsa_key_filename();\n-\n-        let pem = format!(\"{}.pem\", key);\n-        let priv_der = format!(\"{}.der\", key);\n-        let pub_der = format!(\"{}.pub.der\", key);\n+    let priv_path = CONFIG.private_rsa_key();\n+    let pub_path = CONFIG.public_rsa_key();\n \n-        let mut success = Command::new(\"openssl\")\n-            .args(&[\"genrsa\", \"-out\", &pem])\n-            .status()\n-            .expect(\"Failed to create private pem file\")\n-            .success();\n+    if !util::file_exists(&priv_path) {\n+        let rsa_key = openssl::rsa::Rsa::generate(2048)?;\n \n-        success &= Command::new(\"openssl\")\n-            .args(&[\"rsa\", \"-in\", &pem, \"-outform\", \"DER\", \"-out\", &priv_der])\n-            .status()\n-            .expect(\"Failed to create private der file\")\n-            .success();\n+        let priv_key = rsa_key.private_key_to_pem()?;\n+        crate::util::write_file(&priv_path, &priv_key)?;\n+        info!(\"Private key created correctly.\");\n+    }\n \n-        success &= Command::new(\"openssl\")\n-            .args(&[\"rsa\", \"-in\", &priv_der, \"-inform\", \"DER\"])\n-            .args(&[\"-RSAPublicKey_out\", \"-outform\", \"DER\", \"-out\", &pub_der])\n-            .status()\n-            .expect(\"Failed to create public der file\")\n-            .success();\n+    if !util::file_exists(&pub_path) {\n+        let rsa_key = openssl::rsa::Rsa::private_key_from_pem(&util::read_file(&priv_path)?)?;\n \n-        if success {\n-            info!(\"Keys created correctly.\");\n-        } else {\n-            error!(\"Error creating keys, exiting...\");\n-            exit(1);\n-        }\n+        let pub_key = rsa_key.public_key_to_pem()?;\n+        crate::util::write_file(&pub_path, &pub_key)?;\n+        info!(\"Public key created correctly.\");\n     }\n+\n+    auth::load_keys();\n+    Ok(())\n }\n \n fn check_web_vault() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "e3a2dfffab7d8af64bb0c964fc740988979eb1a0",
            "timestamp": "2021-06-26T14:21:58+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 2,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -17,15 +17,7 @@ extern crate diesel;\n extern crate diesel_migrations;\n \n use job_scheduler::{Job, JobScheduler};\n-use std::{\n-    fs::create_dir_all,\n-    panic,\n-    path::Path,\n-    process::exit,\n-    str::FromStr,\n-    thread,\n-    time::Duration,\n-};\n+use std::{fs::create_dir_all, panic, path::Path, process::exit, str::FromStr, thread, time::Duration};\n \n #[macro_use]\n mod error;\n@@ -252,7 +244,7 @@ fn check_data_folder() {\n     }\n }\n \n-fn check_rsa_keys()-> Result<(), crate::error::Error> {\n+fn check_rsa_keys() -> Result<(), crate::error::Error> {\n     // If the RSA keys don't exist, try to create them\n     let priv_path = CONFIG.private_rsa_key();\n     let pub_path = CONFIG.public_rsa_key();\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -345,6 +345,18 @@ fn schedule_jobs(pool: db::DbPool) {\n                 }));\n             }\n \n+            if !CONFIG.emergency_request_timeout_schedule().is_empty() {\n+                sched.add(Job::new(CONFIG.emergency_request_timeout_schedule().parse().unwrap(), || {\n+                    api::emergency_request_timeout_job(pool.clone());\n+                }));\n+            }\n+\n+            if !CONFIG.emergency_notification_reminder_schedule().is_empty() {\n+                sched.add(Job::new(CONFIG.emergency_notification_reminder_schedule().parse().unwrap(), || {\n+                    api::emergency_notification_reminder_job(pool.clone());\n+                }));\n+            }\n+\n             // Periodically check for jobs to run. We probably won't need any\n             // jobs that run more often than once a minute, so a default poll\n             // interval of 30 seconds should be sufficient. Users who want to\n",
            "comment_added_diff": []
        }
    ],
    "accounts.rs": [
        {
            "commit": "00a11b1b784af6283a8321d240a309bb637d23a6",
            "timestamp": "2019-11-01T22:34:42+00:00",
            "author": "Miro Prasil",
            "commit_message": "Stop leaking usernames when SIGNUPS_ALLOWED=false\n\nThis fixes #691 - respond in less specific way to not leak the\nfact that user is already registered on the server.",
            "additions": 7,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -62,7 +62,11 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n     let mut user = match User::find_by_mail(&data.Email, &conn) {\n         Some(user) => {\n             if !user.password_hash.is_empty() {\n-                err!(\"User already exists\")\n+                if CONFIG.signups_allowed() {\n+                    err!(\"User already exists\")\n+                } else {\n+                    err!(\"Registration not allowed or user already exists\")\n+                }\n             }\n \n             if let Some(token) = data.Token {\n@@ -82,14 +86,14 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n             } else if CONFIG.signups_allowed() {\n                 err!(\"Account with this email already exists\")\n             } else {\n-                err!(\"Registration not allowed\")\n+                err!(\"Registration not allowed or user already exists\")\n             }\n         }\n         None => {\n             if CONFIG.signups_allowed() || Invitation::take(&data.Email, &conn) {\n                 User::new(data.Email.clone())\n             } else {\n-                err!(\"Registration not allowed\")\n+                err!(\"Registration not allowed or user already exists\")\n             }\n         }\n     };\n",
            "comment_added_diff": []
        },
        {
            "commit": "64d6f72e6c71dec7cbcb5992f31473c416d0678e",
            "timestamp": "2019-11-16T15:01:45-07:00",
            "author": "tomuta",
            "commit_message": "Add the ability to disable signups, but allow signups from a whitelist\n\nThis feature can be enabled by setting SIGNUPS_ALLOWED=false and\nproviding a comma-separated list of whitelisted domains in\nSIGNUPS_DOMAINS_WHITELIST.\n\nFixes #727",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -90,7 +90,7 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n             }\n         }\n         None => {\n-            if CONFIG.signups_allowed() || Invitation::take(&data.Email, &conn) {\n+            if CONFIG.signups_allowed() || Invitation::take(&data.Email, &conn) || CONFIG.can_signup_user(&data.Email) {\n                 User::new(data.Email.clone())\n             } else {\n                 err!(\"Registration not allowed or user already exists\")\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 170,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -1,11 +1,13 @@\n use rocket_contrib::json::Json;\n+use chrono::Utc;\n \n use crate::db::models::*;\n use crate::db::DbConn;\n \n use crate::api::{EmptyResult, JsonResult, JsonUpcase, Notify, NumberOrString, PasswordData, UpdateType};\n-use crate::auth::{decode_invite, Headers};\n+use crate::auth::{decode_invite, decode_delete, decode_verify_email, Headers};\n use crate::mail;\n+use crate::crypto;\n \n use crate::CONFIG;\n \n@@ -25,6 +27,10 @@ pub fn routes() -> Vec<Route> {\n         post_sstamp,\n         post_email_token,\n         post_email,\n+        post_verify_email,\n+        post_verify_email_token,\n+        post_delete_recover,\n+        post_delete_recover_token,\n         delete_account,\n         post_delete_account,\n         revision_date,\n@@ -126,6 +132,20 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n         user.public_key = Some(keys.PublicKey);\n     }\n \n+    if CONFIG.mail_enabled() {\n+        if CONFIG.signups_verify() {\n+            if let Err(e) = mail::send_welcome_must_verify(&user.email, &user.uuid) {\n+                error!(\"Error sending welcome email: {:#?}\", e);\n+            }\n+\n+            user.last_verifying_at = Some(user.created_at);\n+        } else {\n+            if let Err(e) = mail::send_welcome(&user.email) {\n+                error!(\"Error sending welcome email: {:#?}\", e);\n+            }\n+        }\n+    }\n+\n     user.save(&conn)\n }\n \n@@ -341,8 +361,9 @@ struct EmailTokenData {\n #[post(\"/accounts/email-token\", data = \"<data>\")]\n fn post_email_token(data: JsonUpcase<EmailTokenData>, headers: Headers, conn: DbConn) -> EmptyResult {\n     let data: EmailTokenData = data.into_inner().data;\n+    let mut user = headers.user;\n \n-    if !headers.user.check_valid_password(&data.MasterPasswordHash) {\n+    if !user.check_valid_password(&data.MasterPasswordHash) {\n         err!(\"Invalid password\")\n     }\n \n@@ -350,7 +371,21 @@ fn post_email_token(data: JsonUpcase<EmailTokenData>, headers: Headers, conn: Db\n         err!(\"Email already in use\");\n     }\n \n-    Ok(())\n+    if !CONFIG.signups_allowed() && !CONFIG.can_signup_user(&data.NewEmail) {\n+        err!(\"Email cannot be changed to this address\");\n+    }\n+\n+    let token = crypto::generate_token(6)?;\n+\n+    if CONFIG.mail_enabled() {\n+        if let Err(e) = mail::send_change_email(&data.NewEmail, &token) {\n+            error!(\"Error sending change-email email: {:#?}\", e);\n+        }\n+    }\n+\n+    user.email_new = Some(data.NewEmail);\n+    user.email_new_token = Some(token);\n+    user.save(&conn)\n }\n \n #[derive(Deserialize)]\n@@ -361,8 +396,7 @@ struct ChangeEmailData {\n \n     Key: String,\n     NewMasterPasswordHash: String,\n-    #[serde(rename = \"Token\")]\n-    _Token: NumberOrString,\n+    Token: NumberOrString,\n }\n \n #[post(\"/accounts/email\", data = \"<data>\")]\n@@ -378,7 +412,32 @@ fn post_email(data: JsonUpcase<ChangeEmailData>, headers: Headers, conn: DbConn)\n         err!(\"Email already in use\");\n     }\n \n+    match user.email_new {\n+        Some(ref val) => {\n+            if *val != data.NewEmail.to_string() {\n+                err!(\"Email change mismatch\");\n+            }\n+        },\n+        None => err!(\"No email change pending\"),\n+    }\n+\n+    if CONFIG.mail_enabled() {\n+        // Only check the token if we sent out an email...\n+        match user.email_new_token {\n+            Some(ref val) =>\n+                if *val != data.Token.into_string() {\n+                    err!(\"Token mismatch\");\n+                }\n+            None => err!(\"No email change pending\"),\n+        }\n+        user.verified_at = Some(Utc::now().naive_utc());\n+    } else {\n+        user.verified_at = None;\n+    }\n+\n     user.email = data.NewEmail;\n+    user.email_new = None;\n+    user.email_new_token = None;\n \n     user.set_password(&data.NewMasterPasswordHash);\n     user.akey = data.Key;\n@@ -386,6 +445,112 @@ fn post_email(data: JsonUpcase<ChangeEmailData>, headers: Headers, conn: DbConn)\n     user.save(&conn)\n }\n \n+#[post(\"/accounts/verify-email\")]\n+fn post_verify_email(headers: Headers, _conn: DbConn) -> EmptyResult {\n+    let user = headers.user;\n+\n+    if !CONFIG.mail_enabled() {\n+        err!(\"Cannot verify email address\");\n+    }\n+\n+    if let Err(e) = mail::send_verify_email(&user.email, &user.uuid) {\n+        error!(\"Error sending delete account email: {:#?}\", e);\n+    }\n+\n+    Ok(())\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct VerifyEmailTokenData {\n+    UserId: String,\n+    Token: String,\n+}\n+\n+#[post(\"/accounts/verify-email-token\", data = \"<data>\")]\n+fn post_verify_email_token(data: JsonUpcase<VerifyEmailTokenData>, conn: DbConn) -> EmptyResult {\n+    let data: VerifyEmailTokenData = data.into_inner().data;\n+\n+    let mut user = match User::find_by_uuid(&data.UserId, &conn) {\n+        Some(user) => user,\n+        None => err!(\"User doesn't exist\"),\n+    };\n+\n+    let claims = match decode_verify_email(&data.Token) {\n+        Ok(claims) => claims,\n+        Err(_) => err!(\"Invalid claim\"),\n+    };\n+    \n+    if claims.sub != user.uuid {\n+       err!(\"Invalid claim\");\n+    }\n+    \n+    user.verified_at = Some(Utc::now().naive_utc());\n+    user.last_verifying_at = None;\n+    user.login_verify_count = 0;\n+    if let Err(e) = user.save(&conn) {\n+        error!(\"Error saving email verification: {:#?}\", e);\n+    }\n+\n+    Ok(())\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct DeleteRecoverData {\n+    Email: String,\n+}\n+\n+#[post(\"/accounts/delete-recover\", data=\"<data>\")]\n+fn post_delete_recover(data: JsonUpcase<DeleteRecoverData>, conn: DbConn) -> EmptyResult {\n+    let data: DeleteRecoverData = data.into_inner().data;\n+\n+    let user = User::find_by_mail(&data.Email, &conn);\n+\n+    if CONFIG.mail_enabled() {\n+        if let Some(user) = user {\n+            if let Err(e) = mail::send_delete_account(&user.email, &user.uuid) {\n+                error!(\"Error sending delete account email: {:#?}\", e);\n+            }\n+        }\n+        Ok(())\n+    } else {\n+        // We don't support sending emails, but we shouldn't allow anybody\n+        // to delete accounts without at least logging in... And if the user\n+        // cannot remember their password then they will need to contact\n+        // the administrator to delete it...\n+        err!(\"Please contact the administrator to delete your account\");\n+    }\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct DeleteRecoverTokenData {\n+    UserId: String,\n+    Token: String,\n+}\n+\n+#[post(\"/accounts/delete-recover-token\", data=\"<data>\")]\n+fn post_delete_recover_token(data: JsonUpcase<DeleteRecoverTokenData>, conn: DbConn) -> EmptyResult {\n+    let data: DeleteRecoverTokenData = data.into_inner().data;\n+\n+    let user = match User::find_by_uuid(&data.UserId, &conn) {\n+        Some(user) => user,\n+        None => err!(\"User doesn't exist\"),\n+    };\n+\n+    let claims = match decode_delete(&data.Token) {\n+        Ok(claims) => claims,\n+        Err(_) => err!(\"Invalid claim\"),\n+    };\n+    \n+    if claims.sub != user.uuid {\n+       err!(\"Invalid claim\");\n+    }\n+    \n+    user.delete(&conn)\n+}\n+\n #[post(\"/accounts/delete\", data = \"<data>\")]\n fn post_delete_account(data: JsonUpcase<PasswordData>, headers: Headers, conn: DbConn) -> EmptyResult {\n     delete_account(data, headers, conn)\n",
            "comment_added_diff": [
                [
                    425,
                    "        // Only check the token if we sent out an email..."
                ],
                [
                    518,
                    "        // We don't support sending emails, but we shouldn't allow anybody"
                ],
                [
                    519,
                    "        // to delete accounts without at least logging in... And if the user"
                ],
                [
                    520,
                    "        // cannot remember their password then they will need to contact"
                ],
                [
                    521,
                    "        // the administrator to delete it..."
                ]
            ]
        },
        {
            "commit": "912e1f93b78625e5cfc1e53b5d8cd265b728dfc2",
            "timestamp": "2019-12-06T22:12:41+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix some lints",
            "additions": 11,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -1,13 +1,13 @@\n-use rocket_contrib::json::Json;\n use chrono::Utc;\n+use rocket_contrib::json::Json;\n \n use crate::db::models::*;\n use crate::db::DbConn;\n \n use crate::api::{EmptyResult, JsonResult, JsonUpcase, Notify, NumberOrString, PasswordData, UpdateType};\n-use crate::auth::{decode_invite, decode_delete, decode_verify_email, Headers};\n-use crate::mail;\n+use crate::auth::{decode_delete, decode_invite, decode_verify_email, Headers};\n use crate::crypto;\n+use crate::mail;\n \n use crate::CONFIG;\n \n@@ -414,20 +414,21 @@ fn post_email(data: JsonUpcase<ChangeEmailData>, headers: Headers, conn: DbConn)\n \n     match user.email_new {\n         Some(ref val) => {\n-            if *val != data.NewEmail.to_string() {\n+            if val != &data.NewEmail {\n                 err!(\"Email change mismatch\");\n             }\n-        },\n+        }\n         None => err!(\"No email change pending\"),\n     }\n \n     if CONFIG.mail_enabled() {\n         // Only check the token if we sent out an email...\n         match user.email_new_token {\n-            Some(ref val) =>\n+            Some(ref val) => {\n                 if *val != data.Token.into_string() {\n                     err!(\"Token mismatch\");\n                 }\n+            }\n             None => err!(\"No email change pending\"),\n         }\n         user.verified_at = Some(Utc::now().naive_utc());\n@@ -480,11 +481,9 @@ fn post_verify_email_token(data: JsonUpcase<VerifyEmailTokenData>, conn: DbConn)\n         Ok(claims) => claims,\n         Err(_) => err!(\"Invalid claim\"),\n     };\n-    \n     if claims.sub != user.uuid {\n-       err!(\"Invalid claim\");\n+        err!(\"Invalid claim\");\n     }\n-    \n     user.verified_at = Some(Utc::now().naive_utc());\n     user.last_verifying_at = None;\n     user.login_verify_count = 0;\n@@ -501,7 +500,7 @@ struct DeleteRecoverData {\n     Email: String,\n }\n \n-#[post(\"/accounts/delete-recover\", data=\"<data>\")]\n+#[post(\"/accounts/delete-recover\", data = \"<data>\")]\n fn post_delete_recover(data: JsonUpcase<DeleteRecoverData>, conn: DbConn) -> EmptyResult {\n     let data: DeleteRecoverData = data.into_inner().data;\n \n@@ -530,7 +529,7 @@ struct DeleteRecoverTokenData {\n     Token: String,\n }\n \n-#[post(\"/accounts/delete-recover-token\", data=\"<data>\")]\n+#[post(\"/accounts/delete-recover-token\", data = \"<data>\")]\n fn post_delete_recover_token(data: JsonUpcase<DeleteRecoverTokenData>, conn: DbConn) -> EmptyResult {\n     let data: DeleteRecoverTokenData = data.into_inner().data;\n \n@@ -543,11 +542,9 @@ fn post_delete_recover_token(data: JsonUpcase<DeleteRecoverTokenData>, conn: DbC\n         Ok(claims) => claims,\n         Err(_) => err!(\"Invalid claim\"),\n     };\n-    \n     if claims.sub != user.uuid {\n-       err!(\"Invalid claim\");\n+        err!(\"Invalid claim\");\n     }\n-    \n     user.delete(&conn)\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "c2a324e5da24bf2b59b5ccb745335783b4ea633f",
            "timestamp": "2020-04-09T01:42:27-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up domain whitelist logic\n\n* Make `SIGNUPS_DOMAINS_WHITELIST` override the `SIGNUPS_ALLOWED` setting.\n  Otherwise, a common pitfall is to set `SIGNUPS_DOMAINS_WHITELIST` without\n  realizing that `SIGNUPS_ALLOWED=false` must also be set.\n\n* Whitespace is now accepted in `SIGNUPS_DOMAINS_WHITELIST`. That is,\n  `foo.com, bar.com` is now equivalent to `foo.com,bar.com`.\n\n* Add validation on `SIGNUPS_DOMAINS_WHITELIST`. For example, `foo.com,`\n  is rejected as containing an empty token.",
            "additions": 7,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -68,7 +68,7 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n     let mut user = match User::find_by_mail(&data.Email, &conn) {\n         Some(user) => {\n             if !user.password_hash.is_empty() {\n-                if CONFIG.signups_allowed() {\n+                if CONFIG.is_signup_allowed(&data.Email) {\n                     err!(\"User already exists\")\n                 } else {\n                     err!(\"Registration not allowed or user already exists\")\n@@ -89,14 +89,17 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n                 }\n \n                 user\n-            } else if CONFIG.signups_allowed() {\n+            } else if CONFIG.is_signup_allowed(&data.Email) {\n                 err!(\"Account with this email already exists\")\n             } else {\n                 err!(\"Registration not allowed or user already exists\")\n             }\n         }\n         None => {\n-            if CONFIG.signups_allowed() || Invitation::take(&data.Email, &conn) || CONFIG.can_signup_user(&data.Email) {\n+            // Order is important here; the invitation check must come first\n+            // because the bitwarden_rs admin can invite anyone, regardless\n+            // of other signup restrictions.\n+            if Invitation::take(&data.Email, &conn) || CONFIG.is_signup_allowed(&data.Email) {\n                 User::new(data.Email.clone())\n             } else {\n                 err!(\"Registration not allowed or user already exists\")\n@@ -371,7 +374,7 @@ fn post_email_token(data: JsonUpcase<EmailTokenData>, headers: Headers, conn: Db\n         err!(\"Email already in use\");\n     }\n \n-    if !CONFIG.signups_allowed() && !CONFIG.can_signup_user(&data.NewEmail) {\n+    if !CONFIG.is_signup_allowed(&data.NewEmail) {\n         err!(\"Email cannot be changed to this address\");\n     }\n \n",
            "comment_added_diff": [
                [
                    99,
                    "            // Order is important here; the invitation check must come first"
                ],
                [
                    100,
                    "            // because the bitwarden_rs admin can invite anyone, regardless"
                ],
                [
                    101,
                    "            // of other signup restrictions."
                ]
            ]
        },
        {
            "commit": "5571a5d8ed54c546e86b5d24108351c640c5b86c",
            "timestamp": "2020-05-08T13:38:49-04:00",
            "author": "theycallmesteve",
            "commit_message": "Update post_keys to return a keys response model",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -210,7 +210,12 @@ fn post_keys(data: JsonUpcase<KeysData>, headers: Headers, conn: DbConn) -> Json\n     user.public_key = Some(data.PublicKey);\n \n     user.save(&conn)?;\n-    Ok(Json(user.to_json(&conn)))\n+\n+    Ok(Json(json!({\n+        \"PrivateKey\": user.private_key,\n+        \"PublicKey\": user.public_key,\n+        \"Object\":\"keys\"\n+    })))\n }\n \n #[derive(Deserialize)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "a3149335571d47af810aff3665665f0eb5c9f168",
            "timestamp": "2020-05-24T14:38:19-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Allow email changes for existing accounts even when signups are disabled",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -379,8 +379,8 @@ fn post_email_token(data: JsonUpcase<EmailTokenData>, headers: Headers, conn: Db\n         err!(\"Email already in use\");\n     }\n \n-    if !CONFIG.is_signup_allowed(&data.NewEmail) {\n-        err!(\"Email cannot be changed to this address\");\n+    if !CONFIG.is_email_domain_allowed(&data.NewEmail) {\n+        err!(\"Email domain not allowed\");\n     }\n \n     let token = crypto::generate_token(6)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 9,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -1,19 +1,15 @@\n use chrono::Utc;\n use rocket_contrib::json::Json;\n \n-use crate::db::models::*;\n-use crate::db::DbConn;\n-\n-use crate::api::{EmptyResult, JsonResult, JsonUpcase, Notify, NumberOrString, PasswordData, UpdateType};\n-use crate::auth::{decode_delete, decode_invite, decode_verify_email, Headers};\n-use crate::crypto;\n-use crate::mail;\n-\n-use crate::CONFIG;\n-\n-use rocket::Route;\n-\n-pub fn routes() -> Vec<Route> {\n+use crate::{\n+    api::{EmptyResult, JsonResult, JsonUpcase, Notify, NumberOrString, PasswordData, UpdateType},\n+    auth::{decode_delete, decode_invite, decode_verify_email, Headers},\n+    crypto,\n+    db::{models::*, DbConn},\n+    mail, CONFIG,\n+};\n+\n+pub fn routes() -> Vec<rocket::Route> {\n     routes![\n         register,\n         profile,\n",
            "comment_added_diff": []
        },
        {
            "commit": "c64560016e80517eb490b2b863be6da261c02b27",
            "timestamp": "2020-09-25T18:26:48+02:00",
            "author": "BlackDex",
            "commit_message": "Add /api/accounts/verify-password endpoint\n\nIf for some reason the hashed password is cleared from memory within a\nbitwarden client it will try to verify the password at the server side.\n\nThis endpoint was missing.\n\nResolves #1156",
            "additions": 18,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -32,6 +32,7 @@ pub fn routes() -> Vec<rocket::Route> {\n         revision_date,\n         password_hint,\n         prelogin,\n+        verify_password,\n     ]\n }\n \n@@ -623,3 +624,20 @@ fn prelogin(data: JsonUpcase<PreloginData>, conn: DbConn) -> JsonResult {\n         \"KdfIterations\": kdf_iter\n     })))\n }\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct VerifyPasswordData {\n+    MasterPasswordHash: String,\n+}\n+\n+#[post(\"/accounts/verify-password\", data = \"<data>\")]\n+fn verify_password(data: JsonUpcase<VerifyPasswordData>, headers: Headers, _conn: DbConn) -> EmptyResult {\n+    let data: VerifyPasswordData = data.into_inner().data;\n+    let user = headers.user;\n+\n+    if !user.check_valid_password(&data.MasterPasswordHash) {\n+        err!(\"Invalid password\")\n+    }\n+\n+    Ok(())\n+}\n",
            "comment_added_diff": []
        },
        {
            "commit": "b41a0d840cc963a5e1810c1ef3e6aa7cfddc0f21",
            "timestamp": "2020-10-23T10:30:25+02:00",
            "author": "Fabian van Steen",
            "commit_message": "Correction of verify_email error message",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -460,7 +460,7 @@ fn post_verify_email(headers: Headers, _conn: DbConn) -> EmptyResult {\n     }\n \n     if let Err(e) = mail::send_verify_email(&user.email, &user.uuid) {\n-        error!(\"Error sending delete account email: {:#?}\", e);\n+        error!(\"Error sending verify_email email: {:#?}\", e);\n     }\n \n     Ok(())\n",
            "comment_added_diff": []
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 5,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -115,7 +115,7 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n         user.client_kdf_type = client_kdf_type;\n     }\n \n-    user.set_password(&data.MasterPasswordHash);\n+    user.set_password(&data.MasterPasswordHash, None);\n     user.akey = data.Key;\n \n     // Add extra fields if present\n@@ -232,7 +232,7 @@ fn post_password(data: JsonUpcase<ChangePassData>, headers: Headers, conn: DbCon\n         err!(\"Invalid password\")\n     }\n \n-    user.set_password(&data.NewMasterPasswordHash);\n+    user.set_password(&data.NewMasterPasswordHash, Some(\"post_rotatekey\"));\n     user.akey = data.Key;\n     user.save(&conn)\n }\n@@ -259,7 +259,7 @@ fn post_kdf(data: JsonUpcase<ChangeKdfData>, headers: Headers, conn: DbConn) ->\n \n     user.client_kdf_iter = data.KdfIterations;\n     user.client_kdf_type = data.Kdf;\n-    user.set_password(&data.NewMasterPasswordHash);\n+    user.set_password(&data.NewMasterPasswordHash, None);\n     user.akey = data.Key;\n     user.save(&conn)\n }\n@@ -338,6 +338,7 @@ fn post_rotatekey(data: JsonUpcase<KeyData>, headers: Headers, conn: DbConn, nt:\n     user.akey = data.Key;\n     user.private_key = Some(data.PrivateKey);\n     user.reset_security_stamp();\n+    user.reset_stamp_exception();\n \n     user.save(&conn)\n }\n@@ -445,7 +446,7 @@ fn post_email(data: JsonUpcase<ChangeEmailData>, headers: Headers, conn: DbConn)\n     user.email_new = None;\n     user.email_new_token = None;\n \n-    user.set_password(&data.NewMasterPasswordHash);\n+    user.set_password(&data.NewMasterPasswordHash, None);\n     user.akey = data.Key;\n \n     user.save(&conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "a8138be69b0c051da9f97827a9f5427c98dd3051",
            "timestamp": "2021-03-27T14:03:31+00:00",
            "author": "Jake Howard",
            "commit_message": "Use `if let` more",
            "additions": 2,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -139,10 +139,8 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n             }\n \n             user.last_verifying_at = Some(user.created_at);\n-        } else {\n-            if let Err(e) = mail::send_welcome(&user.email) {\n-                error!(\"Error sending welcome email: {:#?}\", e);\n-            }\n+        } else if let Err(e) = mail::send_welcome(&user.email) {\n+            error!(\"Error sending welcome email: {:#?}\", e);\n         }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 6,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,6 @@\n use chrono::Utc;\n use rocket_contrib::json::Json;\n+use serde_json::Value;\n \n use crate::{\n     api::{EmptyResult, JsonResult, JsonUpcase, Notify, NumberOrString, PasswordData, UpdateType},\n@@ -148,8 +149,8 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n }\n \n #[get(\"/accounts/profile\")]\n-fn profile(headers: Headers, conn: DbConn) -> JsonResult {\n-    Ok(Json(headers.user.to_json(&conn)))\n+fn profile(headers: Headers, conn: DbConn) -> Json<Value> {\n+    Json(headers.user.to_json(&conn))\n }\n \n #[derive(Deserialize, Debug)]\n@@ -610,7 +611,7 @@ struct PreloginData {\n }\n \n #[post(\"/accounts/prelogin\", data = \"<data>\")]\n-fn prelogin(data: JsonUpcase<PreloginData>, conn: DbConn) -> JsonResult {\n+fn prelogin(data: JsonUpcase<PreloginData>, conn: DbConn) -> Json<Value> {\n     let data: PreloginData = data.into_inner().data;\n \n     let (kdf_type, kdf_iter) = match User::find_by_mail(&data.Email, &conn) {\n@@ -618,10 +619,10 @@ fn prelogin(data: JsonUpcase<PreloginData>, conn: DbConn) -> JsonResult {\n         None => (User::CLIENT_KDF_TYPE_DEFAULT, User::CLIENT_KDF_ITER_DEFAULT),\n     };\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"Kdf\": kdf_type,\n         \"KdfIterations\": kdf_iter\n-    })))\n+    }))\n }\n #[derive(Deserialize)]\n #[allow(non_snake_case)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 1,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -320,15 +320,7 @@ fn post_rotatekey(data: JsonUpcase<KeyData>, headers: Headers, conn: DbConn, nt:\n             err!(\"The cipher is not owned by the user\")\n         }\n \n-        update_cipher_from_data(\n-            &mut saved_cipher,\n-            cipher_data,\n-            &headers,\n-            false,\n-            &conn,\n-            &nt,\n-            UpdateType::CipherUpdate,\n-        )?\n+        update_cipher_from_data(&mut saved_cipher, cipher_data, &headers, false, &conn, &nt, UpdateType::CipherUpdate)?\n     }\n \n     // Update user data\n",
            "comment_added_diff": []
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -95,7 +95,7 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n         }\n         None => {\n             // Order is important here; the invitation check must come first\n-            // because the bitwarden_rs admin can invite anyone, regardless\n+            // because the vaultwarden admin can invite anyone, regardless\n             // of other signup restrictions.\n             if Invitation::take(&data.Email, &conn) || CONFIG.is_signup_allowed(&data.Email) {\n                 User::new(data.Email.clone())\n",
            "comment_added_diff": [
                [
                    98,
                    "            // because the vaultwarden admin can invite anyone, regardless"
                ]
            ]
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 7,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -231,7 +231,10 @@ fn post_password(data: JsonUpcase<ChangePassData>, headers: Headers, conn: DbCon\n         err!(\"Invalid password\")\n     }\n \n-    user.set_password(&data.NewMasterPasswordHash, Some(\"post_rotatekey\"));\n+    user.set_password(\n+        &data.NewMasterPasswordHash,\n+        Some(vec![String::from(\"post_rotatekey\"), String::from(\"get_contacts\")]),\n+    );\n     user.akey = data.Key;\n     user.save(&conn)\n }\n@@ -320,7 +323,9 @@ fn post_rotatekey(data: JsonUpcase<KeyData>, headers: Headers, conn: DbConn, nt:\n             err!(\"The cipher is not owned by the user\")\n         }\n \n-        update_cipher_from_data(&mut saved_cipher, cipher_data, &headers, false, &conn, &nt, UpdateType::CipherUpdate)?\n+        // Prevent triggering cipher updates via WebSockets by settings UpdateType::None\n+        // The user sessions are invalidated because all the ciphers were re-encrypted and thus triggering an update could cause issues.\n+        update_cipher_from_data(&mut saved_cipher, cipher_data, &headers, false, &conn, &nt, UpdateType::None)?\n     }\n \n     // Update user data\n@@ -329,7 +334,6 @@ fn post_rotatekey(data: JsonUpcase<KeyData>, headers: Headers, conn: DbConn, nt:\n     user.akey = data.Key;\n     user.private_key = Some(data.PrivateKey);\n     user.reset_security_stamp();\n-    user.reset_stamp_exception();\n \n     user.save(&conn)\n }\n",
            "comment_added_diff": [
                [
                    326,
                    "        // Prevent triggering cipher updates via WebSockets by settings UpdateType::None"
                ],
                [
                    327,
                    "        // The user sessions are invalidated because all the ciphers were re-encrypted and thus triggering an update could cause issues."
                ]
            ]
        },
        {
            "commit": "88bea44dd81c6fc9755d42d9bee2533db8765c2a",
            "timestamp": "2021-07-10T01:21:27-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Prevent user enumeration via password hints\n\nWhen `show_password_hint` is enabled but mail is not configured, the previous\nimplementation returned a differentiable response for non-existent email\naddresses.\n\nEven if mail is enabled, there is a timing side channel since mail is sent\nsynchronously. Add a randomized sleep to mitigate this somewhat.",
            "additions": 35,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -576,24 +576,45 @@ struct PasswordHintData {\n \n #[post(\"/accounts/password-hint\", data = \"<data>\")]\n fn password_hint(data: JsonUpcase<PasswordHintData>, conn: DbConn) -> EmptyResult {\n-    let data: PasswordHintData = data.into_inner().data;\n+    if !CONFIG.mail_enabled() && !CONFIG.show_password_hint() {\n+        err!(\"This server is not configured to provide password hints.\");\n+    }\n \n-    let hint = match User::find_by_mail(&data.Email, &conn) {\n-        Some(user) => user.password_hint,\n-        None => return Ok(()),\n-    };\n+    const NO_HINT: &str = \"Sorry, you have no password hint...\";\n \n-    if CONFIG.mail_enabled() {\n-        mail::send_password_hint(&data.Email, hint)?;\n-    } else if CONFIG.show_password_hint() {\n-        if let Some(hint) = hint {\n-            err!(format!(\"Your password hint is: {}\", &hint));\n-        } else {\n-            err!(\"Sorry, you have no password hint...\");\n+    let data: PasswordHintData = data.into_inner().data;\n+    let email = &data.Email;\n+\n+    match User::find_by_mail(email, &conn) {\n+        None => {\n+            // To prevent user enumeration, act as if the user exists.\n+            if CONFIG.mail_enabled() {\n+                // There is still a timing side channel here in that the code\n+                // paths that send mail take noticeably longer than ones that\n+                // don't. Add a randomized sleep to mitigate this somewhat.\n+                use rand::{thread_rng, Rng};\n+                let mut rng = thread_rng();\n+                let base = 1000;\n+                let delta: i32 = 100;\n+                let sleep_ms = (base + rng.gen_range(-delta..=delta)) as u64;\n+                std::thread::sleep(std::time::Duration::from_millis(sleep_ms));\n+                Ok(())\n+            } else {\n+                err!(NO_HINT);\n+            }\n+        }\n+        Some(user) => {\n+            let hint: Option<String> = user.password_hint;\n+            if CONFIG.mail_enabled() {\n+                mail::send_password_hint(email, hint)?;\n+                Ok(())\n+            } else if let Some(hint) = hint {\n+                err!(format!(\"Your password hint is: {}\", hint));\n+            } else {\n+                err!(NO_HINT);\n+            }\n         }\n     }\n-\n-    Ok(())\n }\n \n #[derive(Deserialize)]\n",
            "comment_added_diff": [
                [
                    590,
                    "            // To prevent user enumeration, act as if the user exists."
                ],
                [
                    592,
                    "                // There is still a timing side channel here in that the code"
                ],
                [
                    593,
                    "                // paths that send mail take noticeably longer than ones that"
                ],
                [
                    594,
                    "                // don't. Add a randomized sleep to mitigate this somewhat."
                ]
            ]
        },
        {
            "commit": "10d5c7738afad9f81958e24baa923530314a587f",
            "timestamp": "2021-09-09T13:52:39+02:00",
            "author": "BlackDex",
            "commit_message": "Fix issue when using uppercase chars in emails\n\nIn the case when SMTP is disabled and.\nwhen inviting new users either via the admin interface or into an\norganization and using uppercase letters, this would fail for those\nusers to be able to register since the checks which were done are\ncase-sensitive and never matched.\n\nThis PR fixes that issue by ensuring everything is lowercase.\nFixes #1963",
            "additions": 9,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -62,11 +62,12 @@ struct KeysData {\n #[post(\"/accounts/register\", data = \"<data>\")]\n fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n     let data: RegisterData = data.into_inner().data;\n+    let email = data.Email.to_lowercase();\n \n-    let mut user = match User::find_by_mail(&data.Email, &conn) {\n+    let mut user = match User::find_by_mail(&email, &conn) {\n         Some(user) => {\n             if !user.password_hash.is_empty() {\n-                if CONFIG.is_signup_allowed(&data.Email) {\n+                if CONFIG.is_signup_allowed(&email) {\n                     err!(\"User already exists\")\n                 } else {\n                     err!(\"Registration not allowed or user already exists\")\n@@ -75,19 +76,19 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n \n             if let Some(token) = data.Token {\n                 let claims = decode_invite(&token)?;\n-                if claims.email == data.Email {\n+                if claims.email == email {\n                     user\n                 } else {\n                     err!(\"Registration email does not match invite email\")\n                 }\n-            } else if Invitation::take(&data.Email, &conn) {\n+            } else if Invitation::take(&email, &conn) {\n                 for mut user_org in UserOrganization::find_invited_by_user(&user.uuid, &conn).iter_mut() {\n                     user_org.status = UserOrgStatus::Accepted as i32;\n                     user_org.save(&conn)?;\n                 }\n \n                 user\n-            } else if CONFIG.is_signup_allowed(&data.Email) {\n+            } else if CONFIG.is_signup_allowed(&email) {\n                 err!(\"Account with this email already exists\")\n             } else {\n                 err!(\"Registration not allowed or user already exists\")\n@@ -97,8 +98,8 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n             // Order is important here; the invitation check must come first\n             // because the vaultwarden admin can invite anyone, regardless\n             // of other signup restrictions.\n-            if Invitation::take(&data.Email, &conn) || CONFIG.is_signup_allowed(&data.Email) {\n-                User::new(data.Email.clone())\n+            if Invitation::take(&email, &conn) || CONFIG.is_signup_allowed(&email) {\n+                User::new(email.clone())\n             } else {\n                 err!(\"Registration not allowed or user already exists\")\n             }\n@@ -106,7 +107,7 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n     };\n \n     // Make sure we don't leave a lingering invitation.\n-    Invitation::take(&data.Email, &conn);\n+    Invitation::take(&email, &conn);\n \n     if let Some(client_kdf_iter) = data.KdfIterations {\n         user.client_kdf_iter = client_kdf_iter;\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -89,7 +89,12 @@ fn register(data: JsonUpcase<RegisterData>, conn: DbConn) -> EmptyResult {\n \n                 user\n             } else if CONFIG.is_signup_allowed(&email) {\n-                err!(\"Account with this email already exists\")\n+                // check if it's invited by emergency contact\n+                if EmergencyAccess::find_invited_by_grantee_email(&data.Email, &conn).is_some() {\n+                    user\n+                } else {\n+                    err!(\"Account with this email already exists\")\n+                }\n             } else {\n                 err!(\"Registration not allowed or user already exists\")\n             }\n",
            "comment_added_diff": [
                [
                    92,
                    "                // check if it's invited by emergency contact"
                ]
            ]
        },
        {
            "commit": "ca20b3d80c75e42b9229ab3a9625a334c83e79a8",
            "timestamp": "2021-09-17T01:25:47+02:00",
            "author": "thelittlefireman",
            "commit_message": "[PATCH] Some fixes to the Emergency Access PR\n\n- Changed the date of the migration folders to be from this date.\n- Removed a lot is_email_domain_allowed checks.\n  This check only needs to be done during the invite it self, else\neverything else will fail even if a user has an account created via the\n/admin interface which bypasses that specific check! Also, the check was\nat the wrong place anyway's, since it would only not send out an e-mail,\nbut would still have allowed an not allowed domain to be used when\ne-mail would have been disabled. While that check always works, even if\nsending e-mails is disasbled.\n- Added an extra allowed route during password/key-rotation change which\nupdates/checks the public-key afterwards.\n- A small change with some `Some` and `None` orders.\n- Change the new invite object to only generate the UTC time once, since\nit could be possible that there will be a second difference, and we only\nneed to call it just once.\n\nby black.dex@gmail.com\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -239,7 +239,7 @@ fn post_password(data: JsonUpcase<ChangePassData>, headers: Headers, conn: DbCon\n \n     user.set_password(\n         &data.NewMasterPasswordHash,\n-        Some(vec![String::from(\"post_rotatekey\"), String::from(\"get_contacts\")]),\n+        Some(vec![String::from(\"post_rotatekey\"), String::from(\"get_contacts\"), String::from(\"get_public_keys\")]),\n     );\n     user.akey = data.Key;\n     user.save(&conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "b4c95fb4ac5176ffc17f408e15e12b6e19a17c71",
            "timestamp": "2021-09-22T21:39:31+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Hide some warnings for unused struct fields",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -49,6 +49,7 @@ struct RegisterData {\n     MasterPasswordHint: Option<String>,\n     Name: Option<String>,\n     Token: Option<String>,\n+    #[allow(dead_code)]\n     OrganizationUserId: Option<String>,\n }\n \n",
            "comment_added_diff": []
        }
    ],
    "folders.rs": [
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -59,7 +59,7 @@ pub struct FolderData {\n fn post_folders(data: JsonUpcase<FolderData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     let data: FolderData = data.into_inner().data;\n \n-    let mut folder = Folder::new(headers.user.uuid.clone(), data.Name);\n+    let mut folder = Folder::new(headers.user.uuid, data.Name);\n \n     folder.save(&conn)?;\n     nt.send_folder_update(UpdateType::FolderCreate, &folder);\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -50,7 +50,6 @@ fn get_folder(uuid: String, headers: Headers, conn: DbConn) -> JsonResult {\n \n #[derive(Deserialize)]\n #[allow(non_snake_case)]\n-\n pub struct FolderData {\n     pub Name: String,\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 6,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -1,15 +1,13 @@\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use crate::db::models::*;\n-use crate::db::DbConn;\n+use crate::{\n+    api::{EmptyResult, JsonResult, JsonUpcase, Notify, UpdateType},\n+    auth::Headers,\n+    db::{models::*, DbConn},\n+};\n \n-use crate::api::{EmptyResult, JsonResult, JsonUpcase, Notify, UpdateType};\n-use crate::auth::Headers;\n-\n-use rocket::Route;\n-\n-pub fn routes() -> Vec<Route> {\n+pub fn routes() -> Vec<rocket::Route> {\n     routes![\n         get_folders,\n         get_folder,\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -20,16 +20,16 @@ pub fn routes() -> Vec<rocket::Route> {\n }\n \n #[get(\"/folders\")]\n-fn get_folders(headers: Headers, conn: DbConn) -> JsonResult {\n+fn get_folders(headers: Headers, conn: DbConn) -> Json<Value> {\n     let folders = Folder::find_by_user(&headers.user.uuid, &conn);\n \n     let folders_json: Vec<Value> = folders.iter().map(Folder::to_json).collect();\n \n-    Ok(Json(json!({\n+    Json(json!({\n       \"Data\": folders_json,\n       \"Object\": \"list\",\n       \"ContinuationToken\": null,\n-    })))\n+    }))\n }\n \n #[get(\"/folders/<uuid>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 1,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -8,15 +8,7 @@ use crate::{\n };\n \n pub fn routes() -> Vec<rocket::Route> {\n-    routes![\n-        get_folders,\n-        get_folder,\n-        post_folders,\n-        post_folder,\n-        put_folder,\n-        delete_folder_post,\n-        delete_folder,\n-    ]\n+    routes![get_folders, get_folder, post_folders, post_folder, put_folder, delete_folder_post, delete_folder,]\n }\n \n #[get(\"/folders\")]\n",
            "comment_added_diff": []
        }
    ],
    "organizations.rs": [
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -77,7 +77,7 @@ fn create_organization(headers: Headers, data: JsonUpcase<OrgData>, conn: DbConn\n     let data: OrgData = data.into_inner().data;\n \n     let org = Organization::new(data.Name, data.BillingEmail);\n-    let mut user_org = UserOrganization::new(headers.user.uuid.clone(), org.uuid.clone());\n+    let mut user_org = UserOrganization::new(headers.user.uuid, org.uuid.clone());\n     let collection = Collection::new(org.uuid.clone(), data.CollectionName);\n \n     user_org.akey = data.Key;\n@@ -221,7 +221,7 @@ fn post_organization_collections(\n         None => err!(\"Can't find organization details\"),\n     };\n \n-    let collection = Collection::new(org.uuid.clone(), data.Name);\n+    let collection = Collection::new(org.uuid, data.Name);\n     collection.save(&conn)?;\n \n     Ok(Json(collection.to_json()))\n@@ -262,7 +262,7 @@ fn post_organization_collection_update(\n         err!(\"Collection is not owned by organization\");\n     }\n \n-    collection.name = data.Name.clone();\n+    collection.name = data.Name;\n     collection.save(&conn)?;\n \n     Ok(Json(collection.to_json()))\n@@ -581,7 +581,7 @@ fn reinvite_user(org_id: String, user_org: String, headers: AdminHeaders, conn:\n             Some(headers.user.email),\n         )?;\n     } else {\n-        let invitation = Invitation::new(user.email.clone());\n+        let invitation = Invitation::new(user.email);\n         invitation.save(&conn)?;\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 63,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -2,6 +2,7 @@ use rocket::request::Form;\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n+use num_traits::FromPrimitive;\n \n use crate::api::{\n     EmptyResult, JsonResult, JsonUpcase, JsonUpcaseVec, Notify, NumberOrString, PasswordData, UpdateType,\n@@ -45,6 +46,9 @@ pub fn routes() -> Vec<Route> {\n         delete_user,\n         post_delete_user,\n         post_org_import,\n+        list_policies,\n+        get_policy,\n+        put_policy,\n     ]\n }\n \n@@ -830,22 +834,13 @@ struct RelationsData {\n fn post_org_import(\n     query: Form<OrgIdData>,\n     data: JsonUpcase<ImportData>,\n-    headers: Headers,\n+    headers: AdminHeaders,\n     conn: DbConn,\n     nt: Notify,\n ) -> EmptyResult {\n     let data: ImportData = data.into_inner().data;\n     let org_id = query.into_inner().organization_id;\n \n-    let org_user = match UserOrganization::find_by_user_and_org(&headers.user.uuid, &org_id, &conn) {\n-        Some(user) => user,\n-        None => err!(\"User is not part of the organization\"),\n-    };\n-\n-    if org_user.atype < UserOrgType::Admin {\n-        err!(\"Only admins or owners can import into an organization\")\n-    }\n-\n     // Read and create the collections\n     let collections: Vec<_> = data\n         .Collections\n@@ -866,6 +861,8 @@ fn post_org_import(\n         relations.push((relation.Key, relation.Value));\n     }\n \n+    let headers: Headers = headers.into();\n+\n     // Read and create the ciphers\n     let ciphers: Vec<_> = data\n         .Ciphers\n@@ -901,3 +898,59 @@ fn post_org_import(\n     let mut user = headers.user;\n     user.update_revision(&conn)\n }\n+\n+#[get(\"/organizations/<org_id>/policies\")]\n+fn list_policies(org_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+    let policies = OrgPolicy::find_by_org(&org_id, &conn);\n+    let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n+\n+    Ok(Json(json!({\n+        \"Data\": policies_json,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    })))\n+}\n+\n+#[get(\"/organizations/<org_id>/policies/<pol_type>\")]\n+fn get_policy(org_id: String, pol_type: i32, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+    let pol_type_enum = match OrgPolicyType::from_i32(pol_type) {\n+        Some(pt) => pt,\n+        None => err!(\"Invalid policy type\"),\n+    };\n+\n+    let policy = match OrgPolicy::find_by_org_and_type(&org_id, pol_type, &conn) {\n+        Some(p) => p,\n+        None => OrgPolicy::new(org_id, pol_type_enum, \"{}\".to_string()),\n+    };\n+\n+    Ok(Json(policy.to_json()))\n+}\n+\n+#[derive(Deserialize)]\n+struct PolicyData {\n+    enabled: bool,\n+    #[serde(rename = \"type\")]\n+    _type: i32,\n+    data: Value,\n+}\n+\n+#[put(\"/organizations/<org_id>/policies/<pol_type>\", data = \"<data>\")]\n+fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+    let data: PolicyData = data.into_inner();\n+\n+    let pol_type_enum = match OrgPolicyType::from_i32(pol_type) {\n+        Some(pt) => pt,\n+        None => err!(\"Invalid policy type\"),\n+    };\n+\n+    let mut policy = match OrgPolicy::find_by_org_and_type(&org_id, pol_type, &conn) {\n+        Some(p) => p,\n+        None => OrgPolicy::new(org_id, pol_type_enum, \"{}\".to_string()),\n+    };\n+\n+    policy.enabled = data.enabled;\n+    policy.data = serde_json::to_string(&data.data)?;\n+    policy.save(&conn)?;\n+\n+    Ok(Json(policy.to_json()))\n+}\n\\ No newline at end of file\n",
            "comment_added_diff": []
        },
        {
            "commit": "94341f9f3f273eaa14b058c310f39dd6536f84cb",
            "timestamp": "2020-03-20T10:51:17+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix token error while accepting invite",
            "additions": 25,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -47,6 +47,7 @@ pub fn routes() -> Vec<Route> {\n         post_delete_user,\n         post_org_import,\n         list_policies,\n+        list_policies_token,\n         get_policy,\n         put_policy,\n     ]\n@@ -911,6 +912,30 @@ fn list_policies(org_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonRe\n     })))\n }\n \n+#[get(\"/organizations/<org_id>/policies/token?<token>\")]\n+fn list_policies_token(org_id: String, token: String, conn: DbConn) -> JsonResult {\n+    let invite = crate::auth::decode_invite(&token)?;\n+\n+    let invite_org_id = match invite.org_id {\n+        Some(invite_org_id) => invite_org_id,\n+        None => err!(\"Invalid token\"),\n+    };\n+\n+    if invite_org_id != org_id {\n+        err!(\"Token doesn't match request organization\");\n+    }\n+    \n+    // TODO: We receive the invite token as ?token=<>, validate it contains the org id\n+    let policies = OrgPolicy::find_by_org(&org_id, &conn);\n+    let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n+\n+    Ok(Json(json!({\n+        \"Data\": policies_json,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    })))\n+}\n+\n #[get(\"/organizations/<org_id>/policies/<pol_type>\")]\n fn get_policy(org_id: String, pol_type: i32, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n     let pol_type_enum = match OrgPolicyType::from_i32(pol_type) {\n",
            "comment_added_diff": [
                [
                    928,
                    "    // TODO: We receive the invite token as ?token=<>, validate it contains the org id"
                ]
            ]
        },
        {
            "commit": "e4d08836e2ccc8bd4f1b926f306aa881f26a33d8",
            "timestamp": "2020-04-09T01:51:05-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Make org owner invitations respect the email domain whitelist\n\nThis closes a loophole where org owners can invite new users from any domain.",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -485,7 +485,11 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n         let user = match User::find_by_mail(&email, &conn) {\n             None => {\n                 if !CONFIG.invitations_allowed() {\n-                    err!(format!(\"User email does not exist: {}\", email))\n+                    err!(format!(\"User does not exist: {}\", email))\n+                }\n+\n+                if !CONFIG.signups_domains_whitelist().is_empty() && !CONFIG.is_email_domain_whitelisted(&email) {\n+                    err!(\"Email domain not eligible for invitations\")\n                 }\n \n                 if !CONFIG.mail_enabled() {\n@@ -978,4 +982,4 @@ fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: A\n     policy.save(&conn)?;\n \n     Ok(Json(policy.to_json()))\n-}\n\\ No newline at end of file\n+}\n",
            "comment_added_diff": []
        },
        {
            "commit": "6a8c65493f2194c065705bfd180b4106e9db6478",
            "timestamp": "2020-05-08T13:37:40-04:00",
            "author": "theycallmesteve",
            "commit_message": "Rename collection_user_details to collection_read_only to reflect the response model",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -374,7 +374,7 @@ fn get_collection_users(org_id: String, coll_id: String, _headers: AdminHeaders,\n         .map(|col_user| {\n             UserOrganization::find_by_user_and_org(&col_user.user_uuid, &org_id, &conn)\n                 .unwrap()\n-                .to_json_collection_user_details(col_user.read_only)\n+                .to_json_read_only(col_user.read_only)\n         })\n         .collect();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "a3149335571d47af810aff3665665f0eb5c9f168",
            "timestamp": "2020-05-24T14:38:19-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Allow email changes for existing accounts even when signups are disabled",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -488,7 +488,7 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n                     err!(format!(\"User does not exist: {}\", email))\n                 }\n \n-                if !CONFIG.signups_domains_whitelist().is_empty() && !CONFIG.is_email_domain_whitelisted(&email) {\n+                if !CONFIG.is_email_domain_allowed(&email) {\n                     err!(\"Email domain not eligible for invitations\")\n                 }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 11,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -374,7 +374,7 @@ fn get_collection_users(org_id: String, coll_id: String, _headers: AdminHeaders,\n         .map(|col_user| {\n             UserOrganization::find_by_user_and_org(&col_user.user_uuid, &org_id, &conn)\n                 .unwrap()\n-                .to_json_read_only(col_user.read_only)\n+                .to_json_user_access_restrictions(&col_user)\n         })\n         .collect();\n \n@@ -408,7 +408,9 @@ fn put_collection_users(\n             continue;\n         }\n \n-        CollectionUser::save(&user.user_uuid, &coll_id, d.ReadOnly, &conn)?;\n+        CollectionUser::save(&user.user_uuid, &coll_id,\n+                             d.ReadOnly, d.HidePasswords,\n+                             &conn)?;\n     }\n \n     Ok(())\n@@ -452,6 +454,7 @@ fn get_org_users(org_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonRe\n struct CollectionData {\n     Id: String,\n     ReadOnly: bool,\n+    HidePasswords: bool,\n }\n \n #[derive(Deserialize)]\n@@ -523,7 +526,9 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n                 match Collection::find_by_uuid_and_org(&col.Id, &org_id, &conn) {\n                     None => err!(\"Collection not found in Organization\"),\n                     Some(collection) => {\n-                        CollectionUser::save(&user.uuid, &collection.uuid, col.ReadOnly, &conn)?;\n+                        CollectionUser::save(&user.uuid, &collection.uuid,\n+                                             col.ReadOnly, col.HidePasswords,\n+                                             &conn)?;\n                     }\n                 }\n             }\n@@ -778,7 +783,9 @@ fn edit_user(\n             match Collection::find_by_uuid_and_org(&col.Id, &org_id, &conn) {\n                 None => err!(\"Collection not found in Organization\"),\n                 Some(collection) => {\n-                    CollectionUser::save(&user_to_edit.user_uuid, &collection.uuid, col.ReadOnly, &conn)?;\n+                    CollectionUser::save(&user_to_edit.user_uuid, &collection.uuid,\n+                                         col.ReadOnly, col.HidePasswords,\n+                                         &conn)?;\n                 }\n             }\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 8,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -1,17 +1,14 @@\n-use rocket::request::Form;\n-use rocket::Route;\n+use num_traits::FromPrimitive;\n+use rocket::{request::Form, Route};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n-use num_traits::FromPrimitive;\n \n-use crate::api::{\n-    EmptyResult, JsonResult, JsonUpcase, JsonUpcaseVec, Notify, NumberOrString, PasswordData, UpdateType,\n+use crate::{\n+    api::{EmptyResult, JsonResult, JsonUpcase, JsonUpcaseVec, Notify, NumberOrString, PasswordData, UpdateType},\n+    auth::{decode_invite, AdminHeaders, Headers, OwnerHeaders},\n+    db::{models::*, DbConn},\n+    mail, CONFIG,\n };\n-use crate::auth::{decode_invite, AdminHeaders, Headers, OwnerHeaders};\n-use crate::db::models::*;\n-use crate::db::DbConn;\n-use crate::mail;\n-use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n     routes![\n@@ -935,7 +932,7 @@ fn list_policies_token(org_id: String, token: String, conn: DbConn) -> JsonResul\n     if invite_org_id != org_id {\n         err!(\"Token doesn't match request organization\");\n     }\n-    \n+\n     // TODO: We receive the invite token as ?token=<>, validate it contains the org id\n     let policies = OrgPolicy::find_by_org(&org_id, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n",
            "comment_added_diff": []
        },
        {
            "commit": "570d6c8bf97d6c554a9f5265c9cc9aa4e8482f24",
            "timestamp": "2020-08-05T22:35:29-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for restricting org creation to certain users",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -76,6 +76,10 @@ struct NewCollectionData {\n \n #[post(\"/organizations\", data = \"<data>\")]\n fn create_organization(headers: Headers, data: JsonUpcase<OrgData>, conn: DbConn) -> JsonResult {\n+    if !CONFIG.is_org_creation_allowed(&headers.user.email) {\n+        err!(\"User not allowed to create organizations\")\n+    }\n+\n     let data: OrgData = data.into_inner().data;\n \n     let org = Organization::new(data.Name, data.BillingEmail);\n",
            "comment_added_diff": []
        },
        {
            "commit": "9a478216424733b731ef23924c8d9b629ad08cf9",
            "timestamp": "2020-09-14T08:34:17+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed creating a new organization\n\n- The new web-vault needs a new api endpoint.\n- Added this new endpoint.\n\nFixes #1139",
            "additions": 53,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -47,6 +47,7 @@ pub fn routes() -> Vec<Route> {\n         list_policies_token,\n         get_policy,\n         put_policy,\n+        get_plans,\n     ]\n }\n \n@@ -991,3 +992,55 @@ fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: A\n \n     Ok(Json(policy.to_json()))\n }\n+\n+#[get(\"/plans\")]\n+fn get_plans(_headers: Headers, _conn: DbConn) -> JsonResult {\n+    Ok(Json(json!({\n+        \"Object\": \"list\",\n+        \"Data\": [\n+        {\n+            \"Object\": \"plan\",\n+            \"Type\": 0,\n+            \"Product\": 0,\n+            \"Name\": \"Free\",\n+            \"IsAnnual\": false,\n+            \"NameLocalizationKey\": \"planNameFree\",\n+            \"DescriptionLocalizationKey\": \"planDescFree\",\n+            \"CanBeUsedByBusiness\": false,\n+            \"BaseSeats\": 2,\n+            \"BaseStorageGb\": null,\n+            \"MaxCollections\": 2,\n+            \"MaxUsers\": 2,\n+            \"HasAdditionalSeatsOption\": false,\n+            \"MaxAdditionalSeats\": null,\n+            \"HasAdditionalStorageOption\": false,\n+            \"MaxAdditionalStorage\": null,\n+            \"HasPremiumAccessOption\": false,\n+            \"TrialPeriodDays\": null,\n+            \"HasSelfHost\": false,\n+            \"HasPolicies\": false,\n+            \"HasGroups\": false,\n+            \"HasDirectory\": false,\n+            \"HasEvents\": false,\n+            \"HasTotp\": false,\n+            \"Has2fa\": false,\n+            \"HasApi\": false,\n+            \"HasSso\": false,\n+            \"UsersGetPremium\": false,\n+            \"UpgradeSortOrder\": -1,\n+            \"DisplaySortOrder\": -1,\n+            \"LegacyYear\": null,\n+            \"Disabled\": false,\n+            \"StripePlanId\": null,\n+            \"StripeSeatPlanId\": null,\n+            \"StripeStoragePlanId\": null,\n+            \"StripePremiumAccessPlanId\": null,\n+            \"BasePrice\": 0.0,\n+            \"SeatPrice\": 0.0,\n+            \"AdditionalStoragePricePerGb\": 0.0,\n+            \"PremiumAccessOptionPrice\": 0.0\n+            }\n+        ],\n+        \"ContinuationToken\": null\n+    })))\n+}\n\\ No newline at end of file\n",
            "comment_added_diff": []
        },
        {
            "commit": "7cf8809d777cd88ad5aa932324e51561724e3c32",
            "timestamp": "2020-12-02T22:50:51+01:00",
            "author": "BlackDex",
            "commit_message": "Adding Manager Role support\n\nThis has been requested a few times (#1136 & #246 & forum), and there already were two\n(1:1 duplicate) PR's (#1222 & #1223) which needed some changes and no\nfollowups or further comments unfortunally.\n\nThis PR adds two auth headers.\n- ManagerHeaders\n  Checks if the user-type is Manager or higher and if the manager is\npart of that collection or not.\n- ManagerHeadersLoose\n  Check if the user-type is Manager or higher, but does not check if the\nuser is part of the collection, needed for a few features like\nretreiving all the users of an org.\n\nI think this is the safest way to implement this instead of having to\ncheck this within every function which needs this manually.\n\nAlso some extra checks if a manager has access to all collections or\njust a selection.\n\nfixes #1136",
            "additions": 23,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ use serde_json::Value;\n \n use crate::{\n     api::{EmptyResult, JsonResult, JsonUpcase, JsonUpcaseVec, Notify, NumberOrString, PasswordData, UpdateType},\n-    auth::{decode_invite, AdminHeaders, Headers, OwnerHeaders},\n+    auth::{decode_invite, AdminHeaders, Headers, OwnerHeaders, ManagerHeaders, ManagerHeadersLoose},\n     db::{models::*, DbConn},\n     mail, CONFIG,\n };\n@@ -217,7 +217,7 @@ fn get_org_collections(org_id: String, _headers: AdminHeaders, conn: DbConn) ->\n #[post(\"/organizations/<org_id>/collections\", data = \"<data>\")]\n fn post_organization_collections(\n     org_id: String,\n-    _headers: AdminHeaders,\n+    headers: ManagerHeadersLoose,\n     data: JsonUpcase<NewCollectionData>,\n     conn: DbConn,\n ) -> JsonResult {\n@@ -228,9 +228,22 @@ fn post_organization_collections(\n         None => err!(\"Can't find organization details\"),\n     };\n \n+    // Get the user_organization record so that we can check if the user has access to all collections.\n+    let user_org = match UserOrganization::find_by_user_and_org(&headers.user.uuid, &org_id, &conn) {\n+        Some(u) => u,\n+        None => err!(\"User is not part of organization\"),\n+    };\n+\n     let collection = Collection::new(org.uuid, data.Name);\n     collection.save(&conn)?;\n \n+    // If the user doesn't have access to all collections, only in case of a Manger,\n+    // then we need to save the creating user uuid (Manager) to the users_collection table.\n+    // Else the user will not have access to his own created collection.\n+    if !user_org.access_all {\n+        CollectionUser::save(&headers.user.uuid, &collection.uuid, false, false, &conn)?;\n+    }\n+\n     Ok(Json(collection.to_json()))\n }\n \n@@ -238,7 +251,7 @@ fn post_organization_collections(\n fn put_organization_collection_update(\n     org_id: String,\n     col_id: String,\n-    headers: AdminHeaders,\n+    headers: ManagerHeaders,\n     data: JsonUpcase<NewCollectionData>,\n     conn: DbConn,\n ) -> JsonResult {\n@@ -249,7 +262,7 @@ fn put_organization_collection_update(\n fn post_organization_collection_update(\n     org_id: String,\n     col_id: String,\n-    _headers: AdminHeaders,\n+    _headers: ManagerHeaders,\n     data: JsonUpcase<NewCollectionData>,\n     conn: DbConn,\n ) -> JsonResult {\n@@ -317,7 +330,7 @@ fn post_organization_collection_delete_user(\n }\n \n #[delete(\"/organizations/<org_id>/collections/<col_id>\")]\n-fn delete_organization_collection(org_id: String, col_id: String, _headers: AdminHeaders, conn: DbConn) -> EmptyResult {\n+fn delete_organization_collection(org_id: String, col_id: String, _headers: ManagerHeaders, conn: DbConn) -> EmptyResult {\n     match Collection::find_by_uuid(&col_id, &conn) {\n         None => err!(\"Collection not found\"),\n         Some(collection) => {\n@@ -341,7 +354,7 @@ struct DeleteCollectionData {\n fn post_organization_collection_delete(\n     org_id: String,\n     col_id: String,\n-    headers: AdminHeaders,\n+    headers: ManagerHeaders,\n     _data: JsonUpcase<DeleteCollectionData>,\n     conn: DbConn,\n ) -> EmptyResult {\n@@ -349,7 +362,7 @@ fn post_organization_collection_delete(\n }\n \n #[get(\"/organizations/<org_id>/collections/<coll_id>/details\")]\n-fn get_org_collection_detail(org_id: String, coll_id: String, headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+fn get_org_collection_detail(org_id: String, coll_id: String, headers: ManagerHeaders, conn: DbConn) -> JsonResult {\n     match Collection::find_by_uuid_and_user(&coll_id, &headers.user.uuid, &conn) {\n         None => err!(\"Collection not found\"),\n         Some(collection) => {\n@@ -363,7 +376,7 @@ fn get_org_collection_detail(org_id: String, coll_id: String, headers: AdminHead\n }\n \n #[get(\"/organizations/<org_id>/collections/<coll_id>/users\")]\n-fn get_collection_users(org_id: String, coll_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+fn get_collection_users(org_id: String, coll_id: String, _headers: ManagerHeaders, conn: DbConn) -> JsonResult {\n     // Get org and collection, check that collection is from org\n     let collection = match Collection::find_by_uuid_and_org(&coll_id, &org_id, &conn) {\n         None => err!(\"Collection not found in Organization\"),\n@@ -388,7 +401,7 @@ fn put_collection_users(\n     org_id: String,\n     coll_id: String,\n     data: JsonUpcaseVec<CollectionData>,\n-    _headers: AdminHeaders,\n+    _headers: ManagerHeaders,\n     conn: DbConn,\n ) -> EmptyResult {\n     // Get org and collection, check that collection is from org\n@@ -440,7 +453,7 @@ fn get_org_details(data: Form<OrgIdData>, headers: Headers, conn: DbConn) -> Jso\n }\n \n #[get(\"/organizations/<org_id>/users\")]\n-fn get_org_users(org_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+fn get_org_users(org_id: String, _headers: ManagerHeadersLoose, conn: DbConn) -> JsonResult {\n     let users = UserOrganization::find_by_org(&org_id, &conn);\n     let users_json: Vec<Value> = users.iter().map(|c| c.to_json_user_details(&conn)).collect();\n \n",
            "comment_added_diff": [
                [
                    231,
                    "    // Get the user_organization record so that we can check if the user has access to all collections."
                ],
                [
                    240,
                    "    // If the user doesn't have access to all collections, only in case of a Manger,"
                ],
                [
                    241,
                    "    // then we need to save the creating user uuid (Manager) to the users_collection table."
                ],
                [
                    242,
                    "    // Else the user will not have access to his own created collection."
                ]
            ]
        },
        {
            "commit": "9f86196a9d537ce8295add4c4fe682d5565e63fe",
            "timestamp": "2021-01-23T20:50:06-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Personal Ownership policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1013\n* https://bitwarden.com/help/article/policies/#personal-ownership",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -966,7 +966,7 @@ fn list_policies_token(org_id: String, token: String, conn: DbConn) -> JsonResul\n fn get_policy(org_id: String, pol_type: i32, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n     let pol_type_enum = match OrgPolicyType::from_i32(pol_type) {\n         Some(pt) => pt,\n-        None => err!(\"Invalid policy type\"),\n+        None => err!(\"Invalid or unsupported policy type\"),\n     };\n \n     let policy = match OrgPolicy::find_by_org_and_type(&org_id, pol_type, &conn) {\n@@ -1056,4 +1056,4 @@ fn get_plans(_headers: Headers, _conn: DbConn) -> JsonResult {\n         ],\n         \"ContinuationToken\": null\n     })))\n-}\n\\ No newline at end of file\n+}\n",
            "comment_added_diff": []
        },
        {
            "commit": "7dff8c01dd86f69761f4822b8b0c41709f03f271",
            "timestamp": "2021-01-31T21:46:37+01:00",
            "author": "BlackDex",
            "commit_message": "JSON Response updates and small fixes\n\nUpdated several json response models.\nAlso fixed a few small bugs.\n\nciphers.rs:\n  - post_ciphers_create:\n    * Prevent cipher creation to organization without a collection.\n  - update_cipher_from_data:\n    * ~~Fixed removal of user_uuid which prevent user-owned shared-cipher to be not editable anymore when set to read-only.~~\n    * Cleanup the json_data by removing the `Response` key/values from several objects.\n  - delete_all:\n    * Do not delete all Collections during the Purge of an Organization (same as upstream).\n\ncipher.rs:\n  - Cipher::to_json:\n    * Updated json response to match upstream.\n    * Return empty json object if there is no type_data instead of values which should not be set for the type_data.\n\norganizations.rs:\n  * Added two new endpoints to prevent Javascript errors regarding tax\n\norganization.rs:\n  - Organization::to_json:\n    * Updated response model to match upstream\n  - UserOrganization::to_json:\n    * Updated response model to match upstream\n\ncollection.rs:\n  - Collection::{to_json, to_json_details}:\n    * Updated the json response model, and added a detailed version used during the sync\n  - hide_passwords_for_user:\n    * Added this function to return if the passwords should be hidden or not for the user at the specific collection (used by `to_json_details`)\n\nUpdate 1: Some small changes after comments from @jjlin.\nUpdate 2: Fixed vault purge by user to make sure the cipher is not part of an organization.\n\nResolves #971\nCloses #990, Closes #991",
            "additions": 19,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -47,7 +47,9 @@ pub fn routes() -> Vec<Route> {\n         list_policies_token,\n         get_policy,\n         put_policy,\n+        get_organization_tax,\n         get_plans,\n+        get_plans_tax_rates,\n     ]\n }\n \n@@ -1006,6 +1008,13 @@ fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: A\n     Ok(Json(policy.to_json()))\n }\n \n+#[allow(unused_variables)]\n+#[get(\"/organizations/<org_id>/tax\")]\n+fn get_organization_tax(org_id: String, _headers: Headers, _conn: DbConn) -> EmptyResult {\n+    // Prevent a 404 error, which also causes Javascript errors.\n+    err!(\"Only allowed when not self hosted.\")\n+}\n+\n #[get(\"/plans\")]\n fn get_plans(_headers: Headers, _conn: DbConn) -> JsonResult {\n     Ok(Json(json!({\n@@ -1057,3 +1066,13 @@ fn get_plans(_headers: Headers, _conn: DbConn) -> JsonResult {\n         \"ContinuationToken\": null\n     })))\n }\n+\n+#[get(\"/plans/sales-tax-rates\")]\n+fn get_plans_tax_rates(_headers: Headers, _conn: DbConn) -> JsonResult {\n+    // Prevent a 404 error, which also causes Javascript errors.\n+    Ok(Json(json!({\n+        \"Object\": \"list\",\n+        \"Data\": [],\n+        \"ContinuationToken\": null\n+    })))\n+}\n",
            "comment_added_diff": [
                [
                    1014,
                    "    // Prevent a 404 error, which also causes Javascript errors."
                ],
                [
                    1072,
                    "    // Prevent a 404 error, which also causes Javascript errors."
                ]
            ]
        },
        {
            "commit": "85e3c73525d327042c1ad142e48c044a5dbdd89c",
            "timestamp": "2021-02-06T20:15:42+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Basic experimental ldap import support with the official directory connector",
            "additions": 99,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -50,6 +50,7 @@ pub fn routes() -> Vec<Route> {\n         get_organization_tax,\n         get_plans,\n         get_plans_tax_rates,\n+        import,\n     ]\n }\n \n@@ -1076,3 +1077,101 @@ fn get_plans_tax_rates(_headers: Headers, _conn: DbConn) -> JsonResult {\n         \"ContinuationToken\": null\n     })))\n }\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct OrgImportGroupData {\n+    Name: String,       // \"GroupName\"\n+    ExternalId: String, // \"cn=GroupName,ou=Groups,dc=example,dc=com\"\n+    Users: Vec<String>, // [\"uid=user,ou=People,dc=example,dc=com\"]\n+}\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct OrgImportUserData {\n+    Email: String,      // \"user@maildomain.net\"\n+    ExternalId: String, // \"uid=user,ou=People,dc=example,dc=com\"\n+    Deleted: bool,\n+}\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct OrgImportData {\n+    Groups: Vec<OrgImportGroupData>,\n+    OverwriteExisting: bool,\n+    Users: Vec<OrgImportUserData>,\n+}\n+\n+#[post(\"/organizations/<org_id>/import\", data = \"<data>\")]\n+fn import(org_id: String, data: JsonUpcase<OrgImportData>, headers: Headers, conn: DbConn) -> EmptyResult {\n+    let data = data.into_inner().data;\n+    println!(\"{:#?}\", data);\n+\n+    // TODO: Currently we aren't storing the externalId's anywhere, so we also don't have a way\n+    // to differentiate between auto-imported users and manually added ones.\n+    // This means that this endpoint can end up removing users that were added manually by an admin,\n+    // as opposed to upstream which only removes auto-imported users.\n+\n+    // User needs to be admin or owner to use the Directry Connector\n+    match UserOrganization::find_by_user_and_org(&headers.user.uuid, &org_id, &conn) {\n+        Some(user_org) if user_org.atype >= UserOrgType::Admin => { /* Okay, nothing to do */ }\n+        Some(_) => err!(\"User has insufficient permissions to use Directory Connector\"),\n+        None => err!(\"User not part of organization\"),\n+    };\n+\n+    for user_data in &data.Users {\n+        if user_data.Deleted {\n+            // If user is marked for deletion and it exists, delete it\n+            if let Some(user_org) = UserOrganization::find_by_email_and_org(&user_data.Email, &org_id, &conn) {\n+                user_org.delete(&conn)?;\n+            }\n+\n+        // If user is not part of the organization, but it exists\n+        } else if UserOrganization::find_by_email_and_org(&user_data.Email, &org_id, &conn).is_none() {\n+            if let Some (user) = User::find_by_mail(&user_data.Email, &conn) {\n+                \n+                let user_org_status = if CONFIG.mail_enabled() {\n+                    UserOrgStatus::Invited as i32\n+                } else {\n+                    UserOrgStatus::Accepted as i32 // Automatically mark user as accepted if no email invites\n+                };\n+\n+                let mut new_org_user = UserOrganization::new(user.uuid.clone(), org_id.clone());\n+                new_org_user.access_all = false;\n+                new_org_user.atype = UserOrgType::User as i32;\n+                new_org_user.status = user_org_status;\n+\n+                new_org_user.save(&conn)?;\n+\n+                if CONFIG.mail_enabled() {\n+                    let org_name = match Organization::find_by_uuid(&org_id, &conn) {\n+                        Some(org) => org.name,\n+                        None => err!(\"Error looking up organization\"),\n+                    };\n+\n+                    mail::send_invite(\n+                        &user_data.Email,\n+                        &user.uuid,\n+                        Some(org_id.clone()),\n+                        Some(new_org_user.uuid),\n+                        &org_name,\n+                        Some(headers.user.email.clone()),\n+                    )?;\n+                }\n+            }  \n+        }\n+    }\n+\n+    // If this flag is enabled, any user that isn't provided in the Users list will be removed (by default they will be kept unless they have Deleted == true)\n+    if data.OverwriteExisting {\n+        for user_org in UserOrganization::find_by_org_and_type(&org_id, UserOrgType::User as i32, &conn) {  \n+            if let Some (user_email) = User::find_by_uuid(&user_org.user_uuid, &conn).map(|u| u.email) {\n+                if !data.Users.iter().any(|u| u.Email == user_email) {\n+                    user_org.delete(&conn)?;\n+                }\n+            } \n+        }\n+    }\n+\n+    Ok(())\n+}\n",
            "comment_added_diff": [
                [
                    1084,
                    "    Name: String,       // \"GroupName\""
                ],
                [
                    1085,
                    "    ExternalId: String, // \"cn=GroupName,ou=Groups,dc=example,dc=com\""
                ],
                [
                    1086,
                    "    Users: Vec<String>, // [\"uid=user,ou=People,dc=example,dc=com\"]"
                ],
                [
                    1092,
                    "    Email: String,      // \"user@maildomain.net\""
                ],
                [
                    1093,
                    "    ExternalId: String, // \"uid=user,ou=People,dc=example,dc=com\""
                ],
                [
                    1110,
                    "    // TODO: Currently we aren't storing the externalId's anywhere, so we also don't have a way"
                ],
                [
                    1111,
                    "    // to differentiate between auto-imported users and manually added ones."
                ],
                [
                    1112,
                    "    // This means that this endpoint can end up removing users that were added manually by an admin,"
                ],
                [
                    1113,
                    "    // as opposed to upstream which only removes auto-imported users."
                ],
                [
                    1115,
                    "    // User needs to be admin or owner to use the Directry Connector"
                ],
                [
                    1124,
                    "            // If user is marked for deletion and it exists, delete it"
                ],
                [
                    1129,
                    "        // If user is not part of the organization, but it exists"
                ],
                [
                    1136,
                    "                    UserOrgStatus::Accepted as i32 // Automatically mark user as accepted if no email invites"
                ],
                [
                    1165,
                    "    // If this flag is enabled, any user that isn't provided in the Users list will be removed (by default they will be kept unless they have Deleted == true)"
                ]
            ]
        },
        {
            "commit": "9323c57f498815e088448bf82414d411700d636e",
            "timestamp": "2021-02-07T00:22:39+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug print",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1105,7 +1105,6 @@ struct OrgImportData {\n #[post(\"/organizations/<org_id>/import\", data = \"<data>\")]\n fn import(org_id: String, data: JsonUpcase<OrgImportData>, headers: Headers, conn: DbConn) -> EmptyResult {\n     let data = data.into_inner().data;\n-    println!(\"{:#?}\", data);\n \n     // TODO: Currently we aren't storing the externalId's anywhere, so we also don't have a way\n     // to differentiate between auto-imported users and manually added ones.\n",
            "comment_added_diff": []
        },
        {
            "commit": "a75d05000198bc8407e52324496def9a29a10d10",
            "timestamp": "2021-03-03T23:03:55-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix custom org name in invitation confirmation email\n\nThe org name in the invitation email was made customizable in 8867626, but\nthe org name is still hardcoded as \"bitwarden_rs\" in the confirmation email.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -655,7 +655,7 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n     }\n \n     if CONFIG.mail_enabled() {\n-        let mut org_name = String::from(\"bitwarden_rs\");\n+        let mut org_name = CONFIG.invitation_org_name();\n         if let Some(org_id) = &claims.org_id {\n             org_name = match Organization::find_by_uuid(&org_id, &conn) {\n                 Some(org) => org.name,\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 25,
            "deletions": 25,
            "change_type": "MODIFY",
            "diff": "@@ -192,8 +192,8 @@ fn post_organization(\n \n // GET /api/collections?writeOnly=false\n #[get(\"/collections\")]\n-fn get_user_collections(headers: Headers, conn: DbConn) -> JsonResult {\n-    Ok(Json(json!({\n+fn get_user_collections(headers: Headers, conn: DbConn) -> Json<Value> {\n+    Json(json!({\n         \"Data\":\n             Collection::find_by_user_uuid(&headers.user.uuid, &conn)\n             .iter()\n@@ -201,12 +201,12 @@ fn get_user_collections(headers: Headers, conn: DbConn) -> JsonResult {\n             .collect::<Value>(),\n         \"Object\": \"list\",\n         \"ContinuationToken\": null,\n-    })))\n+    }))\n }\n \n #[get(\"/organizations/<org_id>/collections\")]\n-fn get_org_collections(org_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n-    Ok(Json(json!({\n+fn get_org_collections(org_id: String, _headers: AdminHeaders, conn: DbConn) -> Json<Value> {\n+    Json(json!({\n         \"Data\":\n             Collection::find_by_organization(&org_id, &conn)\n             .iter()\n@@ -214,7 +214,7 @@ fn get_org_collections(org_id: String, _headers: AdminHeaders, conn: DbConn) ->\n             .collect::<Value>(),\n         \"Object\": \"list\",\n         \"ContinuationToken\": null,\n-    })))\n+    }))\n }\n \n #[post(\"/organizations/<org_id>/collections\", data = \"<data>\")]\n@@ -441,30 +441,30 @@ struct OrgIdData {\n }\n \n #[get(\"/ciphers/organization-details?<data..>\")]\n-fn get_org_details(data: Form<OrgIdData>, headers: Headers, conn: DbConn) -> JsonResult {\n+fn get_org_details(data: Form<OrgIdData>, headers: Headers, conn: DbConn) -> Json<Value> {\n     let ciphers = Cipher::find_by_org(&data.organization_id, &conn);\n     let ciphers_json: Vec<Value> = ciphers\n         .iter()\n         .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n         .collect();\n \n-    Ok(Json(json!({\n+    Json(json!({\n       \"Data\": ciphers_json,\n       \"Object\": \"list\",\n       \"ContinuationToken\": null,\n-    })))\n+    }))\n }\n \n #[get(\"/organizations/<org_id>/users\")]\n-fn get_org_users(org_id: String, _headers: ManagerHeadersLoose, conn: DbConn) -> JsonResult {\n+fn get_org_users(org_id: String, _headers: ManagerHeadersLoose, conn: DbConn) -> Json<Value> {\n     let users = UserOrganization::find_by_org(&org_id, &conn);\n     let users_json: Vec<Value> = users.iter().map(|c| c.to_json_user_details(&conn)).collect();\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"Data\": users_json,\n         \"Object\": \"list\",\n         \"ContinuationToken\": null,\n-    })))\n+    }))\n }\n \n #[derive(Deserialize)]\n@@ -930,15 +930,15 @@ fn post_org_import(\n }\n \n #[get(\"/organizations/<org_id>/policies\")]\n-fn list_policies(org_id: String, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+fn list_policies(org_id: String, _headers: AdminHeaders, conn: DbConn) -> Json<Value> {\n     let policies = OrgPolicy::find_by_org(&org_id, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"Data\": policies_json,\n         \"Object\": \"list\",\n         \"ContinuationToken\": null\n-    })))\n+    }))\n }\n \n #[get(\"/organizations/<org_id>/policies/token?<token>\")]\n@@ -1017,8 +1017,8 @@ fn get_organization_tax(org_id: String, _headers: Headers, _conn: DbConn) -> Emp\n }\n \n #[get(\"/plans\")]\n-fn get_plans(_headers: Headers, _conn: DbConn) -> JsonResult {\n-    Ok(Json(json!({\n+fn get_plans(_headers: Headers, _conn: DbConn) -> Json<Value> {\n+    Json(json!({\n         \"Object\": \"list\",\n         \"Data\": [\n         {\n@@ -1065,17 +1065,17 @@ fn get_plans(_headers: Headers, _conn: DbConn) -> JsonResult {\n             }\n         ],\n         \"ContinuationToken\": null\n-    })))\n+    }))\n }\n \n #[get(\"/plans/sales-tax-rates\")]\n-fn get_plans_tax_rates(_headers: Headers, _conn: DbConn) -> JsonResult {\n+fn get_plans_tax_rates(_headers: Headers, _conn: DbConn) -> Json<Value> {\n     // Prevent a 404 error, which also causes Javascript errors.\n-    Ok(Json(json!({\n+    Json(json!({\n         \"Object\": \"list\",\n         \"Data\": [],\n         \"ContinuationToken\": null\n-    })))\n+    }))\n }\n \n #[derive(Deserialize, Debug)]\n@@ -1128,7 +1128,7 @@ fn import(org_id: String, data: JsonUpcase<OrgImportData>, headers: Headers, con\n         // If user is not part of the organization, but it exists\n         } else if UserOrganization::find_by_email_and_org(&user_data.Email, &org_id, &conn).is_none() {\n             if let Some (user) = User::find_by_mail(&user_data.Email, &conn) {\n-                \n+\n                 let user_org_status = if CONFIG.mail_enabled() {\n                     UserOrgStatus::Invited as i32\n                 } else {\n@@ -1157,18 +1157,18 @@ fn import(org_id: String, data: JsonUpcase<OrgImportData>, headers: Headers, con\n                         Some(headers.user.email.clone()),\n                     )?;\n                 }\n-            }  \n+            }\n         }\n     }\n \n     // If this flag is enabled, any user that isn't provided in the Users list will be removed (by default they will be kept unless they have Deleted == true)\n     if data.OverwriteExisting {\n-        for user_org in UserOrganization::find_by_org_and_type(&org_id, UserOrgType::User as i32, &conn) {  \n+        for user_org in UserOrganization::find_by_org_and_type(&org_id, UserOrgType::User as i32, &conn) {\n             if let Some (user_email) = User::find_by_uuid(&user_org.user_uuid, &conn).map(|u| u.email) {\n                 if !data.Users.iter().any(|u| u.Email == user_email) {\n                     user_org.delete(&conn)?;\n                 }\n-            } \n+            }\n         }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 25,
            "deletions": 15,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ use serde_json::Value;\n \n use crate::{\n     api::{EmptyResult, JsonResult, JsonUpcase, JsonUpcaseVec, Notify, NumberOrString, PasswordData, UpdateType},\n-    auth::{decode_invite, AdminHeaders, Headers, OwnerHeaders, ManagerHeaders, ManagerHeadersLoose},\n+    auth::{decode_invite, AdminHeaders, Headers, ManagerHeaders, ManagerHeadersLoose, OwnerHeaders},\n     db::{models::*, DbConn},\n     mail, CONFIG,\n };\n@@ -333,7 +333,12 @@ fn post_organization_collection_delete_user(\n }\n \n #[delete(\"/organizations/<org_id>/collections/<col_id>\")]\n-fn delete_organization_collection(org_id: String, col_id: String, _headers: ManagerHeaders, conn: DbConn) -> EmptyResult {\n+fn delete_organization_collection(\n+    org_id: String,\n+    col_id: String,\n+    _headers: ManagerHeaders,\n+    conn: DbConn,\n+) -> EmptyResult {\n     match Collection::find_by_uuid(&col_id, &conn) {\n         None => err!(\"Collection not found\"),\n         Some(collection) => {\n@@ -426,9 +431,7 @@ fn put_collection_users(\n             continue;\n         }\n \n-        CollectionUser::save(&user.user_uuid, &coll_id,\n-                             d.ReadOnly, d.HidePasswords,\n-                             &conn)?;\n+        CollectionUser::save(&user.user_uuid, &coll_id, d.ReadOnly, d.HidePasswords, &conn)?;\n     }\n \n     Ok(())\n@@ -544,9 +547,7 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n                 match Collection::find_by_uuid_and_org(&col.Id, &org_id, &conn) {\n                     None => err!(\"Collection not found in Organization\"),\n                     Some(collection) => {\n-                        CollectionUser::save(&user.uuid, &collection.uuid,\n-                                             col.ReadOnly, col.HidePasswords,\n-                                             &conn)?;\n+                        CollectionUser::save(&user.uuid, &collection.uuid, col.ReadOnly, col.HidePasswords, &conn)?;\n                     }\n                 }\n             }\n@@ -801,9 +802,13 @@ fn edit_user(\n             match Collection::find_by_uuid_and_org(&col.Id, &org_id, &conn) {\n                 None => err!(\"Collection not found in Organization\"),\n                 Some(collection) => {\n-                    CollectionUser::save(&user_to_edit.user_uuid, &collection.uuid,\n-                                         col.ReadOnly, col.HidePasswords,\n-                                         &conn)?;\n+                    CollectionUser::save(\n+                        &user_to_edit.user_uuid,\n+                        &collection.uuid,\n+                        col.ReadOnly,\n+                        col.HidePasswords,\n+                        &conn,\n+                    )?;\n                 }\n             }\n         }\n@@ -989,7 +994,13 @@ struct PolicyData {\n }\n \n #[put(\"/organizations/<org_id>/policies/<pol_type>\", data = \"<data>\")]\n-fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+fn put_policy(\n+    org_id: String,\n+    pol_type: i32,\n+    data: Json<PolicyData>,\n+    _headers: AdminHeaders,\n+    conn: DbConn,\n+) -> JsonResult {\n     let data: PolicyData = data.into_inner();\n \n     let pol_type_enum = match OrgPolicyType::from_i32(pol_type) {\n@@ -1127,8 +1138,7 @@ fn import(org_id: String, data: JsonUpcase<OrgImportData>, headers: Headers, con\n \n         // If user is not part of the organization, but it exists\n         } else if UserOrganization::find_by_email_and_org(&user_data.Email, &org_id, &conn).is_none() {\n-            if let Some (user) = User::find_by_mail(&user_data.Email, &conn) {\n-\n+            if let Some(user) = User::find_by_mail(&user_data.Email, &conn) {\n                 let user_org_status = if CONFIG.mail_enabled() {\n                     UserOrgStatus::Invited as i32\n                 } else {\n@@ -1164,7 +1174,7 @@ fn import(org_id: String, data: JsonUpcase<OrgImportData>, headers: Headers, con\n     // If this flag is enabled, any user that isn't provided in the Users list will be removed (by default they will be kept unless they have Deleted == true)\n     if data.OverwriteExisting {\n         for user_org in UserOrganization::find_by_org_and_type(&org_id, UserOrgType::User as i32, &conn) {\n-            if let Some (user_email) = User::find_by_uuid(&user_org.user_uuid, &conn).map(|u| u.email) {\n+            if let Some(user_email) = User::find_by_uuid(&user_org.user_uuid, &conn).map(|u| u.email) {\n                 if !data.Users.iter().any(|u| u.Email == user_email) {\n                     user_org.delete(&conn)?;\n                 }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 4,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -446,10 +446,8 @@ struct OrgIdData {\n #[get(\"/ciphers/organization-details?<data..>\")]\n fn get_org_details(data: Form<OrgIdData>, headers: Headers, conn: DbConn) -> Json<Value> {\n     let ciphers = Cipher::find_by_org(&data.organization_id, &conn);\n-    let ciphers_json: Vec<Value> = ciphers\n-        .iter()\n-        .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n-        .collect();\n+    let ciphers_json: Vec<Value> =\n+        ciphers.iter().map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn)).collect();\n \n     Json(json!({\n       \"Data\": ciphers_json,\n@@ -904,16 +902,8 @@ fn post_org_import(\n         .into_iter()\n         .map(|cipher_data| {\n             let mut cipher = Cipher::new(cipher_data.Type, cipher_data.Name.clone());\n-            update_cipher_from_data(\n-                &mut cipher,\n-                cipher_data,\n-                &headers,\n-                false,\n-                &conn,\n-                &nt,\n-                UpdateType::CipherCreate,\n-            )\n-            .ok();\n+            update_cipher_from_data(&mut cipher, cipher_data, &headers, false, &conn, &nt, UpdateType::CipherCreate)\n+                .ok();\n             cipher\n         })\n         .collect();\n",
            "comment_added_diff": []
        },
        {
            "commit": "d75a80bd2dbe21e5a1eb2b0a6b18a9422441e071",
            "timestamp": "2021-04-11T22:57:17-04:00",
            "author": "Olivier Martin",
            "commit_message": "Resolves dani-garcia/bitwarden_rs#981\n* a user without 2fa trying to join a 2fa org will fail, but user gets an email to enable 2fa\n* a user disabling 2fa will be removed from 2fa orgs; user gets an email for each org\n* an org enabling 2fa policy will remove users without 2fa; users get an email",
            "additions": 33,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -647,6 +647,21 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n                     err!(\"User already accepted the invitation\")\n                 }\n \n+                let user_twofactor_disabled = TwoFactor::find_by_user(&user_org.user_uuid, &conn).is_empty();\n+\n+                let policy = OrgPolicyType::TwoFactorAuthentication as i32;\n+                let org_twofactor_policy_enabled = match OrgPolicy::find_by_org_and_type(&user_org.org_uuid, policy, &conn) {\n+                    Some(p) => p.enabled,\n+                    None => false,\n+                };\n+\n+                if org_twofactor_policy_enabled && user_twofactor_disabled {\n+                    let org = Organization::find_by_uuid(&org, &conn).unwrap();\n+                    // you haven't joined yet, but mail explains why you were unable to accept invitation\n+                    mail::send_2fa_removed_from_org(&claims.email, &org.name)?;\n+                    err!(\"Organization policy requires that you enable two Two-step Login begin joining.\")\n+                }\n+\n                 user_org.status = UserOrgStatus::Accepted as i32;\n                 user_org.save(&conn)?;\n             }\n@@ -996,6 +1011,24 @@ fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: A\n         Some(pt) => pt,\n         None => err!(\"Invalid policy type\"),\n     };\n+       \n+    if pol_type_enum == OrgPolicyType::TwoFactorAuthentication && data.enabled {\n+\n+        let org_list = UserOrganization::find_by_org(&org_id, &conn);\n+\n+        for user_org in org_list.into_iter() {\n+            let user_twofactor_disabled = TwoFactor::find_by_user(&user_org.user_uuid, &conn).is_empty();\n+\n+            if user_twofactor_disabled && user_org.atype < UserOrgType::Admin {\n+\n+                let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n+                let user = User::find_by_uuid(&user_org.user_uuid, &conn).unwrap();\n+\n+                mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n+                user_org.delete(&conn)?;\n+            }\n+        }        \n+    }\n \n     let mut policy = match OrgPolicy::find_by_org_and_type(&org_id, pol_type, &conn) {\n         Some(p) => p,\n",
            "comment_added_diff": [
                [
                    660,
                    "                    // you haven't joined yet, but mail explains why you were unable to accept invitation"
                ]
            ]
        },
        {
            "commit": "1db37bf3d06543c890612ff88193813035763034",
            "timestamp": "2021-04-12T21:54:57-04:00",
            "author": "Olivier Martin",
            "commit_message": "make error toast display detailed message\nreplace invite accept error message with the one from upstream\ncheck if config mail is enabled",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -656,10 +656,8 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n                 };\n \n                 if org_twofactor_policy_enabled && user_twofactor_disabled {\n-                    let org = Organization::find_by_uuid(&org, &conn).unwrap();\n-                    // you haven't joined yet, but mail explains why you were unable to accept invitation\n-                    mail::send_2fa_removed_from_org(&claims.email, &org.name)?;\n-                    err!(\"Organization policy requires that you enable two Two-step Login begin joining.\")\n+\n+                    err!(\"You cannot join this organization until you enable two-step login on your user account.\")\n                 }\n \n                 user_org.status = UserOrgStatus::Accepted as i32;\n@@ -1021,10 +1019,12 @@ fn put_policy(org_id: String, pol_type: i32, data: Json<PolicyData>, _headers: A\n \n             if user_twofactor_disabled && user_org.atype < UserOrgType::Admin {\n \n-                let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n-                let user = User::find_by_uuid(&user_org.user_uuid, &conn).unwrap();\n+                if CONFIG.mail_enabled() {\n+                    let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n+                    let user = User::find_by_uuid(&user_org.user_uuid, &conn).unwrap();\n \n-                mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n+                    mail::send_2fa_removed_from_org(&user.email, &org.name)?;\n+                }\n                 user_org.delete(&conn)?;\n             }\n         }        \n",
            "comment_added_diff": []
        },
        {
            "commit": "89a68741d6c049e827e84dc224566d1a61dda1f7",
            "timestamp": "2021-04-16T14:49:59-04:00",
            "author": "Olivier Martin",
            "commit_message": "ran cargo fmt --all",
            "additions": 7,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -649,13 +649,13 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n                 let user_twofactor_disabled = TwoFactor::find_by_user(&user_org.user_uuid, &conn).is_empty();\n \n                 let policy = OrgPolicyType::TwoFactorAuthentication as i32;\n-                let org_twofactor_policy_enabled = match OrgPolicy::find_by_org_and_type(&user_org.org_uuid, policy, &conn) {\n-                    Some(p) => p.enabled,\n-                    None => false,\n-                };\n+                let org_twofactor_policy_enabled =\n+                    match OrgPolicy::find_by_org_and_type(&user_org.org_uuid, policy, &conn) {\n+                        Some(p) => p.enabled,\n+                        None => false,\n+                    };\n \n                 if org_twofactor_policy_enabled && user_twofactor_disabled {\n-\n                     err!(\"You cannot join this organization until you enable two-step login on your user account.\")\n                 }\n \n@@ -1010,16 +1010,14 @@ fn put_policy(\n         Some(pt) => pt,\n         None => err!(\"Invalid policy type\"),\n     };\n-       \n-    if pol_type_enum == OrgPolicyType::TwoFactorAuthentication && data.enabled {\n \n+    if pol_type_enum == OrgPolicyType::TwoFactorAuthentication && data.enabled {\n         let org_list = UserOrganization::find_by_org(&org_id, &conn);\n \n         for user_org in org_list.into_iter() {\n             let user_twofactor_disabled = TwoFactor::find_by_user(&user_org.user_uuid, &conn).is_empty();\n \n             if user_twofactor_disabled && user_org.atype < UserOrgType::Admin {\n-\n                 if CONFIG.mail_enabled() {\n                     let org = Organization::find_by_uuid(&user_org.org_uuid, &conn).unwrap();\n                     let user = User::find_by_uuid(&user_org.user_uuid, &conn).unwrap();\n@@ -1028,7 +1026,7 @@ fn put_policy(\n                 }\n                 user_org.delete(&conn)?;\n             }\n-        }        \n+        }\n     }\n \n     let mut policy = match OrgPolicy::find_by_org_and_type(&org_id, pol_type, &conn) {\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 6,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -397,7 +397,7 @@ fn get_collection_users(org_id: String, coll_id: String, _headers: ManagerHeader\n         .map(|col_user| {\n             UserOrganization::find_by_user_and_org(&col_user.user_uuid, &org_id, &conn)\n                 .unwrap()\n-                .to_json_user_access_restrictions(&col_user)\n+                .to_json_user_access_restrictions(col_user)\n         })\n         .collect();\n \n@@ -504,13 +504,13 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n         } else {\n             UserOrgStatus::Accepted as i32 // Automatically mark user as accepted if no email invites\n         };\n-        let user = match User::find_by_mail(&email, &conn) {\n+        let user = match User::find_by_mail(email, &conn) {\n             None => {\n                 if !CONFIG.invitations_allowed() {\n                     err!(format!(\"User does not exist: {}\", email))\n                 }\n \n-                if !CONFIG.is_email_domain_allowed(&email) {\n+                if !CONFIG.is_email_domain_allowed(email) {\n                     err!(\"Email domain not eligible for invitations\")\n                 }\n \n@@ -560,7 +560,7 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n             };\n \n             mail::send_invite(\n-                &email,\n+                email,\n                 &user.uuid,\n                 Some(org_id.clone()),\n                 Some(new_user.uuid),\n@@ -630,7 +630,7 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n     // The web-vault passes org_id and org_user_id in the URL, but we are just reading them from the JWT instead\n     let data: AcceptData = data.into_inner().data;\n     let token = &data.Token;\n-    let claims = decode_invite(&token)?;\n+    let claims = decode_invite(token)?;\n \n     match User::find_by_mail(&claims.email, &conn) {\n         Some(_) => {\n@@ -656,7 +656,7 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n     if CONFIG.mail_enabled() {\n         let mut org_name = CONFIG.invitation_org_name();\n         if let Some(org_id) = &claims.org_id {\n-            org_name = match Organization::find_by_uuid(&org_id, &conn) {\n+            org_name = match Organization::find_by_uuid(org_id, &conn) {\n                 Some(org) => org.name,\n                 None => err!(\"Organization not found.\"),\n             };\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 42,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -51,6 +51,7 @@ pub fn routes() -> Vec<Route> {\n         get_plans,\n         get_plans_tax_rates,\n         import,\n+        post_org_keys,\n     ]\n }\n \n@@ -61,6 +62,7 @@ struct OrgData {\n     CollectionName: String,\n     Key: String,\n     Name: String,\n+    Keys: Option<OrgKeyData>,\n     #[serde(rename = \"PlanType\")]\n     _PlanType: NumberOrString, // Ignored, always use the same plan\n }\n@@ -78,6 +80,13 @@ struct NewCollectionData {\n     Name: String,\n }\n \n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct OrgKeyData {\n+    EncryptedPrivateKey: String,\n+    PublicKey: String,\n+}\n+\n #[post(\"/organizations\", data = \"<data>\")]\n fn create_organization(headers: Headers, data: JsonUpcase<OrgData>, conn: DbConn) -> JsonResult {\n     if !CONFIG.is_org_creation_allowed(&headers.user.email) {\n@@ -85,8 +94,14 @@ fn create_organization(headers: Headers, data: JsonUpcase<OrgData>, conn: DbConn\n     }\n \n     let data: OrgData = data.into_inner().data;\n+    let (private_key, public_key) = if data.Keys.is_some() {\n+        let keys: OrgKeyData = data.Keys.unwrap();\n+        (Some(keys.EncryptedPrivateKey), Some(keys.PublicKey))\n+    } else {\n+        (None, None)\n+    };\n \n-    let org = Organization::new(data.Name, data.BillingEmail);\n+    let org = Organization::new(data.Name, data.BillingEmail, private_key, public_key);\n     let mut user_org = UserOrganization::new(headers.user.uuid, org.uuid.clone());\n     let collection = Collection::new(org.uuid.clone(), data.CollectionName);\n \n@@ -468,6 +483,32 @@ fn get_org_users(org_id: String, _headers: ManagerHeadersLoose, conn: DbConn) ->\n     }))\n }\n \n+#[post(\"/organizations/<org_id>/keys\", data = \"<data>\")]\n+fn post_org_keys(org_id: String, data: JsonUpcase<OrgKeyData>, _headers: AdminHeaders, conn: DbConn) -> JsonResult {\n+    let data: OrgKeyData = data.into_inner().data;\n+\n+    let mut org = match Organization::find_by_uuid(&org_id, &conn) {\n+        Some(organization) => {\n+            if organization.private_key.is_some() && organization.public_key.is_some() {\n+                err!(\"Organization Keys already exist\")\n+            }\n+            organization\n+        }\n+        None => err!(\"Can't find organization details\"),\n+    };\n+\n+    org.private_key = Some(data.EncryptedPrivateKey);\n+    org.public_key = Some(data.PublicKey);\n+\n+    org.save(&conn)?;\n+\n+    Ok(Json(json!({\n+        \"Object\": \"organizationKeys\",\n+        \"PublicKey\": org.public_key,\n+        \"PrivateKey\": org.private_key,\n+    })))\n+}\n+\n #[derive(Deserialize)]\n #[allow(non_snake_case)]\n struct CollectionData {\n",
            "comment_added_diff": []
        },
        {
            "commit": "10d5c7738afad9f81958e24baa923530314a587f",
            "timestamp": "2021-09-09T13:52:39+02:00",
            "author": "BlackDex",
            "commit_message": "Fix issue when using uppercase chars in emails\n\nIn the case when SMTP is disabled and.\nwhen inviting new users either via the admin interface or into an\norganization and using uppercase letters, this would fail for those\nusers to be able to register since the checks which were done are\ncase-sensitive and never matched.\n\nThis PR fixes that issue by ensuring everything is lowercase.\nFixes #1963",
            "additions": 4,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -540,18 +540,19 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n     }\n \n     for email in data.Emails.iter() {\n+        let email = email.to_lowercase();\n         let mut user_org_status = if CONFIG.mail_enabled() {\n             UserOrgStatus::Invited as i32\n         } else {\n             UserOrgStatus::Accepted as i32 // Automatically mark user as accepted if no email invites\n         };\n-        let user = match User::find_by_mail(email, &conn) {\n+        let user = match User::find_by_mail(&email, &conn) {\n             None => {\n                 if !CONFIG.invitations_allowed() {\n                     err!(format!(\"User does not exist: {}\", email))\n                 }\n \n-                if !CONFIG.is_email_domain_allowed(email) {\n+                if !CONFIG.is_email_domain_allowed(&email) {\n                     err!(\"Email domain not eligible for invitations\")\n                 }\n \n@@ -601,7 +602,7 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n             };\n \n             mail::send_invite(\n-                email,\n+                &email,\n                 &user.uuid,\n                 Some(org_id.clone()),\n                 Some(new_user.uuid),\n",
            "comment_added_diff": []
        },
        {
            "commit": "f36bd72a7f772fd108b31e5ca1f502238ab1ef00",
            "timestamp": "2021-09-18T14:22:14+02:00",
            "author": "BlackDex",
            "commit_message": "Add Organization bulk actions support\n\nFor user management within the organization view you are able to select\nmultiple users to re-invite, confirm or delete them.\n\nThese actions were not working which this PR fixes by adding support for\nthese endpoints. This will make it easier to confirm and delete multiple\nusers at once instead of having to do this one-by-one.",
            "additions": 165,
            "deletions": 17,
            "change_type": "MODIFY",
            "diff": "@@ -35,12 +35,15 @@ pub fn routes() -> Vec<Route> {\n         get_org_users,\n         send_invite,\n         reinvite_user,\n+        bulk_reinvite_user,\n         confirm_invite,\n+        bulk_confirm_invite,\n         accept_invite,\n         get_user,\n         edit_user,\n         put_organization_user,\n         delete_user,\n+        bulk_delete_user,\n         post_delete_user,\n         post_org_import,\n         list_policies,\n@@ -52,6 +55,7 @@ pub fn routes() -> Vec<Route> {\n         get_plans_tax_rates,\n         import,\n         post_org_keys,\n+        bulk_public_keys,\n     ]\n }\n \n@@ -87,6 +91,12 @@ struct OrgKeyData {\n     PublicKey: String,\n }\n \n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct OrgBulkIds {\n+    Ids: Vec<String>,\n+}\n+\n #[post(\"/organizations\", data = \"<data>\")]\n fn create_organization(headers: Headers, data: JsonUpcase<OrgData>, conn: DbConn) -> JsonResult {\n     if !CONFIG.is_org_creation_allowed(&headers.user.email) {\n@@ -615,8 +625,44 @@ fn send_invite(org_id: String, data: JsonUpcase<InviteData>, headers: AdminHeade\n     Ok(())\n }\n \n+#[post(\"/organizations/<org_id>/users/reinvite\", data = \"<data>\")]\n+fn bulk_reinvite_user(\n+    org_id: String,\n+    data: JsonUpcase<OrgBulkIds>,\n+    headers: AdminHeaders,\n+    conn: DbConn,\n+) -> Json<Value> {\n+    let data: OrgBulkIds = data.into_inner().data;\n+\n+    let mut bulk_response = Vec::new();\n+    for org_user_id in data.Ids {\n+        let err_msg = match _reinvite_user(&org_id, &org_user_id, &headers.user.email, &conn) {\n+            Ok(_) => String::from(\"\"),\n+            Err(e) => format!(\"{:?}\", e),\n+        };\n+\n+        bulk_response.push(json!(\n+            {\n+                \"Object\": \"OrganizationBulkConfirmResponseModel\",\n+                \"Id\": org_user_id,\n+                \"Error\": err_msg\n+            }\n+        ))\n+    }\n+\n+    Json(json!({\n+        \"Data\": bulk_response,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    }))\n+}\n+\n #[post(\"/organizations/<org_id>/users/<user_org>/reinvite\")]\n fn reinvite_user(org_id: String, user_org: String, headers: AdminHeaders, conn: DbConn) -> EmptyResult {\n+    _reinvite_user(&org_id, &user_org, &headers.user.email, &conn)\n+}\n+\n+fn _reinvite_user(org_id: &str, user_org: &str, invited_by_email: &str, conn: &DbConn) -> EmptyResult {\n     if !CONFIG.invitations_allowed() {\n         err!(\"Invitations are not allowed.\")\n     }\n@@ -625,7 +671,7 @@ fn reinvite_user(org_id: String, user_org: String, headers: AdminHeaders, conn:\n         err!(\"SMTP is not configured.\")\n     }\n \n-    let user_org = match UserOrganization::find_by_uuid(&user_org, &conn) {\n+    let user_org = match UserOrganization::find_by_uuid(user_org, conn) {\n         Some(user_org) => user_org,\n         None => err!(\"The user hasn't been invited to the organization.\"),\n     };\n@@ -634,12 +680,12 @@ fn reinvite_user(org_id: String, user_org: String, headers: AdminHeaders, conn:\n         err!(\"The user is already accepted or confirmed to the organization\")\n     }\n \n-    let user = match User::find_by_uuid(&user_org.user_uuid, &conn) {\n+    let user = match User::find_by_uuid(&user_org.user_uuid, conn) {\n         Some(user) => user,\n         None => err!(\"User not found.\"),\n     };\n \n-    let org_name = match Organization::find_by_uuid(&org_id, &conn) {\n+    let org_name = match Organization::find_by_uuid(org_id, conn) {\n         Some(org) => org.name,\n         None => err!(\"Error looking up organization.\"),\n     };\n@@ -648,14 +694,14 @@ fn reinvite_user(org_id: String, user_org: String, headers: AdminHeaders, conn:\n         mail::send_invite(\n             &user.email,\n             &user.uuid,\n-            Some(org_id),\n+            Some(org_id.to_string()),\n             Some(user_org.uuid),\n             &org_name,\n-            Some(headers.user.email),\n+            Some(invited_by_email.to_string()),\n         )?;\n     } else {\n         let invitation = Invitation::new(user.email);\n-        invitation.save(&conn)?;\n+        invitation.save(conn)?;\n     }\n \n     Ok(())\n@@ -728,6 +774,40 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n     Ok(())\n }\n \n+#[post(\"/organizations/<org_id>/users/confirm\", data = \"<data>\")]\n+fn bulk_confirm_invite(org_id: String, data: JsonUpcase<Value>, headers: AdminHeaders, conn: DbConn) -> Json<Value> {\n+    let data = data.into_inner().data;\n+\n+    let mut bulk_response = Vec::new();\n+    match data[\"Keys\"].as_array() {\n+        Some(keys) => {\n+            for invite in keys {\n+                let org_user_id = invite[\"Id\"].as_str().unwrap_or_default();\n+                let user_key = invite[\"Key\"].as_str().unwrap_or_default();\n+                let err_msg = match _confirm_invite(&org_id, org_user_id, user_key, &headers, &conn) {\n+                    Ok(_) => String::from(\"\"),\n+                    Err(e) => format!(\"{:?}\", e),\n+                };\n+\n+                bulk_response.push(json!(\n+                    {\n+                        \"Object\": \"OrganizationBulkConfirmResponseModel\",\n+                        \"Id\": org_user_id,\n+                        \"Error\": err_msg\n+                    }\n+                ));\n+            }\n+        }\n+        None => error!(\"No keys to confirm\"),\n+    }\n+\n+    Json(json!({\n+        \"Data\": bulk_response,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    }))\n+}\n+\n #[post(\"/organizations/<org_id>/users/<org_user_id>/confirm\", data = \"<data>\")]\n fn confirm_invite(\n     org_id: String,\n@@ -737,8 +817,16 @@ fn confirm_invite(\n     conn: DbConn,\n ) -> EmptyResult {\n     let data = data.into_inner().data;\n+    let user_key = data[\"Key\"].as_str().unwrap_or_default();\n+    _confirm_invite(&org_id, &org_user_id, user_key, &headers, &conn)\n+}\n \n-    let mut user_to_confirm = match UserOrganization::find_by_uuid_and_org(&org_user_id, &org_id, &conn) {\n+fn _confirm_invite(org_id: &str, org_user_id: &str, key: &str, headers: &AdminHeaders, conn: &DbConn) -> EmptyResult {\n+    if key.is_empty() || org_user_id.is_empty() {\n+        err!(\"Key or UserId is not set, unable to process request\");\n+    }\n+\n+    let mut user_to_confirm = match UserOrganization::find_by_uuid_and_org(org_user_id, org_id, conn) {\n         Some(user) => user,\n         None => err!(\"The specified user isn't a member of the organization\"),\n     };\n@@ -752,24 +840,21 @@ fn confirm_invite(\n     }\n \n     user_to_confirm.status = UserOrgStatus::Confirmed as i32;\n-    user_to_confirm.akey = match data[\"Key\"].as_str() {\n-        Some(key) => key.to_string(),\n-        None => err!(\"Invalid key provided\"),\n-    };\n+    user_to_confirm.akey = key.to_string();\n \n     if CONFIG.mail_enabled() {\n-        let org_name = match Organization::find_by_uuid(&org_id, &conn) {\n+        let org_name = match Organization::find_by_uuid(org_id, conn) {\n             Some(org) => org.name,\n             None => err!(\"Error looking up organization.\"),\n         };\n-        let address = match User::find_by_uuid(&user_to_confirm.user_uuid, &conn) {\n+        let address = match User::find_by_uuid(&user_to_confirm.user_uuid, conn) {\n             Some(user) => user.email,\n             None => err!(\"Error looking up user.\"),\n         };\n         mail::send_invite_confirmed(&address, &org_name)?;\n     }\n \n-    user_to_confirm.save(&conn)\n+    user_to_confirm.save(conn)\n }\n \n #[get(\"/organizations/<org_id>/users/<org_user_id>\")]\n@@ -870,9 +955,40 @@ fn edit_user(\n     user_to_edit.save(&conn)\n }\n \n+#[delete(\"/organizations/<org_id>/users\", data = \"<data>\")]\n+fn bulk_delete_user(org_id: String, data: JsonUpcase<OrgBulkIds>, headers: AdminHeaders, conn: DbConn) -> Json<Value> {\n+    let data: OrgBulkIds = data.into_inner().data;\n+\n+    let mut bulk_response = Vec::new();\n+    for org_user_id in data.Ids {\n+        let err_msg = match _delete_user(&org_id, &org_user_id, &headers, &conn) {\n+            Ok(_) => String::from(\"\"),\n+            Err(e) => format!(\"{:?}\", e),\n+        };\n+\n+        bulk_response.push(json!(\n+            {\n+                \"Object\": \"OrganizationBulkConfirmResponseModel\",\n+                \"Id\": org_user_id,\n+                \"Error\": err_msg\n+            }\n+        ))\n+    }\n+\n+    Json(json!({\n+        \"Data\": bulk_response,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    }))\n+}\n+\n #[delete(\"/organizations/<org_id>/users/<org_user_id>\")]\n fn delete_user(org_id: String, org_user_id: String, headers: AdminHeaders, conn: DbConn) -> EmptyResult {\n-    let user_to_delete = match UserOrganization::find_by_uuid_and_org(&org_user_id, &org_id, &conn) {\n+    _delete_user(&org_id, &org_user_id, &headers, &conn)\n+}\n+\n+fn _delete_user(org_id: &str, org_user_id: &str, headers: &AdminHeaders, conn: &DbConn) -> EmptyResult {\n+    let user_to_delete = match UserOrganization::find_by_uuid_and_org(org_user_id, org_id, conn) {\n         Some(user) => user,\n         None => err!(\"User to delete isn't member of the organization\"),\n     };\n@@ -883,14 +999,14 @@ fn delete_user(org_id: String, org_user_id: String, headers: AdminHeaders, conn:\n \n     if user_to_delete.atype == UserOrgType::Owner {\n         // Removing owner, check that there are at least another owner\n-        let num_owners = UserOrganization::find_by_org_and_type(&org_id, UserOrgType::Owner as i32, &conn).len();\n+        let num_owners = UserOrganization::find_by_org_and_type(org_id, UserOrgType::Owner as i32, conn).len();\n \n         if num_owners <= 1 {\n             err!(\"Can't delete the last owner\")\n         }\n     }\n \n-    user_to_delete.delete(&conn)\n+    user_to_delete.delete(conn)\n }\n \n #[post(\"/organizations/<org_id>/users/<org_user_id>/delete\")]\n@@ -898,6 +1014,38 @@ fn post_delete_user(org_id: String, org_user_id: String, headers: AdminHeaders,\n     delete_user(org_id, org_user_id, headers, conn)\n }\n \n+#[post(\"/organizations/<org_id>/users/public-keys\", data = \"<data>\")]\n+fn bulk_public_keys(org_id: String, data: JsonUpcase<OrgBulkIds>, _headers: AdminHeaders, conn: DbConn) -> Json<Value> {\n+    let data: OrgBulkIds = data.into_inner().data;\n+\n+    let mut bulk_response = Vec::new();\n+    // Check all received UserOrg UUID's and find the matching User to retreive the public-key.\n+    // If the user does not exists, just ignore it, and do not return any information regarding that UserOrg UUID.\n+    // The web-vault will then ignore that user for the folowing steps.\n+    for user_org_id in data.Ids {\n+        match UserOrganization::find_by_uuid_and_org(&user_org_id, &org_id, &conn) {\n+            Some(user_org) => match User::find_by_uuid(&user_org.user_uuid, &conn) {\n+                Some(user) => bulk_response.push(json!(\n+                    {\n+                        \"Object\": \"organizationUserPublicKeyResponseModel\",\n+                        \"Id\": user_org_id,\n+                        \"UserId\": user.uuid,\n+                        \"Key\": user.public_key\n+                    }\n+                )),\n+                None => debug!(\"User doesn't exist\"),\n+            },\n+            None => debug!(\"UserOrg doesn't exist\"),\n+        }\n+    }\n+\n+    Json(json!({\n+        \"Data\": bulk_response,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    }))\n+}\n+\n use super::ciphers::update_cipher_from_data;\n use super::ciphers::CipherData;\n \n",
            "comment_added_diff": [
                [
                    1022,
                    "    // Check all received UserOrg UUID's and find the matching User to retreive the public-key."
                ],
                [
                    1023,
                    "    // If the user does not exists, just ignore it, and do not return any information regarding that UserOrg UUID."
                ],
                [
                    1024,
                    "    // The web-vault will then ignore that user for the folowing steps."
                ]
            ]
        },
        {
            "commit": "b4c95fb4ac5176ffc17f408e15e12b6e19a17c71",
            "timestamp": "2021-09-22T21:39:31+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Hide some warnings for unused struct fields",
            "additions": 5,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -377,7 +377,7 @@ fn delete_organization_collection(\n }\n \n #[derive(Deserialize, Debug)]\n-#[allow(non_snake_case)]\n+#[allow(non_snake_case, dead_code)]\n struct DeleteCollectionData {\n     Id: String,\n     OrgId: String,\n@@ -1301,7 +1301,7 @@ fn get_plans_tax_rates(_headers: Headers, _conn: DbConn) -> Json<Value> {\n }\n \n #[derive(Deserialize, Debug)]\n-#[allow(non_snake_case)]\n+#[allow(non_snake_case, dead_code)]\n struct OrgImportGroupData {\n     Name: String,       // \"GroupName\"\n     ExternalId: String, // \"cn=GroupName,ou=Groups,dc=example,dc=com\"\n@@ -1311,7 +1311,8 @@ struct OrgImportGroupData {\n #[derive(Deserialize, Debug)]\n #[allow(non_snake_case)]\n struct OrgImportUserData {\n-    Email: String,      // \"user@maildomain.net\"\n+    Email: String, // \"user@maildomain.net\"\n+    #[allow(dead_code)]\n     ExternalId: String, // \"uid=user,ou=People,dc=example,dc=com\"\n     Deleted: bool,\n }\n@@ -1319,6 +1320,7 @@ struct OrgImportUserData {\n #[derive(Deserialize, Debug)]\n #[allow(non_snake_case)]\n struct OrgImportData {\n+    #[allow(dead_code)]\n     Groups: Vec<OrgImportGroupData>,\n     OverwriteExisting: bool,\n     Users: Vec<OrgImportUserData>,\n",
            "comment_added_diff": [
                [
                    1314,
                    "    Email: String, // \"user@maildomain.net\""
                ]
            ]
        },
        {
            "commit": "e3678b4b567a89d5a72af99fdf61d1b5f1eb18f4",
            "timestamp": "2021-09-24T17:20:44+02:00",
            "author": "Adam Jones",
            "commit_message": "fix: Support no-data enterprise policies\n\nBoolean-toggle enterprise policies (like 'Two-Step Login' and 'Personal Ownership') don't provide a data attribute in the new version of the web client. This updates the backend to expect these to be optional.\n\nWeb change introduced in https://github.com/bitwarden/web/pull/1147 which added https://github.com/bitwarden/web/blob/2cbe023a38792ff70a2a4907f4748354bb4e0573/src/app/organizations/policies/base-policy.component.ts#L48-L50",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1183,7 +1183,7 @@ struct PolicyData {\n     enabled: bool,\n     #[serde(rename = \"type\")]\n     _type: i32,\n-    data: Value,\n+    data: Option<Value>,\n }\n \n #[put(\"/organizations/<org_id>/policies/<pol_type>\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 56,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -102,6 +102,11 @@ fn create_organization(headers: Headers, data: JsonUpcase<OrgData>, conn: DbConn\n     if !CONFIG.is_org_creation_allowed(&headers.user.email) {\n         err!(\"User not allowed to create organizations\")\n     }\n+    if OrgPolicy::is_applicable_to_user(&headers.user.uuid, OrgPolicyType::SingleOrg, &conn) {\n+        err!(\n+            \"You may not create an organization. You belong to an organization which has a policy that prohibits you from being a member of any other organization.\"\n+        )\n+    }\n \n     let data: OrgData = data.into_inner().data;\n     let (private_key, public_key) = if data.Keys.is_some() {\n@@ -747,6 +752,30 @@ fn accept_invite(_org_id: String, _org_user_id: String, data: JsonUpcase<AcceptD\n                     err!(\"You cannot join this organization until you enable two-step login on your user account.\")\n                 }\n \n+                // Enforce Single Organization Policy of organization user is trying to join\n+                let single_org_policy_enabled =\n+                    match OrgPolicy::find_by_org_and_type(&user_org.org_uuid, OrgPolicyType::SingleOrg as i32, &conn) {\n+                        Some(p) => p.enabled,\n+                        None => false,\n+                    };\n+                if single_org_policy_enabled && user_org.atype < UserOrgType::Admin {\n+                    let is_member_of_another_org = UserOrganization::find_any_state_by_user(&user_org.user_uuid, &conn)\n+                        .into_iter()\n+                        .filter(|uo| uo.org_uuid != user_org.org_uuid)\n+                        .count()\n+                        > 1;\n+                    if is_member_of_another_org {\n+                        err!(\"You may not join this organization until you leave or remove all other organizations.\")\n+                    }\n+                }\n+\n+                // Enforce Single Organization Policy of other organizations user is a member of\n+                if OrgPolicy::is_applicable_to_user(&user_org.user_uuid, OrgPolicyType::SingleOrg, &conn) {\n+                    err!(\n+                        \"You cannot join this organization because you are a member of an organization which forbids it\"\n+                    )\n+                }\n+\n                 user_org.status = UserOrgStatus::Accepted as i32;\n                 user_org.save(&conn)?;\n             }\n@@ -1219,6 +1248,33 @@ fn put_policy(\n         }\n     }\n \n+    // If enabling the SingleOrg policy, remove this org's members that are members of other orgs\n+    if pol_type_enum == OrgPolicyType::SingleOrg && data.enabled {\n+        let org_members = UserOrganization::find_by_org(&org_id, &conn);\n+\n+        for member in org_members.into_iter() {\n+            // Policy only applies to non-Owner/non-Admin members who have accepted joining the org\n+            if member.atype < UserOrgType::Admin && member.status != UserOrgStatus::Invited as i32 {\n+                let is_member_of_another_org = UserOrganization::find_any_state_by_user(&member.user_uuid, &conn)\n+                    .into_iter()\n+                    // Other UserOrganization's where they have accepted being a member of\n+                    .filter(|uo| uo.uuid != member.uuid && uo.status != UserOrgStatus::Invited as i32)\n+                    .count()\n+                    > 1;\n+\n+                if is_member_of_another_org {\n+                    if CONFIG.mail_enabled() {\n+                        let org = Organization::find_by_uuid(&member.org_uuid, &conn).unwrap();\n+                        let user = User::find_by_uuid(&member.user_uuid, &conn).unwrap();\n+\n+                        mail::send_single_org_removed_from_org(&user.email, &org.name)?;\n+                    }\n+                    member.delete(&conn)?;\n+                }\n+            }\n+        }\n+    }\n+\n     let mut policy = match OrgPolicy::find_by_org_and_type(&org_id, pol_type, &conn) {\n         Some(p) => p,\n         None => OrgPolicy::new(org_id, pol_type_enum, \"{}\".to_string()),\n",
            "comment_added_diff": [
                [
                    755,
                    "                // Enforce Single Organization Policy of organization user is trying to join"
                ],
                [
                    772,
                    "                // Enforce Single Organization Policy of other organizations user is a member of"
                ],
                [
                    1251,
                    "    // If enabling the SingleOrg policy, remove this org's members that are members of other orgs"
                ],
                [
                    1256,
                    "            // Policy only applies to non-Owner/non-Admin members who have accepted joining the org"
                ],
                [
                    1260,
                    "                    // Other UserOrganization's where they have accepted being a member of"
                ]
            ]
        }
    ],
    "duo.rs": [
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -167,7 +167,7 @@ fn activate_duo(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbConn)\n     };\n \n     let type_ = TwoFactorType::Duo;\n-    let twofactor = TwoFactor::new(headers.user.uuid.clone(), type_, data_str);\n+    let twofactor = TwoFactor::new(headers.user.uuid, type_, data_str);\n     twofactor.save(&conn)?;\n \n     Ok(Json(json!({\n",
            "comment_added_diff": []
        },
        {
            "commit": "e449912f05d63a3499609ae00184796dd7390bf0",
            "timestamp": "2019-11-02T18:31:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Generate recovery codes for email and duo",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -4,6 +4,7 @@ use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json;\n \n+use crate::api::core::two_factor::_generate_recover_code;\n use crate::api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, PasswordData};\n use crate::auth::Headers;\n use crate::crypto;\n@@ -152,8 +153,9 @@ fn check_duo_fields_custom(data: &EnableDuoData) -> bool {\n #[post(\"/two-factor/duo\", data = \"<data>\")]\n fn activate_duo(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let data: EnableDuoData = data.into_inner().data;\n+    let mut user = headers.user;\n \n-    if !headers.user.check_valid_password(&data.MasterPasswordHash) {\n+    if !user.check_valid_password(&data.MasterPasswordHash) {\n         err!(\"Invalid password\");\n     }\n \n@@ -167,8 +169,10 @@ fn activate_duo(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbConn)\n     };\n \n     let type_ = TwoFactorType::Duo;\n-    let twofactor = TwoFactor::new(headers.user.uuid, type_, data_str);\n+    let twofactor = TwoFactor::new(user.uuid.clone(), type_, data_str);\n     twofactor.save(&conn)?;\n+    \n+    _generate_recover_code(&mut user, &conn);\n \n     Ok(Json(json!({\n         \"Enabled\": true,\n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 2,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -16,11 +16,7 @@ use crate::error::MapResult;\n use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n-    routes![\n-        get_duo,\n-        activate_duo,\n-        activate_duo_put,\n-    ]\n+    routes![get_duo, activate_duo, activate_duo_put,]\n }\n \n #[derive(Serialize, Deserialize)]\n@@ -171,7 +167,7 @@ fn activate_duo(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbConn)\n     let type_ = TwoFactorType::Duo;\n     let twofactor = TwoFactor::new(user.uuid.clone(), type_, data_str);\n     twofactor.save(&conn)?;\n-    \n+\n     _generate_recover_code(&mut user, &conn);\n \n     Ok(Json(json!({\n",
            "comment_added_diff": []
        },
        {
            "commit": "1b4b40c95dab106a5b06b8b1685004b59abf21dd",
            "timestamp": "2020-03-14T23:12:45+01:00",
            "author": "BlackDex",
            "commit_message": "Updated reqwest to the latest version.\n\n- Use the blocking client (no async).\n- Disabled gzip.\n- use_sys_proxy is now default.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -187,7 +187,7 @@ fn activate_duo_put(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbC\n fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> EmptyResult {\n     const AGENT: &str = \"bitwarden_rs:Duo/1.0 (Rust)\";\n \n-    use reqwest::{header::*, Client, Method};\n+    use reqwest::{header::*, Method, blocking::Client};\n     use std::str::FromStr;\n \n     let url = format!(\"https://{}{}\", &data.host, path);\n",
            "comment_added_diff": []
        },
        {
            "commit": "6cd8512bbd869dbb2370798fc473abfbec47fbb3",
            "timestamp": "2020-04-07T20:40:51-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix Duo auth failure with non-lowercased email addresses",
            "additions": 8,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -21,9 +21,9 @@ pub fn routes() -> Vec<Route> {\n \n #[derive(Serialize, Deserialize)]\n struct DuoData {\n-    host: String,\n-    ik: String,\n-    sk: String,\n+    host: String, // Duo API hostname\n+    ik: String,   // integration key\n+    sk: String,   // secret key\n }\n \n impl DuoData {\n@@ -190,6 +190,7 @@ fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> Em\n     use reqwest::{header::*, Method, blocking::Client};\n     use std::str::FromStr;\n \n+    // https://duo.com/docs/authapi#api-details\n     let url = format!(\"https://{}{}\", &data.host, path);\n     let date = Utc::now().to_rfc2822();\n     let username = &data.ik;\n@@ -268,6 +269,10 @@ fn sign_duo_values(key: &str, email: &str, ikey: &str, prefix: &str, expire: i64\n }\n \n pub fn validate_duo_login(email: &str, response: &str, conn: &DbConn) -> EmptyResult {\n+    // email is as entered by the user, so it needs to be normalized before\n+    // comparison with auth_user below.\n+    let email = &email.to_lowercase();\n+\n     let split: Vec<&str> = response.split(':').collect();\n     if split.len() != 2 {\n         err!(\"Invalid response length\");\n",
            "comment_added_diff": [
                [
                    24,
                    "    host: String, // Duo API hostname"
                ],
                [
                    25,
                    "    ik: String,   // integration key"
                ],
                [
                    26,
                    "    sk: String,   // secret key"
                ],
                [
                    193,
                    "    // https://duo.com/docs/authapi#api-details"
                ],
                [
                    272,
                    "    // email is as entered by the user, so it needs to be normalized before"
                ],
                [
                    273,
                    "    // comparison with auth_user below."
                ]
            ]
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -2,7 +2,6 @@ use chrono::Utc;\n use data_encoding::BASE64;\n use rocket::Route;\n use rocket_contrib::json::Json;\n-use serde_json;\n \n use crate::api::core::two_factor::_generate_recover_code;\n use crate::api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, PasswordData};\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 11,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -3,16 +3,17 @@ use data_encoding::BASE64;\n use rocket::Route;\n use rocket_contrib::json::Json;\n \n-use crate::api::core::two_factor::_generate_recover_code;\n-use crate::api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, PasswordData};\n-use crate::auth::Headers;\n-use crate::crypto;\n-use crate::db::{\n-    models::{TwoFactor, TwoFactorType, User},\n-    DbConn,\n+use crate::{\n+    api::{core::two_factor::_generate_recover_code, ApiResult, EmptyResult, JsonResult, JsonUpcase, PasswordData},\n+    auth::Headers,\n+    crypto,\n+    db::{\n+        models::{TwoFactor, TwoFactorType, User},\n+        DbConn,\n+    },\n+    error::MapResult,\n+    CONFIG,\n };\n-use crate::error::MapResult;\n-use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n     routes![get_duo, activate_duo, activate_duo_put,]\n@@ -186,7 +187,7 @@ fn activate_duo_put(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbC\n fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> EmptyResult {\n     const AGENT: &str = \"bitwarden_rs:Duo/1.0 (Rust)\";\n \n-    use reqwest::{header::*, Method, blocking::Client};\n+    use reqwest::{blocking::Client, header::*, Method};\n     use std::str::FromStr;\n \n     // https://duo.com/docs/authapi#api-details\n",
            "comment_added_diff": []
        },
        {
            "commit": "155109dea120e109e1e027d4e1312b6adad4c231",
            "timestamp": "2021-04-06T21:04:37+01:00",
            "author": "Jake Howard",
            "commit_message": "Extract client creation to a single place",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -12,6 +12,7 @@ use crate::{\n         DbConn,\n     },\n     error::MapResult,\n+    util::get_reqwest_client,\n     CONFIG,\n };\n \n@@ -185,9 +186,7 @@ fn activate_duo_put(data: JsonUpcase<EnableDuoData>, headers: Headers, conn: DbC\n }\n \n fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> EmptyResult {\n-    const AGENT: &str = \"bitwarden_rs:Duo/1.0 (Rust)\";\n-\n-    use reqwest::{blocking::Client, header::*, Method};\n+    use reqwest::{header, Method};\n     use std::str::FromStr;\n \n     // https://duo.com/docs/authapi#api-details\n@@ -199,11 +198,12 @@ fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> Em\n \n     let m = Method::from_str(method).unwrap_or_default();\n \n-    Client::new()\n-        .request(m, &url)\n+    let client = get_reqwest_client();\n+\n+    client.request(m, &url)\n         .basic_auth(username, Some(password))\n-        .header(USER_AGENT, AGENT)\n-        .header(DATE, date)\n+        .header(header::USER_AGENT, \"bitwarden_rs:Duo/1.0 (Rust)\")\n+        .header(header::DATE, date)\n         .send()?\n         .error_for_status()?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -59,7 +59,11 @@ impl DuoData {\n         ik.replace_range(digits.., replaced);\n         sk.replace_range(digits.., replaced);\n \n-        Self { host, ik, sk }\n+        Self {\n+            host,\n+            ik,\n+            sk,\n+        }\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "305de2e2cd820ae6651a6442d88f5ca637263fae",
            "timestamp": "2021-04-15T18:30:23+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Format the changes from merge to master",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -204,7 +204,8 @@ fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> Em\n \n     let client = get_reqwest_client();\n \n-    client.request(m, &url)\n+    client\n+        .request(m, &url)\n         .basic_auth(username, Some(password))\n         .header(header::USER_AGENT, \"bitwarden_rs:Duo/1.0 (Rust)\")\n         .header(header::DATE, date)\n",
            "comment_added_diff": []
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -207,7 +207,7 @@ fn duo_api_request(method: &str, path: &str, params: &str, data: &DuoData) -> Em\n     client\n         .request(m, &url)\n         .basic_auth(username, Some(password))\n-        .header(header::USER_AGENT, \"bitwarden_rs:Duo/1.0 (Rust)\")\n+        .header(header::USER_AGENT, \"vaultwarden:Duo/1.0 (Rust)\")\n         .header(header::DATE, date)\n         .send()?\n         .error_for_status()?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -226,7 +226,7 @@ fn get_user_duo_data(uuid: &str, conn: &DbConn) -> DuoStatus {\n     let type_ = TwoFactorType::Duo as i32;\n \n     // If the user doesn't have an entry, disabled\n-    let twofactor = match TwoFactor::find_by_user_and_type(uuid, type_, &conn) {\n+    let twofactor = match TwoFactor::find_by_user_and_type(uuid, type_, conn) {\n         Some(t) => t,\n         None => return DuoStatus::Disabled(DuoData::global().is_some()),\n     };\n@@ -247,8 +247,8 @@ fn get_user_duo_data(uuid: &str, conn: &DbConn) -> DuoStatus {\n \n // let (ik, sk, ak, host) = get_duo_keys();\n fn get_duo_keys_email(email: &str, conn: &DbConn) -> ApiResult<(String, String, String, String)> {\n-    let data = User::find_by_mail(email, &conn)\n-        .and_then(|u| get_user_duo_data(&u.uuid, &conn).data())\n+    let data = User::find_by_mail(email, conn)\n+        .and_then(|u| get_user_duo_data(&u.uuid, conn).data())\n         .or_else(DuoData::global)\n         .map_res(\"Can't fetch Duo keys\")?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -343,7 +343,7 @@ fn parse_duo_values(key: &str, val: &str, ikey: &str, prefix: &str, time: i64) -\n         err!(\"Invalid ikey\")\n     }\n \n-    let expire = match expire.parse() {\n+    let expire: i64 = match expire.parse() {\n         Ok(e) => e,\n         Err(_) => err!(\"Invalid expire time\"),\n     };\n",
            "comment_added_diff": []
        }
    ],
    "u2f.rs": [
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -164,7 +164,7 @@ fn activate_u2f(data: JsonUpcase<EnableU2FData>, headers: Headers, conn: DbConn)\n         err!(\"Error registering U2F token\")\n     }\n \n-    let registration = U2F.register_response(challenge.clone(), response.into())?;\n+    let registration = U2F.register_response(challenge, response.into())?;\n     let full_registration = U2FRegistration {\n         id: data.Id.into_i32()?,\n         name: data.Name,\n",
            "comment_added_diff": []
        },
        {
            "commit": "adc443ea80be98a5aaf260eb8c2c7be6e43f6377",
            "timestamp": "2019-12-01T21:41:46+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add endpoint to delete specific U2F key",
            "additions": 45,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -29,6 +29,7 @@ pub fn routes() -> Vec<Route> {\n         generate_u2f_challenge,\n         activate_u2f,\n         activate_u2f_put,\n+        delete_u2f,\n     ]\n }\n \n@@ -194,6 +195,50 @@ fn activate_u2f_put(data: JsonUpcase<EnableU2FData>, headers: Headers, conn: DbC\n     activate_u2f(data, headers, conn)\n }\n \n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct DeleteU2FData {\n+    Id: NumberOrString,\n+    MasterPasswordHash: String,\n+}\n+\n+#[delete(\"/two-factor/u2f\", data = \"<data>\")]\n+fn delete_u2f(data: JsonUpcase<DeleteU2FData>, headers: Headers, conn: DbConn) -> JsonResult {\n+    let data: DeleteU2FData = data.into_inner().data;\n+\n+    let id = data.Id.into_i32()?;\n+\n+    if !headers.user.check_valid_password(&data.MasterPasswordHash) {\n+        err!(\"Invalid password\");\n+    }\n+\n+    let type_ = TwoFactorType::U2f as i32;\n+    let mut tf = match TwoFactor::find_by_user_and_type(&headers.user.uuid, type_, &conn) {\n+        Some(tf) => tf,\n+        None => err!(\"U2F data not found!\"),\n+    };\n+\n+    let mut data: Vec<U2FRegistration> = match serde_json::from_str(&tf.data) {\n+        Ok(d) => d,\n+        Err(_) => err!(\"Error parsing U2F data\"),\n+    };\n+\n+    data.retain(|r| r.id != id);\n+\n+    let new_data_str = serde_json::to_string(&data)?;\n+\n+    tf.data = new_data_str;\n+    tf.save(&conn)?;\n+\n+    let keys_json: Vec<Value> = data.iter().map(U2FRegistration::to_json).collect();\n+\n+    Ok(Json(json!({\n+        \"Enabled\": true,\n+        \"Keys\": keys_json,\n+        \"Object\": \"twoFactorU2f\"\n+    })))\n+}\n+\n fn _create_u2f_challenge(user_uuid: &str, type_: TwoFactorType, conn: &DbConn) -> Challenge {\n     let challenge = U2F.generate_challenge().unwrap();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "84ed1855798d6d64718d2f429e173f2735d255dd",
            "timestamp": "2020-01-19T21:34:13+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update u2f to 0.2, which requires OpenSSL but also might solve the problems we've had with certificates.\nThe rust image doesn't need installing curl or tar, so removed. Also collapsed ENV lines.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -92,6 +92,7 @@ struct RegistrationDef {\n     key_handle: Vec<u8>,\n     pub_key: Vec<u8>,\n     attestation_cert: Option<Vec<u8>>,\n+    device_name: Option<String>,\n }\n \n #[derive(Serialize, Deserialize)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "70f3ab8ec3d6ccfd8ec8c71c888459de484d9b43",
            "timestamp": "2020-03-09T22:04:03+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Migrate lazy_static to once_cell, less macro magic and slightly faster",
            "additions": 3,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -1,3 +1,4 @@\n+use once_cell::sync::Lazy;\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json;\n@@ -18,10 +19,8 @@ use crate::CONFIG;\n \n const U2F_VERSION: &str = \"U2F_V2\";\n \n-lazy_static! {\n-    static ref APP_ID: String = format!(\"{}/app-id.json\", &CONFIG.domain());\n-    static ref U2F: U2f = U2f::new(APP_ID.clone());\n-}\n+static APP_ID: Lazy<String> = Lazy::new(|| format!(\"{}/app-id.json\", &CONFIG.domain()));\n+static U2F: Lazy<U2f> = Lazy::new(|| U2f::new(APP_ID.clone()));\n \n pub fn routes() -> Vec<Route> {\n     routes![\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,6 @@\n use once_cell::sync::Lazy;\n use rocket::Route;\n use rocket_contrib::json::Json;\n-use serde_json;\n use serde_json::Value;\n use u2f::messages::{RegisterResponse, SignResponse, U2fSignRequest};\n use u2f::protocol::{Challenge, U2f};\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 18,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -2,19 +2,25 @@ use once_cell::sync::Lazy;\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n-use u2f::messages::{RegisterResponse, SignResponse, U2fSignRequest};\n-use u2f::protocol::{Challenge, U2f};\n-use u2f::register::Registration;\n-\n-use crate::api::core::two_factor::_generate_recover_code;\n-use crate::api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, NumberOrString, PasswordData};\n-use crate::auth::Headers;\n-use crate::db::{\n-    models::{TwoFactor, TwoFactorType},\n-    DbConn,\n+use u2f::{\n+    messages::{RegisterResponse, SignResponse, U2fSignRequest},\n+    protocol::{Challenge, U2f},\n+    register::Registration,\n+};\n+\n+use crate::{\n+    api::{\n+        core::two_factor::_generate_recover_code, ApiResult, EmptyResult, JsonResult, JsonUpcase, NumberOrString,\n+        PasswordData,\n+    },\n+    auth::Headers,\n+    db::{\n+        models::{TwoFactor, TwoFactorType},\n+        DbConn,\n+    },\n+    error::Error,\n+    CONFIG,\n };\n-use crate::error::Error;\n-use crate::CONFIG;\n \n const U2F_VERSION: &str = \"U2F_V2\";\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "6b1daeba0533516c6d50fd2cebcc1e8060fd6df2",
            "timestamp": "2021-03-27T14:19:57+00:00",
            "author": "Jake Howard",
            "commit_message": "Implement `From` over `Into`\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#from_over_into",
            "additions": 5,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -131,12 +131,12 @@ struct RegisterResponseCopy {\n     pub error_code: Option<NumberOrString>,\n }\n \n-impl Into<RegisterResponse> for RegisterResponseCopy {\n-    fn into(self) -> RegisterResponse {\n+impl From<RegisterResponseCopy> for RegisterResponse {\n+    fn from(r: RegisterResponseCopy) -> RegisterResponse {\n         RegisterResponse {\n-            registration_data: self.registration_data,\n-            version: self.version,\n-            client_data: self.client_data,\n+            registration_data: r.registration_data,\n+            version: r.version,\n+            client_data: r.client_data,\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 4,
            "deletions": 20,
            "change_type": "MODIFY",
            "diff": "@@ -28,13 +28,7 @@ static APP_ID: Lazy<String> = Lazy::new(|| format!(\"{}/app-id.json\", &CONFIG.dom\n static U2F: Lazy<U2f> = Lazy::new(|| U2f::new(APP_ID.clone()));\n \n pub fn routes() -> Vec<Route> {\n-    routes![\n-        generate_u2f,\n-        generate_u2f_challenge,\n-        activate_u2f,\n-        activate_u2f_put,\n-        delete_u2f,\n-    ]\n+    routes![generate_u2f, generate_u2f_challenge, activate_u2f, activate_u2f_put, delete_u2f,]\n }\n \n #[post(\"/two-factor/get-u2f\", data = \"<data>\")]\n@@ -161,10 +155,7 @@ fn activate_u2f(data: JsonUpcase<EnableU2FData>, headers: Headers, conn: DbConn)\n \n     let response: RegisterResponseCopy = serde_json::from_str(&data.DeviceResponse)?;\n \n-    let error_code = response\n-        .error_code\n-        .clone()\n-        .map_or(\"0\".into(), NumberOrString::into_string);\n+    let error_code = response.error_code.clone().map_or(\"0\".into(), NumberOrString::into_string);\n \n     if error_code != \"0\" {\n         err!(\"Error registering U2F token\")\n@@ -300,20 +291,13 @@ fn _old_parse_registrations(registations: &str) -> Vec<Registration> {\n \n     let regs: Vec<Value> = serde_json::from_str(registations).expect(\"Can't parse Registration data\");\n \n-    regs.into_iter()\n-        .map(|r| serde_json::from_value(r).unwrap())\n-        .map(|Helper(r)| r)\n-        .collect()\n+    regs.into_iter().map(|r| serde_json::from_value(r).unwrap()).map(|Helper(r)| r).collect()\n }\n \n pub fn generate_u2f_login(user_uuid: &str, conn: &DbConn) -> ApiResult<U2fSignRequest> {\n     let challenge = _create_u2f_challenge(user_uuid, TwoFactorType::U2fLoginChallenge, conn);\n \n-    let registrations: Vec<_> = get_u2f_registrations(user_uuid, conn)?\n-        .1\n-        .into_iter()\n-        .map(|r| r.reg)\n-        .collect();\n+    let registrations: Vec<_> = get_u2f_registrations(user_uuid, conn)?.1.into_iter().map(|r| r.reg).collect();\n \n     if registrations.is_empty() {\n         err!(\"No U2F devices registered\")\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 8,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -94,13 +94,14 @@ struct RegistrationDef {\n }\n \n #[derive(Serialize, Deserialize)]\n-struct U2FRegistration {\n-    id: i32,\n-    name: String,\n+pub struct U2FRegistration {\n+    pub id: i32,\n+    pub name: String,\n     #[serde(with = \"RegistrationDef\")]\n-    reg: Registration,\n-    counter: u32,\n+    pub reg: Registration,\n+    pub counter: u32,\n     compromised: bool,\n+    pub migrated: Option<bool>,\n }\n \n impl U2FRegistration {\n@@ -168,6 +169,7 @@ fn activate_u2f(data: JsonUpcase<EnableU2FData>, headers: Headers, conn: DbConn)\n         reg: registration,\n         compromised: false,\n         counter: 0,\n+        migrated: None,\n     };\n \n     let mut regs = get_u2f_registrations(&user.uuid, &conn)?.1;\n@@ -273,6 +275,7 @@ fn get_u2f_registrations(user_uuid: &str, conn: &DbConn) -> Result<(bool, Vec<U2\n                 reg: old_regs.remove(0),\n                 compromised: false,\n                 counter: 0,\n+                migrated: None,\n             }];\n \n             // Save new format\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 6,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -248,7 +248,7 @@ fn _create_u2f_challenge(user_uuid: &str, type_: TwoFactorType, conn: &DbConn) -\n }\n \n fn save_u2f_registrations(user_uuid: &str, regs: &[U2FRegistration], conn: &DbConn) -> EmptyResult {\n-    TwoFactor::new(user_uuid.into(), TwoFactorType::U2f, serde_json::to_string(regs)?).save(&conn)\n+    TwoFactor::new(user_uuid.into(), TwoFactorType::U2f, serde_json::to_string(regs)?).save(conn)\n }\n \n fn get_u2f_registrations(user_uuid: &str, conn: &DbConn) -> Result<(bool, Vec<U2FRegistration>), Error> {\n@@ -279,7 +279,7 @@ fn get_u2f_registrations(user_uuid: &str, conn: &DbConn) -> Result<(bool, Vec<U2\n             }];\n \n             // Save new format\n-            save_u2f_registrations(user_uuid, &new_regs, &conn)?;\n+            save_u2f_registrations(user_uuid, &new_regs, conn)?;\n \n             new_regs\n         }\n@@ -311,12 +311,12 @@ pub fn generate_u2f_login(user_uuid: &str, conn: &DbConn) -> ApiResult<U2fSignRe\n \n pub fn validate_u2f_login(user_uuid: &str, response: &str, conn: &DbConn) -> EmptyResult {\n     let challenge_type = TwoFactorType::U2fLoginChallenge as i32;\n-    let tf_challenge = TwoFactor::find_by_user_and_type(user_uuid, challenge_type, &conn);\n+    let tf_challenge = TwoFactor::find_by_user_and_type(user_uuid, challenge_type, conn);\n \n     let challenge = match tf_challenge {\n         Some(tf_challenge) => {\n             let challenge: Challenge = serde_json::from_str(&tf_challenge.data)?;\n-            tf_challenge.delete(&conn)?;\n+            tf_challenge.delete(conn)?;\n             challenge\n         }\n         None => err!(\"Can't recover login challenge\"),\n@@ -332,13 +332,13 @@ pub fn validate_u2f_login(user_uuid: &str, response: &str, conn: &DbConn) -> Emp\n         match response {\n             Ok(new_counter) => {\n                 reg.counter = new_counter;\n-                save_u2f_registrations(user_uuid, &registrations, &conn)?;\n+                save_u2f_registrations(user_uuid, &registrations, conn)?;\n \n                 return Ok(());\n             }\n             Err(u2f::u2ferror::U2fError::CounterTooLow) => {\n                 reg.compromised = true;\n-                save_u2f_registrations(user_uuid, &registrations, &conn)?;\n+                save_u2f_registrations(user_uuid, &registrations, conn)?;\n \n                 err!(\"This device might be compromised!\");\n             }\n",
            "comment_added_diff": []
        }
    ],
    "auth.rs": [
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 6,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -118,7 +118,7 @@ pub fn generate_invite_claims(\n     uuid: String,\n     email: String,\n     org_id: Option<String>,\n-    org_user_id: Option<String>,\n+    user_org_id: Option<String>,\n     invited_by_email: Option<String>,\n ) -> InviteJWTClaims {\n     let time_now = Utc::now().naive_utc();\n@@ -126,11 +126,11 @@ pub fn generate_invite_claims(\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::days(5)).timestamp(),\n         iss: JWT_INVITE_ISSUER.to_string(),\n-        sub: uuid.clone(),\n-        email: email.clone(),\n-        org_id: org_id.clone(),\n-        user_org_id: org_user_id.clone(),\n-        invited_by_email: invited_by_email.clone(),\n+        sub: uuid,\n+        email,\n+        org_id,\n+        user_org_id,\n+        invited_by_email,\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 58,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -18,6 +18,8 @@ lazy_static! {\n     static ref JWT_HEADER: Header = Header::new(JWT_ALGORITHM);\n     pub static ref JWT_LOGIN_ISSUER: String = format!(\"{}|login\", CONFIG.domain());\n     pub static ref JWT_INVITE_ISSUER: String = format!(\"{}|invite\", CONFIG.domain());\n+    pub static ref JWT_DELETE_ISSUER: String = format!(\"{}|delete\", CONFIG.domain());\n+    pub static ref JWT_VERIFYEMAIL_ISSUER: String = format!(\"{}|verifyemail\", CONFIG.domain());\n     pub static ref JWT_ADMIN_ISSUER: String = format!(\"{}|admin\", CONFIG.domain());\n     static ref PRIVATE_RSA_KEY: Vec<u8> = match read_file(&CONFIG.private_rsa_key()) {\n         Ok(key) => key,\n@@ -62,6 +64,14 @@ pub fn decode_invite(token: &str) -> Result<InviteJWTClaims, Error> {\n     decode_jwt(token, JWT_INVITE_ISSUER.to_string())\n }\n \n+pub fn decode_delete(token: &str) -> Result<DeleteJWTClaims, Error> {\n+    decode_jwt(token, JWT_DELETE_ISSUER.to_string())\n+}\n+\n+pub fn decode_verify_email(token: &str) -> Result<VerifyEmailJWTClaims, Error> {\n+    decode_jwt(token, JWT_VERIFYEMAIL_ISSUER.to_string())\n+}\n+\n pub fn decode_admin(token: &str) -> Result<AdminJWTClaims, Error> {\n     decode_jwt(token, JWT_ADMIN_ISSUER.to_string())\n }\n@@ -134,6 +144,54 @@ pub fn generate_invite_claims(\n     }\n }\n \n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct DeleteJWTClaims {\n+    // Not before\n+    pub nbf: i64,\n+    // Expiration time\n+    pub exp: i64,\n+    // Issuer\n+    pub iss: String,\n+    // Subject\n+    pub sub: String,\n+}\n+\n+pub fn generate_delete_claims(\n+    uuid: String,\n+) -> DeleteJWTClaims {\n+    let time_now = Utc::now().naive_utc();\n+    DeleteJWTClaims {\n+        nbf: time_now.timestamp(),\n+        exp: (time_now + Duration::days(5)).timestamp(),\n+        iss: JWT_DELETE_ISSUER.to_string(),\n+        sub: uuid,\n+    }\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct VerifyEmailJWTClaims {\n+    // Not before\n+    pub nbf: i64,\n+    // Expiration time\n+    pub exp: i64,\n+    // Issuer\n+    pub iss: String,\n+    // Subject\n+    pub sub: String,\n+}\n+\n+pub fn generate_verify_email_claims(\n+    uuid: String,\n+) -> DeleteJWTClaims {\n+    let time_now = Utc::now().naive_utc();\n+    DeleteJWTClaims {\n+        nbf: time_now.timestamp(),\n+        exp: (time_now + Duration::days(5)).timestamp(),\n+        iss: JWT_VERIFYEMAIL_ISSUER.to_string(),\n+        sub: uuid,\n+    }\n+}\n+\n #[derive(Debug, Serialize, Deserialize)]\n pub struct AdminJWTClaims {\n     // Not before\n",
            "comment_added_diff": [
                [
                    149,
                    "    // Not before"
                ],
                [
                    151,
                    "    // Expiration time"
                ],
                [
                    153,
                    "    // Issuer"
                ],
                [
                    155,
                    "    // Subject"
                ],
                [
                    173,
                    "    // Not before"
                ],
                [
                    175,
                    "    // Expiration time"
                ],
                [
                    177,
                    "    // Issuer"
                ],
                [
                    179,
                    "    // Subject"
                ]
            ]
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 2,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -156,9 +156,7 @@ pub struct DeleteJWTClaims {\n     pub sub: String,\n }\n \n-pub fn generate_delete_claims(\n-    uuid: String,\n-) -> DeleteJWTClaims {\n+pub fn generate_delete_claims(uuid: String) -> DeleteJWTClaims {\n     let time_now = Utc::now().naive_utc();\n     DeleteJWTClaims {\n         nbf: time_now.timestamp(),\n@@ -180,9 +178,7 @@ pub struct VerifyEmailJWTClaims {\n     pub sub: String,\n }\n \n-pub fn generate_verify_email_claims(\n-    uuid: String,\n-) -> DeleteJWTClaims {\n+pub fn generate_verify_email_claims(uuid: String) -> DeleteJWTClaims {\n     let time_now = Utc::now().naive_utc();\n     DeleteJWTClaims {\n         nbf: time_now.timestamp(),\n",
            "comment_added_diff": []
        },
        {
            "commit": "88c56de97b48bb5b9b8af350d0d0e0d5f080ff0e",
            "timestamp": "2019-12-27T18:42:39+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Config option for client IP header",
            "additions": 13,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -426,12 +426,21 @@ pub struct ClientIp {\n impl<'a, 'r> FromRequest<'a, 'r> for ClientIp {\n     type Error = ();\n \n-    fn from_request(request: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n-        let ip = match request.client_ip() {\n-            Some(addr) => addr,\n-            None => \"0.0.0.0\".parse().unwrap(),\n+    fn from_request(req: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+        let ip = if CONFIG._ip_header_enabled() {\n+            req.headers().get_one(&CONFIG.ip_header()).and_then(|ip| {\n+                ip.parse()\n+                    .map_err(|_| warn_!(\"'{}' header is malformed: {}\", CONFIG.ip_header(), ip))\n+                    .ok()\n+            })\n+        } else {\n+            None\n         };\n \n+        let ip = ip\n+            .or_else(|| req.remote().map(|r| r.ip()))\n+            .unwrap_or_else(|| \"0.0.0.0\".parse().unwrap());\n+\n         Outcome::Success(ClientIp { ip })\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "cb6f3927745b8f5feb69662fe7aa2b355c818612",
            "timestamp": "2019-12-28T15:09:07+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "When receiving a comma separated list as IP, pick the first",
            "additions": 7,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -429,9 +429,13 @@ impl<'a, 'r> FromRequest<'a, 'r> for ClientIp {\n     fn from_request(req: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n         let ip = if CONFIG._ip_header_enabled() {\n             req.headers().get_one(&CONFIG.ip_header()).and_then(|ip| {\n-                ip.parse()\n-                    .map_err(|_| warn_!(\"'{}' header is malformed: {}\", CONFIG.ip_header(), ip))\n-                    .ok()\n+                match ip.find(',') {\n+                    Some(idx) => &ip[..idx],\n+                    None => ip,\n+                }\n+                .parse()\n+                .map_err(|_| warn!(\"'{}' header is malformed: {}\", CONFIG.ip_header(), ip))\n+                .ok()\n             })\n         } else {\n             None\n",
            "comment_added_diff": []
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 5,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -16,11 +16,11 @@ const JWT_ALGORITHM: Algorithm = Algorithm::RS256;\n lazy_static! {\n     pub static ref DEFAULT_VALIDITY: Duration = Duration::hours(2);\n     static ref JWT_HEADER: Header = Header::new(JWT_ALGORITHM);\n-    pub static ref JWT_LOGIN_ISSUER: String = format!(\"{}|login\", CONFIG.domain());\n-    pub static ref JWT_INVITE_ISSUER: String = format!(\"{}|invite\", CONFIG.domain());\n-    pub static ref JWT_DELETE_ISSUER: String = format!(\"{}|delete\", CONFIG.domain());\n-    pub static ref JWT_VERIFYEMAIL_ISSUER: String = format!(\"{}|verifyemail\", CONFIG.domain());\n-    pub static ref JWT_ADMIN_ISSUER: String = format!(\"{}|admin\", CONFIG.domain());\n+    pub static ref JWT_LOGIN_ISSUER: String = format!(\"{}|login\", CONFIG.domain_origin());\n+    pub static ref JWT_INVITE_ISSUER: String = format!(\"{}|invite\", CONFIG.domain_origin());\n+    pub static ref JWT_DELETE_ISSUER: String = format!(\"{}|delete\", CONFIG.domain_origin());\n+    pub static ref JWT_VERIFYEMAIL_ISSUER: String = format!(\"{}|verifyemail\", CONFIG.domain_origin());\n+    pub static ref JWT_ADMIN_ISSUER: String = format!(\"{}|admin\", CONFIG.domain_origin());\n     static ref PRIVATE_RSA_KEY: Vec<u8> = match read_file(&CONFIG.private_rsa_key()) {\n         Ok(key) => key,\n         Err(e) => panic!(\"Error loading private RSA Key.\\n Error: {}\", e),\n",
            "comment_added_diff": []
        },
        {
            "commit": "70f3ab8ec3d6ccfd8ec8c71c888459de484d9b43",
            "timestamp": "2020-03-09T22:04:03+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Migrate lazy_static to once_cell, less macro magic and slightly faster",
            "additions": 16,
            "deletions": 17,
            "change_type": "MODIFY",
            "diff": "@@ -3,6 +3,7 @@\n //\n use crate::util::read_file;\n use chrono::{Duration, Utc};\n+use once_cell::sync::Lazy;\n \n use jsonwebtoken::{self, Algorithm, Header};\n use serde::de::DeserializeOwned;\n@@ -13,23 +14,21 @@ use crate::CONFIG;\n \n const JWT_ALGORITHM: Algorithm = Algorithm::RS256;\n \n-lazy_static! {\n-    pub static ref DEFAULT_VALIDITY: Duration = Duration::hours(2);\n-    static ref JWT_HEADER: Header = Header::new(JWT_ALGORITHM);\n-    pub static ref JWT_LOGIN_ISSUER: String = format!(\"{}|login\", CONFIG.domain_origin());\n-    pub static ref JWT_INVITE_ISSUER: String = format!(\"{}|invite\", CONFIG.domain_origin());\n-    pub static ref JWT_DELETE_ISSUER: String = format!(\"{}|delete\", CONFIG.domain_origin());\n-    pub static ref JWT_VERIFYEMAIL_ISSUER: String = format!(\"{}|verifyemail\", CONFIG.domain_origin());\n-    pub static ref JWT_ADMIN_ISSUER: String = format!(\"{}|admin\", CONFIG.domain_origin());\n-    static ref PRIVATE_RSA_KEY: Vec<u8> = match read_file(&CONFIG.private_rsa_key()) {\n-        Ok(key) => key,\n-        Err(e) => panic!(\"Error loading private RSA Key.\\n Error: {}\", e),\n-    };\n-    static ref PUBLIC_RSA_KEY: Vec<u8> = match read_file(&CONFIG.public_rsa_key()) {\n-        Ok(key) => key,\n-        Err(e) => panic!(\"Error loading public RSA Key.\\n Error: {}\", e),\n-    };\n-}\n+pub static DEFAULT_VALIDITY: Lazy<Duration> = Lazy::new(|| Duration::hours(2));\n+static JWT_HEADER: Lazy<Header> = Lazy::new(|| Header::new(JWT_ALGORITHM));\n+pub static JWT_LOGIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|login\", CONFIG.domain_origin()));\n+static JWT_INVITE_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|invite\", CONFIG.domain_origin()));\n+static JWT_DELETE_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|delete\", CONFIG.domain_origin()));\n+static JWT_VERIFYEMAIL_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|verifyemail\", CONFIG.domain_origin()));\n+static JWT_ADMIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|admin\", CONFIG.domain_origin()));\n+static PRIVATE_RSA_KEY: Lazy<Vec<u8>> = Lazy::new(|| match read_file(&CONFIG.private_rsa_key()) {\n+    Ok(key) => key,\n+    Err(e) => panic!(\"Error loading private RSA Key.\\n Error: {}\", e),\n+});\n+static PUBLIC_RSA_KEY: Lazy<Vec<u8>> = Lazy::new(|| match read_file(&CONFIG.public_rsa_key()) {\n+    Ok(key) => key,\n+    Err(e) => panic!(\"Error loading public RSA Key.\\n Error: {}\", e),\n+});\n \n pub fn encode_jwt<T: Serialize>(claims: &T) -> String {\n     match jsonwebtoken::encode(&JWT_HEADER, claims, &PRIVATE_RSA_KEY) {\n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 11,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -4,6 +4,7 @@\n use crate::util::read_file;\n use chrono::{Duration, Utc};\n use once_cell::sync::Lazy;\n+use num_traits::FromPrimitive;\n \n use jsonwebtoken::{self, Algorithm, Header};\n use serde::de::DeserializeOwned;\n@@ -385,6 +386,16 @@ impl<'a, 'r> FromRequest<'a, 'r> for AdminHeaders {\n     }\n }\n \n+impl Into<Headers> for AdminHeaders {    \n+    fn into(self) -> Headers { \n+        Headers {\n+            host: self.host,\n+            device: self.device,\n+            user: self.user\n+        }\n+     }\n+}\n+\n pub struct OwnerHeaders {\n     pub host: String,\n     pub device: Device,\n",
            "comment_added_diff": []
        },
        {
            "commit": "37b212427c80a1c56db748510ebe6dee4d218b4a",
            "timestamp": "2020-03-16T16:38:00+01:00",
            "author": "BlackDex",
            "commit_message": "Updated jsonwebtoken\n\nUpdated to the latest version of jsonwebtoken.\nSome small code changes to match the new versions.",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -6,7 +6,7 @@ use chrono::{Duration, Utc};\n use once_cell::sync::Lazy;\n use num_traits::FromPrimitive;\n \n-use jsonwebtoken::{self, Algorithm, Header};\n+use jsonwebtoken::{self, Algorithm, Header, EncodingKey, DecodingKey};\n use serde::de::DeserializeOwned;\n use serde::ser::Serialize;\n \n@@ -32,7 +32,7 @@ static PUBLIC_RSA_KEY: Lazy<Vec<u8>> = Lazy::new(|| match read_file(&CONFIG.publ\n });\n \n pub fn encode_jwt<T: Serialize>(claims: &T) -> String {\n-    match jsonwebtoken::encode(&JWT_HEADER, claims, &PRIVATE_RSA_KEY) {\n+    match jsonwebtoken::encode(&JWT_HEADER, claims, &EncodingKey::from_rsa_der(&PRIVATE_RSA_KEY)) {\n         Ok(token) => token,\n         Err(e) => panic!(\"Error encoding jwt {}\", e),\n     }\n@@ -51,7 +51,7 @@ fn decode_jwt<T: DeserializeOwned>(token: &str, issuer: String) -> Result<T, Err\n \n     let token = token.replace(char::is_whitespace, \"\");\n \n-    jsonwebtoken::decode(&token, &PUBLIC_RSA_KEY, &validation)\n+    jsonwebtoken::decode(&token, &DecodingKey::from_rsa_der(&PUBLIC_RSA_KEY), &validation)\n         .map(|d| d.claims)\n         .map_res(\"Error decoding JWT\")\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "669b101e6a68ab639526bc5b1405e8ced4a9f94e",
            "timestamp": "2020-03-19T16:50:47+01:00",
            "author": "BlackDex",
            "commit_message": "Fixing issue #908\n\nSometimes an org-uuid is not within the path but in a query value,\nThis fixes the check for that.",
            "additions": 53,
            "deletions": 34,
            "change_type": "MODIFY",
            "diff": "@@ -315,41 +315,60 @@ impl<'a, 'r> FromRequest<'a, 'r> for OrgHeaders {\n             Outcome::Forward(_) => Outcome::Forward(()),\n             Outcome::Failure(f) => Outcome::Failure(f),\n             Outcome::Success(headers) => {\n-                // org_id is expected to be the second param (\"/organizations/<org_id>\")\n-                match request.get_param::<String>(1) {\n-                    Some(Ok(org_id)) => {\n-                        let conn = match request.guard::<DbConn>() {\n-                            Outcome::Success(conn) => conn,\n-                            _ => err_handler!(\"Error getting DB\"),\n-                        };\n-\n-                        let user = headers.user;\n-                        let org_user = match UserOrganization::find_by_user_and_org(&user.uuid, &org_id, &conn) {\n-                            Some(user) => {\n-                                if user.status == UserOrgStatus::Confirmed as i32 {\n-                                    user\n-                                } else {\n-                                    err_handler!(\"The current user isn't confirmed member of the organization\")\n-                                }\n-                            }\n-                            None => err_handler!(\"The current user isn't member of the organization\"),\n-                        };\n-\n-                        Outcome::Success(Self {\n-                            host: headers.host,\n-                            device: headers.device,\n-                            user,\n-                            org_user_type: {\n-                                if let Some(org_usr_type) = UserOrgType::from_i32(org_user.atype) {\n-                                    org_usr_type\n-                                } else {\n-                                    // This should only happen if the DB is corrupted\n-                                    err_handler!(\"Unknown user type in the database\")\n-                                }\n-                            },\n-                        })\n+                // org_id is usually the second param (\"/organizations/<org_id>\")\n+                // But there are cases where it is located in a query value.\n+                // First check the param, if this is not a valid uuid, we will try the query value.\n+                let query_org_id = match request.get_query_value::<String>(\"organizationId\") {\n+                    Some(Ok(query_org_id)) => { query_org_id }\n+                    _ => { \"\".into() }\n+                };\n+                let param_org_id = match request.get_param::<String>(1) {\n+                    Some(Ok(param_org_id)) => { param_org_id }\n+                    _ => { \"\".into() }\n+                };\n+\n+                let org_uuid: _ = match uuid::Uuid::parse_str(&param_org_id) {\n+                    Ok(uuid) => uuid,\n+                    _ => match uuid::Uuid::parse_str(&query_org_id) {\n+                        Ok(uuid) => uuid,\n+                        _ => err_handler!(\"Error getting the organization id\"),\n                     }\n-                    _ => err_handler!(\"Error getting the organization id\"),\n+                };\n+\n+                let org_id: &str = &org_uuid.to_string();\n+                if !org_id.is_empty() {\n+                    let conn = match request.guard::<DbConn>() {\n+                        Outcome::Success(conn) => conn,\n+                        _ => err_handler!(\"Error getting DB\"),\n+                    };\n+\n+                    let user = headers.user;\n+                    let org_user = match UserOrganization::find_by_user_and_org(&user.uuid, &org_id, &conn) {\n+                        Some(user) => {\n+                            if user.status == UserOrgStatus::Confirmed as i32 {\n+                                user\n+                            } else {\n+                                err_handler!(\"The current user isn't confirmed member of the organization\")\n+                            }\n+                        }\n+                        None => err_handler!(\"The current user isn't member of the organization\"),\n+                    };\n+\n+                    Outcome::Success(Self {\n+                        host: headers.host,\n+                        device: headers.device,\n+                        user,\n+                        org_user_type: {\n+                            if let Some(org_usr_type) = UserOrgType::from_i32(org_user.atype) {\n+                                org_usr_type\n+                            } else {\n+                                // This should only happen if the DB is corrupted\n+                                err_handler!(\"Unknown user type in the database\")\n+                            }\n+                        },\n+                    })\n+                } else {\n+                    err_handler!(\"Error getting the organization id\")\n                 }\n             }\n         }\n",
            "comment_added_diff": [
                [
                    318,
                    "                // org_id is usually the second param (\"/organizations/<org_id>\")"
                ],
                [
                    319,
                    "                // But there are cases where it is located in a query value."
                ],
                [
                    320,
                    "                // First check the param, if this is not a valid uuid, we will try the query value."
                ],
                [
                    365,
                    "                                // This should only happen if the DB is corrupted"
                ]
            ]
        },
        {
            "commit": "baac8d9627945c7a307d8c617558eb9be07308b0",
            "timestamp": "2020-03-19T17:37:10+01:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #908\n\nThe organization uuid is most of the time within the uri path as a\nparameter. But sometimes it only is there as a query value.\n\nThis fix checks both, and returns the uuid when possible.",
            "additions": 52,
            "deletions": 53,
            "change_type": "MODIFY",
            "diff": "@@ -307,6 +307,25 @@ pub struct OrgHeaders {\n     pub org_user_type: UserOrgType,\n }\n \n+// org_id is usually the second param (\"/organizations/<org_id>\")\n+// But there are cases where it is located in a query value.\n+// First check the param, if this is not a valid uuid, we will try the query value.\n+fn get_org_id(request: &Request) -> Option<String> {\n+    if let Some(Ok(org_id)) = request.get_param::<String>(1) {\n+        if uuid::Uuid::parse_str(&org_id).is_ok() {\n+            return Some(org_id);\n+        }\n+    }\n+\n+    if let Some(Ok(org_id)) = request.get_query_value::<String>(\"organizationId\") {\n+        if uuid::Uuid::parse_str(&org_id).is_ok() {\n+            return Some(org_id);\n+        }\n+    }\n+\n+    None\n+}\n+\n impl<'a, 'r> FromRequest<'a, 'r> for OrgHeaders {\n     type Error = &'static str;\n \n@@ -315,60 +334,40 @@ impl<'a, 'r> FromRequest<'a, 'r> for OrgHeaders {\n             Outcome::Forward(_) => Outcome::Forward(()),\n             Outcome::Failure(f) => Outcome::Failure(f),\n             Outcome::Success(headers) => {\n-                // org_id is usually the second param (\"/organizations/<org_id>\")\n-                // But there are cases where it is located in a query value.\n-                // First check the param, if this is not a valid uuid, we will try the query value.\n-                let query_org_id = match request.get_query_value::<String>(\"organizationId\") {\n-                    Some(Ok(query_org_id)) => { query_org_id }\n-                    _ => { \"\".into() }\n-                };\n-                let param_org_id = match request.get_param::<String>(1) {\n-                    Some(Ok(param_org_id)) => { param_org_id }\n-                    _ => { \"\".into() }\n-                };\n-\n-                let org_uuid: _ = match uuid::Uuid::parse_str(&param_org_id) {\n-                    Ok(uuid) => uuid,\n-                    _ => match uuid::Uuid::parse_str(&query_org_id) {\n-                        Ok(uuid) => uuid,\n-                        _ => err_handler!(\"Error getting the organization id\"),\n-                    }\n-                };\n-\n-                let org_id: &str = &org_uuid.to_string();\n-                if !org_id.is_empty() {\n-                    let conn = match request.guard::<DbConn>() {\n-                        Outcome::Success(conn) => conn,\n-                        _ => err_handler!(\"Error getting DB\"),\n-                    };\n-\n-                    let user = headers.user;\n-                    let org_user = match UserOrganization::find_by_user_and_org(&user.uuid, &org_id, &conn) {\n-                        Some(user) => {\n-                            if user.status == UserOrgStatus::Confirmed as i32 {\n-                                user\n-                            } else {\n-                                err_handler!(\"The current user isn't confirmed member of the organization\")\n+                match get_org_id(request) {\n+                    Some(org_id) => {\n+                        let conn = match request.guard::<DbConn>() {\n+                            Outcome::Success(conn) => conn,\n+                            _ => err_handler!(\"Error getting DB\"),\n+                        };\n+\n+                        let user = headers.user;\n+                        let org_user = match UserOrganization::find_by_user_and_org(&user.uuid, &org_id, &conn) {\n+                            Some(user) => {\n+                                if user.status == UserOrgStatus::Confirmed as i32 {\n+                                    user\n+                                } else {\n+                                    err_handler!(\"The current user isn't confirmed member of the organization\")\n+                                }\n                             }\n-                        }\n-                        None => err_handler!(\"The current user isn't member of the organization\"),\n-                    };\n-\n-                    Outcome::Success(Self {\n-                        host: headers.host,\n-                        device: headers.device,\n-                        user,\n-                        org_user_type: {\n-                            if let Some(org_usr_type) = UserOrgType::from_i32(org_user.atype) {\n-                                org_usr_type\n-                            } else {\n-                                // This should only happen if the DB is corrupted\n-                                err_handler!(\"Unknown user type in the database\")\n-                            }\n-                        },\n-                    })\n-                } else {\n-                    err_handler!(\"Error getting the organization id\")\n+                            None => err_handler!(\"The current user isn't member of the organization\"),\n+                        };\n+\n+                        Outcome::Success(Self {\n+                            host: headers.host,\n+                            device: headers.device,\n+                            user,\n+                            org_user_type: {\n+                                if let Some(org_usr_type) = UserOrgType::from_i32(org_user.atype) {\n+                                    org_usr_type\n+                                } else {\n+                                    // This should only happen if the DB is corrupted\n+                                    err_handler!(\"Unknown user type in the database\")\n+                                }\n+                            },\n+                        })\n+                    },\n+                    _ => err_handler!(\"Error getting the organization id\"),\n                 }\n             }\n         }\n",
            "comment_added_diff": [
                [
                    310,
                    "// org_id is usually the second param (\"/organizations/<org_id>\")"
                ],
                [
                    311,
                    "// But there are cases where it is located in a query value."
                ],
                [
                    312,
                    "// First check the param, if this is not a valid uuid, we will try the query value."
                ],
                [
                    364,
                    "                                    // This should only happen if the DB is corrupted"
                ]
            ]
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 20,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -1,17 +1,19 @@\n //\n // JWT Handling\n //\n-use crate::util::read_file;\n use chrono::{Duration, Utc};\n-use once_cell::sync::Lazy;\n use num_traits::FromPrimitive;\n+use once_cell::sync::Lazy;\n \n-use jsonwebtoken::{self, Algorithm, Header, EncodingKey, DecodingKey};\n+use jsonwebtoken::{self, Algorithm, DecodingKey, EncodingKey, Header};\n use serde::de::DeserializeOwned;\n use serde::ser::Serialize;\n \n-use crate::error::{Error, MapResult};\n-use crate::CONFIG;\n+use crate::{\n+    error::{Error, MapResult},\n+    util::read_file,\n+    CONFIG,\n+};\n \n const JWT_ALGORITHM: Algorithm = Algorithm::RS256;\n \n@@ -213,11 +215,15 @@ pub fn generate_admin_claims() -> AdminJWTClaims {\n //\n // Bearer token authentication\n //\n-use rocket::request::{self, FromRequest, Request};\n-use rocket::Outcome;\n+use rocket::{\n+    request::{self, FromRequest, Request},\n+    Outcome,\n+};\n \n-use crate::db::models::{Device, User, UserOrgStatus, UserOrgType, UserOrganization};\n-use crate::db::DbConn;\n+use crate::db::{\n+    models::{Device, User, UserOrgStatus, UserOrgType, UserOrganization},\n+    DbConn,\n+};\n \n pub struct Headers {\n     pub host: String,\n@@ -366,7 +372,7 @@ impl<'a, 'r> FromRequest<'a, 'r> for OrgHeaders {\n                                 }\n                             },\n                         })\n-                    },\n+                    }\n                     _ => err_handler!(\"Error getting the organization id\"),\n                 }\n             }\n@@ -404,14 +410,14 @@ impl<'a, 'r> FromRequest<'a, 'r> for AdminHeaders {\n     }\n }\n \n-impl Into<Headers> for AdminHeaders {    \n-    fn into(self) -> Headers { \n+impl Into<Headers> for AdminHeaders {\n+    fn into(self) -> Headers {\n         Headers {\n             host: self.host,\n             device: self.device,\n-            user: self.user\n+            user: self.user,\n         }\n-     }\n+    }\n }\n \n pub struct OwnerHeaders {\n",
            "comment_added_diff": []
        },
        {
            "commit": "32cfaab5eefa1564b31819685a7b51f4a5025a59",
            "timestamp": "2020-07-23T21:07:04+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated dependencies and changed rocket request imports",
            "additions": 6,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -216,8 +216,7 @@ pub fn generate_admin_claims() -> AdminJWTClaims {\n // Bearer token authentication\n //\n use rocket::{\n-    request::{self, FromRequest, Request},\n-    Outcome,\n+    request::{FromRequest, Request, Outcome},\n };\n \n use crate::db::{\n@@ -234,7 +233,7 @@ pub struct Headers {\n impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n     type Error = &'static str;\n \n-    fn from_request(request: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n         let headers = request.headers();\n \n         // Get host\n@@ -335,7 +334,7 @@ fn get_org_id(request: &Request) -> Option<String> {\n impl<'a, 'r> FromRequest<'a, 'r> for OrgHeaders {\n     type Error = &'static str;\n \n-    fn from_request(request: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n         match request.guard::<Headers>() {\n             Outcome::Forward(_) => Outcome::Forward(()),\n             Outcome::Failure(f) => Outcome::Failure(f),\n@@ -390,7 +389,7 @@ pub struct AdminHeaders {\n impl<'a, 'r> FromRequest<'a, 'r> for AdminHeaders {\n     type Error = &'static str;\n \n-    fn from_request(request: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n         match request.guard::<OrgHeaders>() {\n             Outcome::Forward(_) => Outcome::Forward(()),\n             Outcome::Failure(f) => Outcome::Failure(f),\n@@ -429,7 +428,7 @@ pub struct OwnerHeaders {\n impl<'a, 'r> FromRequest<'a, 'r> for OwnerHeaders {\n     type Error = &'static str;\n \n-    fn from_request(request: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n         match request.guard::<OrgHeaders>() {\n             Outcome::Forward(_) => Outcome::Forward(()),\n             Outcome::Failure(f) => Outcome::Failure(f),\n@@ -460,7 +459,7 @@ pub struct ClientIp {\n impl<'a, 'r> FromRequest<'a, 'r> for ClientIp {\n     type Error = ();\n \n-    fn from_request(req: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+    fn from_request(req: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n         let ip = if CONFIG._ip_header_enabled() {\n             req.headers().get_one(&CONFIG.ip_header()).and_then(|ip| {\n                 match ip.find(',') {\n",
            "comment_added_diff": []
        },
        {
            "commit": "7cf8809d777cd88ad5aa932324e51561724e3c32",
            "timestamp": "2020-12-02T22:50:51+01:00",
            "author": "BlackDex",
            "commit_message": "Adding Manager Role support\n\nThis has been requested a few times (#1136 & #246 & forum), and there already were two\n(1:1 duplicate) PR's (#1222 & #1223) which needed some changes and no\nfollowups or further comments unfortunally.\n\nThis PR adds two auth headers.\n- ManagerHeaders\n  Checks if the user-type is Manager or higher and if the manager is\npart of that collection or not.\n- ManagerHeadersLoose\n  Check if the user-type is Manager or higher, but does not check if the\nuser is part of the collection, needed for a few features like\nretreiving all the users of an org.\n\nI think this is the safest way to implement this instead of having to\ncheck this within every function which needs this manually.\n\nAlso some extra checks if a manager has access to all collections or\njust a selection.\n\nfixes #1136",
            "additions": 130,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -220,7 +220,7 @@ use rocket::{\n };\n \n use crate::db::{\n-    models::{Device, User, UserOrgStatus, UserOrgType, UserOrganization},\n+    models::{Device, User, UserOrgStatus, UserOrgType, UserOrganization, CollectionUser},\n     DbConn,\n };\n \n@@ -310,6 +310,8 @@ pub struct OrgHeaders {\n     pub device: Device,\n     pub user: User,\n     pub org_user_type: UserOrgType,\n+    pub org_user: UserOrganization,\n+    pub org_id: String,\n }\n \n // org_id is usually the second param (\"/organizations/<org_id>\")\n@@ -370,6 +372,8 @@ impl<'a, 'r> FromRequest<'a, 'r> for OrgHeaders {\n                                     err_handler!(\"Unknown user type in the database\")\n                                 }\n                             },\n+                            org_user,\n+                            org_id,\n                         })\n                     }\n                     _ => err_handler!(\"Error getting the organization id\"),\n@@ -419,6 +423,131 @@ impl Into<Headers> for AdminHeaders {\n     }\n }\n \n+\n+\n+\n+\n+// col_id is usually the forth param (\"/organizations/<org_id>/collections/<col_id>\")\n+// But there cloud be cases where it is located in a query value.\n+// First check the param, if this is not a valid uuid, we will try the query value.\n+fn get_col_id(request: &Request) -> Option<String> {\n+    if let Some(Ok(col_id)) = request.get_param::<String>(3) {\n+        if uuid::Uuid::parse_str(&col_id).is_ok() {\n+            return Some(col_id);\n+        }\n+    }\n+\n+    if let Some(Ok(col_id)) = request.get_query_value::<String>(\"collectionId\") {\n+        if uuid::Uuid::parse_str(&col_id).is_ok() {\n+            return Some(col_id);\n+        }\n+    }\n+\n+    None\n+}\n+\n+/// The ManagerHeaders are used to check if you are at least a Manager\n+/// and have access to the specific collection provided via the <col_id>/collections/collectionId.\n+/// This does strict checking on the collection_id, ManagerHeadersLoose does not.\n+pub struct ManagerHeaders {\n+    pub host: String,\n+    pub device: Device,\n+    pub user: User,\n+    pub org_user_type: UserOrgType,\n+}\n+\n+impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeaders {\n+    type Error = &'static str;\n+\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n+        match request.guard::<OrgHeaders>() {\n+            Outcome::Forward(_) => Outcome::Forward(()),\n+            Outcome::Failure(f) => Outcome::Failure(f),\n+            Outcome::Success(headers) => {\n+                if headers.org_user_type >= UserOrgType::Manager {\n+                    match get_col_id(request) {\n+                        Some(col_id) => {\n+                            let conn = match request.guard::<DbConn>() {\n+                                Outcome::Success(conn) => conn,\n+                                _ => err_handler!(\"Error getting DB\"),\n+                            };\n+\n+                            if !headers.org_user.access_all {\n+                                match CollectionUser::find_by_collection_and_user(&col_id, &headers.org_user.user_uuid, &conn) {\n+                                    Some(_) => (),\n+                                    None => err_handler!(\"The current user isn't a manager for this collection\"),\n+                                }\n+                            }\n+                        },\n+                        _ => err_handler!(\"Error getting the collection id\"),\n+                    }\n+\n+                    Outcome::Success(Self {\n+                        host: headers.host,\n+                        device: headers.device,\n+                        user: headers.user,\n+                        org_user_type: headers.org_user_type,\n+                    })\n+                } else {\n+                    err_handler!(\"You need to be a Manager, Admin or Owner to call this endpoint\")\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+impl Into<Headers> for ManagerHeaders {\n+    fn into(self) -> Headers {\n+        Headers {\n+            host: self.host,\n+            device: self.device,\n+            user: self.user,\n+        }\n+    }\n+}\n+\n+/// The ManagerHeadersLoose is used when you at least need to be a Manager,\n+/// but there is no collection_id sent with the request (either in the path or as form data).\n+pub struct ManagerHeadersLoose {\n+    pub host: String,\n+    pub device: Device,\n+    pub user: User,\n+    pub org_user_type: UserOrgType,\n+}\n+\n+impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeadersLoose {\n+    type Error = &'static str;\n+\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n+        match request.guard::<OrgHeaders>() {\n+            Outcome::Forward(_) => Outcome::Forward(()),\n+            Outcome::Failure(f) => Outcome::Failure(f),\n+            Outcome::Success(headers) => {\n+                if headers.org_user_type >= UserOrgType::Manager {\n+                    Outcome::Success(Self {\n+                        host: headers.host,\n+                        device: headers.device,\n+                        user: headers.user,\n+                        org_user_type: headers.org_user_type,\n+                    })\n+                } else {\n+                    err_handler!(\"You need to be a Manager, Admin or Owner to call this endpoint\")\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+impl Into<Headers> for ManagerHeadersLoose {\n+    fn into(self) -> Headers {\n+        Headers {\n+            host: self.host,\n+            device: self.device,\n+            user: self.user,\n+        }\n+    }\n+}\n+\n pub struct OwnerHeaders {\n     pub host: String,\n     pub device: Device,\n",
            "comment_added_diff": [
                [
                    430,
                    "// col_id is usually the forth param (\"/organizations/<org_id>/collections/<col_id>\")"
                ],
                [
                    431,
                    "// But there cloud be cases where it is located in a query value."
                ],
                [
                    432,
                    "// First check the param, if this is not a valid uuid, we will try the query value."
                ],
                [
                    449,
                    "/// The ManagerHeaders are used to check if you are at least a Manager"
                ],
                [
                    450,
                    "/// and have access to the specific collection provided via the <col_id>/collections/collectionId."
                ],
                [
                    451,
                    "/// This does strict checking on the collection_id, ManagerHeadersLoose does not."
                ],
                [
                    509,
                    "/// The ManagerHeadersLoose is used when you at least need to be a Manager,"
                ],
                [
                    510,
                    "/// but there is no collection_id sent with the request (either in the path or as form data)."
                ]
            ]
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 22,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -215,12 +215,10 @@ pub fn generate_admin_claims() -> AdminJWTClaims {\n //\n // Bearer token authentication\n //\n-use rocket::{\n-    request::{FromRequest, Request, Outcome},\n-};\n+use rocket::request::{FromRequest, Outcome, Request};\n \n use crate::db::{\n-    models::{Device, User, UserOrgStatus, UserOrgType, UserOrganization, CollectionUser},\n+    models::{CollectionUser, Device, User, UserOrgStatus, UserOrgType, UserOrganization, UserStampException},\n     DbConn,\n };\n \n@@ -298,7 +296,25 @@ impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n         };\n \n         if user.security_stamp != claims.sstamp {\n-            err_handler!(\"Invalid security stamp\")\n+            if let Some(stamp_exception) = user\n+                .stamp_exception\n+                .as_deref()\n+                .and_then(|s| serde_json::from_str::<UserStampException>(s).ok())\n+            {\n+                let current_route = match request.route().and_then(|r| r.name) {\n+                    Some(name) => name,\n+                    _ => err_handler!(\"Error getting current route for stamp exception\"),\n+                };\n+\n+                // Check if both match, if not this route is not allowed with the current security stamp.\n+                if stamp_exception.route != current_route {\n+                    err_handler!(\"Invalid security stamp: Current route and exception route do not match\")\n+                } else if stamp_exception.security_stamp != claims.sstamp {\n+                    err_handler!(\"Invalid security stamp for matched stamp exception\")\n+                }\n+            } else {\n+                err_handler!(\"Invalid security stamp\")\n+            }\n         }\n \n         Outcome::Success(Headers { host, device, user })\n@@ -423,10 +439,6 @@ impl Into<Headers> for AdminHeaders {\n     }\n }\n \n-\n-\n-\n-\n // col_id is usually the forth param (\"/organizations/<org_id>/collections/<col_id>\")\n // But there cloud be cases where it is located in a query value.\n // First check the param, if this is not a valid uuid, we will try the query value.\n@@ -478,7 +490,7 @@ impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeaders {\n                                     None => err_handler!(\"The current user isn't a manager for this collection\"),\n                                 }\n                             }\n-                        },\n+                        }\n                         _ => err_handler!(\"Error getting the collection id\"),\n                     }\n \n",
            "comment_added_diff": [
                [
                    309,
                    "                // Check if both match, if not this route is not allowed with the current security stamp."
                ]
            ]
        },
        {
            "commit": "67c657003df89c6005de0c4180d93ddfa792ba40",
            "timestamp": "2021-01-26T22:35:09-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix collection access issues for owner/admin users\n\nThe implementation of the `Manager` user type (#1242) introduced a regression\nwhereby owner/admin users are incorrectly denied access to certain collection\nAPIs if their access control for collections isn't set to \"access all\".\n\nOwner/admin users should always have full access to collection APIs, per\nhttps://bitwarden.com/help/article/user-types-access-control/#access-control:\n\n> Assigning Admins and Owners to Collections via Access Control will only\n> impact which Collections appear readily in the Filters section of their\n> Vault. Admins and Owners will always be able to access \"un-assigned\"\n> Collections via the Organization view.",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -330,9 +330,9 @@ pub struct OrgHeaders {\n     pub org_id: String,\n }\n \n-// org_id is usually the second param (\"/organizations/<org_id>\")\n-// But there are cases where it is located in a query value.\n-// First check the param, if this is not a valid uuid, we will try the query value.\n+// org_id is usually the second path param (\"/organizations/<org_id>\"),\n+// but there are cases where it is a query value.\n+// First check the path, if this is not a valid uuid, try the query values.\n fn get_org_id(request: &Request) -> Option<String> {\n     if let Some(Ok(org_id)) = request.get_param::<String>(1) {\n         if uuid::Uuid::parse_str(&org_id).is_ok() {\n@@ -439,9 +439,9 @@ impl Into<Headers> for AdminHeaders {\n     }\n }\n \n-// col_id is usually the forth param (\"/organizations/<org_id>/collections/<col_id>\")\n-// But there cloud be cases where it is located in a query value.\n-// First check the param, if this is not a valid uuid, we will try the query value.\n+// col_id is usually the fourth path param (\"/organizations/<org_id>/collections/<col_id>\"),\n+// but there could be cases where it is a query value.\n+// First check the path, if this is not a valid uuid, try the query values.\n fn get_col_id(request: &Request) -> Option<String> {\n     if let Some(Ok(col_id)) = request.get_param::<String>(3) {\n         if uuid::Uuid::parse_str(&col_id).is_ok() {\n@@ -484,7 +484,7 @@ impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeaders {\n                                 _ => err_handler!(\"Error getting DB\"),\n                             };\n \n-                            if !headers.org_user.access_all {\n+                            if !headers.org_user.has_full_access() {\n                                 match CollectionUser::find_by_collection_and_user(&col_id, &headers.org_user.user_uuid, &conn) {\n                                     Some(_) => (),\n                                     None => err_handler!(\"The current user isn't a manager for this collection\"),\n",
            "comment_added_diff": [
                [
                    333,
                    "// org_id is usually the second path param (\"/organizations/<org_id>\"),"
                ],
                [
                    334,
                    "// but there are cases where it is a query value."
                ],
                [
                    335,
                    "// First check the path, if this is not a valid uuid, try the query values."
                ],
                [
                    442,
                    "// col_id is usually the fourth path param (\"/organizations/<org_id>/collections/<col_id>\"),"
                ],
                [
                    443,
                    "// but there could be cases where it is a query value."
                ],
                [
                    444,
                    "// First check the path, if this is not a valid uuid, try the query values."
                ]
            ]
        },
        {
            "commit": "2969e87b5262b0c75d9298f8a2bf4a82336e918d",
            "timestamp": "2021-03-14T23:24:47+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add separate host-only fromrequest handler",
            "additions": 26,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -222,13 +222,12 @@ use crate::db::{\n     DbConn,\n };\n \n-pub struct Headers {\n-    pub host: String,\n-    pub device: Device,\n-    pub user: User,\n+pub struct Host {\n+    pub host: String\n }\n \n-impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n+\n+impl<'a, 'r> FromRequest<'a, 'r> for Host {\n     type Error = &'static str;\n \n     fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n@@ -262,6 +261,28 @@ impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n             format!(\"{}://{}\", protocol, host)\n         };\n \n+        Outcome::Success(Host { host })\n+    }\n+}\n+\n+pub struct Headers {\n+    pub host: String,\n+    pub device: Device,\n+    pub user: User,\n+}\n+\n+impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n+    type Error = &'static str;\n+\n+    fn from_request(request: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n+        let headers = request.headers();\n+\n+        let host = match Host::from_request(request) {\n+            Outcome::Forward(_) => return Outcome::Forward(()),\n+            Outcome::Failure(f) => return Outcome::Failure(f),\n+            Outcome::Success(host) => host.host,\n+        };\n+\n         // Get access_token\n         let access_token: &str = match headers.get_one(\"Authorization\") {\n             Some(a) => match a.rsplit(\"Bearer \").next() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "6b1daeba0533516c6d50fd2cebcc1e8060fd6df2",
            "timestamp": "2021-03-27T14:19:57+00:00",
            "author": "Jake Howard",
            "commit_message": "Implement `From` over `Into`\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#from_over_into",
            "additions": 15,
            "deletions": 15,
            "change_type": "MODIFY",
            "diff": "@@ -450,12 +450,12 @@ impl<'a, 'r> FromRequest<'a, 'r> for AdminHeaders {\n     }\n }\n \n-impl Into<Headers> for AdminHeaders {\n-    fn into(self) -> Headers {\n+impl From<AdminHeaders> for Headers {\n+    fn from(h: AdminHeaders) -> Headers {\n         Headers {\n-            host: self.host,\n-            device: self.device,\n-            user: self.user,\n+            host: h.host,\n+            device: h.device,\n+            user: h.user,\n         }\n     }\n }\n@@ -529,12 +529,12 @@ impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeaders {\n     }\n }\n \n-impl Into<Headers> for ManagerHeaders {\n-    fn into(self) -> Headers {\n+impl From<ManagerHeaders> for Headers {\n+    fn from(h: ManagerHeaders) -> Headers {\n         Headers {\n-            host: self.host,\n-            device: self.device,\n-            user: self.user,\n+            host: h.host,\n+            device: h.device,\n+            user: h.user,\n         }\n     }\n }\n@@ -571,12 +571,12 @@ impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeadersLoose {\n     }\n }\n \n-impl Into<Headers> for ManagerHeadersLoose {\n-    fn into(self) -> Headers {\n+impl From<ManagerHeadersLoose> for Headers {\n+    fn from(h: ManagerHeadersLoose) -> Headers {\n         Headers {\n-            host: self.host,\n-            device: self.device,\n-            user: self.user,\n+            host: h.host,\n+            device: h.device,\n+            user: h.user,\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "49af9cf4f5f8264384c7fa9063299f44e7536068",
            "timestamp": "2021-03-27T14:26:32+00:00",
            "author": "Jake Howard",
            "commit_message": "Correctly camelCase acronyms\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#upper_case_acronyms",
            "additions": 18,
            "deletions": 18,
            "change_type": "MODIFY",
            "diff": "@@ -58,28 +58,28 @@ fn decode_jwt<T: DeserializeOwned>(token: &str, issuer: String) -> Result<T, Err\n         .map_res(\"Error decoding JWT\")\n }\n \n-pub fn decode_login(token: &str) -> Result<LoginJWTClaims, Error> {\n+pub fn decode_login(token: &str) -> Result<LoginJwtClaims, Error> {\n     decode_jwt(token, JWT_LOGIN_ISSUER.to_string())\n }\n \n-pub fn decode_invite(token: &str) -> Result<InviteJWTClaims, Error> {\n+pub fn decode_invite(token: &str) -> Result<InviteJwtClaims, Error> {\n     decode_jwt(token, JWT_INVITE_ISSUER.to_string())\n }\n \n-pub fn decode_delete(token: &str) -> Result<DeleteJWTClaims, Error> {\n+pub fn decode_delete(token: &str) -> Result<DeleteJwtClaims, Error> {\n     decode_jwt(token, JWT_DELETE_ISSUER.to_string())\n }\n \n-pub fn decode_verify_email(token: &str) -> Result<VerifyEmailJWTClaims, Error> {\n+pub fn decode_verify_email(token: &str) -> Result<VerifyEmailJwtClaims, Error> {\n     decode_jwt(token, JWT_VERIFYEMAIL_ISSUER.to_string())\n }\n \n-pub fn decode_admin(token: &str) -> Result<AdminJWTClaims, Error> {\n+pub fn decode_admin(token: &str) -> Result<AdminJwtClaims, Error> {\n     decode_jwt(token, JWT_ADMIN_ISSUER.to_string())\n }\n \n #[derive(Debug, Serialize, Deserialize)]\n-pub struct LoginJWTClaims {\n+pub struct LoginJwtClaims {\n     // Not before\n     pub nbf: i64,\n     // Expiration time\n@@ -110,7 +110,7 @@ pub struct LoginJWTClaims {\n }\n \n #[derive(Debug, Serialize, Deserialize)]\n-pub struct InviteJWTClaims {\n+pub struct InviteJwtClaims {\n     // Not before\n     pub nbf: i64,\n     // Expiration time\n@@ -132,9 +132,9 @@ pub fn generate_invite_claims(\n     org_id: Option<String>,\n     user_org_id: Option<String>,\n     invited_by_email: Option<String>,\n-) -> InviteJWTClaims {\n+) -> InviteJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    InviteJWTClaims {\n+    InviteJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::days(5)).timestamp(),\n         iss: JWT_INVITE_ISSUER.to_string(),\n@@ -147,7 +147,7 @@ pub fn generate_invite_claims(\n }\n \n #[derive(Debug, Serialize, Deserialize)]\n-pub struct DeleteJWTClaims {\n+pub struct DeleteJwtClaims {\n     // Not before\n     pub nbf: i64,\n     // Expiration time\n@@ -158,9 +158,9 @@ pub struct DeleteJWTClaims {\n     pub sub: String,\n }\n \n-pub fn generate_delete_claims(uuid: String) -> DeleteJWTClaims {\n+pub fn generate_delete_claims(uuid: String) -> DeleteJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    DeleteJWTClaims {\n+    DeleteJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::days(5)).timestamp(),\n         iss: JWT_DELETE_ISSUER.to_string(),\n@@ -169,7 +169,7 @@ pub fn generate_delete_claims(uuid: String) -> DeleteJWTClaims {\n }\n \n #[derive(Debug, Serialize, Deserialize)]\n-pub struct VerifyEmailJWTClaims {\n+pub struct VerifyEmailJwtClaims {\n     // Not before\n     pub nbf: i64,\n     // Expiration time\n@@ -180,9 +180,9 @@ pub struct VerifyEmailJWTClaims {\n     pub sub: String,\n }\n \n-pub fn generate_verify_email_claims(uuid: String) -> DeleteJWTClaims {\n+pub fn generate_verify_email_claims(uuid: String) -> DeleteJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    DeleteJWTClaims {\n+    DeleteJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::days(5)).timestamp(),\n         iss: JWT_VERIFYEMAIL_ISSUER.to_string(),\n@@ -191,7 +191,7 @@ pub fn generate_verify_email_claims(uuid: String) -> DeleteJWTClaims {\n }\n \n #[derive(Debug, Serialize, Deserialize)]\n-pub struct AdminJWTClaims {\n+pub struct AdminJwtClaims {\n     // Not before\n     pub nbf: i64,\n     // Expiration time\n@@ -202,9 +202,9 @@ pub struct AdminJWTClaims {\n     pub sub: String,\n }\n \n-pub fn generate_admin_claims() -> AdminJWTClaims {\n+pub fn generate_admin_claims() -> AdminJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    AdminJWTClaims {\n+    AdminJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::minutes(20)).timestamp(),\n         iss: JWT_ADMIN_ISSUER.to_string(),\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 6,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -223,10 +223,9 @@ use crate::db::{\n };\n \n pub struct Host {\n-    pub host: String\n+    pub host: String,\n }\n \n-\n impl<'a, 'r> FromRequest<'a, 'r> for Host {\n     type Error = &'static str;\n \n@@ -506,7 +505,11 @@ impl<'a, 'r> FromRequest<'a, 'r> for ManagerHeaders {\n                             };\n \n                             if !headers.org_user.has_full_access() {\n-                                match CollectionUser::find_by_collection_and_user(&col_id, &headers.org_user.user_uuid, &conn) {\n+                                match CollectionUser::find_by_collection_and_user(\n+                                    &col_id,\n+                                    &headers.org_user.user_uuid,\n+                                    &conn,\n+                                ) {\n                                     Some(_) => (),\n                                     None => err_handler!(\"The current user isn't a manager for this collection\"),\n                                 }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 14,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -260,7 +260,9 @@ impl<'a, 'r> FromRequest<'a, 'r> for Host {\n             format!(\"{}://{}\", protocol, host)\n         };\n \n-        Outcome::Success(Host { host })\n+        Outcome::Success(Host {\n+            host,\n+        })\n     }\n }\n \n@@ -316,10 +318,8 @@ impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n         };\n \n         if user.security_stamp != claims.sstamp {\n-            if let Some(stamp_exception) = user\n-                .stamp_exception\n-                .as_deref()\n-                .and_then(|s| serde_json::from_str::<UserStampException>(s).ok())\n+            if let Some(stamp_exception) =\n+                user.stamp_exception.as_deref().and_then(|s| serde_json::from_str::<UserStampException>(s).ok())\n             {\n                 let current_route = match request.route().and_then(|r| r.name) {\n                     Some(name) => name,\n@@ -337,7 +337,11 @@ impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n             }\n         }\n \n-        Outcome::Success(Headers { host, device, user })\n+        Outcome::Success(Headers {\n+            host,\n+            device,\n+            user,\n+        })\n     }\n }\n \n@@ -639,10 +643,10 @@ impl<'a, 'r> FromRequest<'a, 'r> for ClientIp {\n             None\n         };\n \n-        let ip = ip\n-            .or_else(|| req.remote().map(|r| r.ip()))\n-            .unwrap_or_else(|| \"0.0.0.0\".parse().unwrap());\n+        let ip = ip.or_else(|| req.remote().map(|r| r.ip())).unwrap_or_else(|| \"0.0.0.0\".parse().unwrap());\n \n-        Outcome::Success(ClientIp { ip })\n+        Outcome::Success(ClientIp {\n+            ip,\n+        })\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "2cd17fe7afeaef2a29787999b1cb48a512811571",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add token with short expiration time to send url",
            "additions": 27,
            "deletions": 34,
            "change_type": "MODIFY",
            "diff": "@@ -19,11 +19,14 @@ const JWT_ALGORITHM: Algorithm = Algorithm::RS256;\n \n pub static DEFAULT_VALIDITY: Lazy<Duration> = Lazy::new(|| Duration::hours(2));\n static JWT_HEADER: Lazy<Header> = Lazy::new(|| Header::new(JWT_ALGORITHM));\n+\n pub static JWT_LOGIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|login\", CONFIG.domain_origin()));\n static JWT_INVITE_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|invite\", CONFIG.domain_origin()));\n static JWT_DELETE_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|delete\", CONFIG.domain_origin()));\n static JWT_VERIFYEMAIL_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|verifyemail\", CONFIG.domain_origin()));\n static JWT_ADMIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|admin\", CONFIG.domain_origin()));\n+static JWT_SEND_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|send\", CONFIG.domain_origin()));\n+\n static PRIVATE_RSA_KEY: Lazy<Vec<u8>> = Lazy::new(|| match read_file(&CONFIG.private_rsa_key()) {\n     Ok(key) => key,\n     Err(e) => panic!(\"Error loading private RSA Key.\\n Error: {}\", e),\n@@ -66,18 +69,22 @@ pub fn decode_invite(token: &str) -> Result<InviteJwtClaims, Error> {\n     decode_jwt(token, JWT_INVITE_ISSUER.to_string())\n }\n \n-pub fn decode_delete(token: &str) -> Result<DeleteJwtClaims, Error> {\n+pub fn decode_delete(token: &str) -> Result<BasicJwtClaims, Error> {\n     decode_jwt(token, JWT_DELETE_ISSUER.to_string())\n }\n \n-pub fn decode_verify_email(token: &str) -> Result<VerifyEmailJwtClaims, Error> {\n+pub fn decode_verify_email(token: &str) -> Result<BasicJwtClaims, Error> {\n     decode_jwt(token, JWT_VERIFYEMAIL_ISSUER.to_string())\n }\n \n-pub fn decode_admin(token: &str) -> Result<AdminJwtClaims, Error> {\n+pub fn decode_admin(token: &str) -> Result<BasicJwtClaims, Error> {\n     decode_jwt(token, JWT_ADMIN_ISSUER.to_string())\n }\n \n+pub fn decode_send(token: &str) -> Result<BasicJwtClaims, Error> {\n+    decode_jwt(token, JWT_SEND_ISSUER.to_string())\n+}\n+\n #[derive(Debug, Serialize, Deserialize)]\n pub struct LoginJwtClaims {\n     // Not before\n@@ -147,7 +154,7 @@ pub fn generate_invite_claims(\n }\n \n #[derive(Debug, Serialize, Deserialize)]\n-pub struct DeleteJwtClaims {\n+pub struct BasicJwtClaims {\n     // Not before\n     pub nbf: i64,\n     // Expiration time\n@@ -158,9 +165,9 @@ pub struct DeleteJwtClaims {\n     pub sub: String,\n }\n \n-pub fn generate_delete_claims(uuid: String) -> DeleteJwtClaims {\n+pub fn generate_delete_claims(uuid: String) -> BasicJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    DeleteJwtClaims {\n+    BasicJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::days(5)).timestamp(),\n         iss: JWT_DELETE_ISSUER.to_string(),\n@@ -168,21 +175,9 @@ pub fn generate_delete_claims(uuid: String) -> DeleteJwtClaims {\n     }\n }\n \n-#[derive(Debug, Serialize, Deserialize)]\n-pub struct VerifyEmailJwtClaims {\n-    // Not before\n-    pub nbf: i64,\n-    // Expiration time\n-    pub exp: i64,\n-    // Issuer\n-    pub iss: String,\n-    // Subject\n-    pub sub: String,\n-}\n-\n-pub fn generate_verify_email_claims(uuid: String) -> DeleteJwtClaims {\n+pub fn generate_verify_email_claims(uuid: String) -> BasicJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    DeleteJwtClaims {\n+    BasicJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::days(5)).timestamp(),\n         iss: JWT_VERIFYEMAIL_ISSUER.to_string(),\n@@ -190,21 +185,9 @@ pub fn generate_verify_email_claims(uuid: String) -> DeleteJwtClaims {\n     }\n }\n \n-#[derive(Debug, Serialize, Deserialize)]\n-pub struct AdminJwtClaims {\n-    // Not before\n-    pub nbf: i64,\n-    // Expiration time\n-    pub exp: i64,\n-    // Issuer\n-    pub iss: String,\n-    // Subject\n-    pub sub: String,\n-}\n-\n-pub fn generate_admin_claims() -> AdminJwtClaims {\n+pub fn generate_admin_claims() -> BasicJwtClaims {\n     let time_now = Utc::now().naive_utc();\n-    AdminJwtClaims {\n+    BasicJwtClaims {\n         nbf: time_now.timestamp(),\n         exp: (time_now + Duration::minutes(20)).timestamp(),\n         iss: JWT_ADMIN_ISSUER.to_string(),\n@@ -212,6 +195,16 @@ pub fn generate_admin_claims() -> AdminJwtClaims {\n     }\n }\n \n+pub fn generate_send_claims(send_id: &str, file_id: &str) -> BasicJwtClaims {\n+    let time_now = Utc::now().naive_utc();\n+    BasicJwtClaims {\n+        nbf: time_now.timestamp(),\n+        exp: (time_now + Duration::minutes(2)).timestamp(),\n+        iss: JWT_SEND_ISSUER.to_string(),\n+        sub: format!(\"{}/{}\", send_id, file_id),\n+    }\n+}\n+\n //\n // Bearer token authentication\n //\n",
            "comment_added_diff": []
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 17,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -27,17 +27,26 @@ static JWT_VERIFYEMAIL_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|verifyema\n static JWT_ADMIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|admin\", CONFIG.domain_origin()));\n static JWT_SEND_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|send\", CONFIG.domain_origin()));\n \n-static PRIVATE_RSA_KEY: Lazy<Vec<u8>> = Lazy::new(|| match read_file(&CONFIG.private_rsa_key()) {\n-    Ok(key) => key,\n-    Err(e) => panic!(\"Error loading private RSA Key.\\n Error: {}\", e),\n+static PRIVATE_RSA_KEY_VEC: Lazy<Vec<u8>> = Lazy::new(|| {\n+    read_file(&CONFIG.private_rsa_key()).unwrap_or_else(|e| panic!(\"Error loading private RSA Key.\\n{}\", e))\n });\n-static PUBLIC_RSA_KEY: Lazy<Vec<u8>> = Lazy::new(|| match read_file(&CONFIG.public_rsa_key()) {\n-    Ok(key) => key,\n-    Err(e) => panic!(\"Error loading public RSA Key.\\n Error: {}\", e),\n+static PRIVATE_RSA_KEY: Lazy<EncodingKey> = Lazy::new(|| {\n+    EncodingKey::from_rsa_pem(&PRIVATE_RSA_KEY_VEC).unwrap_or_else(|e| panic!(\"Error decoding private RSA Key.\\n{}\", e))\n+});\n+static PUBLIC_RSA_KEY_VEC: Lazy<Vec<u8>> = Lazy::new(|| {\n+    read_file(&CONFIG.public_rsa_key()).unwrap_or_else(|e| panic!(\"Error loading public RSA Key.\\n{}\", e))\n+});\n+static PUBLIC_RSA_KEY: Lazy<DecodingKey> = Lazy::new(|| {\n+    DecodingKey::from_rsa_pem(&PUBLIC_RSA_KEY_VEC).unwrap_or_else(|e| panic!(\"Error decoding public RSA Key.\\n{}\", e))\n });\n \n+pub fn load_keys() {\n+    Lazy::force(&PRIVATE_RSA_KEY);\n+    Lazy::force(&PUBLIC_RSA_KEY);\n+}\n+\n pub fn encode_jwt<T: Serialize>(claims: &T) -> String {\n-    match jsonwebtoken::encode(&JWT_HEADER, claims, &EncodingKey::from_rsa_der(&PRIVATE_RSA_KEY)) {\n+    match jsonwebtoken::encode(&JWT_HEADER, claims, &PRIVATE_RSA_KEY) {\n         Ok(token) => token,\n         Err(e) => panic!(\"Error encoding jwt {}\", e),\n     }\n@@ -55,10 +64,7 @@ fn decode_jwt<T: DeserializeOwned>(token: &str, issuer: String) -> Result<T, Err\n     };\n \n     let token = token.replace(char::is_whitespace, \"\");\n-\n-    jsonwebtoken::decode(&token, &DecodingKey::from_rsa_der(&PUBLIC_RSA_KEY), &validation)\n-        .map(|d| d.claims)\n-        .map_res(\"Error decoding JWT\")\n+    jsonwebtoken::decode(&token, &&PUBLIC_RSA_KEY, &validation).map(|d| d.claims).map_res(\"Error decoding JWT\")\n }\n \n pub fn decode_login(token: &str) -> Result<LoginJwtClaims, Error> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "0dcea757641b4f914960704066f2421622b69285",
            "timestamp": "2021-06-26T13:35:09+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused lifetime and double referencing",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -64,7 +64,7 @@ fn decode_jwt<T: DeserializeOwned>(token: &str, issuer: String) -> Result<T, Err\n     };\n \n     let token = token.replace(char::is_whitespace, \"\");\n-    jsonwebtoken::decode(&token, &&PUBLIC_RSA_KEY, &validation).map(|d| d.claims).map_res(\"Error decoding JWT\")\n+    jsonwebtoken::decode(&token, &PUBLIC_RSA_KEY, &validation).map(|d| d.claims).map_res(\"Error decoding JWT\")\n }\n \n pub fn decode_login(token: &str) -> Result<LoginJwtClaims, Error> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 13,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -325,8 +325,19 @@ impl<'a, 'r> FromRequest<'a, 'r> for Headers {\n                     _ => err_handler!(\"Error getting current route for stamp exception\"),\n                 };\n \n-                // Check if both match, if not this route is not allowed with the current security stamp.\n-                if stamp_exception.route != current_route {\n+                // Check if the stamp exception has expired first.\n+                // Then, check if the current route matches any of the allowed routes.\n+                // After that check the stamp in exception matches the one in the claims.\n+                if Utc::now().naive_utc().timestamp() > stamp_exception.expire {\n+                    // If the stamp exception has been expired remove it from the database.\n+                    // This prevents checking this stamp exception for new requests.\n+                    let mut user = user;\n+                    user.reset_stamp_exception();\n+                    if let Err(e) = user.save(&conn) {\n+                        error!(\"Error updating user: {:#?}\", e);\n+                    }\n+                    err_handler!(\"Stamp exception is expired\")\n+                } else if !stamp_exception.routes.contains(&current_route.to_string()) {\n                     err_handler!(\"Invalid security stamp: Current route and exception route do not match\")\n                 } else if stamp_exception.security_stamp != claims.sstamp {\n                     err_handler!(\"Invalid security stamp for matched stamp exception\")\n",
            "comment_added_diff": [
                [
                    328,
                    "                // Check if the stamp exception has expired first."
                ],
                [
                    329,
                    "                // Then, check if the current route matches any of the allowed routes."
                ],
                [
                    330,
                    "                // After that check the stamp in exception matches the one in the claims."
                ],
                [
                    332,
                    "                    // If the stamp exception has been expired remove it from the database."
                ],
                [
                    333,
                    "                    // This prevents checking this stamp exception for new requests."
                ]
            ]
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 44,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,8 @@ static JWT_HEADER: Lazy<Header> = Lazy::new(|| Header::new(JWT_ALGORITHM));\n \n pub static JWT_LOGIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|login\", CONFIG.domain_origin()));\n static JWT_INVITE_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|invite\", CONFIG.domain_origin()));\n+static JWT_EMERGENCY_ACCESS_INVITE_ISSUER: Lazy<String> =\n+    Lazy::new(|| format!(\"{}|emergencyaccessinvite\", CONFIG.domain_origin()));\n static JWT_DELETE_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|delete\", CONFIG.domain_origin()));\n static JWT_VERIFYEMAIL_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|verifyemail\", CONFIG.domain_origin()));\n static JWT_ADMIN_ISSUER: Lazy<String> = Lazy::new(|| format!(\"{}|admin\", CONFIG.domain_origin()));\n@@ -75,6 +77,10 @@ pub fn decode_invite(token: &str) -> Result<InviteJwtClaims, Error> {\n     decode_jwt(token, JWT_INVITE_ISSUER.to_string())\n }\n \n+pub fn decode_emergency_access_invite(token: &str) -> Result<EmergencyAccessInviteJwtClaims, Error> {\n+    decode_jwt(token, JWT_EMERGENCY_ACCESS_INVITE_ISSUER.to_string())\n+}\n+\n pub fn decode_delete(token: &str) -> Result<BasicJwtClaims, Error> {\n     decode_jwt(token, JWT_DELETE_ISSUER.to_string())\n }\n@@ -159,6 +165,44 @@ pub fn generate_invite_claims(\n     }\n }\n \n+//           var token = _dataProtector.Protect($\"EmergencyAccessInvite {emergencyAccess.Id} {emergencyAccess.Email} {nowMillis}\");\n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct EmergencyAccessInviteJwtClaims {\n+    // Not before\n+    pub nbf: i64,\n+    // Expiration time\n+    pub exp: i64,\n+    // Issuer\n+    pub iss: String,\n+    // Subject\n+    pub sub: String,\n+\n+    pub email: String,\n+    pub emer_id: Option<String>,\n+    pub grantor_name: Option<String>,\n+    pub grantor_email: Option<String>,\n+}\n+\n+pub fn generate_emergency_access_invite_claims(\n+    uuid: String,\n+    email: String,\n+    emer_id: Option<String>,\n+    grantor_name: Option<String>,\n+    grantor_email: Option<String>,\n+) -> EmergencyAccessInviteJwtClaims {\n+    let time_now = Utc::now().naive_utc();\n+    EmergencyAccessInviteJwtClaims {\n+        nbf: time_now.timestamp(),\n+        exp: (time_now + Duration::days(5)).timestamp(),\n+        iss: JWT_EMERGENCY_ACCESS_INVITE_ISSUER.to_string(),\n+        sub: uuid,\n+        email,\n+        emer_id,\n+        grantor_name,\n+        grantor_email,\n+    }\n+}\n+\n #[derive(Debug, Serialize, Deserialize)]\n pub struct BasicJwtClaims {\n     // Not before\n",
            "comment_added_diff": [
                [
                    168,
                    "//           var token = _dataProtector.Protect($\"EmergencyAccessInvite {emergencyAccess.Id} {emergencyAccess.Email} {nowMillis}\");"
                ],
                [
                    171,
                    "    // Not before"
                ],
                [
                    173,
                    "    // Expiration time"
                ],
                [
                    175,
                    "    // Issuer"
                ],
                [
                    177,
                    "    // Subject"
                ]
            ]
        }
    ],
    "mail.rs": [
        {
            "commit": "d29b6bee2850795ac9565ee1ab70f4c53be68536",
            "timestamp": "2019-11-02T17:39:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary clones and other clippy fixes",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -105,7 +105,7 @@ pub fn send_invite(\n         String::from(address),\n         org_id.clone(),\n         org_user_id.clone(),\n-        invited_by_email.clone(),\n+        invited_by_email,\n     );\n     let invite_token = encode_jwt(&claims);\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "c52adef919419a1e823fbc26c49aaef9032248ff",
            "timestamp": "2019-11-06T21:39:33+01:00",
            "author": "BlackDex",
            "commit_message": "Added configurable smtp timeout.\n\n - Added config option for smtp timeout\n - Lowered default timeout to 15 seconds instead of default 60.",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -33,6 +33,8 @@ fn mailer() -> SmtpTransport {\n         ClientSecurity::None\n     };\n \n+    use std::time::Duration;\n+\n     let smtp_client = SmtpClient::new((host.as_str(), CONFIG.smtp_port()), client_security).unwrap();\n \n     let smtp_client = match (&CONFIG.smtp_username(), &CONFIG.smtp_password()) {\n@@ -53,6 +55,7 @@ fn mailer() -> SmtpTransport {\n \n     smtp_client\n         .smtp_utf8(true)\n+        .timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())))\n         .connection_reuse(ConnectionReuseParameters::NoReuse)\n         .transport()\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 80,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -8,7 +8,7 @@ use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n use quoted_printable::encode_to_str;\n \n use crate::api::EmptyResult;\n-use crate::auth::{encode_jwt, generate_invite_claims};\n+use crate::auth::{encode_jwt, generate_invite_claims, generate_delete_claims, generate_verify_email_claims};\n use crate::error::Error;\n use crate::CONFIG;\n use chrono::NaiveDateTime;\n@@ -95,6 +95,73 @@ pub fn send_password_hint(address: &str, hint: Option<String>) -> EmptyResult {\n     send_email(&address, &subject, &body_html, &body_text)\n }\n \n+pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n+    let claims = generate_delete_claims(\n+        uuid.to_string(),\n+    );\n+    let delete_token = encode_jwt(&claims);\n+\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/delete_account\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"user_id\": uuid,\n+            \"email\": percent_encode(address.as_bytes(), NON_ALPHANUMERIC).to_string(),\n+            \"token\": delete_token,\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n+pub fn send_verify_email(address: &str, uuid: &str) -> EmptyResult {\n+    let claims = generate_verify_email_claims(\n+        uuid.to_string(),\n+    );\n+    let verify_email_token = encode_jwt(&claims);\n+\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/verify_email\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"user_id\": uuid,\n+            \"email\": percent_encode(address.as_bytes(), NON_ALPHANUMERIC).to_string(),\n+            \"token\": verify_email_token,\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n+pub fn send_welcome(address: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/welcome\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n+pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n+    let claims = generate_verify_email_claims(\n+        uuid.to_string(),\n+    );\n+    let verify_email_token = encode_jwt(&claims);\n+\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/welcome_must_verify\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"user_id\": uuid,\n+            \"token\": verify_email_token,\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n pub fn send_invite(\n     address: &str,\n     uuid: &str,\n@@ -183,6 +250,18 @@ pub fn send_token(address: &str, token: &str) -> EmptyResult {\n     send_email(&address, &subject, &body_html, &body_text)\n }\n \n+pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/change_email\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"token\": token,\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) -> EmptyResult {\n     let html = PartBuilder::new()\n         .body(encode_to_str(body_html))\n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 4,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -8,7 +8,7 @@ use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n use quoted_printable::encode_to_str;\n \n use crate::api::EmptyResult;\n-use crate::auth::{encode_jwt, generate_invite_claims, generate_delete_claims, generate_verify_email_claims};\n+use crate::auth::{encode_jwt, generate_delete_claims, generate_invite_claims, generate_verify_email_claims};\n use crate::error::Error;\n use crate::CONFIG;\n use chrono::NaiveDateTime;\n@@ -96,9 +96,7 @@ pub fn send_password_hint(address: &str, hint: Option<String>) -> EmptyResult {\n }\n \n pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n-    let claims = generate_delete_claims(\n-        uuid.to_string(),\n-    );\n+    let claims = generate_delete_claims(uuid.to_string());\n     let delete_token = encode_jwt(&claims);\n \n     let (subject, body_html, body_text) = get_text(\n@@ -115,9 +113,7 @@ pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n }\n \n pub fn send_verify_email(address: &str, uuid: &str) -> EmptyResult {\n-    let claims = generate_verify_email_claims(\n-        uuid.to_string(),\n-    );\n+    let claims = generate_verify_email_claims(uuid.to_string());\n     let verify_email_token = encode_jwt(&claims);\n \n     let (subject, body_html, body_text) = get_text(\n@@ -145,9 +141,7 @@ pub fn send_welcome(address: &str) -> EmptyResult {\n }\n \n pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n-    let claims = generate_verify_email_claims(\n-        uuid.to_string(),\n-    );\n+    let claims = generate_verify_email_claims(uuid.to_string());\n     let verify_email_token = encode_jwt(&claims);\n \n     let (subject, body_html, body_text) = get_text(\n",
            "comment_added_diff": []
        },
        {
            "commit": "ff7b4a3d38f07eb5687ae9beaa044777f07dadba",
            "timestamp": "2020-01-26T15:29:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update handlebars to 3.0 which included performance improvements.\nUpdated lettre to newer git revision, which should give better error messages now.",
            "additions": 8,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -1,8 +1,10 @@\n use lettre::smtp::authentication::Credentials;\n use lettre::smtp::authentication::Mechanism as SmtpAuthMechanism;\n use lettre::smtp::ConnectionReuseParameters;\n-use lettre::{ClientSecurity, ClientTlsParameters, SmtpClient, SmtpTransport, Transport};\n-use lettre_email::{EmailBuilder, MimeMultipartType, PartBuilder};\n+use lettre::{\n+    builder::{EmailBuilder, MimeMultipartType, PartBuilder},\n+    ClientSecurity, ClientTlsParameters, SmtpClient, SmtpTransport, Transport,\n+};\n use native_tls::{Protocol, TlsConnector};\n use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n use quoted_printable::encode_to_str;\n@@ -284,12 +286,11 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n \n     let mut transport = mailer();\n \n-    let result = transport\n-        .send(email.into())\n-        .map_err(|e| Error::new(\"Error sending email\", e.to_string()))\n-        .and(Ok(()));\n+    let result = transport.send(email);\n \n     // Explicitly close the connection, in case of error\n     transport.close();\n-    result\n+    \n+    result?;\n+    Ok(())\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "def174a517716967b80d5ecb8407772668bfd631",
            "timestamp": "2020-01-30T22:11:53+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Convert email domains to punycode",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -259,6 +259,18 @@ pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n }\n \n fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) -> EmptyResult {\n+    let address_split: Vec<&str> = address.rsplitn(2, '@').collect();\n+    if address_split.len() != 2 {\n+        err!(\"Invalid email address (no @)\");\n+    }\n+\n+    let domain_puny = match idna::domain_to_ascii_strict(address_split[1]) {\n+        Ok(d) => d,\n+        Err(_) => err!(\"Can't convert email domain to ASCII representation\"),\n+    };\n+\n+    let address = format!(\"{}@{}\", address_split[0], domain_puny);\n+\n     let html = PartBuilder::new()\n         .body(encode_to_str(body_html))\n         .header((\"Content-Type\", \"text/html; charset=utf-8\"))\n",
            "comment_added_diff": []
        },
        {
            "commit": "f5916ec396329a1239641944ebcf2b9e42656179",
            "timestamp": "2020-01-30T22:33:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix backwards indices",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -264,12 +264,12 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n         err!(\"Invalid email address (no @)\");\n     }\n \n-    let domain_puny = match idna::domain_to_ascii_strict(address_split[1]) {\n+    let domain_puny = match idna::domain_to_ascii_strict(address_split[0]) {\n         Ok(d) => d,\n         Err(_) => err!(\"Can't convert email domain to ASCII representation\"),\n     };\n \n-    let address = format!(\"{}@{}\", address_split[0], domain_puny);\n+    let address = format!(\"{}@{}\", address_split[1], domain_puny);\n \n     let html = PartBuilder::new()\n         .body(encode_to_str(body_html))\n",
            "comment_added_diff": []
        },
        {
            "commit": "5f61607419fb329442ebbdd98832cb14349d33ab",
            "timestamp": "2020-02-26T11:02:22+01:00",
            "author": "BlackDex",
            "commit_message": "Added SMTP test button in the admin gui\n\n- Added a test button for checking the e-mail settings.\n- Fixed a bug with the _post JavaScript function:\n  A function was overwriten with a variable and errors were not handled\ncorrectly like a 500 for example.",
            "additions": 11,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -258,6 +258,17 @@ pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n     send_email(&address, &subject, &body_html, &body_text)\n }\n \n+pub fn send_test(address: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/smtp_test\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) -> EmptyResult {\n     let address_split: Vec<&str> = address.rsplitn(2, '@').collect();\n     if address_split.len() != 2 {\n",
            "comment_added_diff": []
        },
        {
            "commit": "5a974c7b944a66adf72d4615004b894ba16ea6bd",
            "timestamp": "2020-02-26T16:49:56+01:00",
            "author": "BlackDex",
            "commit_message": "Added SMTP test button in the admin gui\n\n- Added a test button for checking the e-mail settings.\n- Fixed a bug with the _post JavaScript function:\n  A function was overwriten with a variable and errors were not handled\ncorrectly like a 500 for example.",
            "additions": 11,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -258,6 +258,17 @@ pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n     send_email(&address, &subject, &body_html, &body_text)\n }\n \n+pub fn send_test(address: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/smtp_test\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+        }),\n+    )?;\n+\n+    send_email(&address, &subject, &body_html, &body_text)\n+}\n+\n fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) -> EmptyResult {\n     let address_split: Vec<&str> = address.rsplitn(2, '@').collect();\n     if address_split.len() != 2 {\n",
            "comment_added_diff": []
        },
        {
            "commit": "5d3b765a238f6df35e3233499d6da763ad7c6cd8",
            "timestamp": "2020-03-12T11:40:52+01:00",
            "author": "Samuel Leweke",
            "commit_message": "Use opportunistic TLS in SMTP connections\n\nIf SSL is disabled, the SMTP ClientSecurity of the lettre crate\ndefaults to None, that is, an insecure connection. This is changed to\nOpportunistic, which uses TLS if available. If TLS is not available,\nthe insecure connection is used (i.e., this change is backward\ncompatible).",
            "additions": 9,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -18,21 +18,21 @@ use chrono::NaiveDateTime;\n fn mailer() -> SmtpTransport {\n     let host = CONFIG.smtp_host().unwrap();\n \n-    let client_security = if CONFIG.smtp_ssl() {\n-        let tls = TlsConnector::builder()\n-            .min_protocol_version(Some(Protocol::Tlsv11))\n-            .build()\n-            .unwrap();\n+    let tls = TlsConnector::builder()\n+        .min_protocol_version(Some(Protocol::Tlsv11))\n+        .build()\n+        .unwrap();\n \n-        let params = ClientTlsParameters::new(host.clone(), tls);\n+    let tls_params = ClientTlsParameters::new(host.clone(), tls);\n \n+    let client_security = if CONFIG.smtp_ssl() {\n         if CONFIG.smtp_explicit_tls() {\n-            ClientSecurity::Wrapper(params)\n+            ClientSecurity::Wrapper(tls_params)\n         } else {\n-            ClientSecurity::Required(params)\n+            ClientSecurity::Required(tls_params)\n         }\n     } else {\n-        ClientSecurity::None\n+        ClientSecurity::Opportunistic(tls_params)\n     };\n \n     use std::time::Duration;\n",
            "comment_added_diff": []
        },
        {
            "commit": "afd9f4e278a6a8fa178e30153cce725518893871",
            "timestamp": "2020-03-14T22:31:41+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Allow the smtp mechanism to be provided without quotes and all lowercase",
            "additions": 5,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -44,10 +44,11 @@ fn mailer() -> SmtpTransport {\n         _ => smtp_client,\n     };\n \n-    let smtp_client = match &CONFIG.smtp_auth_mechanism() {\n-        Some(auth_mechanism_json) => {\n-            let auth_mechanism = serde_json::from_str::<SmtpAuthMechanism>(&auth_mechanism_json);\n-            match auth_mechanism {\n+    let smtp_client = match CONFIG.smtp_auth_mechanism() {\n+        Some(mechanism) => {\n+            let correct_mechanism = format!(\"\\\"{}\\\"\", crate::util::upcase_first(&mechanism.trim_matches('\"')));\n+\n+            match serde_json::from_str::<SmtpAuthMechanism>(&correct_mechanism) {\n                 Ok(auth_mechanism) => smtp_client.authentication_mechanism(auth_mechanism),\n                 _ => panic!(\"Failure to parse mechanism. Is it proper Json? Eg. `\\\"Plain\\\"` not `Plain`\"),\n             }\n",
            "comment_added_diff": []
        },
        {
            "commit": "d2d9fb08cc6de0d69e895b854837b3853fd5baf3",
            "timestamp": "2020-03-19T13:56:53+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Revert \"Use opportunistic TLS in SMTP connections\"",
            "additions": 9,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -18,21 +18,21 @@ use chrono::NaiveDateTime;\n fn mailer() -> SmtpTransport {\n     let host = CONFIG.smtp_host().unwrap();\n \n-    let tls = TlsConnector::builder()\n-        .min_protocol_version(Some(Protocol::Tlsv11))\n-        .build()\n-        .unwrap();\n+    let client_security = if CONFIG.smtp_ssl() {\n+        let tls = TlsConnector::builder()\n+            .min_protocol_version(Some(Protocol::Tlsv11))\n+            .build()\n+            .unwrap();\n \n-    let tls_params = ClientTlsParameters::new(host.clone(), tls);\n+        let params = ClientTlsParameters::new(host.clone(), tls);\n \n-    let client_security = if CONFIG.smtp_ssl() {\n         if CONFIG.smtp_explicit_tls() {\n-            ClientSecurity::Wrapper(tls_params)\n+            ClientSecurity::Wrapper(params)\n         } else {\n-            ClientSecurity::Required(tls_params)\n+            ClientSecurity::Required(params)\n         }\n     } else {\n-        ClientSecurity::Opportunistic(tls_params)\n+        ClientSecurity::None\n     };\n \n     use std::time::Duration;\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 13,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -46,7 +46,7 @@ fn mailer() -> SmtpTransport {\n \n     let smtp_client = match CONFIG.smtp_auth_mechanism() {\n         Some(mechanism) => {\n-            let correct_mechanism = format!(\"\\\"{}\\\"\", crate::util::upcase_first(&mechanism.trim_matches('\"')));\n+            let correct_mechanism = format!(\"\\\"{}\\\"\", crate::util::upcase_first(mechanism.trim_matches('\"')));\n \n             match serde_json::from_str::<SmtpAuthMechanism>(&correct_mechanism) {\n                 Ok(auth_mechanism) => smtp_client.authentication_mechanism(auth_mechanism),\n@@ -95,7 +95,7 @@ pub fn send_password_hint(address: &str, hint: Option<String>) -> EmptyResult {\n \n     let (subject, body_html, body_text) = get_text(template_name, json!({ \"hint\": hint, \"url\": CONFIG.domain() }))?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n@@ -112,7 +112,7 @@ pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_verify_email(address: &str, uuid: &str) -> EmptyResult {\n@@ -129,7 +129,7 @@ pub fn send_verify_email(address: &str, uuid: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_welcome(address: &str) -> EmptyResult {\n@@ -140,7 +140,7 @@ pub fn send_welcome(address: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n@@ -156,7 +156,7 @@ pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_invite(\n@@ -188,7 +188,7 @@ pub fn send_invite(\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_invite_accepted(new_user_email: &str, address: &str, org_name: &str) -> EmptyResult {\n@@ -201,7 +201,7 @@ pub fn send_invite_accepted(new_user_email: &str, address: &str, org_name: &str)\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_invite_confirmed(address: &str, org_name: &str) -> EmptyResult {\n@@ -213,7 +213,7 @@ pub fn send_invite_confirmed(address: &str, org_name: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &NaiveDateTime, device: &str) -> EmptyResult {\n@@ -232,7 +232,7 @@ pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &NaiveDateTime, de\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_token(address: &str, token: &str) -> EmptyResult {\n@@ -244,7 +244,7 @@ pub fn send_token(address: &str, token: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n@@ -256,7 +256,7 @@ pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n pub fn send_test(address: &str) -> EmptyResult {\n@@ -267,7 +267,7 @@ pub fn send_test(address: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(&address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, &body_html, &body_text)\n }\n \n fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) -> EmptyResult {\n",
            "comment_added_diff": []
        },
        {
            "commit": "63cbd9ef9c23ff7a13dfbbb7723fbb6ed4c5dc13",
            "timestamp": "2020-05-03T17:41:53+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update lettre to latest master",
            "additions": 36,
            "deletions": 51,
            "change_type": "MODIFY",
            "diff": "@@ -1,13 +1,11 @@\n-use lettre::smtp::authentication::Credentials;\n-use lettre::smtp::authentication::Mechanism as SmtpAuthMechanism;\n-use lettre::smtp::ConnectionReuseParameters;\n-use lettre::{\n-    builder::{EmailBuilder, MimeMultipartType, PartBuilder},\n-    ClientSecurity, ClientTlsParameters, SmtpClient, SmtpTransport, Transport,\n-};\n+use std::str::FromStr;\n+\n+use lettre::message::{header, Mailbox, Message, MultiPart, SinglePart};\n+use lettre::transport::smtp::authentication::{Credentials, Mechanism as SmtpAuthMechanism};\n+use lettre::{Address, SmtpTransport, Tls, TlsParameters, Transport};\n+\n use native_tls::{Protocol, TlsConnector};\n use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n-use quoted_printable::encode_to_str;\n \n use crate::api::EmptyResult;\n use crate::auth::{encode_jwt, generate_delete_claims, generate_invite_claims, generate_verify_email_claims};\n@@ -24,23 +22,23 @@ fn mailer() -> SmtpTransport {\n             .build()\n             .unwrap();\n \n-        let params = ClientTlsParameters::new(host.clone(), tls);\n+        let params = TlsParameters::new(host.clone(), tls);\n \n         if CONFIG.smtp_explicit_tls() {\n-            ClientSecurity::Wrapper(params)\n+            Tls::Wrapper(params)\n         } else {\n-            ClientSecurity::Required(params)\n+            Tls::Required(params)\n         }\n     } else {\n-        ClientSecurity::None\n+        Tls::None\n     };\n \n     use std::time::Duration;\n \n-    let smtp_client = SmtpClient::new((host.as_str(), CONFIG.smtp_port()), client_security).unwrap();\n+    let smtp_client = SmtpTransport::new(host).port(CONFIG.smtp_port()).tls(client_security);\n \n-    let smtp_client = match (&CONFIG.smtp_username(), &CONFIG.smtp_password()) {\n-        (Some(user), Some(pass)) => smtp_client.credentials(Credentials::new(user.clone(), pass.clone())),\n+    let smtp_client = match (CONFIG.smtp_username(), CONFIG.smtp_password()) {\n+        (Some(user), Some(pass)) => smtp_client.credentials(Credentials::new(user, pass)),\n         _ => smtp_client,\n     };\n \n@@ -48,19 +46,16 @@ fn mailer() -> SmtpTransport {\n         Some(mechanism) => {\n             let correct_mechanism = format!(\"\\\"{}\\\"\", crate::util::upcase_first(mechanism.trim_matches('\"')));\n \n+            // TODO: Allow more than one mechanism\n             match serde_json::from_str::<SmtpAuthMechanism>(&correct_mechanism) {\n-                Ok(auth_mechanism) => smtp_client.authentication_mechanism(auth_mechanism),\n+                Ok(auth_mechanism) => smtp_client.authentication(vec![auth_mechanism]),\n                 _ => panic!(\"Failure to parse mechanism. Is it proper Json? Eg. `\\\"Plain\\\"` not `Plain`\"),\n             }\n         }\n         _ => smtp_client,\n     };\n \n-    smtp_client\n-        .smtp_utf8(true)\n-        .timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())))\n-        .connection_reuse(ConnectionReuseParameters::NoReuse)\n-        .transport()\n+    smtp_client.timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())))\n }\n \n fn get_text(template_name: &'static str, data: serde_json::Value) -> Result<(String, String, String), Error> {\n@@ -283,38 +278,28 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n \n     let address = format!(\"{}@{}\", address_split[1], domain_puny);\n \n-    let html = PartBuilder::new()\n-        .body(encode_to_str(body_html))\n-        .header((\"Content-Type\", \"text/html; charset=utf-8\"))\n-        .header((\"Content-Transfer-Encoding\", \"quoted-printable\"))\n-        .build();\n-\n-    let text = PartBuilder::new()\n-        .body(encode_to_str(body_text))\n-        .header((\"Content-Type\", \"text/plain; charset=utf-8\"))\n-        .header((\"Content-Transfer-Encoding\", \"quoted-printable\"))\n-        .build();\n-\n-    let alternative = PartBuilder::new()\n-        .message_type(MimeMultipartType::Alternative)\n-        .child(text)\n-        .child(html);\n-\n-    let email = EmailBuilder::new()\n-        .to(address)\n-        .from((CONFIG.smtp_from().as_str(), CONFIG.smtp_from_name().as_str()))\n-        .subject(subject)\n-        .child(alternative.build())\n-        .build()\n-        .map_err(|e| Error::new(\"Error building email\", e.to_string()))?;\n+    let html = SinglePart::builder()\n+        .header(header::ContentType(\"text/html; charset=utf-8\".parse().unwrap()))\n+        .header(header::ContentTransferEncoding::QuotedPrintable)\n+        .body(body_html);\n \n-    let mut transport = mailer();\n+    let text = SinglePart::builder()\n+        .header(header::ContentType(\"text/plain; charset=utf-8\".parse().unwrap()))\n+        .header(header::ContentTransferEncoding::QuotedPrintable)\n+        .body(body_text);\n \n-    let result = transport.send(email);\n+    let alternative = MultiPart::alternative().singlepart(text).singlepart(html);\n+\n+    let email = Message::builder()\n+        .to(Mailbox::new(None, Address::from_str(&address)?))\n+        .from(Mailbox::new(\n+            Some(CONFIG.smtp_from_name()),\n+            Address::from_str(&CONFIG.smtp_from())?,\n+        ))\n+        .subject(subject)\n+        .multipart(alternative)\n+        .map_err(|e| Error::new(\"Error building email\", e.to_string()))?;\n \n-    // Explicitly close the connection, in case of error\n-    transport.close();\n-    \n-    result?;\n+    let _ = mailer().send(&email)?;\n     Ok(())\n }\n",
            "comment_added_diff": [
                [
                    49,
                    "            // TODO: Allow more than one mechanism"
                ]
            ]
        },
        {
            "commit": "6c5e35ce5c549b82629350dfe9f56f21dc2bc27e",
            "timestamp": "2020-05-07T00:51:46+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Change the mails content types to more closely match what we sent before",
            "additions": 20,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -278,17 +278,25 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n \n     let address = format!(\"{}@{}\", address_split[1], domain_puny);\n \n-    let html = SinglePart::builder()\n-        .header(header::ContentType(\"text/html; charset=utf-8\".parse().unwrap()))\n-        .header(header::ContentTransferEncoding::QuotedPrintable)\n-        .body(body_html);\n-\n-    let text = SinglePart::builder()\n-        .header(header::ContentType(\"text/plain; charset=utf-8\".parse().unwrap()))\n-        .header(header::ContentTransferEncoding::QuotedPrintable)\n-        .body(body_text);\n-\n-    let alternative = MultiPart::alternative().singlepart(text).singlepart(html);\n+    let data = MultiPart::mixed()\n+        .multipart(\n+            MultiPart::alternative()\n+                .singlepart(\n+                    SinglePart::quoted_printable()\n+                        .header(header::ContentType(\"text/plain; charset=utf-8\".parse()?))\n+                        .body(body_text),\n+                )\n+                .multipart(\n+                    MultiPart::related().singlepart(\n+                        SinglePart::quoted_printable()\n+                            .header(header::ContentType(\"text/html; charset=utf-8\".parse()?))\n+                            .body(body_html),\n+                    )\n+                    // .singlepart(SinglePart::base64() -- Inline files would go here\n+                ),\n+        )\n+        // .singlepart(SinglePart::base64()  -- Attachments would go here\n+        ;\n \n     let email = Message::builder()\n         .to(Mailbox::new(None, Address::from_str(&address)?))\n@@ -297,8 +305,7 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n             Address::from_str(&CONFIG.smtp_from())?,\n         ))\n         .subject(subject)\n-        .multipart(alternative)\n-        .map_err(|e| Error::new(\"Error building email\", e.to_string()))?;\n+        .multipart(data)?;\n \n     let _ = mailer().send(&email)?;\n     Ok(())\n",
            "comment_added_diff": [
                [
                    295,
                    "                    // .singlepart(SinglePart::base64() -- Inline files would go here"
                ],
                [
                    298,
                    "        // .singlepart(SinglePart::base64()  -- Attachments would go here"
                ]
            ]
        },
        {
            "commit": "5e802f8aa3b269975cc286c9dd06435fcd599468",
            "timestamp": "2020-05-31T17:58:06+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update lettre to alpha release instead of git commit, and update the rest of dependencies while we are at it",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -35,7 +35,7 @@ fn mailer() -> SmtpTransport {\n \n     use std::time::Duration;\n \n-    let smtp_client = SmtpTransport::new(host).port(CONFIG.smtp_port()).tls(client_security);\n+    let smtp_client = SmtpTransport::builder(host).port(CONFIG.smtp_port()).tls(client_security);\n \n     let smtp_client = match (CONFIG.smtp_username(), CONFIG.smtp_password()) {\n         (Some(user), Some(pass)) => smtp_client.credentials(Credentials::new(user, pass)),\n@@ -55,7 +55,7 @@ fn mailer() -> SmtpTransport {\n         _ => smtp_client,\n     };\n \n-    smtp_client.timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())))\n+    smtp_client.timeout(Some(Duration::from_secs(CONFIG.smtp_timeout()))).build()\n }\n \n fn get_text(template_name: &'static str, data: serde_json::Value) -> Result<(String, String, String), Error> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "596c9b869185a86d7619024066c80a008102199e",
            "timestamp": "2020-07-05T01:59:15+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add option to set name during HELO in email settings",
            "additions": 6,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -2,6 +2,7 @@ use std::str::FromStr;\n \n use lettre::message::{header, Mailbox, Message, MultiPart, SinglePart};\n use lettre::transport::smtp::authentication::{Credentials, Mechanism as SmtpAuthMechanism};\n+use lettre::transport::smtp::extension::ClientId;\n use lettre::{Address, SmtpTransport, Tls, TlsParameters, Transport};\n \n use native_tls::{Protocol, TlsConnector};\n@@ -42,6 +43,11 @@ fn mailer() -> SmtpTransport {\n         _ => smtp_client,\n     };\n \n+    let smtp_client = match CONFIG.helo_name() {\n+        Some(helo_name) => smtp_client.hello_name(ClientId::new(helo_name)),\n+        None => smtp_client,\n+    };\n+\n     let smtp_client = match CONFIG.smtp_auth_mechanism() {\n         Some(mechanism) => {\n             let correct_mechanism = format!(\"\\\"{}\\\"\", crate::util::upcase_first(mechanism.trim_matches('\"')));\n",
            "comment_added_diff": []
        },
        {
            "commit": "a28ebcb401be9a2b0c052d1db319a0c5d6622a3d",
            "timestamp": "2020-07-07T21:30:18-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Use local time in email notifications for new device logins\n\nIn this implementation, the `TZ` environment variable must be set\nin order for the formatted output to use a more user-friendly\ntime zone abbreviation (e.g., `UTC`). Otherwise, the output uses\nthe time zone's UTC offset (e.g., `+00:00`).",
            "additions": 22,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -1,3 +1,4 @@\n+use std::env;\n use std::str::FromStr;\n \n use lettre::message::{header, Mailbox, Message, MultiPart, SinglePart};\n@@ -12,7 +13,9 @@ use crate::api::EmptyResult;\n use crate::auth::{encode_jwt, generate_delete_claims, generate_invite_claims, generate_verify_email_claims};\n use crate::error::Error;\n use crate::CONFIG;\n-use chrono::NaiveDateTime;\n+\n+use chrono::{DateTime, Local};\n+use chrono_tz::Tz;\n \n fn mailer() -> SmtpTransport {\n     let host = CONFIG.smtp_host().unwrap();\n@@ -87,6 +90,22 @@ fn get_template(template_name: &str, data: &serde_json::Value) -> Result<(String\n     Ok((subject, body))\n }\n \n+pub fn format_datetime(dt: &DateTime<Local>) -> String {\n+    let fmt = \"%A, %B %_d, %Y at %r %Z\";\n+\n+    // With a DateTime<Local>, `%Z` formats as the time zone's UTC offset\n+    // (e.g., `+00:00`). If the `TZ` environment variable is set, try to\n+    // format as a time zone abbreviation instead (e.g., `UTC`).\n+    if let Ok(tz) = env::var(\"TZ\") {\n+        if let Ok(tz) = tz.parse::<Tz>() {\n+            return dt.with_timezone(&tz).format(fmt).to_string();\n+        }\n+    }\n+\n+    // Otherwise, fall back to just displaying the UTC offset.\n+    dt.format(fmt).to_string()\n+}\n+\n pub fn send_password_hint(address: &str, hint: Option<String>) -> EmptyResult {\n     let template_name = if hint.is_some() {\n         \"email/pw_hint_some\"\n@@ -217,19 +236,17 @@ pub fn send_invite_confirmed(address: &str, org_name: &str) -> EmptyResult {\n     send_email(address, &subject, &body_html, &body_text)\n }\n \n-pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &NaiveDateTime, device: &str) -> EmptyResult {\n+pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &DateTime<Local>, device: &str) -> EmptyResult {\n     use crate::util::upcase_first;\n     let device = upcase_first(device);\n \n-    let datetime = dt.format(\"%A, %B %_d, %Y at %H:%M\").to_string();\n-\n     let (subject, body_html, body_text) = get_text(\n         \"email/new_device_logged_in\",\n         json!({\n             \"url\": CONFIG.domain(),\n             \"ip\": ip,\n             \"device\": device,\n-            \"datetime\": datetime,\n+            \"datetime\": format_datetime(dt),\n         }),\n     )?;\n \n",
            "comment_added_diff": [
                [
                    96,
                    "    // With a DateTime<Local>, `%Z` formats as the time zone's UTC offset"
                ],
                [
                    97,
                    "    // (e.g., `+00:00`). If the `TZ` environment variable is set, try to"
                ],
                [
                    98,
                    "    // format as a time zone abbreviation instead (e.g., `UTC`)."
                ],
                [
                    105,
                    "    // Otherwise, fall back to just displaying the UTC offset."
                ]
            ]
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 16,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -1,21 +1,23 @@\n-use std::env;\n-use std::str::FromStr;\n-\n-use lettre::message::{header, Mailbox, Message, MultiPart, SinglePart};\n-use lettre::transport::smtp::authentication::{Credentials, Mechanism as SmtpAuthMechanism};\n-use lettre::transport::smtp::extension::ClientId;\n-use lettre::{Address, SmtpTransport, Tls, TlsParameters, Transport};\n+use std::{env, str::FromStr};\n \n+use chrono::{DateTime, Local};\n+use chrono_tz::Tz;\n use native_tls::{Protocol, TlsConnector};\n use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n \n-use crate::api::EmptyResult;\n-use crate::auth::{encode_jwt, generate_delete_claims, generate_invite_claims, generate_verify_email_claims};\n-use crate::error::Error;\n-use crate::CONFIG;\n-\n-use chrono::{DateTime, Local};\n-use chrono_tz::Tz;\n+use lettre::{\n+    message::{header, Mailbox, Message, MultiPart, SinglePart},\n+    transport::smtp::authentication::{Credentials, Mechanism as SmtpAuthMechanism},\n+    transport::smtp::extension::ClientId,\n+    Address, SmtpTransport, Tls, TlsParameters, Transport,\n+};\n+\n+use crate::{\n+    api::EmptyResult,\n+    auth::{encode_jwt, generate_delete_claims, generate_invite_claims, generate_verify_email_claims},\n+    error::Error,\n+    CONFIG,\n+};\n \n fn mailer() -> SmtpTransport {\n     let host = CONFIG.smtp_host().unwrap();\n",
            "comment_added_diff": []
        },
        {
            "commit": "844cf70345733fbcf2bd0a15cc45aa0040b7638d",
            "timestamp": "2020-09-11T23:52:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated lettre (and other crates) and workflow.\n\nGeneral:\n- Updated several dependancies\n\nLettre:\n- Updateded lettere and the workflow\n- Changed encoding to base64\n- Convert unix newlines to dos newlines for e-mails.\n- Created custom e-mail boundary (auto generated could cause errors)\n\nTested the e-mails sent using several clients (Linux, Windows, MacOS, Web).\nRun msglint (https://tools.ietf.org/tools/msglint/) on the generated e-mails until all errors were gone.\n\nLettre has changed quite some stuff compared between alpha.1 and alpha.2, i haven't noticed any issues sending e-mails during my tests.",
            "additions": 27,
            "deletions": 39,
            "change_type": "MODIFY",
            "diff": "@@ -2,14 +2,13 @@ use std::{env, str::FromStr};\n \n use chrono::{DateTime, Local};\n use chrono_tz::Tz;\n-use native_tls::{Protocol, TlsConnector};\n use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n \n use lettre::{\n     message::{header, Mailbox, Message, MultiPart, SinglePart},\n     transport::smtp::authentication::{Credentials, Mechanism as SmtpAuthMechanism},\n     transport::smtp::extension::ClientId,\n-    Address, SmtpTransport, Tls, TlsParameters, Transport,\n+    Address, SmtpTransport, Transport,\n };\n \n use crate::{\n@@ -20,28 +19,23 @@ use crate::{\n };\n \n fn mailer() -> SmtpTransport {\n+    use std::time::Duration;\n     let host = CONFIG.smtp_host().unwrap();\n \n-    let client_security = if CONFIG.smtp_ssl() {\n-        let tls = TlsConnector::builder()\n-            .min_protocol_version(Some(Protocol::Tlsv11))\n-            .build()\n-            .unwrap();\n-\n-        let params = TlsParameters::new(host.clone(), tls);\n-\n+    // Determine security\n+    let smtp_client = if CONFIG.smtp_ssl() {\n         if CONFIG.smtp_explicit_tls() {\n-            Tls::Wrapper(params)\n+            SmtpTransport::relay(host.as_str())\n         } else {\n-            Tls::Required(params)\n+            SmtpTransport::starttls_relay(host.as_str())\n         }\n     } else {\n-        Tls::None\n+        Ok(SmtpTransport::builder_dangerous(host.as_str()))\n     };\n \n-    use std::time::Duration;\n-\n-    let smtp_client = SmtpTransport::builder(host).port(CONFIG.smtp_port()).tls(client_security);\n+    let smtp_client = smtp_client.unwrap()\n+        .port(CONFIG.smtp_port())\n+        .timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())));\n \n     let smtp_client = match (CONFIG.smtp_username(), CONFIG.smtp_password()) {\n         (Some(user), Some(pass)) => smtp_client.credentials(Credentials::new(user, pass)),\n@@ -49,7 +43,7 @@ fn mailer() -> SmtpTransport {\n     };\n \n     let smtp_client = match CONFIG.helo_name() {\n-        Some(helo_name) => smtp_client.hello_name(ClientId::new(helo_name)),\n+        Some(helo_name) => smtp_client.hello_name(ClientId::Domain(helo_name)),\n         None => smtp_client,\n     };\n \n@@ -66,7 +60,7 @@ fn mailer() -> SmtpTransport {\n         _ => smtp_client,\n     };\n \n-    smtp_client.timeout(Some(Duration::from_secs(CONFIG.smtp_timeout()))).build()\n+    smtp_client.build()\n }\n \n fn get_text(template_name: &'static str, data: serde_json::Value) -> Result<(String, String, String), Error> {\n@@ -84,8 +78,9 @@ fn get_template(template_name: &str, data: &serde_json::Value) -> Result<(String\n         None => err!(\"Template doesn't contain subject\"),\n     };\n \n+    use newline_converter::unix2dos;\n     let body = match text_split.next() {\n-        Some(s) => s.trim().to_string(),\n+        Some(s) => unix2dos(s.trim()).to_string(),\n         None => err!(\"Template doesn't contain body\"),\n     };\n \n@@ -303,25 +298,18 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n \n     let address = format!(\"{}@{}\", address_split[1], domain_puny);\n \n-    let data = MultiPart::mixed()\n-        .multipart(\n-            MultiPart::alternative()\n-                .singlepart(\n-                    SinglePart::quoted_printable()\n-                        .header(header::ContentType(\"text/plain; charset=utf-8\".parse()?))\n-                        .body(body_text),\n-                )\n-                .multipart(\n-                    MultiPart::related().singlepart(\n-                        SinglePart::quoted_printable()\n-                            .header(header::ContentType(\"text/html; charset=utf-8\".parse()?))\n-                            .body(body_html),\n-                    )\n-                    // .singlepart(SinglePart::base64() -- Inline files would go here\n-                ),\n-        )\n-        // .singlepart(SinglePart::base64()  -- Attachments would go here\n-        ;\n+    let html = SinglePart::base64()\n+        .header(header::ContentType(\"text/html; charset=utf-8\".parse()?))\n+        .body(body_html);\n+\n+    let text = SinglePart::base64()\n+        .header(header::ContentType(\"text/plain; charset=utf-8\".parse()?))\n+        .body(body_text);\n+\n+    // The boundary generated by Lettre it self is mostly too large based on the RFC822, so we generate one our selfs.\n+    use uuid::Uuid;\n+    let boundary = format!(\"_Part_{}_\", Uuid::new_v4().to_simple());\n+    let alternative = MultiPart::alternative().boundary(boundary).singlepart(text).singlepart(html);\n \n     let email = Message::builder()\n         .to(Mailbox::new(None, Address::from_str(&address)?))\n@@ -330,7 +318,7 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n             Address::from_str(&CONFIG.smtp_from())?,\n         ))\n         .subject(subject)\n-        .multipart(data)?;\n+        .multipart(alternative)?;\n \n     let _ = mailer().send(&email)?;\n     Ok(())\n",
            "comment_added_diff": [
                [
                    25,
                    "    // Determine security"
                ],
                [
                    309,
                    "    // The boundary generated by Lettre it self is mostly too large based on the RFC822, so we generate one our selfs."
                ]
            ]
        },
        {
            "commit": "c877583979ab0bd76c135b1d88d58298bb9e3680",
            "timestamp": "2020-09-12T21:47:24+02:00",
            "author": "BlackDex",
            "commit_message": "Allow multiple SMTP Auth meganisms.\n\n- Allow all SMTP Auth meganisms supported by Lettre.\n- The config value order is leading and values can be separated by a\n  comma ','\n- Case doesn't matter, and invalid values are ignored.\n- Warning is printed when no valid value is found at all.",
            "additions": 16,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -55,12 +55,22 @@ fn mailer() -> SmtpTransport {\n \n     let smtp_client = match CONFIG.smtp_auth_mechanism() {\n         Some(mechanism) => {\n-            let correct_mechanism = format!(\"\\\"{}\\\"\", crate::util::upcase_first(mechanism.trim_matches('\"')));\n-\n-            // TODO: Allow more than one mechanism\n-            match serde_json::from_str::<SmtpAuthMechanism>(&correct_mechanism) {\n-                Ok(auth_mechanism) => smtp_client.authentication(vec![auth_mechanism]),\n-                _ => panic!(\"Failure to parse mechanism. Is it proper Json? Eg. `\\\"Plain\\\"` not `Plain`\"),\n+            let allowed_mechanisms = vec![SmtpAuthMechanism::Plain, SmtpAuthMechanism::Login, SmtpAuthMechanism::Xoauth2];\n+            let mut selected_mechanisms = vec![];\n+            for wanted_mechanism in mechanism.split(',') {\n+                for m in &allowed_mechanisms {\n+                    if m.to_string().to_lowercase() == wanted_mechanism.trim_matches(|c| c == '\"' || c == '\\'' || c == ' ').to_lowercase() {\n+                        selected_mechanisms.push(m.clone());\n+                    }\n+                }\n+            };\n+\n+            if !selected_mechanisms.is_empty() {\n+                smtp_client.authentication(selected_mechanisms)\n+            } else {\n+                // Only show a warning, and return without setting an actual authentication mechanism\n+                warn!(\"No valid SMTP Auth mechanism found for '{}', using default values\", mechanism);\n+                smtp_client\n             }\n         }\n         _ => smtp_client,\n",
            "comment_added_diff": [
                [
                    71,
                    "                // Only show a warning, and return without setting an actual authentication mechanism"
                ]
            ]
        },
        {
            "commit": "6a0d024c69dc6c0a060191085f66c5dc25f1426e",
            "timestamp": "2020-09-14T20:47:46+02:00",
            "author": "BlackDex",
            "commit_message": "Format some common Lettre errors a bit simpler\n\nCurrently when for example using the admin interface to send out a test e-mail just\nreturns `SmtpError`. This is not very helpful. What i have done.\n\n- Match some common Lettre errors to return the error message.\n- Other errors will just be passed on as before.\n\nSome small other changes:\n- Fixed a clippy warning about using clone().\n- Fixed a typo where Lettere was spelled with one t.",
            "additions": 21,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -54,7 +54,7 @@ fn mailer() -> SmtpTransport {\n             for wanted_mechanism in mechanism.split(',') {\n                 for m in &allowed_mechanisms {\n                     if m.to_string().to_lowercase() == wanted_mechanism.trim_matches(|c| c == '\"' || c == '\\'' || c == ' ').to_lowercase() {\n-                        selected_mechanisms.push(m.clone());\n+                        selected_mechanisms.push(*m);\n                     }\n                 }\n             };\n@@ -330,6 +330,24 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n         .subject(subject)\n         .multipart(alternative)?;\n \n-    let _ = mailer().send(&email)?;\n-    Ok(())\n+    match mailer().send(&email) {\n+        Ok(_) => Ok(()),\n+        // Match some common errors and make them more user friendly\n+        Err(e) => match e {\n+            lettre::transport::smtp::Error::Client(x) => {\n+                err!(format!(\"SMTP Client error: {}\", x));\n+            },\n+            lettre::transport::smtp::Error::Transient(x) => {\n+                err!(format!(\"SMTP 4xx error: {:?}\", x.message));\n+            },\n+            lettre::transport::smtp::Error::Permanent(x) => {\n+                err!(format!(\"SMTP 5xx error: {:?}\", x.message));\n+            },\n+            lettre::transport::smtp::Error::Io(x) => {\n+                err!(format!(\"SMTP IO error: {}\", x));\n+            },\n+            // Fallback for all other errors\n+            _ => Err(e.into())\n+        }\n+    }\n }\n",
            "comment_added_diff": [
                [
                    335,
                    "        // Match some common errors and make them more user friendly"
                ],
                [
                    349,
                    "            // Fallback for all other errors"
                ]
            ]
        },
        {
            "commit": "6faaeaae6649ddfa9a1b4b424a27e6792b1f90b3",
            "timestamp": "2020-11-18T12:07:08+01:00",
            "author": "BlackDex",
            "commit_message": "Updated email processing.\n\n- Added an option to enable smtp debugging via SMTP_DEBUG. This will\n  trigger a trace of the smtp commands sent/received to/from the mail\nserver. Useful when troubleshooting.\n- Added two options to ignore invalid certificates which either do not\n  match at all, or only doesn't match the hostname.\n- Updated lettre to the latest alpha.4 version.",
            "additions": 22,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -7,6 +7,7 @@ use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n use lettre::{\n     message::{header, Mailbox, Message, MultiPart, SinglePart},\n     transport::smtp::authentication::{Credentials, Mechanism as SmtpAuthMechanism},\n+    transport::smtp::client::{Tls, TlsParameters},\n     transport::smtp::extension::ClientId,\n     Address, SmtpTransport, Transport,\n };\n@@ -22,21 +23,30 @@ fn mailer() -> SmtpTransport {\n     use std::time::Duration;\n     let host = CONFIG.smtp_host().unwrap();\n \n+    let smtp_client = SmtpTransport::builder_dangerous(host.as_str())\n+        .port(CONFIG.smtp_port())\n+        .timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())));\n+\n     // Determine security\n     let smtp_client = if CONFIG.smtp_ssl() {\n+        let mut tls_parameters = TlsParameters::builder(host);\n+        if CONFIG.smtp_accept_invalid_hostnames() {\n+            tls_parameters.dangerous_accept_invalid_hostnames(true);\n+        }\n+        if CONFIG.smtp_accept_invalid_certs() {\n+            tls_parameters.dangerous_accept_invalid_certs(true);\n+        }\n+        let tls_parameters = tls_parameters.build().unwrap();\n+\n         if CONFIG.smtp_explicit_tls() {\n-            SmtpTransport::relay(host.as_str())\n+            smtp_client.tls(Tls::Wrapper(tls_parameters))\n         } else {\n-            SmtpTransport::starttls_relay(host.as_str())\n+            smtp_client.tls(Tls::Required(tls_parameters))\n         }\n     } else {\n-        Ok(SmtpTransport::builder_dangerous(host.as_str()))\n+        smtp_client\n     };\n \n-    let smtp_client = smtp_client.unwrap()\n-        .port(CONFIG.smtp_port())\n-        .timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())));\n-\n     let smtp_client = match (CONFIG.smtp_username(), CONFIG.smtp_password()) {\n         (Some(user), Some(pass)) => smtp_client.credentials(Credentials::new(user, pass)),\n         _ => smtp_client,\n@@ -318,14 +328,17 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n \n     // The boundary generated by Lettre it self is mostly too large based on the RFC822, so we generate one our selfs.\n     use uuid::Uuid;\n-    let boundary = format!(\"_Part_{}_\", Uuid::new_v4().to_simple());\n+    let unique_id = Uuid::new_v4().to_simple();\n+    let boundary = format!(\"_Part_{}_\", unique_id);\n     let alternative = MultiPart::alternative().boundary(boundary).singlepart(text).singlepart(html);\n+    let smtp_from = &CONFIG.smtp_from();\n \n     let email = Message::builder()\n+        .message_id(Some(format!(\"<{}.{}>\", unique_id, smtp_from)))\n         .to(Mailbox::new(None, Address::from_str(&address)?))\n         .from(Mailbox::new(\n             Some(CONFIG.smtp_from_name()),\n-            Address::from_str(&CONFIG.smtp_from())?,\n+            Address::from_str(smtp_from)?,\n         ))\n         .subject(subject)\n         .multipart(alternative)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "455a23361f9071b7c16048ce320ecfc26adccc2d",
            "timestamp": "2020-12-13T19:49:22-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up datetime output and code\n\n* For clarity, add `UTC` suffix for datetimes in the `Diagnostics` admin tab.\n* Format datetimes in the local timezone in the `Users` admin tab.\n* Refactor some datetime code and add doc comments.",
            "additions": 3,
            "deletions": 19,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,6 @@\n-use std::{env, str::FromStr};\n+use std::{str::FromStr};\n \n use chrono::{DateTime, Local};\n-use chrono_tz::Tz;\n use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n \n use lettre::{\n@@ -107,22 +106,6 @@ fn get_template(template_name: &str, data: &serde_json::Value) -> Result<(String\n     Ok((subject, body))\n }\n \n-pub fn format_datetime(dt: &DateTime<Local>) -> String {\n-    let fmt = \"%A, %B %_d, %Y at %r %Z\";\n-\n-    // With a DateTime<Local>, `%Z` formats as the time zone's UTC offset\n-    // (e.g., `+00:00`). If the `TZ` environment variable is set, try to\n-    // format as a time zone abbreviation instead (e.g., `UTC`).\n-    if let Ok(tz) = env::var(\"TZ\") {\n-        if let Ok(tz) = tz.parse::<Tz>() {\n-            return dt.with_timezone(&tz).format(fmt).to_string();\n-        }\n-    }\n-\n-    // Otherwise, fall back to just displaying the UTC offset.\n-    dt.format(fmt).to_string()\n-}\n-\n pub fn send_password_hint(address: &str, hint: Option<String>) -> EmptyResult {\n     let template_name = if hint.is_some() {\n         \"email/pw_hint_some\"\n@@ -257,13 +240,14 @@ pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &DateTime<Local>,\n     use crate::util::upcase_first;\n     let device = upcase_first(device);\n \n+    let fmt = \"%A, %B %_d, %Y at %r %Z\";\n     let (subject, body_html, body_text) = get_text(\n         \"email/new_device_logged_in\",\n         json!({\n             \"url\": CONFIG.domain(),\n             \"ip\": ip,\n             \"device\": device,\n-            \"datetime\": format_datetime(dt),\n+            \"datetime\": crate::util::format_datetime_local(dt, fmt),\n         }),\n     )?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "58606796246110b8d49deb69e7d2ec352041bd94",
            "timestamp": "2021-01-31T20:07:42+01:00",
            "author": "BlackDex",
            "commit_message": "Updated dependencies and small mail fixes\n\n- Updated rust nightly\n- Updated depenencies\n- Removed unicode support for regex (less dependencies)\n- Fixed dependency and nightly changes/deprications\n- Some mail changes for less spam point triggering",
            "additions": 14,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -302,30 +302,32 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n \n     let address = format!(\"{}@{}\", address_split[1], domain_puny);\n \n-    let html = SinglePart::base64()\n+    let html = SinglePart::builder()\n+        // We force Base64 encoding because in the past we had issues with different encodings.\n+        .header(header::ContentTransferEncoding::Base64)\n         .header(header::ContentType(\"text/html; charset=utf-8\".parse()?))\n-        .body(body_html);\n+        .body(String::from(body_html));\n \n-    let text = SinglePart::base64()\n+    let text = SinglePart::builder()\n+        // We force Base64 encoding because in the past we had issues with different encodings.\n+        .header(header::ContentTransferEncoding::Base64)\n         .header(header::ContentType(\"text/plain; charset=utf-8\".parse()?))\n-        .body(body_text);\n+        .body(String::from(body_text));\n \n-    // The boundary generated by Lettre it self is mostly too large based on the RFC822, so we generate one our selfs.\n-    use uuid::Uuid;\n-    let unique_id = Uuid::new_v4().to_simple();\n-    let boundary = format!(\"_Part_{}_\", unique_id);\n-    let alternative = MultiPart::alternative().boundary(boundary).singlepart(text).singlepart(html);\n     let smtp_from = &CONFIG.smtp_from();\n-\n     let email = Message::builder()\n-        .message_id(Some(format!(\"<{}.{}>\", unique_id, smtp_from)))\n+        .message_id(Some(format!(\"<{}@{}>\", crate::util::get_uuid(), smtp_from.split('@').collect::<Vec<&str>>()[1] )))\n         .to(Mailbox::new(None, Address::from_str(&address)?))\n         .from(Mailbox::new(\n             Some(CONFIG.smtp_from_name()),\n             Address::from_str(smtp_from)?,\n         ))\n         .subject(subject)\n-        .multipart(alternative)?;\n+        .multipart(\n+            MultiPart::alternative()\n+                .singlepart(text)\n+                .singlepart(html)\n+        )?;\n \n     match mailer().send(&email) {\n         Ok(_) => Ok(()),\n",
            "comment_added_diff": [
                [
                    306,
                    "        // We force Base64 encoding because in the past we had issues with different encodings."
                ],
                [
                    312,
                    "        // We force Base64 encoding because in the past we had issues with different encodings."
                ]
            ]
        },
        {
            "commit": "d956d429036596a9c813a4a27381b1466ef11ea0",
            "timestamp": "2021-02-19T20:17:18+01:00",
            "author": "Paolo Barbolini",
            "commit_message": "Remove unnecessary allocations",
            "additions": 18,
            "deletions": 18,
            "change_type": "MODIFY",
            "diff": "@@ -58,7 +58,7 @@ fn mailer() -> SmtpTransport {\n \n     let smtp_client = match CONFIG.smtp_auth_mechanism() {\n         Some(mechanism) => {\n-            let allowed_mechanisms = vec![SmtpAuthMechanism::Plain, SmtpAuthMechanism::Login, SmtpAuthMechanism::Xoauth2];\n+            let allowed_mechanisms = [SmtpAuthMechanism::Plain, SmtpAuthMechanism::Login, SmtpAuthMechanism::Xoauth2];\n             let mut selected_mechanisms = vec![];\n             for wanted_mechanism in mechanism.split(',') {\n                 for m in &allowed_mechanisms {\n@@ -115,7 +115,7 @@ pub fn send_password_hint(address: &str, hint: Option<String>) -> EmptyResult {\n \n     let (subject, body_html, body_text) = get_text(template_name, json!({ \"hint\": hint, \"url\": CONFIG.domain() }))?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n@@ -132,7 +132,7 @@ pub fn send_delete_account(address: &str, uuid: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_verify_email(address: &str, uuid: &str) -> EmptyResult {\n@@ -149,7 +149,7 @@ pub fn send_verify_email(address: &str, uuid: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_welcome(address: &str) -> EmptyResult {\n@@ -160,7 +160,7 @@ pub fn send_welcome(address: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n@@ -176,7 +176,7 @@ pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_invite(\n@@ -200,15 +200,15 @@ pub fn send_invite(\n         \"email/send_org_invite\",\n         json!({\n             \"url\": CONFIG.domain(),\n-            \"org_id\": org_id.unwrap_or_else(|| \"_\".to_string()),\n-            \"org_user_id\": org_user_id.unwrap_or_else(|| \"_\".to_string()),\n+            \"org_id\": org_id.as_deref().unwrap_or(\"_\"),\n+            \"org_user_id\": org_user_id.as_deref().unwrap_or(\"_\"),\n             \"email\": percent_encode(address.as_bytes(), NON_ALPHANUMERIC).to_string(),\n             \"org_name\": org_name,\n             \"token\": invite_token,\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_invite_accepted(new_user_email: &str, address: &str, org_name: &str) -> EmptyResult {\n@@ -221,7 +221,7 @@ pub fn send_invite_accepted(new_user_email: &str, address: &str, org_name: &str)\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_invite_confirmed(address: &str, org_name: &str) -> EmptyResult {\n@@ -233,7 +233,7 @@ pub fn send_invite_confirmed(address: &str, org_name: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &DateTime<Local>, device: &str) -> EmptyResult {\n@@ -251,7 +251,7 @@ pub fn send_new_device_logged_in(address: &str, ip: &str, dt: &DateTime<Local>,\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_token(address: &str, token: &str) -> EmptyResult {\n@@ -263,7 +263,7 @@ pub fn send_token(address: &str, token: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n@@ -275,7 +275,7 @@ pub fn send_change_email(address: &str, token: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n pub fn send_test(address: &str) -> EmptyResult {\n@@ -286,10 +286,10 @@ pub fn send_test(address: &str) -> EmptyResult {\n         }),\n     )?;\n \n-    send_email(address, &subject, &body_html, &body_text)\n+    send_email(address, &subject, body_html, body_text)\n }\n \n-fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) -> EmptyResult {\n+fn send_email(address: &str, subject: &str, body_html: String, body_text: String) -> EmptyResult {\n     let address_split: Vec<&str> = address.rsplitn(2, '@').collect();\n     if address_split.len() != 2 {\n         err!(\"Invalid email address (no @)\");\n@@ -306,13 +306,13 @@ fn send_email(address: &str, subject: &str, body_html: &str, body_text: &str) ->\n         // We force Base64 encoding because in the past we had issues with different encodings.\n         .header(header::ContentTransferEncoding::Base64)\n         .header(header::ContentType(\"text/html; charset=utf-8\".parse()?))\n-        .body(String::from(body_html));\n+        .body(body_html);\n \n     let text = SinglePart::builder()\n         // We force Base64 encoding because in the past we had issues with different encodings.\n         .header(header::ContentTransferEncoding::Base64)\n         .header(header::ContentType(\"text/plain; charset=utf-8\".parse()?))\n-        .body(String::from(body_text));\n+        .body(body_text);\n \n     let smtp_from = &CONFIG.smtp_from();\n     let email = Message::builder()\n",
            "comment_added_diff": []
        },
        {
            "commit": "dad1b1bee9d8429b32cb162de5253be6ccf2e28b",
            "timestamp": "2021-03-06T22:04:01+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated dependencies",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -30,10 +30,10 @@ fn mailer() -> SmtpTransport {\n     let smtp_client = if CONFIG.smtp_ssl() {\n         let mut tls_parameters = TlsParameters::builder(host);\n         if CONFIG.smtp_accept_invalid_hostnames() {\n-            tls_parameters.dangerous_accept_invalid_hostnames(true);\n+            tls_parameters = tls_parameters.dangerous_accept_invalid_hostnames(true);\n         }\n         if CONFIG.smtp_accept_invalid_certs() {\n-            tls_parameters.dangerous_accept_invalid_certs(true);\n+            tls_parameters = tls_parameters.dangerous_accept_invalid_certs(true);\n         }\n         let tls_parameters = tls_parameters.build().unwrap();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "f9ebb780f92c44b63b1cab6be79ff120f183fc4c",
            "timestamp": "2021-03-22T20:00:57+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update dependencies",
            "additions": 13,
            "deletions": 15,
            "change_type": "MODIFY",
            "diff": "@@ -332,21 +332,19 @@ fn send_email(address: &str, subject: &str, body_html: String, body_text: String\n     match mailer().send(&email) {\n         Ok(_) => Ok(()),\n         // Match some common errors and make them more user friendly\n-        Err(e) => match e {\n-            lettre::transport::smtp::Error::Client(x) => {\n-                err!(format!(\"SMTP Client error: {}\", x));\n-            },\n-            lettre::transport::smtp::Error::Transient(x) => {\n-                err!(format!(\"SMTP 4xx error: {:?}\", x.message));\n-            },\n-            lettre::transport::smtp::Error::Permanent(x) => {\n-                err!(format!(\"SMTP 5xx error: {:?}\", x.message));\n-            },\n-            lettre::transport::smtp::Error::Io(x) => {\n-                err!(format!(\"SMTP IO error: {}\", x));\n-            },\n-            // Fallback for all other errors\n-            _ => Err(e.into())\n+        Err(e) => {\n+\n+            if e.is_client() {\n+                err!(format!(\"SMTP Client error: {}\", e)); \n+            } else if e.is_transient() {\n+                err!(format!(\"SMTP 4xx error: {:?}\", e));\n+            } else if e.is_permanent() {\n+                err!(format!(\"SMTP 5xx error: {:?}\", e));\n+            }  else if e.is_timeout() {\n+                err!(format!(\"SMTP timeout error: {:?}\", e));\n+            } else {\n+                Err(e.into())\n+            }\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 24,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,4 @@\n-use std::{str::FromStr};\n+use std::str::FromStr;\n \n use chrono::{DateTime, Local};\n use percent_encoding::{percent_encode, NON_ALPHANUMERIC};\n@@ -58,21 +58,32 @@ fn mailer() -> SmtpTransport {\n \n     let smtp_client = match CONFIG.smtp_auth_mechanism() {\n         Some(mechanism) => {\n-            let allowed_mechanisms = [SmtpAuthMechanism::Plain, SmtpAuthMechanism::Login, SmtpAuthMechanism::Xoauth2];\n+            let allowed_mechanisms = [\n+                SmtpAuthMechanism::Plain,\n+                SmtpAuthMechanism::Login,\n+                SmtpAuthMechanism::Xoauth2,\n+            ];\n             let mut selected_mechanisms = vec![];\n             for wanted_mechanism in mechanism.split(',') {\n                 for m in &allowed_mechanisms {\n-                    if m.to_string().to_lowercase() == wanted_mechanism.trim_matches(|c| c == '\"' || c == '\\'' || c == ' ').to_lowercase() {\n+                    if m.to_string().to_lowercase()\n+                        == wanted_mechanism\n+                            .trim_matches(|c| c == '\"' || c == '\\'' || c == ' ')\n+                            .to_lowercase()\n+                    {\n                         selected_mechanisms.push(*m);\n                     }\n                 }\n-            };\n+            }\n \n             if !selected_mechanisms.is_empty() {\n                 smtp_client.authentication(selected_mechanisms)\n             } else {\n                 // Only show a warning, and return without setting an actual authentication mechanism\n-                warn!(\"No valid SMTP Auth mechanism found for '{}', using default values\", mechanism);\n+                warn!(\n+                    \"No valid SMTP Auth mechanism found for '{}', using default values\",\n+                    mechanism\n+                );\n                 smtp_client\n             }\n         }\n@@ -316,31 +327,30 @@ fn send_email(address: &str, subject: &str, body_html: String, body_text: String\n \n     let smtp_from = &CONFIG.smtp_from();\n     let email = Message::builder()\n-        .message_id(Some(format!(\"<{}@{}>\", crate::util::get_uuid(), smtp_from.split('@').collect::<Vec<&str>>()[1] )))\n+        .message_id(Some(format!(\n+            \"<{}@{}>\",\n+            crate::util::get_uuid(),\n+            smtp_from.split('@').collect::<Vec<&str>>()[1]\n+        )))\n         .to(Mailbox::new(None, Address::from_str(&address)?))\n         .from(Mailbox::new(\n             Some(CONFIG.smtp_from_name()),\n             Address::from_str(smtp_from)?,\n         ))\n         .subject(subject)\n-        .multipart(\n-            MultiPart::alternative()\n-                .singlepart(text)\n-                .singlepart(html)\n-        )?;\n+        .multipart(MultiPart::alternative().singlepart(text).singlepart(html))?;\n \n     match mailer().send(&email) {\n         Ok(_) => Ok(()),\n         // Match some common errors and make them more user friendly\n         Err(e) => {\n-\n             if e.is_client() {\n-                err!(format!(\"SMTP Client error: {}\", e)); \n+                err!(format!(\"SMTP Client error: {}\", e));\n             } else if e.is_transient() {\n                 err!(format!(\"SMTP 4xx error: {:?}\", e));\n             } else if e.is_permanent() {\n                 err!(format!(\"SMTP 5xx error: {:?}\", e));\n-            }  else if e.is_timeout() {\n+            } else if e.is_timeout() {\n                 err!(format!(\"SMTP timeout error: {:?}\", e));\n             } else {\n                 Err(e.into())\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 5,
            "deletions": 21,
            "change_type": "MODIFY",
            "diff": "@@ -58,18 +58,12 @@ fn mailer() -> SmtpTransport {\n \n     let smtp_client = match CONFIG.smtp_auth_mechanism() {\n         Some(mechanism) => {\n-            let allowed_mechanisms = [\n-                SmtpAuthMechanism::Plain,\n-                SmtpAuthMechanism::Login,\n-                SmtpAuthMechanism::Xoauth2,\n-            ];\n+            let allowed_mechanisms = [SmtpAuthMechanism::Plain, SmtpAuthMechanism::Login, SmtpAuthMechanism::Xoauth2];\n             let mut selected_mechanisms = vec![];\n             for wanted_mechanism in mechanism.split(',') {\n                 for m in &allowed_mechanisms {\n                     if m.to_string().to_lowercase()\n-                        == wanted_mechanism\n-                            .trim_matches(|c| c == '\"' || c == '\\'' || c == ' ')\n-                            .to_lowercase()\n+                        == wanted_mechanism.trim_matches(|c| c == '\"' || c == '\\'' || c == ' ').to_lowercase()\n                     {\n                         selected_mechanisms.push(*m);\n                     }\n@@ -80,10 +74,7 @@ fn mailer() -> SmtpTransport {\n                 smtp_client.authentication(selected_mechanisms)\n             } else {\n                 // Only show a warning, and return without setting an actual authentication mechanism\n-                warn!(\n-                    \"No valid SMTP Auth mechanism found for '{}', using default values\",\n-                    mechanism\n-                );\n+                warn!(\"No valid SMTP Auth mechanism found for '{}', using default values\", mechanism);\n                 smtp_client\n             }\n         }\n@@ -327,16 +318,9 @@ fn send_email(address: &str, subject: &str, body_html: String, body_text: String\n \n     let smtp_from = &CONFIG.smtp_from();\n     let email = Message::builder()\n-        .message_id(Some(format!(\n-            \"<{}@{}>\",\n-            crate::util::get_uuid(),\n-            smtp_from.split('@').collect::<Vec<&str>>()[1]\n-        )))\n+        .message_id(Some(format!(\"<{}@{}>\", crate::util::get_uuid(), smtp_from.split('@').collect::<Vec<&str>>()[1])))\n         .to(Mailbox::new(None, Address::from_str(&address)?))\n-        .from(Mailbox::new(\n-            Some(CONFIG.smtp_from_name()),\n-            Address::from_str(smtp_from)?,\n-        ))\n+        .from(Mailbox::new(Some(CONFIG.smtp_from_name()), Address::from_str(smtp_from)?))\n         .subject(subject)\n         .multipart(MultiPart::alternative().singlepart(text).singlepart(html))?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "d75a80bd2dbe21e5a1eb2b0a6b18a9422441e071",
            "timestamp": "2021-04-11T22:57:17-04:00",
            "author": "Olivier Martin",
            "commit_message": "Resolves dani-garcia/bitwarden_rs#981\n* a user without 2fa trying to join a 2fa org will fail, but user gets an email to enable 2fa\n* a user disabling 2fa will be removed from 2fa orgs; user gets an email for each org\n* an org enabling 2fa policy will remove users without 2fa; users get an email",
            "additions": 16,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -179,6 +179,22 @@ pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n     send_email(address, &subject, body_html, body_text)\n }\n \n+pub fn send_2fa_removed_from_org(\n+    address: &str,\n+    org_name: &str,\n+) -> EmptyResult {\n+\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/send_2fa_removed_from_org\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"org_name\": org_name,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n pub fn send_invite(\n     address: &str,\n     uuid: &str,\n",
            "comment_added_diff": []
        },
        {
            "commit": "89a68741d6c049e827e84dc224566d1a61dda1f7",
            "timestamp": "2021-04-16T14:49:59-04:00",
            "author": "Olivier Martin",
            "commit_message": "ran cargo fmt --all",
            "additions": 1,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -181,11 +181,7 @@ pub fn send_welcome_must_verify(address: &str, uuid: &str) -> EmptyResult {\n     send_email(address, &subject, body_html, body_text)\n }\n \n-pub fn send_2fa_removed_from_org(\n-    address: &str,\n-    org_name: &str,\n-) -> EmptyResult {\n-\n+pub fn send_2fa_removed_from_org(address: &str, org_name: &str) -> EmptyResult {\n     let (subject, body_html, body_text) = get_text(\n         \"email/send_2fa_removed_from_org\",\n         json!({\n",
            "comment_added_diff": []
        },
        {
            "commit": "7cb19ef767142b773ab44a457940844589432a74",
            "timestamp": "2021-05-08T17:46:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated branding, email and crates\n\n- Updated branding for admin and emails\n- Updated crates and some deprications\n- Removed newline-converter because this is built-in into lettre\n- Updated email templates to use a shared header and footer template\n- Also trigger SMTP SSL When TLS is selected without SSL\n  Resolves #1641",
            "additions": 4,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -27,7 +27,7 @@ fn mailer() -> SmtpTransport {\n         .timeout(Some(Duration::from_secs(CONFIG.smtp_timeout())));\n \n     // Determine security\n-    let smtp_client = if CONFIG.smtp_ssl() {\n+    let smtp_client = if CONFIG.smtp_ssl() || CONFIG.smtp_explicit_tls() {\n         let mut tls_parameters = TlsParameters::builder(host);\n         if CONFIG.smtp_accept_invalid_hostnames() {\n             tls_parameters = tls_parameters.dangerous_accept_invalid_hostnames(true);\n@@ -99,9 +99,8 @@ fn get_template(template_name: &str, data: &serde_json::Value) -> Result<(String\n         None => err!(\"Template doesn't contain subject\"),\n     };\n \n-    use newline_converter::unix2dos;\n     let body = match text_split.next() {\n-        Some(s) => unix2dos(s.trim()).to_string(),\n+        Some(s) => s.trim().to_string(),\n         None => err!(\"Template doesn't contain body\"),\n     };\n \n@@ -307,13 +306,13 @@ fn send_email(address: &str, subject: &str, body_html: String, body_text: String\n     let html = SinglePart::builder()\n         // We force Base64 encoding because in the past we had issues with different encodings.\n         .header(header::ContentTransferEncoding::Base64)\n-        .header(header::ContentType(\"text/html; charset=utf-8\".parse()?))\n+        .header(header::ContentType::TEXT_HTML)\n         .body(body_html);\n \n     let text = SinglePart::builder()\n         // We force Base64 encoding because in the past we had issues with different encodings.\n         .header(header::ContentTransferEncoding::Base64)\n-        .header(header::ContentType(\"text/plain; charset=utf-8\".parse()?))\n+        .header(header::ContentType::TEXT_PLAIN)\n         .body(body_text);\n \n     let smtp_from = &CONFIG.smtp_from();\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 134,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -13,7 +13,10 @@ use lettre::{\n \n use crate::{\n     api::EmptyResult,\n-    auth::{encode_jwt, generate_delete_claims, generate_invite_claims, generate_verify_email_claims},\n+    auth::{\n+        encode_jwt, generate_delete_claims, generate_emergency_access_invite_claims, generate_invite_claims,\n+        generate_verify_email_claims,\n+    },\n     error::Error,\n     CONFIG,\n };\n@@ -224,6 +227,136 @@ pub fn send_invite(\n     send_email(address, &subject, body_html, body_text)\n }\n \n+pub fn send_emergency_access_invite(\n+    address: &str,\n+    uuid: &str,\n+    emer_id: Option<String>,\n+    grantor_name: Option<String>,\n+    grantor_email: Option<String>,\n+) -> EmptyResult {\n+    let claims = generate_emergency_access_invite_claims(\n+        uuid.to_string(),\n+        String::from(address),\n+        emer_id.clone(),\n+        grantor_name.clone(),\n+        grantor_email,\n+    );\n+\n+    let invite_token = encode_jwt(&claims);\n+\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/send_emergency_access_invite\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"emer_id\": emer_id.unwrap_or_else(|| \"_\".to_string()),\n+            \"email\": percent_encode(address.as_bytes(), NON_ALPHANUMERIC).to_string(),\n+            \"grantor_name\": grantor_name,\n+            \"token\": invite_token,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_invite_accepted(address: &str, grantee_email: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_invite_accepted\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantee_email\": grantee_email,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_invite_confirmed(address: &str, grantor_name: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_invite_confirmed\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantor_name\": grantor_name,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_recovery_approved(address: &str, grantor_name: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_recovery_approved\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantor_name\": grantor_name,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_recovery_initiated(\n+    address: &str,\n+    grantee_name: &str,\n+    atype: &str,\n+    wait_time_days: &str,\n+) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_recovery_initiated\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantee_name\": grantee_name,\n+            \"atype\": atype,\n+            \"wait_time_days\": wait_time_days,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_recovery_reminder(\n+    address: &str,\n+    grantee_name: &str,\n+    atype: &str,\n+    wait_time_days: &str,\n+) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_recovery_reminder\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantee_name\": grantee_name,\n+            \"atype\": atype,\n+            \"wait_time_days\": wait_time_days,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_recovery_rejected(address: &str, grantor_name: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_recovery_rejected\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantor_name\": grantor_name,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n+pub fn send_emergency_access_recovery_timed_out(address: &str, grantee_name: &str, atype: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/emergency_access_recovery_timed_out\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"grantee_name\": grantee_name,\n+            \"atype\": atype,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n pub fn send_invite_accepted(new_user_email: &str, address: &str, org_name: &str) -> EmptyResult {\n     let (subject, body_html, body_text) = get_text(\n         \"email/invite_accepted\",\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -195,6 +195,18 @@ pub fn send_2fa_removed_from_org(address: &str, org_name: &str) -> EmptyResult {\n     send_email(address, &subject, body_html, body_text)\n }\n \n+pub fn send_single_org_removed_from_org(address: &str, org_name: &str) -> EmptyResult {\n+    let (subject, body_html, body_text) = get_text(\n+        \"email/send_single_org_removed_from_org\",\n+        json!({\n+            \"url\": CONFIG.domain(),\n+            \"org_name\": org_name,\n+        }),\n+    )?;\n+\n+    send_email(address, &subject, body_html, body_text)\n+}\n+\n pub fn send_invite(\n     address: &str,\n     uuid: &str,\n",
            "comment_added_diff": []
        },
        {
            "commit": "338756550a27d1084ae947a1a108482abb8f473b",
            "timestamp": "2021-10-08T00:01:24+02:00",
            "author": "BlackDex",
            "commit_message": "Fix error reporting in admin and some small fixes\n\n- Fixed a bug in JavaScript which caused no messages to be shown to the\nuser in-case of an error send by the server.\n- Changed mail error handling for better error messages\n- Changed user/org actions from a to buttons, this should prevent\nstrange issues in-case of javascript issues and the page does re-load.\n- Added Alpine and Debian info for the running docker image\n\nDuring the mail error testing i encountered a bug which caused lettre to\npanic. This panic only happens on debug builds and not release builds,\nso no need to update anything on that part. This bug is also already\nfixed. See https://github.com/lettre/lettre/issues/678 and https://github.com/lettre/lettre/pull/679\n\nResolves #2021\nCould also fix the issue reported here #2022, or at least no hash `#` in\nthe url.",
            "additions": 18,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -473,15 +473,28 @@ fn send_email(address: &str, subject: &str, body_html: String, body_text: String\n         // Match some common errors and make them more user friendly\n         Err(e) => {\n             if e.is_client() {\n-                err!(format!(\"SMTP Client error: {}\", e));\n+                debug!(\"SMTP Client error: {:#?}\", e);\n+                err!(format!(\"SMTP Client error: {}\", e.to_string()));\n             } else if e.is_transient() {\n-                err!(format!(\"SMTP 4xx error: {:?}\", e));\n+                debug!(\"SMTP 4xx error: {:#?}\", e);\n+                err!(format!(\"SMTP 4xx error: {}\", e.to_string()));\n             } else if e.is_permanent() {\n-                err!(format!(\"SMTP 5xx error: {:?}\", e));\n+                debug!(\"SMTP 5xx error: {:#?}\", e);\n+                let mut msg = e.to_string();\n+                // Add a special check for 535 to add a more descriptive message\n+                if msg.contains(\"(535)\") {\n+                    msg = format!(\"{} - Authentication credentials invalid\", msg);\n+                }\n+                err!(format!(\"SMTP 5xx error: {}\", msg));\n             } else if e.is_timeout() {\n-                err!(format!(\"SMTP timeout error: {:?}\", e));\n+                debug!(\"SMTP timeout error: {:#?}\", e);\n+                err!(format!(\"SMTP timeout error: {}\", e.to_string()));\n+            } else if e.is_tls() {\n+                debug!(\"SMTP Encryption error: {:#?}\", e);\n+                err!(format!(\"SMTP Encryption error: {}\", e.to_string()));\n             } else {\n-                Err(e.into())\n+                debug!(\"SMTP {:#?}\", e);\n+                err!(format!(\"SMTP {}\", e.to_string()));\n             }\n         }\n     }\n",
            "comment_added_diff": [
                [
                    484,
                    "                // Add a special check for 535 to add a more descriptive message"
                ]
            ]
        }
    ],
    "ciphers.rs": [
        {
            "commit": "85dbf4e16c60e9657552f6cedab3e5111115fe7c",
            "timestamp": "2019-11-05T21:29:04+13:00",
            "author": "Patrick Li",
            "commit_message": "Don't include excluded global equivalent domains during sync\n\nFixes #681",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -88,7 +88,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let domains_json = if data.exclude_domains {\n         Value::Null\n     } else {\n-        api::core::get_eq_domains(headers).unwrap().into_inner()\n+        api::core::_get_eq_domains(headers, true).unwrap().into_inner()\n     };\n \n     Ok(Json(json!({\n",
            "comment_added_diff": []
        },
        {
            "commit": "325039c31695ac981da3b88dbbe6c6f40c6a180d",
            "timestamp": "2020-02-17T22:56:26+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Attachment size limits, per-user and per-organization",
            "additions": 43,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -642,20 +642,49 @@ fn post_attachment(\n ) -> JsonResult {\n     let cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n         Some(cipher) => cipher,\n-        None => err!(\"Cipher doesn't exist\"),\n+        None => err_discard!(\"Cipher doesn't exist\", data),\n     };\n \n     if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n-        err!(\"Cipher is not write accessible\")\n+        err_discard!(\"Cipher is not write accessible\", data)\n     }\n-\n+    \n     let mut params = content_type.params();\n     let boundary_pair = params.next().expect(\"No boundary provided\");\n     let boundary = boundary_pair.1;\n \n+    let size_limit = if let Some(ref user_uuid) = cipher.user_uuid {\n+        match CONFIG.user_attachment_limit() {\n+            Some(0) => err_discard!(\"Attachments are disabled\", data),\n+            Some(limit) => {\n+                let left = limit - Attachment::size_by_user(user_uuid, &conn);\n+                if left <= 0 {\n+                    err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n+                }\n+                Some(left as u64)\n+            }\n+            None => None,\n+        }\n+    } else if let Some(ref org_uuid) = cipher.organization_uuid {\n+        match CONFIG.org_attachment_limit() {\n+            Some(0) => err_discard!(\"Attachments are disabled\", data),\n+            Some(limit) => {\n+                let left = limit - Attachment::size_by_org(org_uuid, &conn);\n+                if left <= 0 {\n+                    err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n+                }\n+                Some(left as u64)\n+            }\n+            None => None,\n+        }\n+    } else {\n+        err_discard!(\"Cipher is neither owned by a user nor an organization\", data);\n+    };\n+\n     let base_path = Path::new(&CONFIG.attachments_folder()).join(&cipher.uuid);\n \n     let mut attachment_key = None;\n+    let mut error = None;\n \n     Multipart::with_body(data.open(), boundary)\n         .foreach_entry(|mut field| {\n@@ -674,18 +703,21 @@ fn post_attachment(\n                     let file_name = HEXLOWER.encode(&crypto::get_random(vec![0; 10]));\n                     let path = base_path.join(&file_name);\n \n-                    let size = match field.data.save().memory_threshold(0).size_limit(None).with_path(path) {\n+                    let size = match field.data.save().memory_threshold(0).size_limit(size_limit).with_path(path.clone()) {\n                         SaveResult::Full(SavedData::File(_, size)) => size as i32,\n                         SaveResult::Full(other) => {\n-                            error!(\"Attachment is not a file: {:?}\", other);\n+                            std::fs::remove_file(path).ok();\n+                            error = Some(format!(\"Attachment is not a file: {:?}\", other));\n                             return;\n                         }\n                         SaveResult::Partial(_, reason) => {\n-                            error!(\"Partial result: {:?}\", reason);\n+                            std::fs::remove_file(path).ok();\n+                            error = Some(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n                             return;\n                         }\n                         SaveResult::Error(e) => {\n-                            error!(\"Error: {:?}\", e);\n+                            std::fs::remove_file(path).ok();\n+                            error = Some(format!(\"Error: {:?}\", e));\n                             return;\n                         }\n                     };\n@@ -699,6 +731,10 @@ fn post_attachment(\n         })\n         .expect(\"Error processing multipart data\");\n \n+    if let Some(ref e) = error {\n+        err!(e);\n+    }\n+\n     nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n \n     Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n",
            "comment_added_diff": []
        },
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -79,6 +79,9 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let collections = Collection::find_by_user_uuid(&headers.user.uuid, &conn);\n     let collections_json: Vec<Value> = collections.iter().map(Collection::to_json).collect();\n \n+    let policies = OrgPolicy::find_by_user(&headers.user.uuid, &conn);\n+    let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n+\n     let ciphers = Cipher::find_by_user(&headers.user.uuid, &conn);\n     let ciphers_json: Vec<Value> = ciphers\n         .iter()\n@@ -95,6 +98,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n         \"Profile\": user_json,\n         \"Folders\": folders_json,\n         \"Collections\": collections_json,\n+        \"Policies\": policies_json,\n         \"Ciphers\": ciphers_json,\n         \"Domains\": domains_json,\n         \"Object\": \"sync\"\n@@ -648,7 +652,7 @@ fn post_attachment(\n     if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n         err_discard!(\"Cipher is not write accessible\", data)\n     }\n-    \n+\n     let mut params = content_type.params();\n     let boundary_pair = params.next().expect(\"No boundary provided\");\n     let boundary = boundary_pair.1;\n",
            "comment_added_diff": []
        },
        {
            "commit": "a30d5f4cf9039653a55e2eb6b8b3ac98815aac33",
            "timestamp": "2020-03-14T14:08:57+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix cloning issues",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -604,7 +604,9 @@ fn share_cipher_by_uuid(\n     };\n \n     match data.Cipher.OrganizationId.clone() {\n-        None => err!(\"Organization id not provided\"),\n+        // If we don't get an organization ID, we don't do anything\n+        // No error because this is used when using the Clone functionality\n+        None => Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn))),\n         Some(organization_uuid) => {\n             let mut shared_to_collection = false;\n             for uuid in &data.CollectionIds {\n",
            "comment_added_diff": [
                [
                    607,
                    "        // If we don't get an organization ID, we don't do anything"
                ],
                [
                    608,
                    "        // No error because this is used when using the Clone functionality"
                ]
            ]
        },
        {
            "commit": "2ee07ea1d8a7e42ca6532f461f2aeeec4db629be",
            "timestamp": "2020-03-15T17:26:34+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix empty data when cloning cipher",
            "additions": 17,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -603,12 +603,14 @@ fn share_cipher_by_uuid(\n         None => err!(\"Cipher doesn't exist\"),\n     };\n \n+    let mut shared_to_collection = false;\n+\n     match data.Cipher.OrganizationId.clone() {\n         // If we don't get an organization ID, we don't do anything\n         // No error because this is used when using the Clone functionality\n-        None => Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn))),\n+        None => {},\n         Some(organization_uuid) => {\n-            let mut shared_to_collection = false;\n+\n             for uuid in &data.CollectionIds {\n                 match Collection::find_by_uuid_and_org(uuid, &organization_uuid, &conn) {\n                     None => err!(\"Invalid collection ID provided\"),\n@@ -622,19 +624,20 @@ fn share_cipher_by_uuid(\n                     }\n                 }\n             }\n-            update_cipher_from_data(\n-                &mut cipher,\n-                data.Cipher,\n-                &headers,\n-                shared_to_collection,\n-                &conn,\n-                &nt,\n-                UpdateType::CipherUpdate,\n-            )?;\n-\n-            Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n         }\n-    }\n+    };\n+\n+    update_cipher_from_data(\n+        &mut cipher,\n+        data.Cipher,\n+        &headers,\n+        shared_to_collection,\n+        &conn,\n+        &nt,\n+        UpdateType::CipherUpdate,\n+    )?;\n+\n+    Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n }\n \n #[post(\"/ciphers/<uuid>/attachment\", format = \"multipart/form-data\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "7407b8326aa02ca21c4c2dc1d98768fa8104412e",
            "timestamp": "2020-03-31T02:30:28-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix attachment size limit calculation\n\nThe config values (in KB) need to be converted to bytes when comparing\nagainst total attachment sizes.",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -665,8 +665,8 @@ fn post_attachment(\n     let size_limit = if let Some(ref user_uuid) = cipher.user_uuid {\n         match CONFIG.user_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n-            Some(limit) => {\n-                let left = limit - Attachment::size_by_user(user_uuid, &conn);\n+            Some(limit_kb) => {\n+                let left = (limit_kb * 1024) - Attachment::size_by_user(user_uuid, &conn);\n                 if left <= 0 {\n                     err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n                 }\n@@ -677,8 +677,8 @@ fn post_attachment(\n     } else if let Some(ref org_uuid) = cipher.organization_uuid {\n         match CONFIG.org_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n-            Some(limit) => {\n-                let left = limit - Attachment::size_by_org(org_uuid, &conn);\n+            Some(limit_kb) => {\n+                let left = (limit_kb * 1024) - Attachment::size_by_org(org_uuid, &conn);\n                 if left <= 0 {\n                     err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n                 }\n",
            "comment_added_diff": []
        },
        {
            "commit": "e3b00b59a7db760848f6b357fc4328081574aeac",
            "timestamp": "2020-04-17T22:35:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial support for soft deletes",
            "additions": 107,
            "deletions": 24,
            "change_type": "MODIFY",
            "diff": "@@ -49,10 +49,16 @@ pub fn routes() -> Vec<Route> {\n         put_cipher,\n         delete_cipher_post,\n         delete_cipher_post_admin,\n+        delete_cipher_put,\n+        delete_cipher_put_admin,\n         delete_cipher,\n         delete_cipher_admin,\n         delete_cipher_selected,\n         delete_cipher_selected_post,\n+        delete_cipher_selected_put,\n+        restore_cipher_put,\n+        restore_cipher_put_admin,\n+        restore_cipher_selected,\n         delete_all,\n         move_cipher_selected,\n         move_cipher_selected_put,\n@@ -819,48 +825,62 @@ fn delete_attachment_admin(\n \n #[post(\"/ciphers/<uuid>/delete\")]\n fn delete_cipher_post(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    _delete_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n+    _delete_cipher_by_uuid(&uuid, &headers, &conn, false, &nt)\n }\n \n #[post(\"/ciphers/<uuid>/delete-admin\")]\n fn delete_cipher_post_admin(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    _delete_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n+    _delete_cipher_by_uuid(&uuid, &headers, &conn, false, &nt)\n+}\n+\n+#[put(\"/ciphers/<uuid>/delete\")]\n+fn delete_cipher_put(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _delete_cipher_by_uuid(&uuid, &headers, &conn, true, &nt)\n+}\n+\n+#[put(\"/ciphers/<uuid>/delete-admin\")]\n+fn delete_cipher_put_admin(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _delete_cipher_by_uuid(&uuid, &headers, &conn, true, &nt)\n }\n \n #[delete(\"/ciphers/<uuid>\")]\n fn delete_cipher(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    _delete_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n+    _delete_cipher_by_uuid(&uuid, &headers, &conn, false, &nt)\n }\n \n #[delete(\"/ciphers/<uuid>/admin\")]\n fn delete_cipher_admin(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    _delete_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n+    _delete_cipher_by_uuid(&uuid, &headers, &conn, false, &nt)\n }\n \n #[delete(\"/ciphers\", data = \"<data>\")]\n fn delete_cipher_selected(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    let data: Value = data.into_inner().data;\n+    _delete_multiple_ciphers(data, headers, conn, false, nt)\n+}\n \n-    let uuids = match data.get(\"Ids\") {\n-        Some(ids) => match ids.as_array() {\n-            Some(ids) => ids.iter().filter_map(Value::as_str),\n-            None => err!(\"Posted ids field is not an array\"),\n-        },\n-        None => err!(\"Request missing ids field\"),\n-    };\n+#[post(\"/ciphers/delete\", data = \"<data>\")]\n+fn delete_cipher_selected_post(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _delete_multiple_ciphers(data, headers, conn, false, nt)\n+}\n \n-    for uuid in uuids {\n-        if let error @ Err(_) = _delete_cipher_by_uuid(uuid, &headers, &conn, &nt) {\n-            return error;\n-        };\n-    }\n+#[put(\"/ciphers/delete\", data = \"<data>\")]\n+fn delete_cipher_selected_put(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _delete_multiple_ciphers(data, headers, conn, true, nt)\n+}\n \n-    Ok(())\n+#[put(\"/ciphers/<uuid>/restore\")]\n+fn restore_cipher_put(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _restore_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n }\n \n-#[post(\"/ciphers/delete\", data = \"<data>\")]\n-fn delete_cipher_selected_post(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    delete_cipher_selected(data, headers, conn, nt)\n+#[put(\"/ciphers/<uuid>/restore-admin\")]\n+fn restore_cipher_put_admin(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _restore_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n+}\n+\n+#[put(\"/ciphers/restore\", data = \"<data>\")]\n+fn restore_cipher_selected(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    _restore_multiple_ciphers(data, headers, conn, nt)\n }\n \n #[derive(Deserialize)]\n@@ -974,8 +994,8 @@ fn delete_all(\n     }\n }\n \n-fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &Notify) -> EmptyResult {\n-    let cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, soft_delete: bool, nt: &Notify) -> EmptyResult {\n+    let mut cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n         Some(cipher) => cipher,\n         None => err!(\"Cipher doesn't exist\"),\n     };\n@@ -984,11 +1004,74 @@ fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &Not\n         err!(\"Cipher can't be deleted by user\")\n     }\n \n-    cipher.delete(&conn)?;\n+    if soft_delete {\n+        cipher.deleted_at = Some(chrono::Utc::now().naive_utc());\n+        cipher.save(&conn)?;\n+    } else {\n+        cipher.delete(&conn)?;\n+    }\n+\n     nt.send_cipher_update(UpdateType::CipherDelete, &cipher, &cipher.update_users_revision(&conn));\n     Ok(())\n }\n \n+fn _delete_multiple_ciphers(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, soft_delete: bool, nt: Notify) -> EmptyResult {\n+    let data: Value = data.into_inner().data;\n+\n+    let uuids = match data.get(\"Ids\") {\n+        Some(ids) => match ids.as_array() {\n+            Some(ids) => ids.iter().filter_map(Value::as_str),\n+            None => err!(\"Posted ids field is not an array\"),\n+        },\n+        None => err!(\"Request missing ids field\"),\n+    };\n+\n+    for uuid in uuids {\n+        if let error @ Err(_) = _delete_cipher_by_uuid(uuid, &headers, &conn, soft_delete, &nt) {\n+            return error;\n+        };\n+    }\n+\n+    Ok(())\n+}\n+\n+fn _restore_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &Notify) -> EmptyResult {\n+    let mut cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+        Some(cipher) => cipher,\n+        None => err!(\"Cipher doesn't exist\"),\n+    };\n+\n+    if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+        err!(\"Cipher can't be restored by user\")\n+    }\n+\n+    cipher.deleted_at = None;\n+    cipher.save(&conn)?;\n+\n+    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n+    Ok(())\n+}\n+\n+fn _restore_multiple_ciphers(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    let data: Value = data.into_inner().data;\n+\n+    let uuids = match data.get(\"Ids\") {\n+        Some(ids) => match ids.as_array() {\n+            Some(ids) => ids.iter().filter_map(Value::as_str),\n+            None => err!(\"Posted ids field is not an array\"),\n+        },\n+        None => err!(\"Request missing ids field\"),\n+    };\n+\n+    for uuid in uuids {\n+        if let error @ Err(_) = _restore_cipher_by_uuid(uuid, &headers, &conn, &nt) {\n+            return error;\n+        };\n+    }\n+\n+    Ok(())\n+}\n+\n fn _delete_cipher_attachment_by_id(\n     uuid: &str,\n     attachment_id: &str,\n",
            "comment_added_diff": []
        },
        {
            "commit": "632f4d545367b5ab1cefce66bc526e5dc0a786de",
            "timestamp": "2020-05-07T18:02:37-04:00",
            "author": "theycallmesteve",
            "commit_message": "Whitespace fixes",
            "additions": 1,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -767,11 +767,7 @@ fn post_attachment_admin(\n     post_attachment(uuid, data, content_type, headers, conn, nt)\n }\n \n-#[post(\n-    \"/ciphers/<uuid>/attachment/<attachment_id>/share\",\n-    format = \"multipart/form-data\",\n-    data = \"<data>\"\n-)]\n+#[post(\"/ciphers/<uuid>/attachment/<attachment_id>/share\", format = \"multipart/form-data\", data = \"<data>\")]\n fn post_attachment_share(\n     uuid: String,\n     attachment_id: String,\n",
            "comment_added_diff": []
        },
        {
            "commit": "24c914799dc9cb711b4def0c00e99943437c69fe",
            "timestamp": "2020-06-07T17:57:04+02:00",
            "author": "BlackDex",
            "commit_message": "Fixes #1022 cloning with attachments\n\nWhen a cipher has one or more attachments it wasn't able to be cloned.\nThis commit fixes that issue.",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -274,7 +274,10 @@ pub fn update_cipher_from_data(\n             };\n \n             if saved_att.cipher_uuid != cipher.uuid {\n-                err!(\"Attachment is not owned by the cipher\")\n+                // Warn and break here since cloning ciphers provides attachment data but will not be cloned.\n+                // If we error out here it will break the whole cloning and causes empty ciphers to appear.\n+                warn!(\"Attachment is not owned by the cipher\");\n+                break;\n             }\n \n             saved_att.akey = Some(attachment.Key);\n",
            "comment_added_diff": [
                [
                    277,
                    "                // Warn and break here since cloning ciphers provides attachment data but will not be cloned."
                ],
                [
                    278,
                    "                // If we error out here it will break the whole cloning and causes empty ciphers to appear."
                ]
            ]
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 10,
            "deletions": 17,
            "change_type": "MODIFY",
            "diff": "@@ -1,26 +1,20 @@\n use std::collections::{HashMap, HashSet};\n use std::path::Path;\n \n-use rocket::http::ContentType;\n-use rocket::{request::Form, Data, Route};\n-\n+use rocket::{http::ContentType, request::Form, Data, Route};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use multipart::server::save::SavedData;\n-use multipart::server::{Multipart, SaveResult};\n-\n use data_encoding::HEXLOWER;\n+use multipart::server::{save::SavedData, Multipart, SaveResult};\n \n-use crate::db::models::*;\n-use crate::db::DbConn;\n-\n-use crate::crypto;\n-\n-use crate::api::{self, EmptyResult, JsonResult, JsonUpcase, Notify, PasswordData, UpdateType};\n-use crate::auth::Headers;\n-\n-use crate::CONFIG;\n+use crate::{\n+    api::{self, EmptyResult, JsonResult, JsonUpcase, Notify, PasswordData, UpdateType},\n+    auth::Headers,\n+    crypto,\n+    db::{models::*, DbConn},\n+    CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n     routes![\n@@ -617,9 +611,8 @@ fn share_cipher_by_uuid(\n     match data.Cipher.OrganizationId.clone() {\n         // If we don't get an organization ID, we don't do anything\n         // No error because this is used when using the Clone functionality\n-        None => {},\n+        None => {}\n         Some(organization_uuid) => {\n-\n             for uuid in &data.CollectionIds {\n                 match Collection::find_by_uuid_and_org(uuid, &organization_uuid, &conn) {\n                     None => err!(\"Invalid collection ID provided\"),\n",
            "comment_added_diff": []
        },
        {
            "commit": "a846f6c610284ecfe8588d4685f4aaaec1d15127",
            "timestamp": "2020-07-26T16:19:47-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix soft delete notifications\n\nA soft-deleted entry should now show up in the trash folder immediately\n(previously, an extra sync was required).",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -999,11 +999,12 @@ fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, soft_del\n     if soft_delete {\n         cipher.deleted_at = Some(chrono::Utc::now().naive_utc());\n         cipher.save(&conn)?;\n+        nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n     } else {\n         cipher.delete(&conn)?;\n+        nt.send_cipher_update(UpdateType::CipherDelete, &cipher, &cipher.update_users_revision(&conn));\n     }\n \n-    nt.send_cipher_update(UpdateType::CipherDelete, &cipher, &cipher.update_users_revision(&conn));\n     Ok(())\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "f83a8a36d16eb14c4d2f68f7edf7989bbf7973cb",
            "timestamp": "2020-08-19T02:32:58-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Track favorites on a per-user basis\n\nCurrently, favorites are tracked at the cipher level. For org-owned ciphers,\nthis means that if one user sets it as a favorite, it automatically becomes a\nfavorite for all other users that the cipher has been shared with.",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -303,7 +303,6 @@ pub fn update_cipher_from_data(\n     type_data[\"PasswordHistory\"] = data.PasswordHistory.clone().unwrap_or(Value::Null);\n     // TODO: ******* Backwards compat end **********\n \n-    cipher.favorite = data.Favorite.unwrap_or(false);\n     cipher.name = data.Name;\n     cipher.notes = data.Notes;\n     cipher.fields = data.Fields.map(|f| f.to_string());\n@@ -312,6 +311,7 @@ pub fn update_cipher_from_data(\n \n     cipher.save(&conn)?;\n     cipher.move_to_folder(data.FolderId, &headers.user.uuid, &conn)?;\n+    cipher.set_favorite(data.Favorite, &headers.user.uuid, &conn)?;\n \n     if ut != UpdateType::None {\n         nt.send_cipher_update(ut, &cipher, &cipher.update_users_revision(&conn));\n@@ -410,6 +410,11 @@ fn put_cipher(uuid: String, data: JsonUpcase<CipherData>, headers: Headers, conn\n         None => err!(\"Cipher doesn't exist\"),\n     };\n \n+    // TODO: Check if only the folder ID or favorite status is being changed.\n+    // These are per-user properties that technically aren't part of the\n+    // cipher itself, so the user shouldn't need write access to change these.\n+    // Interestingly, upstream Bitwarden doesn't properly handle this either.\n+\n     if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n         err!(\"Cipher is not write accessible\")\n     }\n",
            "comment_added_diff": [
                [
                    413,
                    "    // TODO: Check if only the folder ID or favorite status is being changed."
                ],
                [
                    414,
                    "    // These are per-user properties that technically aren't part of the"
                ],
                [
                    415,
                    "    // cipher itself, so the user shouldn't need write access to change these."
                ],
                [
                    416,
                    "    // Interestingly, upstream Bitwarden doesn't properly handle this either."
                ]
            ]
        },
        {
            "commit": "4c3b328aca359ebf6211f53509c15b6c94d70e3f",
            "timestamp": "2020-09-01T02:20:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Hide ciphers from non-selected collections for org owners/admins\n\nIf org owners/admins set their org access to only include selected\ncollections, then ciphers from non-selected collections shouldn't\nappear in \"My Vault\". This matches the upstream behavior.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -82,7 +82,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let policies = OrgPolicy::find_by_user(&headers.user.uuid, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n \n-    let ciphers = Cipher::find_by_user(&headers.user.uuid, &conn);\n+    let ciphers = Cipher::find_by_user_visible(&headers.user.uuid, &conn);\n     let ciphers_json: Vec<Value> = ciphers\n         .iter()\n         .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n@@ -107,7 +107,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n \n #[get(\"/ciphers\")]\n fn get_ciphers(headers: Headers, conn: DbConn) -> JsonResult {\n-    let ciphers = Cipher::find_by_user(&headers.user.uuid, &conn);\n+    let ciphers = Cipher::find_by_user_visible(&headers.user.uuid, &conn);\n \n     let ciphers_json: Vec<Value> = ciphers\n         .iter()\n",
            "comment_added_diff": []
        },
        {
            "commit": "95caaf2a40194de6db3305ef1d8f28ddeae159e0",
            "timestamp": "2020-10-23T03:42:22-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add missing admin endpoints for deleting ciphers\n\nThis fixes the inability to bulk-delete ciphers from org vault views.",
            "additions": 29,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -17,6 +17,16 @@ use crate::{\n };\n \n pub fn routes() -> Vec<Route> {\n+    // Note that many routes have an `admin` variant; this seems to be\n+    // because the stored procedure that upstream Bitwarden uses to determine\n+    // whether the user can edit a cipher doesn't take into account whether\n+    // the user is an org owner/admin. The `admin` variant first checks\n+    // whether the user is an owner/admin of the relevant org, and if so,\n+    // allows the operation unconditionally.\n+    //\n+    // bitwarden_rs factors in the org owner/admin status as part of\n+    // determining the write accessibility of a cipher, so most\n+    // admin/non-admin implementations can be shared.\n     routes![\n         sync,\n         get_ciphers,\n@@ -50,6 +60,9 @@ pub fn routes() -> Vec<Route> {\n         delete_cipher_selected,\n         delete_cipher_selected_post,\n         delete_cipher_selected_put,\n+        delete_cipher_selected_admin,\n+        delete_cipher_selected_post_admin,\n+        delete_cipher_selected_put_admin,\n         restore_cipher_put,\n         restore_cipher_put_admin,\n         restore_cipher_selected,\n@@ -862,7 +875,22 @@ fn delete_cipher_selected_post(data: JsonUpcase<Value>, headers: Headers, conn:\n \n #[put(\"/ciphers/delete\", data = \"<data>\")]\n fn delete_cipher_selected_put(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    _delete_multiple_ciphers(data, headers, conn, true, nt)\n+    _delete_multiple_ciphers(data, headers, conn, true, nt) // soft delete\n+}\n+\n+#[delete(\"/ciphers/admin\", data = \"<data>\")]\n+fn delete_cipher_selected_admin(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    delete_cipher_selected(data, headers, conn, nt)\n+}\n+\n+#[post(\"/ciphers/delete-admin\", data = \"<data>\")]\n+fn delete_cipher_selected_post_admin(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    delete_cipher_selected_post(data, headers, conn, nt)\n+}\n+\n+#[put(\"/ciphers/delete-admin\", data = \"<data>\")]\n+fn delete_cipher_selected_put_admin(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    delete_cipher_selected_put(data, headers, conn, nt)\n }\n \n #[put(\"/ciphers/<uuid>/restore\")]\n",
            "comment_added_diff": [
                [
                    20,
                    "    // Note that many routes have an `admin` variant; this seems to be"
                ],
                [
                    21,
                    "    // because the stored procedure that upstream Bitwarden uses to determine"
                ],
                [
                    22,
                    "    // whether the user can edit a cipher doesn't take into account whether"
                ],
                [
                    23,
                    "    // the user is an org owner/admin. The `admin` variant first checks"
                ],
                [
                    24,
                    "    // whether the user is an owner/admin of the relevant org, and if so,"
                ],
                [
                    25,
                    "    // allows the operation unconditionally."
                ],
                [
                    26,
                    "    //"
                ],
                [
                    27,
                    "    // bitwarden_rs factors in the org owner/admin status as part of"
                ],
                [
                    28,
                    "    // determining the write accessibility of a cipher, so most"
                ],
                [
                    29,
                    "    // admin/non-admin implementations can be shared."
                ],
                [
                    878,
                    "    _delete_multiple_ciphers(data, headers, conn, true, nt) // soft delete"
                ]
            ]
        },
        {
            "commit": "a9e9a397d82c9bf7a7bc8aa1413b925f7450a16a",
            "timestamp": "2020-12-07T19:34:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Validate cipher updates with revision date\n\nPrevent clients from updating a cipher if the local copy is stale.\nValidation is only performed when the client provides its last known\nrevision date; this date isn't provided when using older clients,\nor when the operation doesn't involve updating an existing cipher.\n\nUpstream PR: https://github.com/bitwarden/server/pull/994",
            "additions": 21,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,7 @@\n use std::collections::{HashMap, HashSet};\n use std::path::Path;\n \n+use chrono::{NaiveDateTime, Utc};\n use rocket::{http::ContentType, request::Form, Data, Route};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n@@ -194,6 +195,14 @@ pub struct CipherData {\n     #[serde(rename = \"Attachments\")]\n     _Attachments: Option<Value>, // Unused, contains map of {id: filename}\n     Attachments2: Option<HashMap<String, Attachments2Data>>,\n+\n+    // The revision datetime (in ISO 8601 format) of the client's local copy\n+    // of the cipher. This is used to prevent a client from updating a cipher\n+    // when it doesn't have the latest version, as that can result in data\n+    // loss. It's not an error when no value is provided; this can happen\n+    // when using older client versions, or if the operation doesn't involve\n+    // updating an existing cipher.\n+    LastKnownRevisionDate: Option<String>,\n }\n \n #[derive(Deserialize, Debug)]\n@@ -238,6 +247,17 @@ pub fn update_cipher_from_data(\n     nt: &Notify,\n     ut: UpdateType,\n ) -> EmptyResult {\n+    // Check that the client isn't updating an existing cipher with stale data.\n+    if let Some(dt) = data.LastKnownRevisionDate {\n+        match NaiveDateTime::parse_from_str(&dt, \"%+\") { // ISO 8601 format\n+            Err(err) =>\n+                warn!(\"Error parsing LastKnownRevisionDate '{}': {}\", dt, err),\n+            Ok(dt) if cipher.updated_at.signed_duration_since(dt).num_seconds() > 1 =>\n+                err!(\"The client copy of this cipher is out of date. Resync the client and try again.\"),\n+            Ok(_) => (),\n+        }\n+    }\n+\n     if cipher.organization_uuid.is_some() && cipher.organization_uuid != data.OrganizationId {\n         err!(\"Organization mismatch. Please resync the client before updating the cipher\")\n     }\n@@ -1030,7 +1050,7 @@ fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, soft_del\n     }\n \n     if soft_delete {\n-        cipher.deleted_at = Some(chrono::Utc::now().naive_utc());\n+        cipher.deleted_at = Some(Utc::now().naive_utc());\n         cipher.save(&conn)?;\n         nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n     } else {\n",
            "comment_added_diff": [
                [
                    199,
                    "    // The revision datetime (in ISO 8601 format) of the client's local copy"
                ],
                [
                    200,
                    "    // of the cipher. This is used to prevent a client from updating a cipher"
                ],
                [
                    201,
                    "    // when it doesn't have the latest version, as that can result in data"
                ],
                [
                    202,
                    "    // loss. It's not an error when no value is provided; this can happen"
                ],
                [
                    203,
                    "    // when using older client versions, or if the operation doesn't involve"
                ],
                [
                    204,
                    "    // updating an existing cipher."
                ],
                [
                    250,
                    "    // Check that the client isn't updating an existing cipher with stale data."
                ],
                [
                    252,
                    "        match NaiveDateTime::parse_from_str(&dt, \"%+\") { // ISO 8601 format"
                ]
            ]
        },
        {
            "commit": "4e60df7a080872487945039860bc9ca3cb8d3225",
            "timestamp": "2020-12-10T00:17:34-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix stale data check failure when cloning a cipher",
            "additions": 22,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -49,7 +49,7 @@ pub fn routes() -> Vec<Route> {\n         post_cipher_admin,\n         post_cipher_share,\n         put_cipher_share,\n-        put_cipher_share_seleted,\n+        put_cipher_share_selected,\n         post_cipher,\n         put_cipher,\n         delete_cipher_post,\n@@ -212,22 +212,35 @@ pub struct Attachments2Data {\n     Key: String,\n }\n \n+/// Called when an org admin clones an org cipher.\n #[post(\"/ciphers/admin\", data = \"<data>\")]\n fn post_ciphers_admin(data: JsonUpcase<ShareCipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n-    let data: ShareCipherData = data.into_inner().data;\n+    post_ciphers_create(data, headers, conn, nt)\n+}\n+\n+/// Called when creating a new org-owned cipher, or cloning a cipher (whether\n+/// user- or org-owned). When cloning a cipher to a user-owned cipher,\n+/// `organizationId` is null.\n+#[post(\"/ciphers/create\", data = \"<data>\")]\n+fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    let mut data: ShareCipherData = data.into_inner().data;\n \n     let mut cipher = Cipher::new(data.Cipher.Type, data.Cipher.Name.clone());\n     cipher.user_uuid = Some(headers.user.uuid.clone());\n     cipher.save(&conn)?;\n \n-    share_cipher_by_uuid(&cipher.uuid, data, &headers, &conn, &nt)\n-}\n+    // When cloning a cipher, the Bitwarden clients seem to set this field\n+    // based on the cipher being cloned (when creating a new cipher, it's set\n+    // to null as expected). However, `cipher.created_at` is initialized to\n+    // the current time, so the stale data check will end up failing down the\n+    // line. Since this function only creates new ciphers (whether by cloning\n+    // or otherwise), we can just ignore this field entirely.\n+    data.Cipher.LastKnownRevisionDate = None;\n \n-#[post(\"/ciphers/create\", data = \"<data>\")]\n-fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n-    post_ciphers_admin(data, headers, conn, nt)\n+    share_cipher_by_uuid(&cipher.uuid, data, &headers, &conn, &nt)\n }\n \n+/// Called when creating a new user-owned cipher.\n #[post(\"/ciphers\", data = \"<data>\")]\n fn post_ciphers(data: JsonUpcase<CipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     let data: CipherData = data.into_inner().data;\n@@ -407,6 +420,7 @@ fn post_ciphers_import(data: JsonUpcase<ImportData>, headers: Headers, conn: DbC\n     Ok(())\n }\n \n+/// Called when an org admin modifies an existing org cipher.\n #[put(\"/ciphers/<uuid>/admin\", data = \"<data>\")]\n fn put_cipher_admin(\n     uuid: String,\n@@ -581,7 +595,7 @@ struct ShareSelectedCipherData {\n }\n \n #[put(\"/ciphers/share\", data = \"<data>\")]\n-fn put_cipher_share_seleted(\n+fn put_cipher_share_selected(\n     data: JsonUpcase<ShareSelectedCipherData>,\n     headers: Headers,\n     conn: DbConn,\n",
            "comment_added_diff": [
                [
                    215,
                    "/// Called when an org admin clones an org cipher."
                ],
                [
                    221,
                    "/// Called when creating a new org-owned cipher, or cloning a cipher (whether"
                ],
                [
                    222,
                    "/// user- or org-owned). When cloning a cipher to a user-owned cipher,"
                ],
                [
                    223,
                    "/// `organizationId` is null."
                ],
                [
                    232,
                    "    // When cloning a cipher, the Bitwarden clients seem to set this field"
                ],
                [
                    233,
                    "    // based on the cipher being cloned (when creating a new cipher, it's set"
                ],
                [
                    234,
                    "    // to null as expected). However, `cipher.created_at` is initialized to"
                ],
                [
                    235,
                    "    // the current time, so the stale data check will end up failing down the"
                ],
                [
                    236,
                    "    // line. Since this function only creates new ciphers (whether by cloning"
                ],
                [
                    237,
                    "    // or otherwise), we can just ignore this field entirely."
                ],
                [
                    243,
                    "/// Called when creating a new user-owned cipher."
                ],
                [
                    423,
                    "/// Called when an org admin modifies an existing org cipher."
                ]
            ]
        },
        {
            "commit": "9f86196a9d537ce8295add4c4fe682d5565e63fe",
            "timestamp": "2021-01-23T20:50:06-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Personal Ownership policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1013\n* https://bitwarden.com/help/article/policies/#personal-ownership",
            "additions": 39,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -225,6 +225,11 @@ fn post_ciphers_admin(data: JsonUpcase<ShareCipherData>, headers: Headers, conn:\n fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     let mut data: ShareCipherData = data.into_inner().data;\n \n+    // This check is usually only needed in update_cipher_from_data(), but we\n+    // need it here as well to avoid creating an empty cipher in the call to\n+    // cipher.save() below.\n+    enforce_personal_ownership_policy(&data.Cipher, &headers, &conn)?;\n+\n     let mut cipher = Cipher::new(data.Cipher.Type, data.Cipher.Name.clone());\n     cipher.user_uuid = Some(headers.user.uuid.clone());\n     cipher.save(&conn)?;\n@@ -251,6 +256,38 @@ fn post_ciphers(data: JsonUpcase<CipherData>, headers: Headers, conn: DbConn, nt\n     Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n }\n \n+/// Enforces the personal ownership policy on user-owned ciphers, if applicable.\n+/// A non-owner/admin user belonging to an org with the personal ownership policy\n+/// enabled isn't allowed to create new user-owned ciphers or modify existing ones\n+/// (that were created before the policy was applicable to the user). The user is\n+/// allowed to delete or share such ciphers to an org, however.\n+///\n+/// Ref: https://bitwarden.com/help/article/policies/#personal-ownership\n+fn enforce_personal_ownership_policy(\n+    data: &CipherData,\n+    headers: &Headers,\n+    conn: &DbConn\n+) -> EmptyResult {\n+    if data.OrganizationId.is_none() {\n+        let user_uuid = &headers.user.uuid;\n+        for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n+            if policy.enabled && policy.has_type(OrgPolicyType::PersonalOwnership) {\n+                let org_uuid = &policy.org_uuid;\n+                match UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n+                    Some(user) =>\n+                        if user.atype < UserOrgType::Admin &&\n+                           user.has_status(UserOrgStatus::Confirmed) {\n+                            err!(\"Due to an Enterprise Policy, you are restricted \\\n+                                  from saving items to your personal vault.\")\n+                        },\n+                    None => err!(\"Error looking up user type\"),\n+                }\n+            }\n+        }\n+    }\n+    Ok(())\n+}\n+\n pub fn update_cipher_from_data(\n     cipher: &mut Cipher,\n     data: CipherData,\n@@ -260,6 +297,8 @@ pub fn update_cipher_from_data(\n     nt: &Notify,\n     ut: UpdateType,\n ) -> EmptyResult {\n+    enforce_personal_ownership_policy(&data, headers, conn)?;\n+\n     // Check that the client isn't updating an existing cipher with stale data.\n     if let Some(dt) = data.LastKnownRevisionDate {\n         match NaiveDateTime::parse_from_str(&dt, \"%+\") { // ISO 8601 format\n",
            "comment_added_diff": [
                [
                    228,
                    "    // This check is usually only needed in update_cipher_from_data(), but we"
                ],
                [
                    229,
                    "    // need it here as well to avoid creating an empty cipher in the call to"
                ],
                [
                    230,
                    "    // cipher.save() below."
                ],
                [
                    259,
                    "/// Enforces the personal ownership policy on user-owned ciphers, if applicable."
                ],
                [
                    260,
                    "/// A non-owner/admin user belonging to an org with the personal ownership policy"
                ],
                [
                    261,
                    "/// enabled isn't allowed to create new user-owned ciphers or modify existing ones"
                ],
                [
                    262,
                    "/// (that were created before the policy was applicable to the user). The user is"
                ],
                [
                    263,
                    "/// allowed to delete or share such ciphers to an org, however."
                ],
                [
                    264,
                    "///"
                ],
                [
                    265,
                    "/// Ref: https://bitwarden.com/help/article/policies/#personal-ownership"
                ]
            ]
        },
        {
            "commit": "1d4f900e488ad9f38ef5e7639c882d57a0be2dc0",
            "timestamp": "2021-01-24T21:57:32-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add cipher response to restore operations\n\nThis matches changes in the upstream Bitwarden server and clients.\n\nUpstream PR: https://github.com/bitwarden/server/pull/1072",
            "additions": 17,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -967,18 +967,18 @@ fn delete_cipher_selected_put_admin(data: JsonUpcase<Value>, headers: Headers, c\n }\n \n #[put(\"/ciphers/<uuid>/restore\")]\n-fn restore_cipher_put(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+fn restore_cipher_put(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     _restore_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n }\n \n #[put(\"/ciphers/<uuid>/restore-admin\")]\n-fn restore_cipher_put_admin(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+fn restore_cipher_put_admin(uuid: String, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     _restore_cipher_by_uuid(&uuid, &headers, &conn, &nt)\n }\n \n #[put(\"/ciphers/restore\", data = \"<data>\")]\n-fn restore_cipher_selected(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n-    _restore_multiple_ciphers(data, headers, conn, nt)\n+fn restore_cipher_selected(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    _restore_multiple_ciphers(data, &headers, &conn, &nt)\n }\n \n #[derive(Deserialize)]\n@@ -1134,7 +1134,7 @@ fn _delete_multiple_ciphers(data: JsonUpcase<Value>, headers: Headers, conn: DbC\n     Ok(())\n }\n \n-fn _restore_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &Notify) -> EmptyResult {\n+fn _restore_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &Notify) -> JsonResult {\n     let mut cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n         Some(cipher) => cipher,\n         None => err!(\"Cipher doesn't exist\"),\n@@ -1148,10 +1148,10 @@ fn _restore_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &No\n     cipher.save(&conn)?;\n \n     nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n-    Ok(())\n+    Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n }\n \n-fn _restore_multiple_ciphers(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+fn _restore_multiple_ciphers(data: JsonUpcase<Value>, headers: &Headers, conn: &DbConn, nt: &Notify) -> JsonResult {\n     let data: Value = data.into_inner().data;\n \n     let uuids = match data.get(\"Ids\") {\n@@ -1162,13 +1162,19 @@ fn _restore_multiple_ciphers(data: JsonUpcase<Value>, headers: Headers, conn: Db\n         None => err!(\"Request missing ids field\"),\n     };\n \n+    let mut ciphers: Vec<Value> = Vec::new();\n     for uuid in uuids {\n-        if let error @ Err(_) = _restore_cipher_by_uuid(uuid, &headers, &conn, &nt) {\n-            return error;\n-        };\n+        match _restore_cipher_by_uuid(uuid, headers, conn, nt) {\n+            Ok(json) => ciphers.push(json.into_inner()),\n+            err => return err\n+        }\n     }\n \n-    Ok(())\n+    Ok(Json(json!({\n+      \"Data\": ciphers,\n+      \"Object\": \"list\",\n+      \"ContinuationToken\": null\n+    })))\n }\n \n fn _delete_cipher_attachment_by_id(\n",
            "comment_added_diff": []
        },
        {
            "commit": "7dff8c01dd86f69761f4822b8b0c41709f03f271",
            "timestamp": "2021-01-31T21:46:37+01:00",
            "author": "BlackDex",
            "commit_message": "JSON Response updates and small fixes\n\nUpdated several json response models.\nAlso fixed a few small bugs.\n\nciphers.rs:\n  - post_ciphers_create:\n    * Prevent cipher creation to organization without a collection.\n  - update_cipher_from_data:\n    * ~~Fixed removal of user_uuid which prevent user-owned shared-cipher to be not editable anymore when set to read-only.~~\n    * Cleanup the json_data by removing the `Response` key/values from several objects.\n  - delete_all:\n    * Do not delete all Collections during the Purge of an Organization (same as upstream).\n\ncipher.rs:\n  - Cipher::to_json:\n    * Updated json response to match upstream.\n    * Return empty json object if there is no type_data instead of values which should not be set for the type_data.\n\norganizations.rs:\n  * Added two new endpoints to prevent Javascript errors regarding tax\n\norganization.rs:\n  - Organization::to_json:\n    * Updated response model to match upstream\n  - UserOrganization::to_json:\n    * Updated response model to match upstream\n\ncollection.rs:\n  - Collection::{to_json, to_json_details}:\n    * Updated the json response model, and added a detailed version used during the sync\n  - hide_passwords_for_user:\n    * Added this function to return if the passwords should be hidden or not for the user at the specific collection (used by `to_json_details`)\n\nUpdate 1: Some small changes after comments from @jjlin.\nUpdate 2: Fixed vault purge by user to make sure the cipher is not part of an organization.\n\nResolves #971\nCloses #990, Closes #991",
            "additions": 42,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -91,7 +91,9 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let folders_json: Vec<Value> = folders.iter().map(Folder::to_json).collect();\n \n     let collections = Collection::find_by_user_uuid(&headers.user.uuid, &conn);\n-    let collections_json: Vec<Value> = collections.iter().map(Collection::to_json).collect();\n+    let collections_json: Vec<Value> = collections.iter()\n+        .map(|c| c.to_json_details(&headers.user.uuid, &conn))\n+        .collect();\n \n     let policies = OrgPolicy::find_by_user(&headers.user.uuid, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n@@ -225,6 +227,12 @@ fn post_ciphers_admin(data: JsonUpcase<ShareCipherData>, headers: Headers, conn:\n fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     let mut data: ShareCipherData = data.into_inner().data;\n \n+    // Check if there are one more more collections selected when this cipher is part of an organization.\n+    // err if this is not the case before creating an empty cipher.\n+    if  data.Cipher.OrganizationId.is_some() && data.CollectionIds.is_empty() {\n+        err!(\"You must select at least one collection.\");\n+    }\n+\n     // This check is usually only needed in update_cipher_from_data(), but we\n     // need it here as well to avoid creating an empty cipher in the call to\n     // cipher.save() below.\n@@ -323,6 +331,11 @@ pub fn update_cipher_from_data(\n                     || cipher.is_write_accessible_to_user(&headers.user.uuid, &conn)\n                 {\n                     cipher.organization_uuid = Some(org_id);\n+                    // After some discussion in PR #1329 re-added the user_uuid = None again.\n+                    // TODO: Audit/Check the whole save/update cipher chain.\n+                    // Upstream uses the user_uuid to allow a cipher added by a user to an org to still allow the user to view/edit the cipher\n+                    // even when the user has hide-passwords configured as there policy.\n+                    // Removing the line below would fix that, but we have to check which effect this would have on the rest of the code.\n                     cipher.user_uuid = None;\n                 } else {\n                     err!(\"You don't have permission to add cipher directly to organization\")\n@@ -366,6 +379,23 @@ pub fn update_cipher_from_data(\n         }\n     }\n \n+    // Cleanup cipher data, like removing the 'Response' key.\n+    // This key is somewhere generated during Javascript so no way for us this fix this.\n+    // Also, upstream only retrieves keys they actually want to store, and thus skip the 'Response' key.\n+    // We do not mind which data is in it, the keep our model more flexible when there are upstream changes.\n+    // But, we at least know we do not need to store and return this specific key.\n+    fn _clean_cipher_data(mut json_data: Value) -> Value {\n+        if json_data.is_array() {\n+            json_data.as_array_mut()\n+                .unwrap()\n+                .iter_mut()\n+                .for_each(|ref mut f| {\n+                    f.as_object_mut().unwrap().remove(\"Response\");\n+                });\n+        };\n+        json_data\n+    }\n+\n     let type_data_opt = match data.Type {\n         1 => data.Login,\n         2 => data.SecureNote,\n@@ -374,23 +404,22 @@ pub fn update_cipher_from_data(\n         _ => err!(\"Invalid type\"),\n     };\n \n-    let mut type_data = match type_data_opt {\n-        Some(data) => data,\n+    let type_data = match type_data_opt {\n+        Some(mut data) => {\n+            // Remove the 'Response' key from the base object.\n+            data.as_object_mut().unwrap().remove(\"Response\");\n+            // Remove the 'Response' key from every Uri.\n+            if data[\"Uris\"].is_array() {\n+                data[\"Uris\"] = _clean_cipher_data(data[\"Uris\"].clone());\n+            }\n+            data\n+        },\n         None => err!(\"Data missing\"),\n     };\n \n-    // TODO: ******* Backwards compat start **********\n-    // To remove backwards compatibility, just delete this code,\n-    // and remove the compat code from cipher::to_json\n-    type_data[\"Name\"] = Value::String(data.Name.clone());\n-    type_data[\"Notes\"] = data.Notes.clone().map(Value::String).unwrap_or(Value::Null);\n-    type_data[\"Fields\"] = data.Fields.clone().unwrap_or(Value::Null);\n-    type_data[\"PasswordHistory\"] = data.PasswordHistory.clone().unwrap_or(Value::Null);\n-    // TODO: ******* Backwards compat end **********\n-\n     cipher.name = data.Name;\n     cipher.notes = data.Notes;\n-    cipher.fields = data.Fields.map(|f| f.to_string());\n+    cipher.fields = data.Fields.map(|f| _clean_cipher_data(f).to_string() );\n     cipher.data = type_data.to_string();\n     cipher.password_history = data.PasswordHistory.map(|f| f.to_string());\n \n@@ -1064,7 +1093,6 @@ fn delete_all(\n                 Some(user_org) => {\n                     if user_org.atype == UserOrgType::Owner {\n                         Cipher::delete_all_by_organization(&org_data.org_id, &conn)?;\n-                        Collection::delete_all_by_organization(&org_data.org_id, &conn)?;\n                         nt.send_user_update(UpdateType::Vault, &user);\n                         Ok(())\n                     } else {\n",
            "comment_added_diff": [
                [
                    230,
                    "    // Check if there are one more more collections selected when this cipher is part of an organization."
                ],
                [
                    231,
                    "    // err if this is not the case before creating an empty cipher."
                ],
                [
                    334,
                    "                    // After some discussion in PR #1329 re-added the user_uuid = None again."
                ],
                [
                    335,
                    "                    // TODO: Audit/Check the whole save/update cipher chain."
                ],
                [
                    336,
                    "                    // Upstream uses the user_uuid to allow a cipher added by a user to an org to still allow the user to view/edit the cipher"
                ],
                [
                    337,
                    "                    // even when the user has hide-passwords configured as there policy."
                ],
                [
                    338,
                    "                    // Removing the line below would fix that, but we have to check which effect this would have on the rest of the code."
                ],
                [
                    382,
                    "    // Cleanup cipher data, like removing the 'Response' key."
                ],
                [
                    383,
                    "    // This key is somewhere generated during Javascript so no way for us this fix this."
                ],
                [
                    384,
                    "    // Also, upstream only retrieves keys they actually want to store, and thus skip the 'Response' key."
                ],
                [
                    385,
                    "    // We do not mind which data is in it, the keep our model more flexible when there are upstream changes."
                ],
                [
                    386,
                    "    // But, we at least know we do not need to store and return this specific key."
                ],
                [
                    409,
                    "            // Remove the 'Response' key from the base object."
                ],
                [
                    411,
                    "            // Remove the 'Response' key from every Uri."
                ]
            ]
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 7,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -104,6 +104,12 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n         .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n         .collect();\n \n+    let sends = Send::find_by_user(&headers.user.uuid, &conn);\n+    let sends_json: Vec<Value> = sends\n+        .iter()\n+        .map(|s| s.to_json())\n+        .collect();\n+\n     let domains_json = if data.exclude_domains {\n         Value::Null\n     } else {\n@@ -117,6 +123,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n         \"Policies\": policies_json,\n         \"Ciphers\": ciphers_json,\n         \"Domains\": domains_json,\n+        \"Sends\": sends_json,\n         \"Object\": \"sync\"\n     })))\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "424d666a505c3e41bc1e77937a682e120e130423",
            "timestamp": "2021-03-16T02:07:45-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Disable Send policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1130\n* https://bitwarden.com/help/article/policies/#disable-send",
            "additions": 4,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -285,19 +285,10 @@ fn enforce_personal_ownership_policy(\n ) -> EmptyResult {\n     if data.OrganizationId.is_none() {\n         let user_uuid = &headers.user.uuid;\n-        for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n-            if policy.enabled && policy.has_type(OrgPolicyType::PersonalOwnership) {\n-                let org_uuid = &policy.org_uuid;\n-                match UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n-                    Some(user) =>\n-                        if user.atype < UserOrgType::Admin &&\n-                           user.has_status(UserOrgStatus::Confirmed) {\n-                            err!(\"Due to an Enterprise Policy, you are restricted \\\n-                                  from saving items to your personal vault.\")\n-                        },\n-                    None => err!(\"Error looking up user type\"),\n-                }\n-            }\n+        let policy_type = OrgPolicyType::PersonalOwnership;\n+        if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n+            err!(\"Due to an Enterprise Policy, you are restricted from \\\n+                  saving items to your personal vault.\")\n         }\n     }\n     Ok(())\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -84,7 +84,7 @@ struct SyncData {\n }\n \n #[get(\"/sync?<data..>\")]\n-fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n+fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n     let user_json = headers.user.to_json(&conn);\n \n     let folders = Folder::find_by_user(&headers.user.uuid, &conn);\n@@ -113,10 +113,10 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n     let domains_json = if data.exclude_domains {\n         Value::Null\n     } else {\n-        api::core::_get_eq_domains(headers, true).unwrap().into_inner()\n+        api::core::_get_eq_domains(headers, true).into_inner()\n     };\n \n-    Ok(Json(json!({\n+    Json(json!({\n         \"Profile\": user_json,\n         \"Folders\": folders_json,\n         \"Collections\": collections_json,\n@@ -125,11 +125,11 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> JsonResult {\n         \"Domains\": domains_json,\n         \"Sends\": sends_json,\n         \"Object\": \"sync\"\n-    })))\n+    }))\n }\n \n #[get(\"/ciphers\")]\n-fn get_ciphers(headers: Headers, conn: DbConn) -> JsonResult {\n+fn get_ciphers(headers: Headers, conn: DbConn) -> Json<Value> {\n     let ciphers = Cipher::find_by_user_visible(&headers.user.uuid, &conn);\n \n     let ciphers_json: Vec<Value> = ciphers\n@@ -137,11 +137,11 @@ fn get_ciphers(headers: Headers, conn: DbConn) -> JsonResult {\n         .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n         .collect();\n \n-    Ok(Json(json!({\n+    Json(json!({\n       \"Data\": ciphers_json,\n       \"Object\": \"list\",\n       \"ContinuationToken\": null\n-    })))\n+    }))\n }\n \n #[get(\"/ciphers/<uuid>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 52,
            "deletions": 32,
            "change_type": "MODIFY",
            "diff": "@@ -91,7 +91,8 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n     let folders_json: Vec<Value> = folders.iter().map(Folder::to_json).collect();\n \n     let collections = Collection::find_by_user_uuid(&headers.user.uuid, &conn);\n-    let collections_json: Vec<Value> = collections.iter()\n+    let collections_json: Vec<Value> = collections\n+        .iter()\n         .map(|c| c.to_json_details(&headers.user.uuid, &conn))\n         .collect();\n \n@@ -105,10 +106,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n         .collect();\n \n     let sends = Send::find_by_user(&headers.user.uuid, &conn);\n-    let sends_json: Vec<Value> = sends\n-        .iter()\n-        .map(|s| s.to_json())\n-        .collect();\n+    let sends_json: Vec<Value> = sends.iter().map(|s| s.to_json()).collect();\n \n     let domains_json = if data.exclude_domains {\n         Value::Null\n@@ -236,7 +234,7 @@ fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn\n \n     // Check if there are one more more collections selected when this cipher is part of an organization.\n     // err if this is not the case before creating an empty cipher.\n-    if  data.Cipher.OrganizationId.is_some() && data.CollectionIds.is_empty() {\n+    if data.Cipher.OrganizationId.is_some() && data.CollectionIds.is_empty() {\n         err!(\"You must select at least one collection.\");\n     }\n \n@@ -278,17 +276,15 @@ fn post_ciphers(data: JsonUpcase<CipherData>, headers: Headers, conn: DbConn, nt\n /// allowed to delete or share such ciphers to an org, however.\n ///\n /// Ref: https://bitwarden.com/help/article/policies/#personal-ownership\n-fn enforce_personal_ownership_policy(\n-    data: &CipherData,\n-    headers: &Headers,\n-    conn: &DbConn\n-) -> EmptyResult {\n+fn enforce_personal_ownership_policy(data: &CipherData, headers: &Headers, conn: &DbConn) -> EmptyResult {\n     if data.OrganizationId.is_none() {\n         let user_uuid = &headers.user.uuid;\n         let policy_type = OrgPolicyType::PersonalOwnership;\n         if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n-            err!(\"Due to an Enterprise Policy, you are restricted from \\\n-                  saving items to your personal vault.\")\n+            err!(\n+                \"Due to an Enterprise Policy, you are restricted from \\\n+                  saving items to your personal vault.\"\n+            )\n         }\n     }\n     Ok(())\n@@ -307,11 +303,12 @@ pub fn update_cipher_from_data(\n \n     // Check that the client isn't updating an existing cipher with stale data.\n     if let Some(dt) = data.LastKnownRevisionDate {\n-        match NaiveDateTime::parse_from_str(&dt, \"%+\") { // ISO 8601 format\n-            Err(err) =>\n-                warn!(\"Error parsing LastKnownRevisionDate '{}': {}\", dt, err),\n-            Ok(dt) if cipher.updated_at.signed_duration_since(dt).num_seconds() > 1 =>\n-                err!(\"The client copy of this cipher is out of date. Resync the client and try again.\"),\n+        match NaiveDateTime::parse_from_str(&dt, \"%+\") {\n+            // ISO 8601 format\n+            Err(err) => warn!(\"Error parsing LastKnownRevisionDate '{}': {}\", dt, err),\n+            Ok(dt) if cipher.updated_at.signed_duration_since(dt).num_seconds() > 1 => {\n+                err!(\"The client copy of this cipher is out of date. Resync the client and try again.\")\n+            }\n             Ok(_) => (),\n         }\n     }\n@@ -384,12 +381,9 @@ pub fn update_cipher_from_data(\n     // But, we at least know we do not need to store and return this specific key.\n     fn _clean_cipher_data(mut json_data: Value) -> Value {\n         if json_data.is_array() {\n-            json_data.as_array_mut()\n-                .unwrap()\n-                .iter_mut()\n-                .for_each(|ref mut f| {\n-                    f.as_object_mut().unwrap().remove(\"Response\");\n-                });\n+            json_data.as_array_mut().unwrap().iter_mut().for_each(|ref mut f| {\n+                f.as_object_mut().unwrap().remove(\"Response\");\n+            });\n         };\n         json_data\n     }\n@@ -411,13 +405,13 @@ pub fn update_cipher_from_data(\n                 data[\"Uris\"] = _clean_cipher_data(data[\"Uris\"].clone());\n             }\n             data\n-        },\n+        }\n         None => err!(\"Data missing\"),\n     };\n \n     cipher.name = data.Name;\n     cipher.notes = data.Notes;\n-    cipher.fields = data.Fields.map(|f| _clean_cipher_data(f).to_string() );\n+    cipher.fields = data.Fields.map(|f| _clean_cipher_data(f).to_string());\n     cipher.data = type_data.to_string();\n     cipher.password_history = data.PasswordHistory.map(|f| f.to_string());\n \n@@ -832,7 +826,13 @@ fn post_attachment(\n                     let file_name = HEXLOWER.encode(&crypto::get_random(vec![0; 10]));\n                     let path = base_path.join(&file_name);\n \n-                    let size = match field.data.save().memory_threshold(0).size_limit(size_limit).with_path(path.clone()) {\n+                    let size = match field\n+                        .data\n+                        .save()\n+                        .memory_threshold(0)\n+                        .size_limit(size_limit)\n+                        .with_path(path.clone())\n+                    {\n                         SaveResult::Full(SavedData::File(_, size)) => size as i32,\n                         SaveResult::Full(other) => {\n                             std::fs::remove_file(path).ok();\n@@ -881,7 +881,11 @@ fn post_attachment_admin(\n     post_attachment(uuid, data, content_type, headers, conn, nt)\n }\n \n-#[post(\"/ciphers/<uuid>/attachment/<attachment_id>/share\", format = \"multipart/form-data\", data = \"<data>\")]\n+#[post(\n+    \"/ciphers/<uuid>/attachment/<attachment_id>/share\",\n+    format = \"multipart/form-data\",\n+    data = \"<data>\"\n+)]\n fn post_attachment_share(\n     uuid: String,\n     attachment_id: String,\n@@ -984,12 +988,22 @@ fn delete_cipher_selected_admin(data: JsonUpcase<Value>, headers: Headers, conn:\n }\n \n #[post(\"/ciphers/delete-admin\", data = \"<data>\")]\n-fn delete_cipher_selected_post_admin(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+fn delete_cipher_selected_post_admin(\n+    data: JsonUpcase<Value>,\n+    headers: Headers,\n+    conn: DbConn,\n+    nt: Notify,\n+) -> EmptyResult {\n     delete_cipher_selected_post(data, headers, conn, nt)\n }\n \n #[put(\"/ciphers/delete-admin\", data = \"<data>\")]\n-fn delete_cipher_selected_put_admin(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+fn delete_cipher_selected_put_admin(\n+    data: JsonUpcase<Value>,\n+    headers: Headers,\n+    conn: DbConn,\n+    nt: Notify,\n+) -> EmptyResult {\n     delete_cipher_selected_put(data, headers, conn, nt)\n }\n \n@@ -1140,7 +1154,13 @@ fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, soft_del\n     Ok(())\n }\n \n-fn _delete_multiple_ciphers(data: JsonUpcase<Value>, headers: Headers, conn: DbConn, soft_delete: bool, nt: Notify) -> EmptyResult {\n+fn _delete_multiple_ciphers(\n+    data: JsonUpcase<Value>,\n+    headers: Headers,\n+    conn: DbConn,\n+    soft_delete: bool,\n+    nt: Notify,\n+) -> EmptyResult {\n     let data: Value = data.into_inner().data;\n \n     let uuids = match data.get(\"Ids\") {\n@@ -1192,7 +1212,7 @@ fn _restore_multiple_ciphers(data: JsonUpcase<Value>, headers: &Headers, conn: &\n     for uuid in uuids {\n         match _restore_cipher_by_uuid(uuid, headers, conn, nt) {\n             Ok(json) => ciphers.push(json.into_inner()),\n-            err => return err\n+            err => return err,\n         }\n     }\n \n",
            "comment_added_diff": [
                [
                    307,
                    "            // ISO 8601 format"
                ]
            ]
        },
        {
            "commit": "93c881a7a9abf30c1d2cfea961d5637de2757b86",
            "timestamp": "2021-03-31T21:45:05+01:00",
            "author": "Jake Howard",
            "commit_message": "Reflow some lines manually",
            "additions": 1,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -281,10 +281,7 @@ fn enforce_personal_ownership_policy(data: &CipherData, headers: &Headers, conn:\n         let user_uuid = &headers.user.uuid;\n         let policy_type = OrgPolicyType::PersonalOwnership;\n         if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n-            err!(\n-                \"Due to an Enterprise Policy, you are restricted from \\\n-                  saving items to your personal vault.\"\n-            )\n+            err!(\"Due to an Enterprise Policy, you are restricted from saving items to your personal vault.\")\n         }\n     }\n     Ok(())\n",
            "comment_added_diff": []
        },
        {
            "commit": "d77333576b1268cd24f17348ffe6d72e07855f54",
            "timestamp": "2021-04-05T23:07:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for auto-deleting trashed items\n\nUpstream will soon auto-delete trashed items after 30 days, but some people\nuse the trash as an archive folder, so to avoid unexpected data loss, this\nimplementation requires the user to explicitly enable auto-deletion.",
            "additions": 10,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -13,7 +13,7 @@ use crate::{\n     api::{self, EmptyResult, JsonResult, JsonUpcase, Notify, PasswordData, UpdateType},\n     auth::Headers,\n     crypto,\n-    db::{models::*, DbConn},\n+    db::{models::*, DbConn, DbPool},\n     CONFIG,\n };\n \n@@ -77,6 +77,15 @@ pub fn routes() -> Vec<Route> {\n     ]\n }\n \n+pub fn purge_trashed_ciphers(pool: DbPool) {\n+    debug!(\"Purging trashed ciphers\");\n+    if let Ok(conn) = pool.get() {\n+        Cipher::purge_trash(&conn);\n+    } else {\n+        error!(\"Failed to get DB connection while purging trashed ciphers\")\n+    }\n+}\n+\n #[derive(FromForm, Default)]\n struct SyncData {\n     #[form(field = \"excludeDomains\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "b268c3dd1cfda78f113cc5c3bf06e08324590379",
            "timestamp": "2021-04-06T20:38:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update web vault and add unnoficialserver response",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -133,6 +133,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n         \"Ciphers\": ciphers_json,\n         \"Domains\": domains_json,\n         \"Sends\": sends_json,\n+        \"unofficialServer\": true,\n         \"Object\": \"sync\"\n     }))\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 28,
            "deletions": 46,
            "change_type": "MODIFY",
            "diff": "@@ -91,19 +91,15 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n     let folders_json: Vec<Value> = folders.iter().map(Folder::to_json).collect();\n \n     let collections = Collection::find_by_user_uuid(&headers.user.uuid, &conn);\n-    let collections_json: Vec<Value> = collections\n-        .iter()\n-        .map(|c| c.to_json_details(&headers.user.uuid, &conn))\n-        .collect();\n+    let collections_json: Vec<Value> =\n+        collections.iter().map(|c| c.to_json_details(&headers.user.uuid, &conn)).collect();\n \n     let policies = OrgPolicy::find_by_user(&headers.user.uuid, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n \n     let ciphers = Cipher::find_by_user_visible(&headers.user.uuid, &conn);\n-    let ciphers_json: Vec<Value> = ciphers\n-        .iter()\n-        .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n-        .collect();\n+    let ciphers_json: Vec<Value> =\n+        ciphers.iter().map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn)).collect();\n \n     let sends = Send::find_by_user(&headers.user.uuid, &conn);\n     let sends_json: Vec<Value> = sends.iter().map(|s| s.to_json()).collect();\n@@ -130,10 +126,8 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n fn get_ciphers(headers: Headers, conn: DbConn) -> Json<Value> {\n     let ciphers = Cipher::find_by_user_visible(&headers.user.uuid, &conn);\n \n-    let ciphers_json: Vec<Value> = ciphers\n-        .iter()\n-        .map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn))\n-        .collect();\n+    let ciphers_json: Vec<Value> =\n+        ciphers.iter().map(|c| c.to_json(&headers.host, &headers.user.uuid, &conn)).collect();\n \n     Json(json!({\n       \"Data\": ciphers_json,\n@@ -583,11 +577,8 @@ fn post_collections_admin(\n     }\n \n     let posted_collections: HashSet<String> = data.CollectionIds.iter().cloned().collect();\n-    let current_collections: HashSet<String> = cipher\n-        .get_collections(&headers.user.uuid, &conn)\n-        .iter()\n-        .cloned()\n-        .collect();\n+    let current_collections: HashSet<String> =\n+        cipher.get_collections(&headers.user.uuid, &conn).iter().cloned().collect();\n \n     for collection in posted_collections.symmetric_difference(&current_collections) {\n         match Collection::find_by_uuid(&collection, &conn) {\n@@ -823,30 +814,25 @@ fn post_attachment(\n                     let file_name = HEXLOWER.encode(&crypto::get_random(vec![0; 10]));\n                     let path = base_path.join(&file_name);\n \n-                    let size = match field\n-                        .data\n-                        .save()\n-                        .memory_threshold(0)\n-                        .size_limit(size_limit)\n-                        .with_path(path.clone())\n-                    {\n-                        SaveResult::Full(SavedData::File(_, size)) => size as i32,\n-                        SaveResult::Full(other) => {\n-                            std::fs::remove_file(path).ok();\n-                            error = Some(format!(\"Attachment is not a file: {:?}\", other));\n-                            return;\n-                        }\n-                        SaveResult::Partial(_, reason) => {\n-                            std::fs::remove_file(path).ok();\n-                            error = Some(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n-                            return;\n-                        }\n-                        SaveResult::Error(e) => {\n-                            std::fs::remove_file(path).ok();\n-                            error = Some(format!(\"Error: {:?}\", e));\n-                            return;\n-                        }\n-                    };\n+                    let size =\n+                        match field.data.save().memory_threshold(0).size_limit(size_limit).with_path(path.clone()) {\n+                            SaveResult::Full(SavedData::File(_, size)) => size as i32,\n+                            SaveResult::Full(other) => {\n+                                std::fs::remove_file(path).ok();\n+                                error = Some(format!(\"Attachment is not a file: {:?}\", other));\n+                                return;\n+                            }\n+                            SaveResult::Partial(_, reason) => {\n+                                std::fs::remove_file(path).ok();\n+                                error = Some(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n+                                return;\n+                            }\n+                            SaveResult::Error(e) => {\n+                                std::fs::remove_file(path).ok();\n+                                error = Some(format!(\"Error: {:?}\", e));\n+                                return;\n+                            }\n+                        };\n \n                     let mut attachment = Attachment::new(file_name, cipher.uuid.clone(), name, size);\n                     attachment.akey = attachment_key.clone();\n@@ -878,11 +864,7 @@ fn post_attachment_admin(\n     post_attachment(uuid, data, content_type, headers, conn, nt)\n }\n \n-#[post(\n-    \"/ciphers/<uuid>/attachment/<attachment_id>/share\",\n-    format = \"multipart/form-data\",\n-    data = \"<data>\"\n-)]\n+#[post(\"/ciphers/<uuid>/attachment/<attachment_id>/share\", format = \"multipart/form-data\", data = \"<data>\")]\n fn post_attachment_share(\n     uuid: String,\n     attachment_id: String,\n",
            "comment_added_diff": []
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -25,7 +25,7 @@ pub fn routes() -> Vec<Route> {\n     // whether the user is an owner/admin of the relevant org, and if so,\n     // allows the operation unconditionally.\n     //\n-    // bitwarden_rs factors in the org owner/admin status as part of\n+    // vaultwarden factors in the org owner/admin status as part of\n     // determining the write accessibility of a cipher, so most\n     // admin/non-admin implementations can be shared.\n     routes![\n",
            "comment_added_diff": [
                [
                    28,
                    "    // vaultwarden factors in the org owner/admin status as part of"
                ]
            ]
        },
        {
            "commit": "a9a5706764a98fbcda1bc6ac2e0ef5f78ea6c202",
            "timestamp": "2021-05-11T20:09:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for password reprompt\n\nUpstream PR: https://github.com/bitwarden/server/pull/1269",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -199,6 +199,7 @@ pub struct CipherData {\n     Identity: Option<Value>,\n \n     Favorite: Option<bool>,\n+    Reprompt: Option<i32>,\n \n     PasswordHistory: Option<Value>,\n \n@@ -415,6 +416,7 @@ pub fn update_cipher_from_data(\n     cipher.fields = data.Fields.map(|f| _clean_cipher_data(f).to_string());\n     cipher.data = type_data.to_string();\n     cipher.password_history = data.PasswordHistory.map(|f| f.to_string());\n+    cipher.reprompt = data.Reprompt;\n \n     cipher.save(&conn)?;\n     cipher.move_to_folder(data.FolderId, &headers.user.uuid, &conn)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "9133e2927d3189804431aa013bff2cf14fc812fb",
            "timestamp": "2021-05-15T22:46:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix attachment downloads\n\nUpstream switched to new upload/download APIs. Uploads fall back to the\nlegacy APIs for now, but not downloads apparently.",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -39,6 +39,7 @@ pub fn routes() -> Vec<Route> {\n         post_ciphers_admin,\n         post_ciphers_create,\n         post_ciphers_import,\n+        get_attachment,\n         post_attachment,\n         post_attachment_admin,\n         post_attachment_share,\n@@ -754,6 +755,15 @@ fn share_cipher_by_uuid(\n     Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n }\n \n+#[get(\"/ciphers/<uuid>/attachment/<attachment_id>\")]\n+fn get_attachment(uuid: String, attachment_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    match Attachment::find_by_id(&attachment_id, &conn) {\n+        Some(attachment) if uuid == attachment.cipher_uuid => Ok(Json(attachment.to_json(&headers.host))),\n+        Some(_) => err!(\"Attachment doesn't belong to cipher\"),\n+        None => err!(\"Attachment doesn't exist\"),\n+    }\n+}\n+\n #[post(\"/ciphers/<uuid>/attachment\", format = \"multipart/form-data\", data = \"<data>\")]\n fn post_attachment(\n     uuid: String,\n",
            "comment_added_diff": []
        },
        {
            "commit": "29ed82a3595e0cdd39deb914dc38002478f89f97",
            "timestamp": "2021-05-25T04:14:51-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for v2 attachment upload APIs\n\nUpstream PR: https://github.com/bitwarden/server/pull/1229",
            "additions": 185,
            "deletions": 21,
            "change_type": "MODIFY",
            "diff": "@@ -6,7 +6,6 @@ use rocket::{http::ContentType, request::Form, Data, Route};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n-use data_encoding::HEXLOWER;\n use multipart::server::{save::SavedData, Multipart, SaveResult};\n \n use crate::{\n@@ -40,8 +39,10 @@ pub fn routes() -> Vec<Route> {\n         post_ciphers_create,\n         post_ciphers_import,\n         get_attachment,\n-        post_attachment,\n-        post_attachment_admin,\n+        post_attachment_v2,\n+        post_attachment_v2_data,\n+        post_attachment,       // legacy\n+        post_attachment_admin, // legacy\n         post_attachment_share,\n         delete_attachment_post,\n         delete_attachment_post_admin,\n@@ -755,6 +756,12 @@ fn share_cipher_by_uuid(\n     Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n }\n \n+/// v2 API for downloading an attachment. This just redirects the client to\n+/// the actual location of an attachment.\n+///\n+/// Upstream added this v2 API to support direct download of attachments from\n+/// their object storage service. For self-hosted instances, it basically just\n+/// redirects to the same location as before the v2 API.\n #[get(\"/ciphers/<uuid>/attachment/<attachment_id>\")]\n fn get_attachment(uuid: String, attachment_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n     match Attachment::find_by_id(&attachment_id, &conn) {\n@@ -764,16 +771,79 @@ fn get_attachment(uuid: String, attachment_id: String, headers: Headers, conn: D\n     }\n }\n \n-#[post(\"/ciphers/<uuid>/attachment\", format = \"multipart/form-data\", data = \"<data>\")]\n-fn post_attachment(\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct AttachmentRequestData {\n+    Key: String,\n+    FileName: String,\n+    FileSize: i32,\n+    // We check org owner/admin status via is_write_accessible_to_user(),\n+    // so we can just ignore this field.\n+    //\n+    // AdminRequest: bool,\n+}\n+\n+enum FileUploadType {\n+    Direct = 0,\n+    // Azure = 1, // only used upstream\n+}\n+\n+/// v2 API for creating an attachment associated with a cipher.\n+/// This redirects the client to the API it should use to upload the attachment.\n+/// For upstream's cloud-hosted service, it's an Azure object storage API.\n+/// For self-hosted instances, it's another API on the local instance.\n+#[post(\"/ciphers/<uuid>/attachment/v2\", data = \"<data>\")]\n+fn post_attachment_v2(\n     uuid: String,\n-    data: Data,\n-    content_type: &ContentType,\n+    data: JsonUpcase<AttachmentRequestData>,\n     headers: Headers,\n     conn: DbConn,\n-    nt: Notify,\n ) -> JsonResult {\n     let cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+        Some(cipher) => cipher,\n+        None => err!(\"Cipher doesn't exist\"),\n+    };\n+\n+    if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+        err!(\"Cipher is not write accessible\")\n+    }\n+\n+    let attachment_id = crypto::generate_file_id();\n+    let data: AttachmentRequestData = data.into_inner().data;\n+    let attachment =\n+        Attachment::new(attachment_id.clone(), cipher.uuid.clone(), data.FileName, data.FileSize, Some(data.Key));\n+    attachment.save(&conn).expect(\"Error saving attachment\");\n+\n+    let url = format!(\"/ciphers/{}/attachment/{}\", cipher.uuid, attachment_id);\n+\n+    Ok(Json(json!({ // AttachmentUploadDataResponseModel\n+        \"Object\": \"attachment-fileUpload\",\n+        \"AttachmentId\": attachment_id,\n+        \"Url\": url,\n+        \"FileUploadType\": FileUploadType::Direct as i32,\n+        \"CipherResponse\": cipher.to_json(&headers.host, &headers.user.uuid, &conn),\n+        \"CipherMiniResponse\": null,\n+    })))\n+}\n+\n+/// Saves the data content of an attachment to a file. This is common code\n+/// shared between the v2 and legacy attachment APIs.\n+///\n+/// When used with the legacy API, this function is responsible for creating\n+/// the attachment database record, so `attachment` is None.\n+///\n+/// When used with the v2 API, post_attachment_v2() has already created the\n+/// database record, which is passed in as `attachment`.\n+fn save_attachment(\n+    mut attachment: Option<Attachment>,\n+    cipher_uuid: String,\n+    data: Data,\n+    content_type: &ContentType,\n+    headers: &Headers,\n+    conn: &DbConn,\n+    nt: Notify,\n+) -> Result<Cipher, crate::error::Error> {\n+    let cipher = match Cipher::find_by_uuid(&cipher_uuid, conn) {\n         Some(cipher) => cipher,\n         None => err_discard!(\"Cipher doesn't exist\", data),\n     };\n@@ -782,10 +852,6 @@ fn post_attachment(\n         err_discard!(\"Cipher is not write accessible\", data)\n     }\n \n-    let mut params = content_type.params();\n-    let boundary_pair = params.next().expect(\"No boundary provided\");\n-    let boundary = boundary_pair.1;\n-\n     let size_limit = if let Some(ref user_uuid) = cipher.user_uuid {\n         match CONFIG.user_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n@@ -814,7 +880,11 @@ fn post_attachment(\n         err_discard!(\"Cipher is neither owned by a user nor an organization\", data);\n     };\n \n-    let base_path = Path::new(&CONFIG.attachments_folder()).join(&cipher.uuid);\n+    let mut params = content_type.params();\n+    let boundary_pair = params.next().expect(\"No boundary provided\");\n+    let boundary = boundary_pair.1;\n+\n+    let base_path = Path::new(&CONFIG.attachments_folder()).join(&cipher_uuid);\n \n     let mut attachment_key = None;\n     let mut error = None;\n@@ -830,11 +900,20 @@ fn post_attachment(\n                     }\n                 }\n                 \"data\" => {\n-                    // This is provided by the client, don't trust it\n-                    let name = field.headers.filename.expect(\"No filename provided\");\n-\n-                    let file_name = HEXLOWER.encode(&crypto::get_random(vec![0; 10]));\n-                    let path = base_path.join(&file_name);\n+                    // In the legacy API, this is the encrypted filename\n+                    // provided by the client, stored to the database as-is.\n+                    // In the v2 API, this value doesn't matter, as it was\n+                    // already provided and stored via an earlier API call.\n+                    let encrypted_filename = field.headers.filename;\n+\n+                    // This random ID is used as the name of the file on disk.\n+                    // In the legacy API, we need to generate this value here.\n+                    // In the v2 API, we use the value from post_attachment_v2().\n+                    let file_id = match &attachment {\n+                        Some(attachment) => attachment.id.clone(), // v2 API\n+                        None => crypto::generate_file_id(),        // Legacy API\n+                    };\n+                    let path = base_path.join(&file_id);\n \n                     let size =\n                         match field.data.save().memory_threshold(0).size_limit(size_limit).with_path(path.clone()) {\n@@ -856,9 +935,50 @@ fn post_attachment(\n                             }\n                         };\n \n-                    let mut attachment = Attachment::new(file_name, cipher.uuid.clone(), name, size);\n-                    attachment.akey = attachment_key.clone();\n-                    attachment.save(&conn).expect(\"Error saving attachment\");\n+                    if let Some(attachment) = &mut attachment {\n+                        // v2 API\n+\n+                        // Check the actual size against the size initially provided by\n+                        // the client. Upstream allows +/- 1 MiB deviation from this\n+                        // size, but it's not clear when or why this is needed.\n+                        const LEEWAY: i32 = 1024 * 1024; // 1 MiB\n+                        let min_size = attachment.file_size - LEEWAY;\n+                        let max_size = attachment.file_size + LEEWAY;\n+\n+                        if min_size <= size && size <= max_size {\n+                            if size != attachment.file_size {\n+                                // Update the attachment with the actual file size.\n+                                attachment.file_size = size;\n+                                attachment.save(conn).expect(\"Error updating attachment\");\n+                            }\n+                        } else {\n+                            std::fs::remove_file(path).ok();\n+                            attachment.delete(conn).ok();\n+\n+                            let err_msg = \"Attachment size mismatch\".to_string();\n+                            error!(\"{} (expected within [{}, {}], got {})\", err_msg, min_size, max_size, size);\n+                            error = Some(err_msg);\n+                        }\n+                    } else {\n+                        // Legacy API\n+\n+                        if encrypted_filename.is_none() {\n+                            error = Some(\"No filename provided\".to_string());\n+                            return;\n+                        }\n+                        if attachment_key.is_none() {\n+                            error = Some(\"No attachment key provided\".to_string());\n+                            return;\n+                        }\n+                        let attachment = Attachment::new(\n+                            file_id,\n+                            cipher_uuid.clone(),\n+                            encrypted_filename.unwrap(),\n+                            size,\n+                            attachment_key.clone(),\n+                        );\n+                        attachment.save(conn).expect(\"Error saving attachment\");\n+                    }\n                 }\n                 _ => error!(\"Invalid multipart name\"),\n             }\n@@ -871,6 +991,50 @@ fn post_attachment(\n \n     nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n \n+    Ok(cipher)\n+}\n+\n+/// v2 API for uploading the actual data content of an attachment.\n+/// This route needs a rank specified so that Rocket prioritizes the\n+/// /ciphers/<uuid>/attachment/v2 route, which would otherwise conflict\n+/// with this one.\n+#[post(\"/ciphers/<uuid>/attachment/<attachment_id>\", format = \"multipart/form-data\", data = \"<data>\", rank = 1)]\n+fn post_attachment_v2_data(\n+    uuid: String,\n+    attachment_id: String,\n+    data: Data,\n+    content_type: &ContentType,\n+    headers: Headers,\n+    conn: DbConn,\n+    nt: Notify,\n+) -> EmptyResult {\n+    let attachment = match Attachment::find_by_id(&attachment_id, &conn) {\n+        Some(attachment) if uuid == attachment.cipher_uuid => Some(attachment),\n+        Some(_) => err!(\"Attachment doesn't belong to cipher\"),\n+        None => err!(\"Attachment doesn't exist\"),\n+    };\n+\n+    save_attachment(attachment, uuid, data, content_type, &headers, &conn, nt)?;\n+\n+    Ok(())\n+}\n+\n+/// Legacy API for creating an attachment associated with a cipher.\n+#[post(\"/ciphers/<uuid>/attachment\", format = \"multipart/form-data\", data = \"<data>\")]\n+fn post_attachment(\n+    uuid: String,\n+    data: Data,\n+    content_type: &ContentType,\n+    headers: Headers,\n+    conn: DbConn,\n+    nt: Notify,\n+) -> JsonResult {\n+    // Setting this as None signifies to save_attachment() that it should create\n+    // the attachment database record as well as saving the data to disk.\n+    let attachment = None;\n+\n+    let cipher = save_attachment(attachment, uuid, data, content_type, &headers, &conn, nt)?;\n+\n     Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n }\n \n",
            "comment_added_diff": [
                [
                    44,
                    "        post_attachment,       // legacy"
                ],
                [
                    45,
                    "        post_attachment_admin, // legacy"
                ],
                [
                    759,
                    "/// v2 API for downloading an attachment. This just redirects the client to"
                ],
                [
                    760,
                    "/// the actual location of an attachment."
                ],
                [
                    761,
                    "///"
                ],
                [
                    762,
                    "/// Upstream added this v2 API to support direct download of attachments from"
                ],
                [
                    763,
                    "/// their object storage service. For self-hosted instances, it basically just"
                ],
                [
                    764,
                    "/// redirects to the same location as before the v2 API."
                ],
                [
                    780,
                    "    // We check org owner/admin status via is_write_accessible_to_user(),"
                ],
                [
                    781,
                    "    // so we can just ignore this field."
                ],
                [
                    782,
                    "    //"
                ],
                [
                    783,
                    "    // AdminRequest: bool,"
                ],
                [
                    788,
                    "    // Azure = 1, // only used upstream"
                ],
                [
                    791,
                    "/// v2 API for creating an attachment associated with a cipher."
                ],
                [
                    792,
                    "/// This redirects the client to the API it should use to upload the attachment."
                ],
                [
                    793,
                    "/// For upstream's cloud-hosted service, it's an Azure object storage API."
                ],
                [
                    794,
                    "/// For self-hosted instances, it's another API on the local instance."
                ],
                [
                    819,
                    "    Ok(Json(json!({ // AttachmentUploadDataResponseModel"
                ],
                [
                    829,
                    "/// Saves the data content of an attachment to a file. This is common code"
                ],
                [
                    830,
                    "/// shared between the v2 and legacy attachment APIs."
                ],
                [
                    831,
                    "///"
                ],
                [
                    832,
                    "/// When used with the legacy API, this function is responsible for creating"
                ],
                [
                    833,
                    "/// the attachment database record, so `attachment` is None."
                ],
                [
                    834,
                    "///"
                ],
                [
                    835,
                    "/// When used with the v2 API, post_attachment_v2() has already created the"
                ],
                [
                    836,
                    "/// database record, which is passed in as `attachment`."
                ],
                [
                    903,
                    "                    // In the legacy API, this is the encrypted filename"
                ],
                [
                    904,
                    "                    // provided by the client, stored to the database as-is."
                ],
                [
                    905,
                    "                    // In the v2 API, this value doesn't matter, as it was"
                ],
                [
                    906,
                    "                    // already provided and stored via an earlier API call."
                ],
                [
                    909,
                    "                    // This random ID is used as the name of the file on disk."
                ],
                [
                    910,
                    "                    // In the legacy API, we need to generate this value here."
                ],
                [
                    911,
                    "                    // In the v2 API, we use the value from post_attachment_v2()."
                ],
                [
                    913,
                    "                        Some(attachment) => attachment.id.clone(), // v2 API"
                ],
                [
                    914,
                    "                        None => crypto::generate_file_id(),        // Legacy API"
                ],
                [
                    939,
                    "                        // v2 API"
                ],
                [
                    941,
                    "                        // Check the actual size against the size initially provided by"
                ],
                [
                    942,
                    "                        // the client. Upstream allows +/- 1 MiB deviation from this"
                ],
                [
                    943,
                    "                        // size, but it's not clear when or why this is needed."
                ],
                [
                    944,
                    "                        const LEEWAY: i32 = 1024 * 1024; // 1 MiB"
                ],
                [
                    950,
                    "                                // Update the attachment with the actual file size."
                ],
                [
                    963,
                    "                        // Legacy API"
                ],
                [
                    997,
                    "/// v2 API for uploading the actual data content of an attachment."
                ],
                [
                    998,
                    "/// This route needs a rank specified so that Rocket prioritizes the"
                ],
                [
                    999,
                    "/// /ciphers/<uuid>/attachment/v2 route, which would otherwise conflict"
                ],
                [
                    1000,
                    "/// with this one."
                ],
                [
                    1022,
                    "/// Legacy API for creating an attachment associated with a cipher."
                ],
                [
                    1032,
                    "    // Setting this as None signifies to save_attachment() that it should create"
                ],
                [
                    1033,
                    "    // the attachment database record as well as saving the data to disk."
                ]
            ]
        },
        {
            "commit": "5fef7983f4e3bc942ec0f029037454edfb057cad",
            "timestamp": "2021-05-25T22:13:04-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up attachment error handling",
            "additions": 4,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,5 @@\n use std::collections::{HashMap, HashSet};\n-use std::path::Path;\n+use std::path::{Path, PathBuf};\n \n use chrono::{NaiveDateTime, Utc};\n use rocket::{http::ContentType, request::Form, Data, Route};\n@@ -885,6 +885,7 @@ fn save_attachment(\n     let boundary = boundary_pair.1;\n \n     let base_path = Path::new(&CONFIG.attachments_folder()).join(&cipher_uuid);\n+    let mut path = PathBuf::new();\n \n     let mut attachment_key = None;\n     let mut error = None;\n@@ -913,23 +914,20 @@ fn save_attachment(\n                         Some(attachment) => attachment.id.clone(), // v2 API\n                         None => crypto::generate_file_id(),        // Legacy API\n                     };\n-                    let path = base_path.join(&file_id);\n+                    path = base_path.join(&file_id);\n \n                     let size =\n                         match field.data.save().memory_threshold(0).size_limit(size_limit).with_path(path.clone()) {\n                             SaveResult::Full(SavedData::File(_, size)) => size as i32,\n                             SaveResult::Full(other) => {\n-                                std::fs::remove_file(path).ok();\n                                 error = Some(format!(\"Attachment is not a file: {:?}\", other));\n                                 return;\n                             }\n                             SaveResult::Partial(_, reason) => {\n-                                std::fs::remove_file(path).ok();\n                                 error = Some(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n                                 return;\n                             }\n                             SaveResult::Error(e) => {\n-                                std::fs::remove_file(path).ok();\n                                 error = Some(format!(\"Error: {:?}\", e));\n                                 return;\n                             }\n@@ -952,7 +950,6 @@ fn save_attachment(\n                                 attachment.save(conn).expect(\"Error updating attachment\");\n                             }\n                         } else {\n-                            std::fs::remove_file(path).ok();\n                             attachment.delete(conn).ok();\n \n                             let err_msg = \"Attachment size mismatch\".to_string();\n@@ -986,6 +983,7 @@ fn save_attachment(\n         .expect(\"Error processing multipart data\");\n \n     if let Some(ref e) = error {\n+        std::fs::remove_file(path).ok();\n         err!(e);\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "c2ef331df9d2a1a3e50ed8129b07cca0a52e6f41",
            "timestamp": "2021-05-25T23:15:24-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Rework file ID generation",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -808,7 +808,7 @@ fn post_attachment_v2(\n         err!(\"Cipher is not write accessible\")\n     }\n \n-    let attachment_id = crypto::generate_file_id();\n+    let attachment_id = crypto::generate_attachment_id();\n     let data: AttachmentRequestData = data.into_inner().data;\n     let attachment =\n         Attachment::new(attachment_id.clone(), cipher.uuid.clone(), data.FileName, data.FileSize, Some(data.Key));\n@@ -912,7 +912,7 @@ fn save_attachment(\n                     // In the v2 API, we use the value from post_attachment_v2().\n                     let file_id = match &attachment {\n                         Some(attachment) => attachment.id.clone(), // v2 API\n-                        None => crypto::generate_file_id(),        // Legacy API\n+                        None => crypto::generate_attachment_id(),  // Legacy API\n                     };\n                     path = base_path.join(&file_id);\n \n",
            "comment_added_diff": [
                [
                    915,
                    "                        None => crypto::generate_attachment_id(),  // Legacy API"
                ]
            ]
        },
        {
            "commit": "3f7e4712cd9e62ce85f58e449074b98e5c95a142",
            "timestamp": "2021-05-25T23:17:22-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix attachment size limit calculation for v2 uploads",
            "additions": 9,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -852,11 +852,18 @@ fn save_attachment(\n         err_discard!(\"Cipher is not write accessible\", data)\n     }\n \n+    // In the v2 API, the attachment record has already been created,\n+    // so the size limit needs to be adjusted to account for that.\n+    let size_adjust = match &attachment {\n+        None => 0,                     // Legacy API\n+        Some(a) => a.file_size as i64, // v2 API\n+    };\n+\n     let size_limit = if let Some(ref user_uuid) = cipher.user_uuid {\n         match CONFIG.user_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n             Some(limit_kb) => {\n-                let left = (limit_kb * 1024) - Attachment::size_by_user(user_uuid, &conn);\n+                let left = (limit_kb * 1024) - Attachment::size_by_user(user_uuid, &conn) + size_adjust;\n                 if left <= 0 {\n                     err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n                 }\n@@ -868,7 +875,7 @@ fn save_attachment(\n         match CONFIG.org_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n             Some(limit_kb) => {\n-                let left = (limit_kb * 1024) - Attachment::size_by_org(org_uuid, &conn);\n+                let left = (limit_kb * 1024) - Attachment::size_by_org(org_uuid, &conn) + size_adjust;\n                 if left <= 0 {\n                     err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n                 }\n",
            "comment_added_diff": [
                [
                    855,
                    "    // In the v2 API, the attachment record has already been created,"
                ],
                [
                    856,
                    "    // so the size limit needs to be adjusted to account for that."
                ],
                [
                    858,
                    "        None => 0,                     // Legacy API"
                ],
                [
                    859,
                    "        Some(a) => a.file_size as i64, // v2 API"
                ]
            ]
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 38,
            "deletions": 38,
            "change_type": "MODIFY",
            "diff": "@@ -322,12 +322,12 @@ pub fn update_cipher_from_data(\n     }\n \n     if let Some(org_id) = data.OrganizationId {\n-        match UserOrganization::find_by_user_and_org(&headers.user.uuid, &org_id, &conn) {\n+        match UserOrganization::find_by_user_and_org(&headers.user.uuid, &org_id, conn) {\n             None => err!(\"You don't have permission to add item to organization\"),\n             Some(org_user) => {\n                 if shared_to_collection\n                     || org_user.has_full_access()\n-                    || cipher.is_write_accessible_to_user(&headers.user.uuid, &conn)\n+                    || cipher.is_write_accessible_to_user(&headers.user.uuid, conn)\n                 {\n                     cipher.organization_uuid = Some(org_id);\n                     // After some discussion in PR #1329 re-added the user_uuid = None again.\n@@ -359,7 +359,7 @@ pub fn update_cipher_from_data(\n     // Modify attachments name and keys when rotating\n     if let Some(attachments) = data.Attachments2 {\n         for (id, attachment) in attachments {\n-            let mut saved_att = match Attachment::find_by_id(&id, &conn) {\n+            let mut saved_att = match Attachment::find_by_id(&id, conn) {\n                 Some(att) => att,\n                 None => err!(\"Attachment doesn't exist\"),\n             };\n@@ -374,7 +374,7 @@ pub fn update_cipher_from_data(\n             saved_att.akey = Some(attachment.Key);\n             saved_att.file_name = attachment.FileName;\n \n-            saved_att.save(&conn)?;\n+            saved_att.save(conn)?;\n         }\n     }\n \n@@ -420,12 +420,12 @@ pub fn update_cipher_from_data(\n     cipher.password_history = data.PasswordHistory.map(|f| f.to_string());\n     cipher.reprompt = data.Reprompt;\n \n-    cipher.save(&conn)?;\n-    cipher.move_to_folder(data.FolderId, &headers.user.uuid, &conn)?;\n-    cipher.set_favorite(data.Favorite, &headers.user.uuid, &conn)?;\n+    cipher.save(conn)?;\n+    cipher.move_to_folder(data.FolderId, &headers.user.uuid, conn)?;\n+    cipher.set_favorite(data.Favorite, &headers.user.uuid, conn)?;\n \n     if ut != UpdateType::None {\n-        nt.send_cipher_update(ut, &cipher, &cipher.update_users_revision(&conn));\n+        nt.send_cipher_update(ut, cipher, &cipher.update_users_revision(conn));\n     }\n \n     Ok(())\n@@ -595,7 +595,7 @@ fn post_collections_admin(\n         cipher.get_collections(&headers.user.uuid, &conn).iter().cloned().collect();\n \n     for collection in posted_collections.symmetric_difference(&current_collections) {\n-        match Collection::find_by_uuid(&collection, &conn) {\n+        match Collection::find_by_uuid(collection, &conn) {\n             None => err!(\"Invalid collection ID provided\"),\n             Some(collection) => {\n                 if collection.is_writable_by_user(&headers.user.uuid, &conn) {\n@@ -709,9 +709,9 @@ fn share_cipher_by_uuid(\n     conn: &DbConn,\n     nt: &Notify,\n ) -> JsonResult {\n-    let mut cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+    let mut cipher = match Cipher::find_by_uuid(uuid, conn) {\n         Some(cipher) => {\n-            if cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+            if cipher.is_write_accessible_to_user(&headers.user.uuid, conn) {\n                 cipher\n             } else {\n                 err!(\"Cipher is not write accessible\")\n@@ -728,11 +728,11 @@ fn share_cipher_by_uuid(\n         None => {}\n         Some(organization_uuid) => {\n             for uuid in &data.CollectionIds {\n-                match Collection::find_by_uuid_and_org(uuid, &organization_uuid, &conn) {\n+                match Collection::find_by_uuid_and_org(uuid, &organization_uuid, conn) {\n                     None => err!(\"Invalid collection ID provided\"),\n                     Some(collection) => {\n-                        if collection.is_writable_by_user(&headers.user.uuid, &conn) {\n-                            CollectionCipher::save(&cipher.uuid, &collection.uuid, &conn)?;\n+                        if collection.is_writable_by_user(&headers.user.uuid, conn) {\n+                            CollectionCipher::save(&cipher.uuid, &collection.uuid, conn)?;\n                             shared_to_collection = true;\n                         } else {\n                             err!(\"No rights to modify the collection\")\n@@ -746,14 +746,14 @@ fn share_cipher_by_uuid(\n     update_cipher_from_data(\n         &mut cipher,\n         data.Cipher,\n-        &headers,\n+        headers,\n         shared_to_collection,\n-        &conn,\n-        &nt,\n+        conn,\n+        nt,\n         UpdateType::CipherUpdate,\n     )?;\n \n-    Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n+    Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, conn)))\n }\n \n /// v2 API for downloading an attachment. This just redirects the client to\n@@ -848,7 +848,7 @@ fn save_attachment(\n         None => err_discard!(\"Cipher doesn't exist\", data),\n     };\n \n-    if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+    if !cipher.is_write_accessible_to_user(&headers.user.uuid, conn) {\n         err_discard!(\"Cipher is not write accessible\", data)\n     }\n \n@@ -863,7 +863,7 @@ fn save_attachment(\n         match CONFIG.user_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n             Some(limit_kb) => {\n-                let left = (limit_kb * 1024) - Attachment::size_by_user(user_uuid, &conn) + size_adjust;\n+                let left = (limit_kb * 1024) - Attachment::size_by_user(user_uuid, conn) + size_adjust;\n                 if left <= 0 {\n                     err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n                 }\n@@ -875,7 +875,7 @@ fn save_attachment(\n         match CONFIG.org_attachment_limit() {\n             Some(0) => err_discard!(\"Attachments are disabled\", data),\n             Some(limit_kb) => {\n-                let left = (limit_kb * 1024) - Attachment::size_by_org(org_uuid, &conn) + size_adjust;\n+                let left = (limit_kb * 1024) - Attachment::size_by_org(org_uuid, conn) + size_adjust;\n                 if left <= 0 {\n                     err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n                 }\n@@ -994,7 +994,7 @@ fn save_attachment(\n         err!(e);\n     }\n \n-    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n+    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(conn));\n \n     Ok(cipher)\n }\n@@ -1303,22 +1303,22 @@ fn delete_all(\n }\n \n fn _delete_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, soft_delete: bool, nt: &Notify) -> EmptyResult {\n-    let mut cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+    let mut cipher = match Cipher::find_by_uuid(uuid, conn) {\n         Some(cipher) => cipher,\n         None => err!(\"Cipher doesn't exist\"),\n     };\n \n-    if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+    if !cipher.is_write_accessible_to_user(&headers.user.uuid, conn) {\n         err!(\"Cipher can't be deleted by user\")\n     }\n \n     if soft_delete {\n         cipher.deleted_at = Some(Utc::now().naive_utc());\n-        cipher.save(&conn)?;\n-        nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n+        cipher.save(conn)?;\n+        nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(conn));\n     } else {\n-        cipher.delete(&conn)?;\n-        nt.send_cipher_update(UpdateType::CipherDelete, &cipher, &cipher.update_users_revision(&conn));\n+        cipher.delete(conn)?;\n+        nt.send_cipher_update(UpdateType::CipherDelete, &cipher, &cipher.update_users_revision(conn));\n     }\n \n     Ok(())\n@@ -1351,20 +1351,20 @@ fn _delete_multiple_ciphers(\n }\n \n fn _restore_cipher_by_uuid(uuid: &str, headers: &Headers, conn: &DbConn, nt: &Notify) -> JsonResult {\n-    let mut cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+    let mut cipher = match Cipher::find_by_uuid(uuid, conn) {\n         Some(cipher) => cipher,\n         None => err!(\"Cipher doesn't exist\"),\n     };\n \n-    if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+    if !cipher.is_write_accessible_to_user(&headers.user.uuid, conn) {\n         err!(\"Cipher can't be restored by user\")\n     }\n \n     cipher.deleted_at = None;\n-    cipher.save(&conn)?;\n+    cipher.save(conn)?;\n \n-    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n-    Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, &conn)))\n+    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(conn));\n+    Ok(Json(cipher.to_json(&headers.host, &headers.user.uuid, conn)))\n }\n \n fn _restore_multiple_ciphers(data: JsonUpcase<Value>, headers: &Headers, conn: &DbConn, nt: &Notify) -> JsonResult {\n@@ -1400,7 +1400,7 @@ fn _delete_cipher_attachment_by_id(\n     conn: &DbConn,\n     nt: &Notify,\n ) -> EmptyResult {\n-    let attachment = match Attachment::find_by_id(&attachment_id, &conn) {\n+    let attachment = match Attachment::find_by_id(attachment_id, conn) {\n         Some(attachment) => attachment,\n         None => err!(\"Attachment doesn't exist\"),\n     };\n@@ -1409,17 +1409,17 @@ fn _delete_cipher_attachment_by_id(\n         err!(\"Attachment from other cipher\")\n     }\n \n-    let cipher = match Cipher::find_by_uuid(&uuid, &conn) {\n+    let cipher = match Cipher::find_by_uuid(uuid, conn) {\n         Some(cipher) => cipher,\n         None => err!(\"Cipher doesn't exist\"),\n     };\n \n-    if !cipher.is_write_accessible_to_user(&headers.user.uuid, &conn) {\n+    if !cipher.is_write_accessible_to_user(&headers.user.uuid, conn) {\n         err!(\"Cipher cannot be deleted by user\")\n     }\n \n     // Delete attachment\n-    attachment.delete(&conn)?;\n-    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(&conn));\n+    attachment.delete(conn)?;\n+    nt.send_cipher_update(UpdateType::CipherUpdate, &cipher, &cipher.update_users_revision(conn));\n     Ok(())\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "49579e4ce77fb5cd5a5fa8b8dc8844a0f2f3abc0",
            "timestamp": "2021-06-19T21:32:11-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Avoid `Error parsing LastKnownRevisionDate` warning for mobile clients\n\nWhen creating a new cipher, the mobile clients seem to set this field to an\ninvalid value, which causes a warning to be logged:\n\n    Error parsing LastKnownRevisionDate '0001-01-01T00:00:00': premature end of input\n\nAvoid this by dropping the `LastKnownRevisionDate` field on cipher creation.",
            "additions": 7,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -268,7 +268,13 @@ fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn\n /// Called when creating a new user-owned cipher.\n #[post(\"/ciphers\", data = \"<data>\")]\n fn post_ciphers(data: JsonUpcase<CipherData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n-    let data: CipherData = data.into_inner().data;\n+    let mut data: CipherData = data.into_inner().data;\n+\n+    // The web/browser clients set this field to null as expected, but the\n+    // mobile clients seem to set the invalid value `0001-01-01T00:00:00`,\n+    // which results in a warning message being logged. This field isn't\n+    // needed when creating a new cipher, so just ignore it unconditionally.\n+    data.LastKnownRevisionDate = None;\n \n     let mut cipher = Cipher::new(data.Type, data.Name.clone());\n     update_cipher_from_data(&mut cipher, data, &headers, false, &conn, &nt, UpdateType::CipherCreate)?;\n",
            "comment_added_diff": [
                [
                    273,
                    "    // The web/browser clients set this field to null as expected, but the"
                ],
                [
                    274,
                    "    // mobile clients seem to set the invalid value `0001-01-01T00:00:00`,"
                ],
                [
                    275,
                    "    // which results in a warning message being logged. This field isn't"
                ],
                [
                    276,
                    "    // needed when creating a new cipher, so just ignore it unconditionally."
                ]
            ]
        },
        {
            "commit": "6ea95d1ede727942e4677cae8c80545123b98e81",
            "timestamp": "2021-07-13T15:17:03+02:00",
            "author": "BlackDex",
            "commit_message": "Updated attachment limit descriptions\n\nThe user and org attachment limit use `size` as wording while it should\nhave been `storage` since it isn't per attachment, but the sum of all attachments.\n\n- Changed the wording in the config/env\n- Changed the wording of the error messages.\n\nResolves #1818",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -871,7 +871,7 @@ fn save_attachment(\n             Some(limit_kb) => {\n                 let left = (limit_kb * 1024) - Attachment::size_by_user(user_uuid, conn) + size_adjust;\n                 if left <= 0 {\n-                    err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n+                    err_discard!(\"Attachment storage limit reached! Delete some attachments to free up space\", data)\n                 }\n                 Some(left as u64)\n             }\n@@ -883,7 +883,7 @@ fn save_attachment(\n             Some(limit_kb) => {\n                 let left = (limit_kb * 1024) - Attachment::size_by_org(org_uuid, conn) + size_adjust;\n                 if left <= 0 {\n-                    err_discard!(\"Attachment size limit reached! Delete some files to open space\", data)\n+                    err_discard!(\"Attachment storage limit reached! Delete some attachments to free up space\", data)\n                 }\n                 Some(left as u64)\n             }\n@@ -937,7 +937,7 @@ fn save_attachment(\n                                 return;\n                             }\n                             SaveResult::Partial(_, reason) => {\n-                                error = Some(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n+                                error = Some(format!(\"Attachment storage limit exceeded with this file: {:?}\", reason));\n                                 return;\n                             }\n                             SaveResult::Error(e) => {\n",
            "comment_added_diff": []
        },
        {
            "commit": "91e80657e4c09cf3b9c254de81724b664a7ba2e3",
            "timestamp": "2021-08-18T20:54:36-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix error with adding file attachment from org vault view",
            "additions": 6,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -783,10 +783,7 @@ struct AttachmentRequestData {\n     Key: String,\n     FileName: String,\n     FileSize: i32,\n-    // We check org owner/admin status via is_write_accessible_to_user(),\n-    // so we can just ignore this field.\n-    //\n-    // AdminRequest: bool,\n+    AdminRequest: Option<bool>, // true when attaching from an org vault view\n }\n \n enum FileUploadType {\n@@ -821,14 +818,17 @@ fn post_attachment_v2(\n     attachment.save(&conn).expect(\"Error saving attachment\");\n \n     let url = format!(\"/ciphers/{}/attachment/{}\", cipher.uuid, attachment_id);\n+    let response_key = match data.AdminRequest {\n+        Some(b) if b => \"CipherMiniResponse\",\n+        _ => \"CipherResponse\",\n+    };\n \n     Ok(Json(json!({ // AttachmentUploadDataResponseModel\n         \"Object\": \"attachment-fileUpload\",\n         \"AttachmentId\": attachment_id,\n         \"Url\": url,\n         \"FileUploadType\": FileUploadType::Direct as i32,\n-        \"CipherResponse\": cipher.to_json(&headers.host, &headers.user.uuid, &conn),\n-        \"CipherMiniResponse\": null,\n+        response_key: cipher.to_json(&headers.host, &headers.user.uuid, &conn),\n     })))\n }\n \n",
            "comment_added_diff": [
                [
                    786,
                    "    AdminRequest: Option<bool>, // true when attaching from an org vault view"
                ]
            ]
        },
        {
            "commit": "56b4f46d7d9c818a392d3ab62322302ed8b0c723",
            "timestamp": "2021-08-16T22:23:33-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix limitation on sharing ciphers with attachments\n\nThis check is several years old, so maybe there was a valid reason\nfor having it before, but it's not correct anymore.",
            "additions": 0,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -687,12 +687,6 @@ fn put_cipher_share_selected(\n         };\n     }\n \n-    let attachments = Attachment::find_by_ciphers(cipher_ids, &conn);\n-\n-    if !attachments.is_empty() {\n-        err!(\"Ciphers should not have any attachments.\")\n-    }\n-\n     while let Some(cipher) = data.Ciphers.pop() {\n         let mut shared_cipher_data = ShareCipherData {\n             Cipher: cipher,\n",
            "comment_added_diff": []
        },
        {
            "commit": "80f23e6d78d24c166ebf28a48a02815aac38b1e1",
            "timestamp": "2021-09-08T23:26:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Enforce Personal Ownership policy on imports\n\nUpstream PR: https://github.com/bitwarden/server/pull/1565",
            "additions": 6,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -248,7 +248,7 @@ fn post_ciphers_create(data: JsonUpcase<ShareCipherData>, headers: Headers, conn\n     // This check is usually only needed in update_cipher_from_data(), but we\n     // need it here as well to avoid creating an empty cipher in the call to\n     // cipher.save() below.\n-    enforce_personal_ownership_policy(&data.Cipher, &headers, &conn)?;\n+    enforce_personal_ownership_policy(Some(&data.Cipher), &headers, &conn)?;\n \n     let mut cipher = Cipher::new(data.Cipher.Type, data.Cipher.Name.clone());\n     cipher.user_uuid = Some(headers.user.uuid.clone());\n@@ -289,8 +289,8 @@ fn post_ciphers(data: JsonUpcase<CipherData>, headers: Headers, conn: DbConn, nt\n /// allowed to delete or share such ciphers to an org, however.\n ///\n /// Ref: https://bitwarden.com/help/article/policies/#personal-ownership\n-fn enforce_personal_ownership_policy(data: &CipherData, headers: &Headers, conn: &DbConn) -> EmptyResult {\n-    if data.OrganizationId.is_none() {\n+fn enforce_personal_ownership_policy(data: Option<&CipherData>, headers: &Headers, conn: &DbConn) -> EmptyResult {\n+    if data.is_none() || data.unwrap().OrganizationId.is_none() {\n         let user_uuid = &headers.user.uuid;\n         let policy_type = OrgPolicyType::PersonalOwnership;\n         if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n@@ -309,7 +309,7 @@ pub fn update_cipher_from_data(\n     nt: &Notify,\n     ut: UpdateType,\n ) -> EmptyResult {\n-    enforce_personal_ownership_policy(&data, headers, conn)?;\n+    enforce_personal_ownership_policy(Some(&data), headers, conn)?;\n \n     // Check that the client isn't updating an existing cipher with stale data.\n     if let Some(dt) = data.LastKnownRevisionDate {\n@@ -458,6 +458,8 @@ struct RelationsData {\n \n #[post(\"/ciphers/import\", data = \"<data>\")]\n fn post_ciphers_import(data: JsonUpcase<ImportData>, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    enforce_personal_ownership_policy(None, &headers, &conn)?;\n+\n     let data: ImportData = data.into_inner().data;\n \n     // Read and create the folders\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -105,7 +105,7 @@ fn sync(data: Form<SyncData>, headers: Headers, conn: DbConn) -> Json<Value> {\n     let collections_json: Vec<Value> =\n         collections.iter().map(|c| c.to_json_details(&headers.user.uuid, &conn)).collect();\n \n-    let policies = OrgPolicy::find_by_user(&headers.user.uuid, &conn);\n+    let policies = OrgPolicy::find_confirmed_by_user(&headers.user.uuid, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n \n     let ciphers = Cipher::find_by_user_visible(&headers.user.uuid, &conn);\n",
            "comment_added_diff": []
        }
    ],
    "crypto.rs": [
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 16,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -4,6 +4,7 @@\n \n use ring::{digest, hmac, pbkdf2};\n use std::num::NonZeroU32;\n+use crate::error::Error;\n \n static DIGEST_ALG: &digest::Algorithm = &digest::SHA256;\n const OUTPUT_LEN: usize = digest::SHA256_OUTPUT_LEN;\n@@ -52,6 +53,21 @@ pub fn get_random(mut array: Vec<u8>) -> Vec<u8> {\n     array\n }\n \n+pub fn generate_token(token_size: u32) -> Result<String, Error> {\n+    if token_size > 19 {\n+        err!(\"Generating token failed\")\n+    }\n+\n+    // 8 bytes to create an u64 for up to 19 token digits\n+    let bytes = get_random(vec![0; 8]);\n+    let mut bytes_array = [0u8; 8];\n+    bytes_array.copy_from_slice(&bytes);\n+\n+    let number = u64::from_be_bytes(bytes_array) % 10u64.pow(token_size);\n+    let token = format!(\"{:0size$}\", number, size = token_size as usize);\n+    Ok(token)\n+}\n+\n //\n // Constant time compare\n //\n",
            "comment_added_diff": [
                [
                    61,
                    "    // 8 bytes to create an u64 for up to 19 token digits"
                ]
            ]
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -2,9 +2,9 @@\n // PBKDF2 derivation\n //\n \n+use crate::error::Error;\n use ring::{digest, hmac, pbkdf2};\n use std::num::NonZeroU32;\n-use crate::error::Error;\n \n static DIGEST_ALG: &digest::Algorithm = &digest::SHA256;\n const OUTPUT_LEN: usize = digest::SHA256_OUTPUT_LEN;\n",
            "comment_added_diff": []
        },
        {
            "commit": "9b1d07365e92f6f5e9b51b82fd3f30fdcab660b5",
            "timestamp": "2020-03-16T16:39:20+01:00",
            "author": "BlackDex",
            "commit_message": "Updated ring\n\nSome small changes to match the updated ring package.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -6,7 +6,7 @@ use crate::error::Error;\n use ring::{digest, hmac, pbkdf2};\n use std::num::NonZeroU32;\n \n-static DIGEST_ALG: &digest::Algorithm = &digest::SHA256;\n+static DIGEST_ALG: pbkdf2::Algorithm = pbkdf2::PBKDF2_HMAC_SHA256;\n const OUTPUT_LEN: usize = digest::SHA256_OUTPUT_LEN;\n \n pub fn hash_password(secret: &[u8], salt: &[u8], iterations: u32) -> Vec<u8> {\n@@ -29,7 +29,7 @@ pub fn verify_password_hash(secret: &[u8], salt: &[u8], previous: &[u8], iterati\n pub fn hmac_sign(key: &str, data: &str) -> String {\n     use data_encoding::HEXLOWER;\n \n-    let key = hmac::SigningKey::new(&digest::SHA1, key.as_bytes());\n+    let key = hmac::Key::new(hmac::HMAC_SHA1_FOR_LEGACY_USE_ONLY, key.as_bytes());\n     let signature = hmac::sign(&key, data.as_bytes());\n \n     HEXLOWER.encode(signature.as_ref())\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 3,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -1,10 +1,11 @@\n //\n // PBKDF2 derivation\n //\n+use std::num::NonZeroU32;\n \n-use crate::error::Error;\n use ring::{digest, hmac, pbkdf2};\n-use std::num::NonZeroU32;\n+\n+use crate::error::Error;\n \n static DIGEST_ALG: pbkdf2::Algorithm = pbkdf2::PBKDF2_HMAC_SHA256;\n const OUTPUT_LEN: usize = digest::SHA256_OUTPUT_LEN;\n",
            "comment_added_diff": []
        },
        {
            "commit": "d9684bef6be88517621cf50f0f81d5709ea199d2",
            "timestamp": "2020-08-22T16:07:53-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Generate tokens more simply and uniformly",
            "additions": 10,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -55,17 +55,21 @@ pub fn get_random(mut array: Vec<u8>) -> Vec<u8> {\n }\n \n pub fn generate_token(token_size: u32) -> Result<String, Error> {\n+    // A u64 can represent all whole numbers up to 19 digits long.\n     if token_size > 19 {\n-        err!(\"Generating token failed\")\n+        err!(\"Token size is limited to 19 digits\")\n     }\n \n-    // 8 bytes to create an u64 for up to 19 token digits\n-    let bytes = get_random(vec![0; 8]);\n-    let mut bytes_array = [0u8; 8];\n-    bytes_array.copy_from_slice(&bytes);\n+    let low: u64 = 0;\n+    let high: u64 = 10u64.pow(token_size);\n \n-    let number = u64::from_be_bytes(bytes_array) % 10u64.pow(token_size);\n+    // Generate a random number in the range [low, high), then format it as a\n+    // token of fixed width, left-padding with 0 as needed.\n+    use rand::{thread_rng, Rng};\n+    let mut rng = thread_rng();\n+    let number: u64 = rng.gen_range(low, high);\n     let token = format!(\"{:0size$}\", number, size = token_size as usize);\n+\n     Ok(token)\n }\n \n",
            "comment_added_diff": [
                [
                    58,
                    "    // A u64 can represent all whole numbers up to 19 digits long."
                ],
                [
                    66,
                    "    // Generate a random number in the range [low, high), then format it as a"
                ],
                [
                    67,
                    "    // token of fixed width, left-padding with 0 as needed."
                ]
            ]
        },
        {
            "commit": "58606796246110b8d49deb69e7d2ec352041bd94",
            "timestamp": "2021-01-31T20:07:42+01:00",
            "author": "BlackDex",
            "commit_message": "Updated dependencies and small mail fixes\n\n- Updated rust nightly\n- Updated depenencies\n- Removed unicode support for regex (less dependencies)\n- Fixed dependency and nightly changes/deprications\n- Some mail changes for less spam point triggering",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -67,7 +67,7 @@ pub fn generate_token(token_size: u32) -> Result<String, Error> {\n     // token of fixed width, left-padding with 0 as needed.\n     use rand::{thread_rng, Rng};\n     let mut rng = thread_rng();\n-    let number: u64 = rng.gen_range(low, high);\n+    let number: u64 = rng.gen_range(low..high);\n     let token = format!(\"{:0size$}\", number, size = token_size as usize);\n \n     Ok(token)\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 1,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -47,9 +47,7 @@ pub fn get_random_64() -> Vec<u8> {\n pub fn get_random(mut array: Vec<u8>) -> Vec<u8> {\n     use ring::rand::{SecureRandom, SystemRandom};\n \n-    SystemRandom::new()\n-        .fill(&mut array)\n-        .expect(\"Error generating random values\");\n+    SystemRandom::new().fill(&mut array).expect(\"Error generating random values\");\n \n     array\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "29ed82a3595e0cdd39deb914dc38002478f89f97",
            "timestamp": "2021-05-25T04:14:51-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for v2 attachment upload APIs\n\nUpstream PR: https://github.com/bitwarden/server/pull/1229",
            "additions": 5,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -3,6 +3,7 @@\n //\n use std::num::NonZeroU32;\n \n+use data_encoding::HEXLOWER;\n use ring::{digest, hmac, pbkdf2};\n \n use crate::error::Error;\n@@ -28,8 +29,6 @@ pub fn verify_password_hash(secret: &[u8], salt: &[u8], previous: &[u8], iterati\n // HMAC\n //\n pub fn hmac_sign(key: &str, data: &str) -> String {\n-    use data_encoding::HEXLOWER;\n-\n     let key = hmac::Key::new(hmac::HMAC_SHA1_FOR_LEGACY_USE_ONLY, key.as_bytes());\n     let signature = hmac::sign(&key, data.as_bytes());\n \n@@ -52,6 +51,10 @@ pub fn get_random(mut array: Vec<u8>) -> Vec<u8> {\n     array\n }\n \n+pub fn generate_file_id() -> String {\n+    HEXLOWER.encode(&get_random(vec![0; 16])) // 128 bits\n+}\n+\n pub fn generate_token(token_size: u32) -> Result<String, Error> {\n     // A u64 can represent all whole numbers up to 19 digits long.\n     if token_size > 19 {\n",
            "comment_added_diff": [
                [
                    55,
                    "    HEXLOWER.encode(&get_random(vec![0; 16])) // 128 bits"
                ]
            ]
        },
        {
            "commit": "c2ef331df9d2a1a3e50ed8129b07cca0a52e6f41",
            "timestamp": "2021-05-25T23:15:24-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Rework file ID generation",
            "additions": 12,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -51,8 +51,18 @@ pub fn get_random(mut array: Vec<u8>) -> Vec<u8> {\n     array\n }\n \n-pub fn generate_file_id() -> String {\n-    HEXLOWER.encode(&get_random(vec![0; 16])) // 128 bits\n+pub fn generate_id(num_bytes: usize) -> String {\n+    HEXLOWER.encode(&get_random(vec![0; num_bytes]))\n+}\n+\n+pub fn generate_send_id() -> String {\n+    // Send IDs are globally scoped, so make them longer to avoid collisions.\n+    generate_id(32) // 256 bits\n+}\n+\n+pub fn generate_attachment_id() -> String {\n+    // Attachment IDs are scoped to a cipher, so they can be smaller.\n+    generate_id(10) // 80 bits\n }\n \n pub fn generate_token(token_size: u32) -> Result<String, Error> {\n",
            "comment_added_diff": [
                [
                    59,
                    "    // Send IDs are globally scoped, so make them longer to avoid collisions."
                ],
                [
                    60,
                    "    generate_id(32) // 256 bits"
                ],
                [
                    64,
                    "    // Attachment IDs are scoped to a cipher, so they can be smaller."
                ],
                [
                    65,
                    "    generate_id(10) // 80 bits"
                ]
            ]
        }
    ],
    "device.rs": [
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,7 @@\n use chrono::{NaiveDateTime, Utc};\n \n use super::User;\n+use crate::CONFIG;\n \n #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n #[table_name = \"devices\"]\n@@ -87,7 +88,7 @@ impl Device {\n             premium: true,\n             name: user.name.to_string(),\n             email: user.email.to_string(),\n-            email_verified: true,\n+            email_verified: !CONFIG.mail_enabled() || user.verified_at.is_some(),\n \n             orgowner,\n             orgadmin,\n",
            "comment_added_diff": []
        },
        {
            "commit": "1ee8e44912a02feb77fd9640a5cc4782b494820b",
            "timestamp": "2020-04-15T16:49:33+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #965\n\nPostgreSQL updates/inserts ignored None/null values.\nThis is nice for new entries, but not for updates.\nAdded derive option to allways add these none/null values for Option<>\nvariables.\n\nThis solves issue #965",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -5,6 +5,7 @@ use crate::CONFIG;\n \n #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n #[table_name = \"devices\"]\n+#[changeset_options(treat_none_as_null=\"true\")]\n #[belongs_to(User, foreign_key = \"user_uuid\")]\n #[primary_key(uuid)]\n pub struct Device {\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -108,7 +108,6 @@ impl Device {\n \n use crate::db::schema::devices;\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n",
            "comment_added_diff": []
        },
        {
            "commit": "632f4d545367b5ab1cefce66bc526e5dc0a786de",
            "timestamp": "2020-05-07T18:02:37-04:00",
            "author": "theycallmesteve",
            "commit_message": "Whitespace fixes",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -77,7 +77,6 @@ impl Device {\n         let orguser: Vec<_> = orgs.iter().filter(|o| o.atype == 2).map(|o| o.org_uuid.clone()).collect();\n         let orgmanager: Vec<_> = orgs.iter().filter(|o| o.atype == 3).map(|o| o.org_uuid.clone()).collect();\n \n-\n         // Create the JWT claims struct, to send to the client\n         use crate::auth::{encode_jwt, LoginJWTClaims, DEFAULT_VALIDITY, JWT_LOGIN_ISSUER};\n         let claims = LoginJWTClaims {\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 63,
            "deletions": 54,
            "change_type": "MODIFY",
            "diff": "@@ -3,26 +3,28 @@ use chrono::{NaiveDateTime, Utc};\n use super::User;\n use crate::CONFIG;\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"devices\"]\n-#[changeset_options(treat_none_as_null=\"true\")]\n-#[belongs_to(User, foreign_key = \"user_uuid\")]\n-#[primary_key(uuid)]\n-pub struct Device {\n-    pub uuid: String,\n-    pub created_at: NaiveDateTime,\n-    pub updated_at: NaiveDateTime,\n-\n-    pub user_uuid: String,\n-\n-    pub name: String,\n-    /// https://github.com/bitwarden/core/tree/master/src/Core/Enums\n-    pub atype: i32,\n-    pub push_token: Option<String>,\n-\n-    pub refresh_token: String,\n-\n-    pub twofactor_remember: Option<String>,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"devices\"]\n+    #[changeset_options(treat_none_as_null=\"true\")]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct Device {\n+        pub uuid: String,\n+        pub created_at: NaiveDateTime,\n+        pub updated_at: NaiveDateTime,\n+\n+        pub user_uuid: String,\n+\n+        pub name: String,\n+        // https://github.com/bitwarden/core/tree/master/src/Core/Enums\n+        pub atype: i32,\n+        pub push_token: Option<String>,\n+\n+        pub refresh_token: String,\n+\n+        pub twofactor_remember: Option<String>,\n+    }\n }\n \n /// Local methods\n@@ -105,41 +107,39 @@ impl Device {\n     }\n }\n \n-use crate::db::schema::devices;\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n \n /// Database methods\n impl Device {\n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n         self.updated_at = Utc::now().naive_utc();\n \n-        crate::util::retry(\n-            || diesel::insert_into(devices::table).values(&*self).on_conflict(devices::uuid).do_update().set(&*self).execute(&**conn),\n-            10,\n-        )\n-            .map_res(\"Error saving device\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n-        self.updated_at = Utc::now().naive_utc();\n-\n-        crate::util::retry(\n-            || diesel::replace_into(devices::table).values(&*self).execute(&**conn),\n-            10,\n-        )\n-        .map_res(\"Error saving device\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                crate::util::retry(\n+                    || diesel::replace_into(devices::table).values(DeviceDb::to_db(self)).execute(conn),\n+                    10,\n+                ).map_res(\"Error saving device\")\n+            }\n+            postgresql {\n+                let value = DeviceDb::to_db(self);\n+                crate::util::retry(\n+                    || diesel::insert_into(devices::table).values(&value).on_conflict(devices::uuid).do_update().set(&value).execute(conn),\n+                    10,\n+                ).map_res(\"Error saving device\")\n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(devices::table.filter(devices::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing device\")\n+        db_run! { conn: {\n+            diesel::delete(devices::table.filter(devices::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing device\")\n+        }}\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -150,23 +150,32 @@ impl Device {\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        devices::table\n-            .filter(devices::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            devices::table\n+                .filter(devices::uuid.eq(uuid))\n+                .first::<DeviceDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_refresh_token(refresh_token: &str, conn: &DbConn) -> Option<Self> {\n-        devices::table\n-            .filter(devices::refresh_token.eq(refresh_token))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            devices::table\n+                .filter(devices::refresh_token.eq(refresh_token))\n+                .first::<DeviceDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        devices::table\n-            .filter(devices::user_uuid.eq(user_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading devices\")\n+        db_run! { conn: {\n+            devices::table\n+                .filter(devices::user_uuid.eq(user_uuid))\n+                .load::<DeviceDb>(conn)\n+                .expect(\"Error loading devices\")\n+                .from_db()\n+        }}\n     }\n }\n",
            "comment_added_diff": [
                [
                    20,
                    "        // https://github.com/bitwarden/core/tree/master/src/Core/Enums"
                ]
            ]
        },
        {
            "commit": "1eb5495802e8447649c054b59843762b15b82b56",
            "timestamp": "2020-12-03T17:07:32+01:00",
            "author": "janost",
            "commit_message": "Show latest active device as last active on admin page",
            "additions": 11,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -178,4 +178,15 @@ impl Device {\n                 .from_db()\n         }}\n     }\n+\n+    pub fn find_latest_active_by_user(user_uuid: &str, conn: &DbConn) -> Option<Self> {\n+        db_run! { conn: {\n+            devices::table\n+                .filter(devices::user_uuid.eq(user_uuid))\n+                .order(devices::updated_at.desc())\n+                .first::<DeviceDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n+    }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use super::User;\n use crate::CONFIG;\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"devices\"]\n     #[changeset_options(treat_none_as_null=\"true\")]\n     #[belongs_to(User, foreign_key = \"user_uuid\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "49af9cf4f5f8264384c7fa9063299f44e7536068",
            "timestamp": "2021-03-27T14:26:32+00:00",
            "author": "Jake Howard",
            "commit_message": "Correctly camelCase acronyms\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#upper_case_acronyms",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -80,8 +80,8 @@ impl Device {\n         let orgmanager: Vec<_> = orgs.iter().filter(|o| o.atype == 3).map(|o| o.org_uuid.clone()).collect();\n \n         // Create the JWT claims struct, to send to the client\n-        use crate::auth::{encode_jwt, LoginJWTClaims, DEFAULT_VALIDITY, JWT_LOGIN_ISSUER};\n-        let claims = LoginJWTClaims {\n+        use crate::auth::{encode_jwt, LoginJwtClaims, DEFAULT_VALIDITY, JWT_LOGIN_ISSUER};\n+        let claims = LoginJwtClaims {\n             nbf: time_now.timestamp(),\n             exp: (time_now + *DEFAULT_VALIDITY).timestamp(),\n             iss: JWT_LOGIN_ISSUER.to_string(),\n@@ -117,7 +117,7 @@ impl Device {\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n         self.updated_at = Utc::now().naive_utc();\n \n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n                 crate::util::retry(\n                     || diesel::replace_into(devices::table).values(DeviceDb::to_db(self)).execute(conn),\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 20,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -74,10 +74,26 @@ impl Device {\n         let time_now = Utc::now().naive_utc();\n         self.updated_at = time_now;\n \n-        let orgowner: Vec<_> = orgs.iter().filter(|o| o.atype == 0).map(|o| o.org_uuid.clone()).collect();\n-        let orgadmin: Vec<_> = orgs.iter().filter(|o| o.atype == 1).map(|o| o.org_uuid.clone()).collect();\n-        let orguser: Vec<_> = orgs.iter().filter(|o| o.atype == 2).map(|o| o.org_uuid.clone()).collect();\n-        let orgmanager: Vec<_> = orgs.iter().filter(|o| o.atype == 3).map(|o| o.org_uuid.clone()).collect();\n+        let orgowner: Vec<_> = orgs\n+            .iter()\n+            .filter(|o| o.atype == 0)\n+            .map(|o| o.org_uuid.clone())\n+            .collect();\n+        let orgadmin: Vec<_> = orgs\n+            .iter()\n+            .filter(|o| o.atype == 1)\n+            .map(|o| o.org_uuid.clone())\n+            .collect();\n+        let orguser: Vec<_> = orgs\n+            .iter()\n+            .filter(|o| o.atype == 2)\n+            .map(|o| o.org_uuid.clone())\n+            .collect();\n+        let orgmanager: Vec<_> = orgs\n+            .iter()\n+            .filter(|o| o.atype == 3)\n+            .map(|o| o.org_uuid.clone())\n+            .collect();\n \n         // Create the JWT claims struct, to send to the client\n         use crate::auth::{encode_jwt, LoginJwtClaims, DEFAULT_VALIDITY, JWT_LOGIN_ISSUER};\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 4,
            "deletions": 20,
            "change_type": "MODIFY",
            "diff": "@@ -74,26 +74,10 @@ impl Device {\n         let time_now = Utc::now().naive_utc();\n         self.updated_at = time_now;\n \n-        let orgowner: Vec<_> = orgs\n-            .iter()\n-            .filter(|o| o.atype == 0)\n-            .map(|o| o.org_uuid.clone())\n-            .collect();\n-        let orgadmin: Vec<_> = orgs\n-            .iter()\n-            .filter(|o| o.atype == 1)\n-            .map(|o| o.org_uuid.clone())\n-            .collect();\n-        let orguser: Vec<_> = orgs\n-            .iter()\n-            .filter(|o| o.atype == 2)\n-            .map(|o| o.org_uuid.clone())\n-            .collect();\n-        let orgmanager: Vec<_> = orgs\n-            .iter()\n-            .filter(|o| o.atype == 3)\n-            .map(|o| o.org_uuid.clone())\n-            .collect();\n+        let orgowner: Vec<_> = orgs.iter().filter(|o| o.atype == 0).map(|o| o.org_uuid.clone()).collect();\n+        let orgadmin: Vec<_> = orgs.iter().filter(|o| o.atype == 1).map(|o| o.org_uuid.clone()).collect();\n+        let orguser: Vec<_> = orgs.iter().filter(|o| o.atype == 2).map(|o| o.org_uuid.clone()).collect();\n+        let orgmanager: Vec<_> = orgs.iter().filter(|o| o.atype == 3).map(|o| o.org_uuid.clone()).collect();\n \n         // Create the JWT claims struct, to send to the client\n         use crate::auth::{encode_jwt, LoginJwtClaims, DEFAULT_VALIDITY, JWT_LOGIN_ISSUER};\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -143,8 +143,8 @@ impl Device {\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for device in Self::find_by_user(user_uuid, &conn) {\n-            device.delete(&conn)?;\n+        for device in Self::find_by_user(user_uuid, conn) {\n+            device.delete(conn)?;\n         }\n         Ok(())\n     }\n",
            "comment_added_diff": []
        }
    ],
    "user.rs": [
        {
            "commit": "bd1e8be32811609fe6df452767ef2e4d542d4508",
            "timestamp": "2019-11-24T22:28:49-07:00",
            "author": "tomuta",
            "commit_message": "Implement change-email, email-verification, account-recovery, and welcome notifications",
            "additions": 11,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -11,8 +11,13 @@ pub struct User {\n     pub uuid: String,\n     pub created_at: NaiveDateTime,\n     pub updated_at: NaiveDateTime,\n+    pub verified_at: Option<NaiveDateTime>,\n+    pub last_verifying_at: Option<NaiveDateTime>,\n+    pub login_verify_count: i32,\n \n     pub email: String,\n+    pub email_new: Option<String>,\n+    pub email_new_token: Option<String>,\n     pub name: String,\n \n     pub password_hash: Vec<u8>,\n@@ -56,9 +61,14 @@ impl User {\n             uuid: crate::util::get_uuid(),\n             created_at: now,\n             updated_at: now,\n+            verified_at: None,\n+            last_verifying_at: None,\n+            login_verify_count: 0,\n             name: email.clone(),\n             email,\n             akey: String::new(),\n+            email_new: None,\n+            email_new_token: None,\n \n             password_hash: Vec::new(),\n             salt: crypto::get_random_64(),\n@@ -135,7 +145,7 @@ impl User {\n             \"Id\": self.uuid,\n             \"Name\": self.name,\n             \"Email\": self.email,\n-            \"EmailVerified\": true,\n+            \"EmailVerified\": !CONFIG.mail_enabled() || self.verified_at.is_some(),\n             \"Premium\": true,\n             \"MasterPasswordHint\": self.password_hint,\n             \"Culture\": \"en-US\",\n",
            "comment_added_diff": []
        },
        {
            "commit": "03233429f4475de558c58707224d1cf72aa28c42",
            "timestamp": "2020-02-16T20:28:50+00:00",
            "author": "Miro Prasil",
            "commit_message": "Remove check from Invitation:take()\n\nI've checked the spots when `Invitation::new()` and `Invitation::take()`\nare used and it seems like all spots are already correctly gated. So to\nenable invitations via admin API even when invitations are otherwise\ndisabled, this check can be removed.",
            "additions": 4,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -319,10 +319,9 @@ impl Invitation {\n     }\n \n     pub fn take(mail: &str, conn: &DbConn) -> bool {\n-        CONFIG.invitations_allowed()\n-            && match Self::find_by_mail(mail, &conn) {\n-                Some(invitation) => invitation.delete(&conn).is_ok(),\n-                None => false,\n-            }\n+        match Self::find_by_mail(mail, &conn) {\n+            Some(invitation) => invitation.delete(&conn).is_ok(),\n+            None => false,\n+        }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "1ee8e44912a02feb77fd9640a5cc4782b494820b",
            "timestamp": "2020-04-15T16:49:33+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #965\n\nPostgreSQL updates/inserts ignored None/null values.\nThis is nice for new entries, but not for updates.\nAdded derive option to allways add these none/null values for Option<>\nvariables.\n\nThis solves issue #965",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -6,6 +6,7 @@ use crate::CONFIG;\n \n #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n #[table_name = \"users\"]\n+#[changeset_options(treat_none_as_null=\"true\")]\n #[primary_key(uuid)]\n pub struct User {\n     pub uuid: String,\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -121,7 +121,6 @@ impl User {\n use super::{Cipher, Device, Folder, TwoFactor, UserOrgType, UserOrganization};\n use crate::db::schema::{invitations, users};\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n@@ -275,7 +274,7 @@ pub struct Invitation {\n }\n \n impl Invitation {\n-    pub fn new(email: String) -> Self {\n+    pub const fn new(email: String) -> Self {\n         Self { email }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 130,
            "deletions": 124,
            "change_type": "MODIFY",
            "diff": "@@ -4,43 +4,53 @@ use serde_json::Value;\n use crate::crypto;\n use crate::CONFIG;\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n-#[table_name = \"users\"]\n-#[changeset_options(treat_none_as_null=\"true\")]\n-#[primary_key(uuid)]\n-pub struct User {\n-    pub uuid: String,\n-    pub created_at: NaiveDateTime,\n-    pub updated_at: NaiveDateTime,\n-    pub verified_at: Option<NaiveDateTime>,\n-    pub last_verifying_at: Option<NaiveDateTime>,\n-    pub login_verify_count: i32,\n-\n-    pub email: String,\n-    pub email_new: Option<String>,\n-    pub email_new_token: Option<String>,\n-    pub name: String,\n-\n-    pub password_hash: Vec<u8>,\n-    pub salt: Vec<u8>,\n-    pub password_iterations: i32,\n-    pub password_hint: Option<String>,\n-\n-    pub akey: String,\n-    pub private_key: Option<String>,\n-    pub public_key: Option<String>,\n-\n-    #[column_name = \"totp_secret\"]\n-    _totp_secret: Option<String>,\n-    pub totp_recover: Option<String>,\n-\n-    pub security_stamp: String,\n-\n-    pub equivalent_domains: String,\n-    pub excluded_globals: String,\n-\n-    pub client_kdf_type: i32,\n-    pub client_kdf_iter: i32,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n+    #[table_name = \"users\"]\n+    #[changeset_options(treat_none_as_null=\"true\")]\n+    #[primary_key(uuid)]\n+    pub struct User {\n+        pub uuid: String,\n+        pub created_at: NaiveDateTime,\n+        pub updated_at: NaiveDateTime,\n+        pub verified_at: Option<NaiveDateTime>,\n+        pub last_verifying_at: Option<NaiveDateTime>,\n+        pub login_verify_count: i32,\n+\n+        pub email: String,\n+        pub email_new: Option<String>,\n+        pub email_new_token: Option<String>,\n+        pub name: String,\n+\n+        pub password_hash: Vec<u8>,\n+        pub salt: Vec<u8>,\n+        pub password_iterations: i32,\n+        pub password_hint: Option<String>,\n+\n+        pub akey: String,\n+        pub private_key: Option<String>,\n+        pub public_key: Option<String>,\n+\n+        #[column_name = \"totp_secret\"] // Note, this is only added to the UserDb structs, not to User\n+        _totp_secret: Option<String>,\n+        pub totp_recover: Option<String>,\n+\n+        pub security_stamp: String,\n+\n+        pub equivalent_domains: String,\n+        pub excluded_globals: String,\n+\n+        pub client_kdf_type: i32,\n+        pub client_kdf_iter: i32,\n+    }\n+\n+\n+    #[derive(Debug, Identifiable, Queryable, Insertable)]\n+    #[table_name = \"invitations\"]\n+    #[primary_key(email)]\n+    pub struct Invitation {\n+        pub email: String,\n+    }\n }\n \n enum UserStatus {\n@@ -119,9 +129,7 @@ impl User {\n }\n \n use super::{Cipher, Device, Folder, TwoFactor, UserOrgType, UserOrganization};\n-use crate::db::schema::{invitations, users};\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n@@ -158,7 +166,6 @@ impl User {\n         })\n     }\n \n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n         if self.email.trim().is_empty() {\n             err!(\"User email can't be empty\")\n@@ -166,49 +173,48 @@ impl User {\n \n         self.updated_at = Utc::now().naive_utc();\n \n-        diesel::insert_into(users::table) // Insert or update\n-            .values(&*self)\n-            .on_conflict(users::uuid)\n-            .do_update()\n-            .set(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving user\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n-        if self.email.trim().is_empty() {\n-            err!(\"User email can't be empty\")\n+        db_run! {conn:\n+            sqlite, mysql {\n+                diesel::replace_into(users::table) // Insert or update\n+                    .values(&UserDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving user\")\n+            }\n+            postgresql {\n+                let value = UserDb::to_db(self);\n+                diesel::insert_into(users::table) // Insert or update\n+                    .values(&value)\n+                    .on_conflict(users::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving user\")\n+            }\n         }\n-\n-        self.updated_at = Utc::now().naive_utc();\n-\n-        diesel::replace_into(users::table) // Insert or update\n-            .values(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving user\")\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        for user_org in UserOrganization::find_by_user(&self.uuid, &*conn) {\n+        for user_org in UserOrganization::find_by_user(&self.uuid, conn) {\n             if user_org.atype == UserOrgType::Owner {\n                 let owner_type = UserOrgType::Owner as i32;\n-                if UserOrganization::find_by_org_and_type(&user_org.org_uuid, owner_type, &conn).len() <= 1 {\n+                if UserOrganization::find_by_org_and_type(&user_org.org_uuid, owner_type, conn).len() <= 1 {\n                     err!(\"Can't delete last owner\")\n                 }\n             }\n         }\n \n-        UserOrganization::delete_all_by_user(&self.uuid, &*conn)?;\n-        Cipher::delete_all_by_user(&self.uuid, &*conn)?;\n-        Folder::delete_all_by_user(&self.uuid, &*conn)?;\n-        Device::delete_all_by_user(&self.uuid, &*conn)?;\n-        TwoFactor::delete_all_by_user(&self.uuid, &*conn)?;\n-        Invitation::take(&self.email, &*conn); // Delete invitation if any\n-\n-        diesel::delete(users::table.filter(users::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting user\")\n+        UserOrganization::delete_all_by_user(&self.uuid, conn)?;\n+        Cipher::delete_all_by_user(&self.uuid, conn)?;\n+        Folder::delete_all_by_user(&self.uuid, conn)?;\n+        Device::delete_all_by_user(&self.uuid, conn)?;\n+        TwoFactor::delete_all_by_user(&self.uuid, conn)?;\n+        Invitation::take(&self.email, conn); // Delete invitation if any\n+\n+        db_run! {conn: {\n+            diesel::delete(users::table.filter(users::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting user\")\n+        }}\n     }\n \n     pub fn update_uuid_revision(uuid: &str, conn: &DbConn) {\n@@ -220,15 +226,14 @@ impl User {\n     pub fn update_all_revisions(conn: &DbConn) -> EmptyResult {\n         let updated_at = Utc::now().naive_utc();\n \n-        crate::util::retry(\n-            || {\n+        db_run! {conn: {\n+            crate::util::retry(|| {\n                 diesel::update(users::table)\n                     .set(users::updated_at.eq(updated_at))\n-                    .execute(&**conn)\n-            },\n-            10,\n-        )\n-        .map_res(\"Error updating revision date for all users\")\n+                    .execute(conn)\n+            }, 10)\n+            .map_res(\"Error updating revision date for all users\")\n+        }}\n     }\n \n     pub fn update_revision(&mut self, conn: &DbConn) -> EmptyResult {\n@@ -238,84 +243,85 @@ impl User {\n     }\n \n     fn _update_revision(uuid: &str, date: &NaiveDateTime, conn: &DbConn) -> EmptyResult {\n-        crate::util::retry(\n-            || {\n+        db_run! {conn: {\n+            crate::util::retry(|| {\n                 diesel::update(users::table.filter(users::uuid.eq(uuid)))\n                     .set(users::updated_at.eq(date))\n-                    .execute(&**conn)\n-            },\n-            10,\n-        )\n-        .map_res(\"Error updating user revision\")\n+                    .execute(conn)\n+            }, 10)\n+            .map_res(\"Error updating user revision\")\n+        }}\n     }\n \n     pub fn find_by_mail(mail: &str, conn: &DbConn) -> Option<Self> {\n         let lower_mail = mail.to_lowercase();\n-        users::table\n-            .filter(users::email.eq(lower_mail))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! {conn: {\n+            users::table\n+                .filter(users::email.eq(lower_mail))\n+                .first::<UserDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        users::table.filter(users::uuid.eq(uuid)).first::<Self>(&**conn).ok()\n+        db_run! {conn: {\n+            users::table.filter(users::uuid.eq(uuid)).first::<UserDb>(conn).ok().from_db()\n+        }}\n     }\n \n     pub fn get_all(conn: &DbConn) -> Vec<Self> {\n-        users::table.load::<Self>(&**conn).expect(\"Error loading users\")\n+        db_run! {conn: {\n+            users::table.load::<UserDb>(conn).expect(\"Error loading users\").from_db()\n+        }}\n     }\n }\n \n-#[derive(Debug, Identifiable, Queryable, Insertable)]\n-#[table_name = \"invitations\"]\n-#[primary_key(email)]\n-pub struct Invitation {\n-    pub email: String,\n-}\n-\n impl Invitation {\n     pub const fn new(email: String) -> Self {\n         Self { email }\n     }\n \n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         if self.email.trim().is_empty() {\n             err!(\"Invitation email can't be empty\")\n         }\n \n-        diesel::insert_into(invitations::table)\n-            .values(self)\n-            .on_conflict(invitations::email)\n-            .do_nothing()\n-            .execute(&**conn)\n-            .map_res(\"Error saving invitation\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        if self.email.trim().is_empty() {\n-            err!(\"Invitation email can't be empty\")\n+        db_run! {conn:\n+            sqlite, mysql {\n+                diesel::replace_into(invitations::table)\n+                    .values(InvitationDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving invitation\")        \n+            }\n+            postgresql {\n+                diesel::insert_into(invitations::table)\n+                    .values(InvitationDb::to_db(self))\n+                    .on_conflict(invitations::email)\n+                    .do_nothing()\n+                    .execute(conn)\n+                    .map_res(\"Error saving invitation\")                \n+            }\n         }\n-\n-        diesel::replace_into(invitations::table)\n-            .values(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving invitation\")\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(invitations::table.filter(invitations::email.eq(self.email)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting invitation\")\n+        db_run! {conn: {\n+            diesel::delete(invitations::table.filter(invitations::email.eq(self.email)))\n+                .execute(conn)\n+                .map_res(\"Error deleting invitation\")\n+        }}\n     }\n \n     pub fn find_by_mail(mail: &str, conn: &DbConn) -> Option<Self> {\n         let lower_mail = mail.to_lowercase();\n-        invitations::table\n-            .filter(invitations::email.eq(lower_mail))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! {conn: {\n+            invitations::table\n+                .filter(invitations::email.eq(lower_mail))\n+                .first::<InvitationDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn take(mail: &str, conn: &DbConn) -> bool {\n",
            "comment_added_diff": [
                [
                    34,
                    "        #[column_name = \"totp_secret\"] // Note, this is only added to the UserDb structs, not to User"
                ],
                [
                    178,
                    "                diesel::replace_into(users::table) // Insert or update"
                ],
                [
                    185,
                    "                diesel::insert_into(users::table) // Insert or update"
                ],
                [
                    211,
                    "        Invitation::take(&self.email, conn); // Delete invitation if any"
                ]
            ]
        },
        {
            "commit": "175d647e47fbd9abec4134c708199ba8aa1ec682",
            "timestamp": "2020-08-26T01:27:38-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Delete associated favorites when deleting a cipher or user\n\nThis prevents foreign key constraint violations.",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -128,7 +128,7 @@ impl User {\n     }\n }\n \n-use super::{Cipher, Device, Folder, TwoFactor, UserOrgType, UserOrganization};\n+use super::{Cipher, Device, Favorite, Folder, TwoFactor, UserOrgType, UserOrganization};\n use crate::db::DbConn;\n \n use crate::api::EmptyResult;\n@@ -205,6 +205,7 @@ impl User {\n \n         UserOrganization::delete_all_by_user(&self.uuid, conn)?;\n         Cipher::delete_all_by_user(&self.uuid, conn)?;\n+        Favorite::delete_all_by_user(&self.uuid, conn)?;\n         Folder::delete_all_by_user(&self.uuid, conn)?;\n         Device::delete_all_by_user(&self.uuid, conn)?;\n         TwoFactor::delete_all_by_user(&self.uuid, conn)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 18,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -175,10 +175,21 @@ impl User {\n \n         db_run! {conn:\n             sqlite, mysql {\n-                diesel::replace_into(users::table) // Insert or update\n-                    .values(&UserDb::to_db(self))\n+                match diesel::replace_into(users::table)\n+                    .values(UserDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving user\")\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(users::table)\n+                            .filter(users::uuid.eq(&self.uuid))\n+                            .set(UserDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving user\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving user\")\n             }\n             postgresql {\n                 let value = UserDb::to_db(self);\n@@ -290,10 +301,12 @@ impl Invitation {\n \n         db_run! {conn:\n             sqlite, mysql {\n+                // Not checking for ForeignKey Constraints here\n+                // Table invitations does not have any ForeignKey Constraints.\n                 diesel::replace_into(invitations::table)\n                     .values(InvitationDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving invitation\")        \n+                    .map_res(\"Error saving invitation\")\n             }\n             postgresql {\n                 diesel::insert_into(invitations::table)\n@@ -301,7 +314,7 @@ impl Invitation {\n                     .on_conflict(invitations::email)\n                     .do_nothing()\n                     .execute(conn)\n-                    .map_res(\"Error saving invitation\")                \n+                    .map_res(\"Error saving invitation\")\n             }\n         }\n     }\n",
            "comment_added_diff": [
                [
                    183,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    304,
                    "                // Not checking for ForeignKey Constraints here"
                ],
                [
                    305,
                    "                // Table invitations does not have any ForeignKey Constraints."
                ]
            ]
        },
        {
            "commit": "448e6ac917e6bf34f7a5af175714eef9058b6021",
            "timestamp": "2020-10-03T22:43:13+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Invalidate sessions when changing password or kdf values",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -121,6 +121,7 @@ impl User {\n \n     pub fn set_password(&mut self, password: &str) {\n         self.password_hash = crypto::hash_password(password.as_bytes(), &self.salt, self.password_iterations as u32);\n+        self.reset_security_stamp();\n     }\n \n     pub fn reset_security_stamp(&mut self) {\n",
            "comment_added_diff": []
        },
        {
            "commit": "043aa27aa36f3918ad273eb67068cc0dc925dfb4",
            "timestamp": "2020-11-30T23:12:56+01:00",
            "author": "janost",
            "commit_message": "Implement admin ability to enable/disable users",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -11,6 +11,7 @@ db_object! {\n     #[primary_key(uuid)]\n     pub struct User {\n         pub uuid: String,\n+        pub enabled: bool,\n         pub created_at: NaiveDateTime,\n         pub updated_at: NaiveDateTime,\n         pub verified_at: Option<NaiveDateTime>,\n@@ -70,6 +71,7 @@ impl User {\n \n         Self {\n             uuid: crate::util::get_uuid(),\n+            enabled: true,\n             created_at: now,\n             updated_at: now,\n             verified_at: None,\n",
            "comment_added_diff": []
        },
        {
            "commit": "1eb5495802e8447649c054b59843762b15b82b56",
            "timestamp": "2020-12-03T17:07:32+01:00",
            "author": "janost",
            "commit_message": "Show latest active device as last active on admin page",
            "additions": 7,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -288,6 +288,13 @@ impl User {\n             users::table.load::<UserDb>(conn).expect(\"Error loading users\").from_db()\n         }}\n     }\n+\n+    pub fn last_active(&self, conn: &DbConn) -> Option<NaiveDateTime> {\n+        match Device::find_latest_active_by_user(&self.uuid, conn) {\n+            Some(device) => Some(device.updated_at),\n+            None => None\n+        }        \n+    }\n }\n \n impl Invitation {\n",
            "comment_added_diff": []
        },
        {
            "commit": "de86aa671eec9d08ab0e0d4cdd30584606882732",
            "timestamp": "2020-12-14T19:58:23+01:00",
            "author": "BlackDex",
            "commit_message": "Fix Key Rotation during password change\n\nWhen ticking the 'Also rotate my account's encryption key' box, the key\nrotated ciphers are posted after the change of password.\n\nDuring the password change the security stamp was reseted which made\nthe posted key's return an invalid auth. This reset is needed to prevent other clients from still being able to read/write.\n\nThis fixes this by adding a new database column which stores a stamp exception which includes the allowed route and the current security stamp before it gets reseted.\nWhen the security stamp check fails it will check if there is a stamp exception and tries to match the route and security stamp.\n\nCurrently it only allows for one exception. But if needed we could expand it by using a Vec<UserStampException> and change the functions accordingly.\n\nfixes #1240",
            "additions": 49,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -37,6 +37,7 @@ db_object! {\n         pub totp_recover: Option<String>,\n \n         pub security_stamp: String,\n+        pub stamp_exception: Option<String>,\n \n         pub equivalent_domains: String,\n         pub excluded_globals: String,\n@@ -60,6 +61,12 @@ enum UserStatus {\n     _Disabled = 2,\n }\n \n+#[derive(Serialize, Deserialize)]\n+pub struct UserStampException {\n+  pub route: String,\n+  pub security_stamp: String\n+}\n+\n /// Local methods\n impl User {\n     pub const CLIENT_KDF_TYPE_DEFAULT: i32 = 0; // PBKDF2: 0\n@@ -88,6 +95,7 @@ impl User {\n             password_iterations: CONFIG.password_iterations(),\n \n             security_stamp: crate::util::get_uuid(),\n+            stamp_exception: None,\n \n             password_hint: None,\n             private_key: None,\n@@ -121,14 +129,52 @@ impl User {\n         }\n     }\n \n-    pub fn set_password(&mut self, password: &str) {\n+    /// Set the password hash generated\n+    /// And resets the security_stamp. Based upon the allow_next_route the security_stamp will be different.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `password` - A str which contains a hashed version of the users master password.\n+    /// * `allow_next_route` - A Option<&str> with the function name of the next allowed (rocket) route.\n+    ///\n+    pub fn set_password(&mut self, password: &str, allow_next_route: Option<&str>) {\n         self.password_hash = crypto::hash_password(password.as_bytes(), &self.salt, self.password_iterations as u32);\n-        self.reset_security_stamp();\n+\n+        if let Some(route) = allow_next_route {\n+            self.set_stamp_exception(route);\n+        }\n+\n+        self.reset_security_stamp()\n     }\n \n     pub fn reset_security_stamp(&mut self) {\n         self.security_stamp = crate::util::get_uuid();\n     }\n+\n+    /// Set the stamp_exception to only allow a subsequent request matching a specific route using the current security-stamp.\n+    ///\n+    /// # Arguments\n+    /// * `route_exception` - A str with the function name of the next allowed (rocket) route.\n+    ///\n+    /// ### Future\n+    /// In the future it could be posible that we need more of these exception routes.\n+    /// In that case we could use an Vec<UserStampException> and add multiple exceptions.\n+    pub fn set_stamp_exception(&mut self, route_exception: &str) {\n+        let stamp_exception = UserStampException {\n+            route: route_exception.to_string(),\n+            security_stamp: self.security_stamp.to_string()\n+        };\n+        self.stamp_exception = Some(serde_json::to_string(&stamp_exception).unwrap_or_default());\n+    }\n+\n+    /// Resets the stamp_exception to prevent re-use of the previous security-stamp\n+    ///\n+    /// ### Future\n+    /// In the future it could be posible that we need more of these exception routes.\n+    /// In that case we could use an Vec<UserStampException> and add multiple exceptions.\n+    pub fn reset_stamp_exception(&mut self) {\n+        self.stamp_exception = None;\n+    }\n }\n \n use super::{Cipher, Device, Favorite, Folder, TwoFactor, UserOrgType, UserOrganization};\n@@ -295,7 +341,7 @@ impl User {\n         match Device::find_latest_active_by_user(&self.uuid, conn) {\n             Some(device) => Some(device.updated_at),\n             None => None\n-        }        \n+        }\n     }\n }\n \n",
            "comment_added_diff": [
                [
                    132,
                    "    /// Set the password hash generated"
                ],
                [
                    133,
                    "    /// And resets the security_stamp. Based upon the allow_next_route the security_stamp will be different."
                ],
                [
                    134,
                    "    ///"
                ],
                [
                    135,
                    "    /// # Arguments"
                ],
                [
                    136,
                    "    ///"
                ],
                [
                    137,
                    "    /// * `password` - A str which contains a hashed version of the users master password."
                ],
                [
                    138,
                    "    /// * `allow_next_route` - A Option<&str> with the function name of the next allowed (rocket) route."
                ],
                [
                    139,
                    "    ///"
                ],
                [
                    154,
                    "    /// Set the stamp_exception to only allow a subsequent request matching a specific route using the current security-stamp."
                ],
                [
                    155,
                    "    ///"
                ],
                [
                    156,
                    "    /// # Arguments"
                ],
                [
                    157,
                    "    /// * `route_exception` - A str with the function name of the next allowed (rocket) route."
                ],
                [
                    158,
                    "    ///"
                ],
                [
                    159,
                    "    /// ### Future"
                ],
                [
                    160,
                    "    /// In the future it could be posible that we need more of these exception routes."
                ],
                [
                    161,
                    "    /// In that case we could use an Vec<UserStampException> and add multiple exceptions."
                ],
                [
                    170,
                    "    /// Resets the stamp_exception to prevent re-use of the previous security-stamp"
                ],
                [
                    171,
                    "    ///"
                ],
                [
                    172,
                    "    /// ### Future"
                ],
                [
                    173,
                    "    /// In the future it could be posible that we need more of these exception routes."
                ],
                [
                    174,
                    "    /// In that case we could use an Vec<UserStampException> and add multiple exceptions."
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ use crate::crypto;\n use crate::CONFIG;\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, AsChangeset)]\n     #[table_name = \"users\"]\n     #[changeset_options(treat_none_as_null=\"true\")]\n     #[primary_key(uuid)]\n@@ -47,7 +47,7 @@ db_object! {\n     }\n \n \n-    #[derive(Debug, Identifiable, Queryable, Insertable)]\n+    #[derive(Identifiable, Queryable, Insertable)]\n     #[table_name = \"invitations\"]\n     #[primary_key(email)]\n     pub struct Invitation {\n",
            "comment_added_diff": []
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -177,7 +177,7 @@ impl User {\n     }\n }\n \n-use super::{Cipher, Device, Favorite, Folder, TwoFactor, UserOrgType, UserOrganization};\n+use super::{Cipher, Device, Favorite, Folder, Send, TwoFactor, UserOrgType, UserOrganization};\n use crate::db::DbConn;\n \n use crate::api::EmptyResult;\n@@ -263,6 +263,7 @@ impl User {\n             }\n         }\n \n+        Send::delete_all_by_user(&self.uuid, conn)?;\n         UserOrganization::delete_all_by_user(&self.uuid, conn)?;\n         Cipher::delete_all_by_user(&self.uuid, conn)?;\n         Favorite::delete_all_by_user(&self.uuid, conn)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -63,8 +63,8 @@ enum UserStatus {\n \n #[derive(Serialize, Deserialize)]\n pub struct UserStampException {\n-  pub route: String,\n-  pub security_stamp: String\n+    pub route: String,\n+    pub security_stamp: String,\n }\n \n /// Local methods\n@@ -162,7 +162,7 @@ impl User {\n     pub fn set_stamp_exception(&mut self, route_exception: &str) {\n         let stamp_exception = UserStampException {\n             route: route_exception.to_string(),\n-            security_stamp: self.security_stamp.to_string()\n+            security_stamp: self.security_stamp.to_string(),\n         };\n         self.stamp_exception = Some(serde_json::to_string(&stamp_exception).unwrap_or_default());\n     }\n@@ -341,7 +341,7 @@ impl User {\n     pub fn last_active(&self, conn: &DbConn) -> Option<NaiveDateTime> {\n         match Device::find_latest_active_by_user(&self.uuid, conn) {\n             Some(device) => Some(device.updated_at),\n-            None => None\n+            None => None,\n         }\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -348,7 +348,9 @@ impl User {\n \n impl Invitation {\n     pub const fn new(email: String) -> Self {\n-        Self { email }\n+        Self {\n+            email,\n+        }\n     }\n \n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -187,7 +187,7 @@ use crate::error::MapResult;\n impl User {\n     pub fn to_json(&self, conn: &DbConn) -> Value {\n         let orgs = UserOrganization::find_by_user(&self.uuid, conn);\n-        let orgs_json: Vec<Value> = orgs.iter().map(|c| c.to_json(&conn)).collect();\n+        let orgs_json: Vec<Value> = orgs.iter().map(|c| c.to_json(conn)).collect();\n         let twofactor_enabled = !TwoFactor::find_by_user(&self.uuid, conn).is_empty();\n \n         // TODO: Might want to save the status field in the DB\n@@ -398,8 +398,8 @@ impl Invitation {\n     }\n \n     pub fn take(mail: &str, conn: &DbConn) -> bool {\n-        match Self::find_by_mail(mail, &conn) {\n-            Some(invitation) => invitation.delete(&conn).is_ok(),\n+        match Self::find_by_mail(mail, conn) {\n+            Some(invitation) => invitation.delete(conn).is_ok(),\n             None => false,\n         }\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 13,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,4 @@\n-use chrono::{NaiveDateTime, Utc};\n+use chrono::{Duration, NaiveDateTime, Utc};\n use serde_json::Value;\n \n use crate::crypto;\n@@ -63,8 +63,9 @@ enum UserStatus {\n \n #[derive(Serialize, Deserialize)]\n pub struct UserStampException {\n-    pub route: String,\n+    pub routes: Vec<String>,\n     pub security_stamp: String,\n+    pub expire: i64,\n }\n \n /// Local methods\n@@ -135,9 +136,11 @@ impl User {\n     /// # Arguments\n     ///\n     /// * `password` - A str which contains a hashed version of the users master password.\n-    /// * `allow_next_route` - A Option<&str> with the function name of the next allowed (rocket) route.\n+    /// * `allow_next_route` - A Option<Vec<String>> with the function names of the next allowed (rocket) routes.\n+    ///                       These routes are able to use the previous stamp id for the next 2 minutes.\n+    ///                       After these 2 minutes this stamp will expire.\n     ///\n-    pub fn set_password(&mut self, password: &str, allow_next_route: Option<&str>) {\n+    pub fn set_password(&mut self, password: &str, allow_next_route: Option<Vec<String>>) {\n         self.password_hash = crypto::hash_password(password.as_bytes(), &self.salt, self.password_iterations as u32);\n \n         if let Some(route) = allow_next_route {\n@@ -154,24 +157,20 @@ impl User {\n     /// Set the stamp_exception to only allow a subsequent request matching a specific route using the current security-stamp.\n     ///\n     /// # Arguments\n-    /// * `route_exception` - A str with the function name of the next allowed (rocket) route.\n+    /// * `route_exception` - A Vec<String> with the function names of the next allowed (rocket) routes.\n+    ///                       These routes are able to use the previous stamp id for the next 2 minutes.\n+    ///                       After these 2 minutes this stamp will expire.\n     ///\n-    /// ### Future\n-    /// In the future it could be posible that we need more of these exception routes.\n-    /// In that case we could use an Vec<UserStampException> and add multiple exceptions.\n-    pub fn set_stamp_exception(&mut self, route_exception: &str) {\n+    pub fn set_stamp_exception(&mut self, route_exception: Vec<String>) {\n         let stamp_exception = UserStampException {\n-            route: route_exception.to_string(),\n+            routes: route_exception,\n             security_stamp: self.security_stamp.to_string(),\n+            expire: (Utc::now().naive_utc() + Duration::minutes(2)).timestamp(),\n         };\n         self.stamp_exception = Some(serde_json::to_string(&stamp_exception).unwrap_or_default());\n     }\n \n     /// Resets the stamp_exception to prevent re-use of the previous security-stamp\n-    ///\n-    /// ### Future\n-    /// In the future it could be posible that we need more of these exception routes.\n-    /// In that case we could use an Vec<UserStampException> and add multiple exceptions.\n     pub fn reset_stamp_exception(&mut self) {\n         self.stamp_exception = None;\n     }\n",
            "comment_added_diff": [
                [
                    139,
                    "    /// * `allow_next_route` - A Option<Vec<String>> with the function names of the next allowed (rocket) routes."
                ],
                [
                    140,
                    "    ///                       These routes are able to use the previous stamp id for the next 2 minutes."
                ],
                [
                    141,
                    "    ///                       After these 2 minutes this stamp will expire."
                ],
                [
                    160,
                    "    /// * `route_exception` - A Vec<String> with the function names of the next allowed (rocket) routes."
                ],
                [
                    161,
                    "    ///                       These routes are able to use the previous stamp id for the next 2 minutes."
                ],
                [
                    162,
                    "    ///                       After these 2 minutes this stamp will expire."
                ]
            ]
        },
        {
            "commit": "58b046fd10f4cd953ba5a0e5a816df480f98061f",
            "timestamp": "2021-08-21T10:36:08+02:00",
            "author": "BlackDex",
            "commit_message": "Fix syncing with Bitwarden Desktop v1.28.0\n\nSyncing with the latest desktop client (v1.28.0) fails because it expects some json key/values to be there.\n\nThis PR adds those key/value pairs.\n\nResolves #1924",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -210,7 +210,10 @@ impl User {\n             \"PrivateKey\": self.private_key,\n             \"SecurityStamp\": self.security_stamp,\n             \"Organizations\": orgs_json,\n-            \"Object\": \"profile\"\n+            \"Providers\": [],\n+            \"ProviderOrganizations\": [],\n+            \"ForcePasswordReset\": false,\n+            \"Object\": \"profile\",\n         })\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "10d5c7738afad9f81958e24baa923530314a587f",
            "timestamp": "2021-09-09T13:52:39+02:00",
            "author": "BlackDex",
            "commit_message": "Fix issue when using uppercase chars in emails\n\nIn the case when SMTP is disabled and.\nwhen inviting new users either via the admin interface or into an\norganization and using uppercase letters, this would fail for those\nusers to be able to register since the checks which were done are\ncase-sensitive and never matched.\n\nThis PR fixes that issue by ensuring everything is lowercase.\nFixes #1963",
            "additions": 4,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -73,9 +73,9 @@ impl User {\n     pub const CLIENT_KDF_TYPE_DEFAULT: i32 = 0; // PBKDF2: 0\n     pub const CLIENT_KDF_ITER_DEFAULT: i32 = 100_000;\n \n-    pub fn new(mail: String) -> Self {\n+    pub fn new(email: String) -> Self {\n         let now = Utc::now().naive_utc();\n-        let email = mail.to_lowercase();\n+        let email = email.to_lowercase();\n \n         Self {\n             uuid: crate::util::get_uuid(),\n@@ -349,7 +349,8 @@ impl User {\n }\n \n impl Invitation {\n-    pub const fn new(email: String) -> Self {\n+    pub fn new(email: String) -> Self {\n+        let email = email.to_lowercase();\n         Self {\n             email,\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -176,7 +176,7 @@ impl User {\n     }\n }\n \n-use super::{Cipher, Device, Favorite, Folder, Send, TwoFactor, UserOrgType, UserOrganization};\n+use super::{Cipher, Device, EmergencyAccess, Favorite, Folder, Send, TwoFactor, UserOrgType, UserOrganization};\n use crate::db::DbConn;\n \n use crate::api::EmptyResult;\n@@ -266,6 +266,7 @@ impl User {\n         }\n \n         Send::delete_all_by_user(&self.uuid, conn)?;\n+        EmergencyAccess::delete_all_by_user(&self.uuid, conn)?;\n         UserOrganization::delete_all_by_user(&self.uuid, conn)?;\n         Cipher::delete_all_by_user(&self.uuid, conn)?;\n         Favorite::delete_all_by_user(&self.uuid, conn)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -185,7 +185,7 @@ use crate::error::MapResult;\n /// Database methods\n impl User {\n     pub fn to_json(&self, conn: &DbConn) -> Value {\n-        let orgs = UserOrganization::find_by_user(&self.uuid, conn);\n+        let orgs = UserOrganization::find_confirmed_by_user(&self.uuid, conn);\n         let orgs_json: Vec<Value> = orgs.iter().map(|c| c.to_json(conn)).collect();\n         let twofactor_enabled = !TwoFactor::find_by_user(&self.uuid, conn).is_empty();\n \n@@ -256,7 +256,7 @@ impl User {\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        for user_org in UserOrganization::find_by_user(&self.uuid, conn) {\n+        for user_org in UserOrganization::find_confirmed_by_user(&self.uuid, conn) {\n             if user_org.atype == UserOrgType::Owner {\n                 let owner_type = UserOrgType::Owner as i32;\n                 if UserOrganization::find_by_org_and_type(&user_org.org_uuid, owner_type, conn).len() <= 1 {\n",
            "comment_added_diff": []
        }
    ],
    "change_email.hbs": [],
    "change_email.html.hbs": [],
    "delete_account.hbs": [],
    "delete_account.html.hbs": [],
    "pw_hint_none.hbs": [],
    "pw_hint_none.html.hbs": [],
    "pw_hint_some.hbs": [],
    "pw_hint_some.html.hbs": [],
    "verify_email.hbs": [],
    "verify_email.html.hbs": [],
    "welcome.hbs": [],
    "welcome.html.hbs": [],
    "welcome_must_verify.hbs": [],
    "welcome_must_verify.html.hbs": [],
    "admin.rs": [
        {
            "commit": "0d32179d07de6533bf03871d4d102f5ff5c0e60a",
            "timestamp": "2019-12-01T21:15:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Logout button in admin page",
            "additions": 9,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -26,6 +26,7 @@ pub fn routes() -> Vec<Route> {\n         post_admin_login,\n         admin_page,\n         invite_user,\n+        logout,\n         delete_user,\n         deauth_user,\n         remove_2fa,\n@@ -109,6 +110,7 @@ struct AdminTemplateData {\n     users: Vec<Value>,\n     config: Value,\n     can_backup: bool,\n+    logged_in: bool\n }\n \n impl AdminTemplateData {\n@@ -119,6 +121,7 @@ impl AdminTemplateData {\n             users,\n             config: CONFIG.prepare_json(),\n             can_backup: *CAN_BACKUP,\n+            logged_in: true\n         }\n     }\n \n@@ -166,6 +169,12 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n     }\n }\n \n+#[get(\"/logout\")]\n+fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n+    cookies.remove(Cookie::named(COOKIE_NAME));\n+    Ok(Redirect::to(ADMIN_PATH))\n+}\n+\n #[get(\"/users\")]\n fn get_users(_token: AdminToken, conn: DbConn) -> JsonResult {\n     let users = User::get_all(&conn);\n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -110,7 +110,7 @@ struct AdminTemplateData {\n     users: Vec<Value>,\n     config: Value,\n     can_backup: bool,\n-    logged_in: bool\n+    logged_in: bool,\n }\n \n impl AdminTemplateData {\n@@ -121,7 +121,7 @@ impl AdminTemplateData {\n             users,\n             config: CONFIG.prepare_json(),\n             can_backup: *CAN_BACKUP,\n-            logged_in: true\n+            logged_in: true,\n         }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "8867626de898bb8416ed8319806b1c220d57dcb1",
            "timestamp": "2020-02-04T22:14:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add option to change invitation org name, fixes #825\nAdd option to allow additional iframe ancestors, fixes #843\nSort the rocket routes before printing them",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -161,8 +161,7 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n     user.save(&conn)?;\n \n     if CONFIG.mail_enabled() {\n-        let org_name = \"bitwarden_rs\";\n-        mail::send_invite(&user.email, &user.uuid, None, None, &org_name, None)\n+        mail::send_invite(&user.email, &user.uuid, None, None, &CONFIG.invitation_org_name(), None)\n     } else {\n         let invitation = Invitation::new(data.email);\n         invitation.save(&conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "0a72c4b6db4e254d7579b8dc3bb6e9e3c067947d",
            "timestamp": "2020-02-16T15:01:07+00:00",
            "author": "Miroslav Prasil",
            "commit_message": "Do not disable invitations via admin API\n\nThis was brought up today:\n\nhttps://github.com/dani-garcia/bitwarden_rs/issues/752#issuecomment-586715073\n\nI don't think it makes much sense in checking whether admin has the\nright to send invitation as admin can change the setting anyway.\n\nRemoving the condition allows users to forbid regular users from\ninviting new users to server while still preserving the option to do so\nvia the admin API.",
            "additions": 0,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -153,10 +153,6 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n         err!(\"User already exists\")\n     }\n \n-    if !CONFIG.invitations_allowed() {\n-        err!(\"Invitations are not allowed\")\n-    }\n-\n     let mut user = User::new(email);\n     user.save(&conn)?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 8,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -52,6 +52,10 @@ const ADMIN_PATH: &str = \"/admin\";\n const BASE_TEMPLATE: &str = \"admin/base\";\n const VERSION: Option<&str> = option_env!(\"GIT_VERSION\");\n \n+fn admin_path() -> String {\n+    format!(\"{}{}\", CONFIG.domain_path(), ADMIN_PATH)\n+}\n+\n #[get(\"/\", rank = 2)]\n fn admin_login(flash: Option<FlashMessage>) -> ApiResult<Html<String>> {\n     // If there is an error, show it\n@@ -76,7 +80,7 @@ fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -\n     if !_validate_token(&data.token) {\n         error!(\"Invalid admin token. IP: {}\", ip.ip);\n         Err(Flash::error(\n-            Redirect::to(ADMIN_PATH),\n+            Redirect::to(admin_path()),\n             \"Invalid admin token, please try again.\",\n         ))\n     } else {\n@@ -85,14 +89,14 @@ fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -\n         let jwt = encode_jwt(&claims);\n \n         let cookie = Cookie::build(COOKIE_NAME, jwt)\n-            .path(ADMIN_PATH)\n+            .path(admin_path())\n             .max_age(chrono::Duration::minutes(20))\n             .same_site(SameSite::Strict)\n             .http_only(true)\n             .finish();\n \n         cookies.add(cookie);\n-        Ok(Redirect::to(ADMIN_PATH))\n+        Ok(Redirect::to(admin_path()))\n     }\n }\n \n@@ -167,7 +171,7 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n #[get(\"/logout\")]\n fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n     cookies.remove(Cookie::named(COOKIE_NAME));\n-    Ok(Redirect::to(ADMIN_PATH))\n+    Ok(Redirect::to(admin_path()))\n }\n \n #[get(\"/users\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "2f4a9865e175e3ce05d724b4b8ea1588cac80749",
            "timestamp": "2020-02-22T17:49:33+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Use absolute paths in the admin page",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -60,7 +60,7 @@ fn admin_path() -> String {\n fn admin_login(flash: Option<FlashMessage>) -> ApiResult<Html<String>> {\n     // If there is an error, show it\n     let msg = flash.map(|msg| format!(\"{}: {}\", msg.name(), msg.msg()));\n-    let json = json!({\"page_content\": \"admin/login\", \"version\": VERSION, \"error\": msg});\n+    let json = json!({\"page_content\": \"admin/login\", \"version\": VERSION, \"error\": msg, \"urlpath\": CONFIG.domain_path()});\n \n     // Return the page\n     let text = CONFIG.render_template(BASE_TEMPLATE, &json)?;\n@@ -115,6 +115,7 @@ struct AdminTemplateData {\n     config: Value,\n     can_backup: bool,\n     logged_in: bool,\n+    urlpath: String,\n }\n \n impl AdminTemplateData {\n@@ -126,6 +127,7 @@ impl AdminTemplateData {\n             config: CONFIG.prepare_json(),\n             can_backup: *CAN_BACKUP,\n             logged_in: true,\n+            urlpath: CONFIG.domain_path(),\n         }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "5f61607419fb329442ebbdd98832cb14349d33ab",
            "timestamp": "2020-02-26T11:02:22+01:00",
            "author": "BlackDex",
            "commit_message": "Added SMTP test button in the admin gui\n\n- Added a test button for checking the e-mail settings.\n- Fixed a bug with the _post JavaScript function:\n  A function was overwriten with a variable and errors were not handled\ncorrectly like a 500 for example.",
            "additions": 13,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -34,6 +34,7 @@ pub fn routes() -> Vec<Route> {\n         post_config,\n         delete_config,\n         backup_db,\n+        test_smtp,\n     ]\n }\n \n@@ -164,6 +165,18 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n     }\n }\n \n+#[post(\"/test/smtp\", data = \"<data>\")]\n+fn test_smtp(data: Json<InviteData>, _token: AdminToken) -> EmptyResult {\n+    let data: InviteData = data.into_inner();\n+    let email = data.email.clone();\n+\n+    if CONFIG.mail_enabled() {\n+        mail::send_test(&email)\n+    } else {\n+        err!(\"Mail is not enabled\")\n+    }\n+}\n+\n #[get(\"/logout\")]\n fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n     cookies.remove(Cookie::named(COOKIE_NAME));\n",
            "comment_added_diff": []
        },
        {
            "commit": "5a974c7b944a66adf72d4615004b894ba16ea6bd",
            "timestamp": "2020-02-26T16:49:56+01:00",
            "author": "BlackDex",
            "commit_message": "Added SMTP test button in the admin gui\n\n- Added a test button for checking the e-mail settings.\n- Fixed a bug with the _post JavaScript function:\n  A function was overwriten with a variable and errors were not handled\ncorrectly like a 500 for example.",
            "additions": 13,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -34,6 +34,7 @@ pub fn routes() -> Vec<Route> {\n         post_config,\n         delete_config,\n         backup_db,\n+        test_smtp,\n     ]\n }\n \n@@ -170,6 +171,18 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n     }\n }\n \n+#[post(\"/test/smtp\", data = \"<data>\")]\n+fn test_smtp(data: Json<InviteData>, _token: AdminToken) -> EmptyResult {\n+    let data: InviteData = data.into_inner();\n+    let email = data.email.clone();\n+\n+    if CONFIG.mail_enabled() {\n+        mail::send_test(&email)\n+    } else {\n+        err!(\"Mail is not enabled\")\n+    }\n+}\n+\n #[get(\"/logout\")]\n fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n     cookies.remove(Cookie::named(COOKIE_NAME));\n",
            "comment_added_diff": []
        },
        {
            "commit": "70f3ab8ec3d6ccfd8ec8c71c888459de484d9b43",
            "timestamp": "2020-03-09T22:04:03+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Migrate lazy_static to once_cell, less macro magic and slightly faster",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -1,3 +1,4 @@\n+use once_cell::sync::Lazy;\n use serde_json::Value;\n use std::process::Command;\n \n@@ -38,9 +39,8 @@ pub fn routes() -> Vec<Route> {\n     ]\n }\n \n-lazy_static! {\n-    static ref CAN_BACKUP: bool = cfg!(feature = \"sqlite\") && Command::new(\"sqlite3\").arg(\"-version\").status().is_ok();\n-}\n+static CAN_BACKUP: Lazy<bool> =\n+    Lazy::new(|| cfg!(feature = \"sqlite\") && Command::new(\"sqlite3\").arg(\"-version\").status().is_ok());\n \n #[get(\"/\")]\n fn admin_disabled() -> &'static str {\n",
            "comment_added_diff": []
        },
        {
            "commit": "37b212427c80a1c56db748510ebe6dee4d218b4a",
            "timestamp": "2020-03-16T16:38:00+01:00",
            "author": "BlackDex",
            "commit_message": "Updated jsonwebtoken\n\nUpdated to the latest version of jsonwebtoken.\nSome small code changes to match the new versions.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -91,7 +91,7 @@ fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -\n \n         let cookie = Cookie::build(COOKIE_NAME, jwt)\n             .path(admin_path())\n-            .max_age(chrono::Duration::minutes(20))\n+            .max_age(time::Duration::minutes(20))\n             .same_site(SameSite::Strict)\n             .http_only(true)\n             .finish();\n",
            "comment_added_diff": []
        },
        {
            "commit": "7a6a3e4160d2a472febd2122248f21ae7dfb0c90",
            "timestamp": "2020-03-22T16:13:34+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Set the cargo version and allow changing it during build time with BWRS_VERSION.\nAlso renamed GIT_VERSION because that's not the only source anymore.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -51,7 +51,7 @@ const COOKIE_NAME: &str = \"BWRS_ADMIN\";\n const ADMIN_PATH: &str = \"/admin\";\n \n const BASE_TEMPLATE: &str = \"admin/base\";\n-const VERSION: Option<&str> = option_env!(\"GIT_VERSION\");\n+const VERSION: Option<&str> = option_env!(\"BWRS_VERSION\");\n \n fn admin_path() -> String {\n     format!(\"{}{}\", CONFIG.domain_path(), ADMIN_PATH)\n",
            "comment_added_diff": []
        },
        {
            "commit": "0a68de6c24a51e4e221ae5afb43d2cfc6b48dac1",
            "timestamp": "2020-04-09T20:55:08-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Warn on empty `ADMIN_TOKEN` instead of bailing out\n\nThe admin page will still be disabled.\n\nFixes #849.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -17,7 +17,7 @@ use crate::mail;\n use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n-    if CONFIG.admin_token().is_none() && !CONFIG.disable_admin_token() {\n+    if !CONFIG.disable_admin_token() && !CONFIG.is_admin_token_set() {\n         return routes![admin_disabled];\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "819d5e2dc8f5a32b5989fae34cd792eba37f82c8",
            "timestamp": "2020-05-01T00:31:47-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Use absolute URIs for admin page redirects\n\nThis is technically required per RFC 2616 (HTTP/1.1); some proxies will\nrewrite a plain `/admin` path to an unexpected URL otherwise.",
            "additions": 9,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -57,6 +57,12 @@ fn admin_path() -> String {\n     format!(\"{}{}\", CONFIG.domain_path(), ADMIN_PATH)\n }\n \n+/// Used for `Location` response headers, which must specify an absolute URI\n+/// (see https://tools.ietf.org/html/rfc2616#section-14.30).\n+fn admin_url() -> String {\n+    format!(\"{}{}\", CONFIG.domain(), ADMIN_PATH)\n+}\n+\n #[get(\"/\", rank = 2)]\n fn admin_login(flash: Option<FlashMessage>) -> ApiResult<Html<String>> {\n     // If there is an error, show it\n@@ -81,7 +87,7 @@ fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -\n     if !_validate_token(&data.token) {\n         error!(\"Invalid admin token. IP: {}\", ip.ip);\n         Err(Flash::error(\n-            Redirect::to(admin_path()),\n+            Redirect::to(admin_url()),\n             \"Invalid admin token, please try again.\",\n         ))\n     } else {\n@@ -97,7 +103,7 @@ fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -\n             .finish();\n \n         cookies.add(cookie);\n-        Ok(Redirect::to(admin_path()))\n+        Ok(Redirect::to(admin_url()))\n     }\n }\n \n@@ -186,7 +192,7 @@ fn test_smtp(data: Json<InviteData>, _token: AdminToken) -> EmptyResult {\n #[get(\"/logout\")]\n fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n     cookies.remove(Cookie::named(COOKIE_NAME));\n-    Ok(Redirect::to(admin_path()))\n+    Ok(Redirect::to(admin_url()))\n }\n \n #[get(\"/users\")]\n",
            "comment_added_diff": [
                [
                    60,
                    "/// Used for `Location` response headers, which must specify an absolute URI"
                ],
                [
                    61,
                    "/// (see https://tools.ietf.org/html/rfc2616#section-14.30)."
                ]
            ]
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -174,10 +174,9 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n #[post(\"/test/smtp\", data = \"<data>\")]\n fn test_smtp(data: Json<InviteData>, _token: AdminToken) -> EmptyResult {\n     let data: InviteData = data.into_inner();\n-    let email = data.email.clone();\n \n     if CONFIG.mail_enabled() {\n-        mail::send_test(&email)\n+        mail::send_test(&data.email)\n     } else {\n         err!(\"Mail is not enabled\")\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "3c66deb5cc7a4387e4176d2a5bdd3f321f09a6bd",
            "timestamp": "2020-05-28T10:46:25+02:00",
            "author": "BlackDex",
            "commit_message": "Redesign of the admin interface.\n\nMain changes:\n - Splitted up settings and users into two separate pages.\n - Added verified shield when the e-mail address has been verified.\n - Added the amount of personal items in the database to the users overview.\n - Added Organizations and Diagnostics pages.\n   - Shows if DNS resolving works.\n   - Shows if there is a posible time drift.\n   - Shows current versions of server and web-vault.\n - Optimized logo-gray.png using optipng\n\nItems which can be added later:\n - Amount of cipher items accessible for a user, not only his personal items.\n - Amount of users per Org\n - Version update check in the diagnostics overview.\n - Copy/Pasteable runtime config which has sensitive data changed or removed for support questions either on the forum or github issues.\n - Option to delete Orgs and all its passwords (when there are no members anymore).\n - Etc....",
            "additions": 117,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -23,7 +23,7 @@ pub fn routes() -> Vec<Route> {\n \n     routes![\n         admin_login,\n-        get_users,\n+        get_users_json,\n         post_admin_login,\n         admin_page,\n         invite_user,\n@@ -36,6 +36,9 @@ pub fn routes() -> Vec<Route> {\n         delete_config,\n         backup_db,\n         test_smtp,\n+        users_overview,\n+        organizations_overview,\n+        diagnostics,\n     ]\n }\n \n@@ -118,7 +121,9 @@ fn _validate_token(token: &str) -> bool {\n struct AdminTemplateData {\n     page_content: String,\n     version: Option<&'static str>,\n-    users: Vec<Value>,\n+    users: Option<Vec<Value>>,\n+    organizations: Option<Vec<Value>>,\n+    diagnostics: Option<Value>,\n     config: Value,\n     can_backup: bool,\n     logged_in: bool,\n@@ -126,15 +131,59 @@ struct AdminTemplateData {\n }\n \n impl AdminTemplateData {\n-    fn new(users: Vec<Value>) -> Self {\n+    fn new() -> Self {\n         Self {\n-            page_content: String::from(\"admin/page\"),\n+            page_content: String::from(\"admin/settings\"),\n             version: VERSION,\n-            users,\n             config: CONFIG.prepare_json(),\n             can_backup: *CAN_BACKUP,\n             logged_in: true,\n             urlpath: CONFIG.domain_path(),\n+            users: None,\n+            organizations: None,\n+            diagnostics: None,\n+        }\n+    }\n+\n+    fn users(users: Vec<Value>) -> Self {\n+        Self {\n+            page_content: String::from(\"admin/users\"),\n+            version: VERSION,\n+            users: Some(users),\n+            config: CONFIG.prepare_json(),\n+            can_backup: *CAN_BACKUP,\n+            logged_in: true,\n+            urlpath: CONFIG.domain_path(),\n+            organizations: None,\n+            diagnostics: None,\n+        }\n+    }\n+\n+    fn organizations(organizations: Vec<Value>) -> Self {\n+        Self {\n+            page_content: String::from(\"admin/organizations\"),\n+            version: VERSION,\n+            organizations: Some(organizations),\n+            config: CONFIG.prepare_json(),\n+            can_backup: *CAN_BACKUP,\n+            logged_in: true,\n+            urlpath: CONFIG.domain_path(),\n+            users: None,\n+            diagnostics: None,\n+        }\n+    }\n+\n+    fn diagnostics(diagnostics: Value) -> Self {\n+        Self {\n+            page_content: String::from(\"admin/diagnostics\"),\n+            version: VERSION,\n+            organizations: None,\n+            config: CONFIG.prepare_json(),\n+            can_backup: *CAN_BACKUP,\n+            logged_in: true,\n+            urlpath: CONFIG.domain_path(),\n+            users: None,\n+            diagnostics: Some(diagnostics),\n         }\n     }\n \n@@ -144,11 +193,8 @@ impl AdminTemplateData {\n }\n \n #[get(\"/\", rank = 1)]\n-fn admin_page(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n-    let users = User::get_all(&conn);\n-    let users_json: Vec<Value> = users.iter().map(|u| u.to_json(&conn)).collect();\n-\n-    let text = AdminTemplateData::new(users_json).render()?;\n+fn admin_page(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n+    let text = AdminTemplateData::new().render()?;\n     Ok(Html(text))\n }\n \n@@ -195,13 +241,29 @@ fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n }\n \n #[get(\"/users\")]\n-fn get_users(_token: AdminToken, conn: DbConn) -> JsonResult {\n+fn get_users_json(_token: AdminToken, conn: DbConn) -> JsonResult {\n     let users = User::get_all(&conn);\n     let users_json: Vec<Value> = users.iter().map(|u| u.to_json(&conn)).collect();\n \n     Ok(Json(Value::Array(users_json)))\n }\n \n+#[get(\"/users/overview\")]\n+fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n+    let users = User::get_all(&conn);\n+    let users_json: Vec<Value> = users.iter()\n+    .map(|u| {\n+        let mut usr = u.to_json(&conn);\n+        if let Some(ciphers) = Cipher::count_owned_by_user(&u.uuid, &conn) {\n+            usr[\"cipher_count\"] = json!(ciphers);\n+        };\n+        usr\n+    }).collect();\n+\n+    let text = AdminTemplateData::users(users_json).render()?;\n+    Ok(Html(text))\n+}\n+\n #[post(\"/users/<uuid>/delete\")]\n fn delete_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n     let user = match User::find_by_uuid(&uuid, &conn) {\n@@ -242,6 +304,50 @@ fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n     User::update_all_revisions(&conn)\n }\n \n+#[get(\"/organizations/overview\")]\n+fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n+    let organizations = Organization::get_all(&conn);\n+    let organizations_json: Vec<Value> = organizations.iter().map(|o| o.to_json()).collect();\n+\n+    let text = AdminTemplateData::organizations(organizations_json).render()?;\n+    Ok(Html(text))\n+}\n+\n+#[derive(Deserialize, Serialize, Debug)]\n+#[allow(non_snake_case)]\n+pub struct WebVaultVersion {\n+    version: String,\n+}\n+\n+#[get(\"/diagnostics\")]\n+fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n+    use std::net::ToSocketAddrs;\n+    use chrono::prelude::*;\n+    use crate::util::read_file_string;\n+\n+    let vault_version_path = format!(\"{}/{}\", CONFIG.web_vault_folder(), \"version.json\");\n+    let vault_version_str = read_file_string(&vault_version_path)?;\n+    let web_vault_version: WebVaultVersion = serde_json::from_str(&vault_version_str)?;\n+\n+    let github_ips = (\"github.com\", 0).to_socket_addrs().map(|mut i| i.next());\n+    let dns_resolved = match github_ips {\n+        Ok(Some(a)) => a.ip().to_string() ,\n+        _ => \"Could not resolve domain name.\".to_string(),\n+    };\n+\n+    let dt = Utc::now();\n+    let server_time = dt.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n+\n+    let diagnostics_json = json!({\n+        \"dns_resolved\": dns_resolved,\n+        \"server_time\": server_time,\n+        \"web_vault_version\": web_vault_version.version,\n+    });\n+\n+    let text = AdminTemplateData::diagnostics(diagnostics_json).render()?;\n+    Ok(Html(text))\n+}\n+\n #[post(\"/config\", data = \"<data>\")]\n fn post_config(data: Json<ConfigBuilder>, _token: AdminToken) -> EmptyResult {\n     let data: ConfigBuilder = data.into_inner();\n",
            "comment_added_diff": []
        },
        {
            "commit": "b6fde857a74b24cbc71631468b13656f01e370c7",
            "timestamp": "2020-05-28T20:25:25+02:00",
            "author": "BlackDex",
            "commit_message": "Added version check to diagnostics\n\n- Added a version check based upon the github api information.",
            "additions": 43,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -319,6 +319,24 @@ pub struct WebVaultVersion {\n     version: String,\n }\n \n+fn get_github_api(url: &str) -> Result<Value, Error> {\n+    use reqwest::{header::USER_AGENT, blocking::Client};\n+    let github_api = Client::builder().build()?;\n+\n+    let res = github_api\n+        .get(url)\n+        .header(USER_AGENT, \"Bitwarden_RS\")\n+        .send()?;\n+\n+    let res_status = res.status();\n+    if res_status != 200 {\n+        error!(\"Could not retrieve '{}', response code: {}\", url, res_status);\n+    }\n+\n+    let value: Value = res.error_for_status()?.json()?;\n+    Ok(value)\n+}\n+\n #[get(\"/diagnostics\")]\n fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n     use std::net::ToSocketAddrs;\n@@ -331,10 +349,31 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n \n     let github_ips = (\"github.com\", 0).to_socket_addrs().map(|mut i| i.next());\n     let dns_resolved = match github_ips {\n-        Ok(Some(a)) => a.ip().to_string() ,\n+        Ok(Some(a)) => a.ip().to_string(),\n         _ => \"Could not resolve domain name.\".to_string(),\n     };\n \n+    let bitwarden_rs_releases = get_github_api(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\");\n+    let latest_release = match &bitwarden_rs_releases {\n+        Ok(j) => j[\"tag_name\"].as_str().unwrap(),\n+        _ => \"-\",\n+    };\n+\n+    let bitwarden_rs_commits = get_github_api(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\");\n+    let mut latest_commit = match &bitwarden_rs_commits {\n+        Ok(j) => j[\"sha\"].as_str().unwrap(),\n+        _ => \"-\",\n+    };\n+    if latest_commit.len() >= 8 {\n+        latest_commit = &latest_commit[..8];\n+    }\n+\n+    let bw_web_builds_releases = get_github_api(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\");\n+    let latest_web_build = match &bw_web_builds_releases {\n+        Ok(j) => j[\"tag_name\"].as_str().unwrap(),\n+        _ => \"-\",\n+    };\n+\n     let dt = Utc::now();\n     let server_time = dt.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n \n@@ -342,6 +381,9 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n         \"dns_resolved\": dns_resolved,\n         \"server_time\": server_time,\n         \"web_vault_version\": web_vault_version.version,\n+        \"latest_release\": latest_release,\n+        \"latest_commit\": latest_commit,\n+        \"latest_web_build\": latest_web_build.replace(\"v\", \"\"),\n     });\n \n     let text = AdminTemplateData::diagnostics(diagnostics_json).render()?;\n",
            "comment_added_diff": [
                [
                    356,
                    "    let bitwarden_rs_releases = get_github_api(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\");"
                ],
                [
                    362,
                    "    let bitwarden_rs_commits = get_github_api(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\");"
                ],
                [
                    371,
                    "    let bw_web_builds_releases = get_github_api(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\");"
                ]
            ]
        },
        {
            "commit": "39d1a097044c8262771eca2d0fb49cf6743bcf17",
            "timestamp": "2020-05-30T01:06:40-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Avoid double-slashes in the admin URL",
            "additions": 3,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -63,7 +63,9 @@ fn admin_path() -> String {\n /// Used for `Location` response headers, which must specify an absolute URI\n /// (see https://tools.ietf.org/html/rfc2616#section-14.30).\n fn admin_url() -> String {\n-    format!(\"{}{}\", CONFIG.domain(), ADMIN_PATH)\n+    // Don't use CONFIG.domain() directly, since the user may want to keep a\n+    // trailing slash there, particularly when running under a subpath.\n+    format!(\"{}{}{}\", CONFIG.domain_origin(), CONFIG.domain_path(), ADMIN_PATH)\n }\n \n #[get(\"/\", rank = 2)]\n",
            "comment_added_diff": [
                [
                    66,
                    "    // Don't use CONFIG.domain() directly, since the user may want to keep a"
                ],
                [
                    67,
                    "    // trailing slash there, particularly when running under a subpath."
                ]
            ]
        },
        {
            "commit": "5c54dfee3adabe4e070dd02020ac3d96972bdec0",
            "timestamp": "2020-06-03T17:07:32+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed an issue when DNS resolving fails.\n\nIn the event of a failed DNS Resolving checking for new versions will\ncause a huge delay, and in the end a timeout when loading the page.\n\n- Check if DNS resolving failed, if that is the case, do not check for\n  new versions\n- Changed `fn get_github_api` to make use of structs\n- Added a timeout of 10 seconds for the version check requests\n- Moved the \"Unknown\" lables to the \"Latest\" lable",
            "additions": 50,
            "deletions": 39,
            "change_type": "MODIFY",
            "diff": "@@ -1,5 +1,6 @@\n use once_cell::sync::Lazy;\n use serde_json::Value;\n+use serde::de::DeserializeOwned;\n use std::process::Command;\n \n use rocket::http::{Cookie, Cookies, SameSite};\n@@ -315,28 +316,34 @@ fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<St\n     Ok(Html(text))\n }\n \n-#[derive(Deserialize, Serialize, Debug)]\n-#[allow(non_snake_case)]\n-pub struct WebVaultVersion {\n+#[derive(Deserialize)]\n+struct WebVaultVersion {\n     version: String,\n }\n \n-fn get_github_api(url: &str) -> Result<Value, Error> {\n+#[derive(Deserialize)]\n+struct GitRelease {\n+    tag_name: String,\n+}\n+\n+#[derive(Deserialize)]\n+struct GitCommit {\n+    sha: String,\n+}\n+\n+fn get_github_api<T: DeserializeOwned>(url: &str) -> Result<T, Error> {\n     use reqwest::{header::USER_AGENT, blocking::Client};\n+    use std::time::Duration;\n     let github_api = Client::builder().build()?;\n \n-    let res = github_api\n-        .get(url)\n+    Ok(\n+        github_api.get(url)\n+        .timeout(Duration::from_secs(10))\n         .header(USER_AGENT, \"Bitwarden_RS\")\n-        .send()?;\n-\n-    let res_status = res.status();\n-    if res_status != 200 {\n-        error!(\"Could not retrieve '{}', response code: {}\", url, res_status);\n-    }\n-\n-    let value: Value = res.error_for_status()?.json()?;\n-    Ok(value)\n+        .send()?\n+        .error_for_status()?\n+        .json::<T>()?\n+    )\n }\n \n #[get(\"/diagnostics\")]\n@@ -350,32 +357,36 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n     let web_vault_version: WebVaultVersion = serde_json::from_str(&vault_version_str)?;\n \n     let github_ips = (\"github.com\", 0).to_socket_addrs().map(|mut i| i.next());\n-    let dns_resolved = match github_ips {\n-        Ok(Some(a)) => a.ip().to_string(),\n-        _ => \"Could not resolve domain name.\".to_string(),\n+    let (dns_resolved, dns_ok) = match github_ips {\n+        Ok(Some(a)) => (a.ip().to_string(), true),\n+        _ => (\"Could not resolve domain name.\".to_string(), false),\n     };\n \n-    let bitwarden_rs_releases = get_github_api(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\");\n-    let latest_release = match &bitwarden_rs_releases {\n-        Ok(j) => j[\"tag_name\"].as_str().unwrap(),\n-        _ => \"-\",\n-    };\n-\n-    let bitwarden_rs_commits = get_github_api(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\");\n-    let mut latest_commit = match &bitwarden_rs_commits {\n-        Ok(j) => j[\"sha\"].as_str().unwrap(),\n-        _ => \"-\",\n-    };\n-    if latest_commit.len() >= 8 {\n-        latest_commit = &latest_commit[..8];\n-    }\n-\n-    let bw_web_builds_releases = get_github_api(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\");\n-    let latest_web_build = match &bw_web_builds_releases {\n-        Ok(j) => j[\"tag_name\"].as_str().unwrap(),\n-        _ => \"-\",\n+    // If the DNS Check failed, do not even attempt to check for new versions since we were not able to resolve github.com\n+    let (latest_release, latest_commit, latest_web_build) = if dns_ok {\n+        (\n+            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\") {\n+                Ok(r) => r.tag_name,\n+                _ => \"-\".to_string()\n+            },\n+            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\") {\n+                Ok(mut c) => {\n+                    c.sha.truncate(8);\n+                    c.sha\n+                },\n+                _ => \"-\".to_string()\n+            },\n+            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {\n+                Ok(r) => r.tag_name.trim_start_matches('v').to_string(),\n+                _ => \"-\".to_string()\n+            },\n+        )\n+    } else {\n+        (\"-\".to_string(), \"-\".to_string(), \"-\".to_string())\n     };\n-\n+    \n+    // Run the date check as the last item right before filling the json.\n+    // This should ensure that the time difference between the browser and the server is as minimal as possible.\n     let dt = Utc::now();\n     let server_time = dt.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n \n@@ -385,7 +396,7 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n         \"web_vault_version\": web_vault_version.version,\n         \"latest_release\": latest_release,\n         \"latest_commit\": latest_commit,\n-        \"latest_web_build\": latest_web_build.replace(\"v\", \"\"),\n+        \"latest_web_build\": latest_web_build,\n     });\n \n     let text = AdminTemplateData::diagnostics(diagnostics_json).render()?;\n",
            "comment_added_diff": [
                [
                    365,
                    "    // If the DNS Check failed, do not even attempt to check for new versions since we were not able to resolve github.com"
                ],
                [
                    368,
                    "            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\") {"
                ],
                [
                    372,
                    "            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\") {"
                ],
                [
                    379,
                    "            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {"
                ],
                [
                    388,
                    "    // Run the date check as the last item right before filling the json."
                ],
                [
                    389,
                    "    // This should ensure that the time difference between the browser and the server is as minimal as possible."
                ]
            ]
        },
        {
            "commit": "2fffaec226e2dcfb9b013aa985049e368b88f368",
            "timestamp": "2020-06-03T17:57:03+02:00",
            "author": "BlackDex",
            "commit_message": "Added attachment info per user and some layout fix\n\n- Added the amount and size of the attachments per user\n- Changed the items count function a bit\n- Some small layout changes",
            "additions": 5,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -253,13 +253,15 @@ fn get_users_json(_token: AdminToken, conn: DbConn) -> JsonResult {\n \n #[get(\"/users/overview\")]\n fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n+    use crate::util::get_display_size;\n+\n     let users = User::get_all(&conn);\n     let users_json: Vec<Value> = users.iter()\n     .map(|u| {\n         let mut usr = u.to_json(&conn);\n-        if let Some(ciphers) = Cipher::count_owned_by_user(&u.uuid, &conn) {\n-            usr[\"cipher_count\"] = json!(ciphers);\n-        };\n+        usr[\"cipher_count\"] = json!(Cipher::count_owned_by_user(&u.uuid, &conn));\n+        usr[\"attachment_count\"] = json!(Attachment::count_by_user(&u.uuid, &conn));\n+        usr[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_user(&u.uuid, &conn) as i32));\n         usr\n     }).collect();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "ac2723f898c45120ec023bbb2e0e66b26ad71a01",
            "timestamp": "2020-06-03T20:37:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated Organizations overview\n\n- Changed HTML to match users overview\n- Added User count\n- Added Org cipher amount\n- Added Attachment count and size",
            "additions": 9,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -15,6 +15,7 @@ use crate::config::ConfigBuilder;\n use crate::db::{backup_database, models::*, DbConn};\n use crate::error::Error;\n use crate::mail;\n+use crate::util::get_display_size;\n use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n@@ -253,8 +254,6 @@ fn get_users_json(_token: AdminToken, conn: DbConn) -> JsonResult {\n \n #[get(\"/users/overview\")]\n fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n-    use crate::util::get_display_size;\n-\n     let users = User::get_all(&conn);\n     let users_json: Vec<Value> = users.iter()\n     .map(|u| {\n@@ -312,7 +311,14 @@ fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n #[get(\"/organizations/overview\")]\n fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let organizations = Organization::get_all(&conn);\n-    let organizations_json: Vec<Value> = organizations.iter().map(|o| o.to_json()).collect();\n+    let organizations_json: Vec<Value> = organizations.iter().map(|o| {\n+        let mut org = o.to_json();\n+        org[\"user_count\"] = json!(UserOrganization::count_by_org(&o.uuid, &conn));\n+        org[\"cipher_count\"] = json!(Cipher::count_by_org(&o.uuid, &conn));\n+        org[\"attachment_count\"] = json!(Attachment::count_by_org(&o.uuid, &conn));\n+        org[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_org(&o.uuid, &conn) as i32));\n+        org\n+    }).collect();\n \n     let text = AdminTemplateData::organizations(organizations_json).render()?;\n     Ok(Html(text))\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 21,
            "deletions": 29,
            "change_type": "MODIFY",
            "diff": "@@ -1,22 +1,26 @@\n use once_cell::sync::Lazy;\n-use serde_json::Value;\n use serde::de::DeserializeOwned;\n+use serde_json::Value;\n use std::process::Command;\n \n-use rocket::http::{Cookie, Cookies, SameSite};\n-use rocket::request::{self, FlashMessage, Form, FromRequest, Request};\n-use rocket::response::{content::Html, Flash, Redirect};\n-use rocket::{Outcome, Route};\n+use rocket::{\n+    http::{Cookie, Cookies, SameSite},\n+    request::{self, FlashMessage, Form, FromRequest, Request},\n+    response::{content::Html, Flash, Redirect},\n+    Outcome, Route,\n+};\n use rocket_contrib::json::Json;\n \n-use crate::api::{ApiResult, EmptyResult, JsonResult};\n-use crate::auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp};\n-use crate::config::ConfigBuilder;\n-use crate::db::{backup_database, models::*, DbConn};\n-use crate::error::Error;\n-use crate::mail;\n-use crate::util::get_display_size;\n-use crate::CONFIG;\n+use crate::{\n+    api::{ApiResult, EmptyResult, JsonResult},\n+    auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp},\n+    config::ConfigBuilder,\n+    db::{backup_database, models::*, DbConn},\n+    error::{Error, MapResult},\n+    mail,\n+    util::get_display_size,\n+    CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n     if !CONFIG.disable_admin_token() && !CONFIG.is_admin_token_set() {\n@@ -270,21 +274,13 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n \n #[post(\"/users/<uuid>/delete\")]\n fn delete_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let user = match User::find_by_uuid(&uuid, &conn) {\n-        Some(user) => user,\n-        None => err!(\"User doesn't exist\"),\n-    };\n-\n+    let user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n     user.delete(&conn)\n }\n \n #[post(\"/users/<uuid>/deauth\")]\n fn deauth_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let mut user = match User::find_by_uuid(&uuid, &conn) {\n-        Some(user) => user,\n-        None => err!(\"User doesn't exist\"),\n-    };\n-\n+    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n     Device::delete_all_by_user(&user.uuid, &conn)?;\n     user.reset_security_stamp();\n \n@@ -293,11 +289,7 @@ fn deauth_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n \n #[post(\"/users/<uuid>/remove-2fa\")]\n fn remove_2fa(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let mut user = match User::find_by_uuid(&uuid, &conn) {\n-        Some(user) => user,\n-        None => err!(\"User doesn't exist\"),\n-    };\n-\n+    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n     TwoFactor::delete_all_by_user(&user.uuid, &conn)?;\n     user.totp_recover = None;\n     user.save(&conn)\n@@ -340,7 +332,7 @@ struct GitCommit {\n }\n \n fn get_github_api<T: DeserializeOwned>(url: &str) -> Result<T, Error> {\n-    use reqwest::{header::USER_AGENT, blocking::Client};\n+    use reqwest::{blocking::Client, header::USER_AGENT};\n     use std::time::Duration;\n     let github_api = Client::builder().build()?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "32cfaab5eefa1564b31819685a7b51f4a5025a59",
            "timestamp": "2020-07-23T21:07:04+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated dependencies and changed rocket request imports",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -5,9 +5,9 @@ use std::process::Command;\n \n use rocket::{\n     http::{Cookie, Cookies, SameSite},\n-    request::{self, FlashMessage, Form, FromRequest, Request},\n+    request::{self, FlashMessage, Form, FromRequest, Request, Outcome},\n     response::{content::Html, Flash, Redirect},\n-    Outcome, Route,\n+    Route,\n };\n use rocket_contrib::json::Json;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "6a972e4b199004d3def62b006bd88ef104f5419a",
            "timestamp": "2020-08-12T19:07:52+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Make the admin URL redirect try to use the referrer first, and use /admin when DOMAIN is not configured and the referrer check doesn't work, to allow users without DOMAIN configured to use the admin page correctly",
            "additions": 52,
            "deletions": 24,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ use std::process::Command;\n \n use rocket::{\n     http::{Cookie, Cookies, SameSite},\n-    request::{self, FlashMessage, Form, FromRequest, Request, Outcome},\n+    request::{self, FlashMessage, Form, FromRequest, Outcome, Request},\n     response::{content::Html, Flash, Redirect},\n     Route,\n };\n@@ -66,12 +66,35 @@ fn admin_path() -> String {\n     format!(\"{}{}\", CONFIG.domain_path(), ADMIN_PATH)\n }\n \n+struct Referer(Option<String>);\n+\n+impl<'a, 'r> FromRequest<'a, 'r> for Referer {\n+    type Error = ();\n+\n+    fn from_request(request: &'a Request<'r>) -> request::Outcome<Self, Self::Error> {\n+        Outcome::Success(Referer(request.headers().get_one(\"Referer\").map(str::to_string)))\n+    }\n+}\n+\n /// Used for `Location` response headers, which must specify an absolute URI\n /// (see https://tools.ietf.org/html/rfc2616#section-14.30).\n-fn admin_url() -> String {\n-    // Don't use CONFIG.domain() directly, since the user may want to keep a\n-    // trailing slash there, particularly when running under a subpath.\n-    format!(\"{}{}{}\", CONFIG.domain_origin(), CONFIG.domain_path(), ADMIN_PATH)\n+fn admin_url(referer: Referer) -> String {\n+    // If we get a referer use that to make it work when, DOMAIN is not set\n+    if let Some(mut referer) = referer.0 {\n+        if let Some(start_index) = referer.find(ADMIN_PATH) {\n+            referer.truncate(start_index + ADMIN_PATH.len());\n+            return referer;\n+        }\n+    }\n+\n+    if CONFIG.domain_set() {\n+        // Don't use CONFIG.domain() directly, since the user may want to keep a\n+        // trailing slash there, particularly when running under a subpath.\n+        format!(\"{}{}{}\", CONFIG.domain_origin(), CONFIG.domain_path(), ADMIN_PATH)\n+    } else {\n+        // Last case, when no referer or domain set, technically invalid but better than nothing\n+        ADMIN_PATH.to_string()\n+    }\n }\n \n #[get(\"/\", rank = 2)]\n@@ -91,14 +114,19 @@ struct LoginForm {\n }\n \n #[post(\"/\", data = \"<data>\")]\n-fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -> Result<Redirect, Flash<Redirect>> {\n+fn post_admin_login(\n+    data: Form<LoginForm>,\n+    mut cookies: Cookies,\n+    ip: ClientIp,\n+    referer: Referer,\n+) -> Result<Redirect, Flash<Redirect>> {\n     let data = data.into_inner();\n \n     // If the token is invalid, redirect to login page\n     if !_validate_token(&data.token) {\n         error!(\"Invalid admin token. IP: {}\", ip.ip);\n         Err(Flash::error(\n-            Redirect::to(admin_url()),\n+            Redirect::to(admin_url(referer)),\n             \"Invalid admin token, please try again.\",\n         ))\n     } else {\n@@ -114,7 +142,7 @@ fn post_admin_login(data: Form<LoginForm>, mut cookies: Cookies, ip: ClientIp) -\n             .finish();\n \n         cookies.add(cookie);\n-        Ok(Redirect::to(admin_url()))\n+        Ok(Redirect::to(admin_url(referer)))\n     }\n }\n \n@@ -243,9 +271,9 @@ fn test_smtp(data: Json<InviteData>, _token: AdminToken) -> EmptyResult {\n }\n \n #[get(\"/logout\")]\n-fn logout(mut cookies: Cookies) -> Result<Redirect, ()> {\n+fn logout(mut cookies: Cookies, referer: Referer) -> Result<Redirect, ()> {\n     cookies.remove(Cookie::named(COOKIE_NAME));\n-    Ok(Redirect::to(admin_url()))\n+    Ok(Redirect::to(admin_url(referer)))\n }\n \n #[get(\"/users\")]\n@@ -260,12 +288,12 @@ fn get_users_json(_token: AdminToken, conn: DbConn) -> JsonResult {\n fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let users = User::get_all(&conn);\n     let users_json: Vec<Value> = users.iter()\n-    .map(|u| {\n-        let mut usr = u.to_json(&conn);\n-        usr[\"cipher_count\"] = json!(Cipher::count_owned_by_user(&u.uuid, &conn));\n-        usr[\"attachment_count\"] = json!(Attachment::count_by_user(&u.uuid, &conn));\n-        usr[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_user(&u.uuid, &conn) as i32));\n-        usr\n+        .map(|u| {\n+            let mut usr = u.to_json(&conn);\n+            usr[\"cipher_count\"] = json!(Cipher::count_owned_by_user(&u.uuid, &conn));\n+            usr[\"attachment_count\"] = json!(Attachment::count_by_user(&u.uuid, &conn));\n+            usr[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_user(&u.uuid, &conn) as i32));\n+            usr\n     }).collect();\n \n     let text = AdminTemplateData::users(users_json).render()?;\n@@ -304,12 +332,12 @@ fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let organizations = Organization::get_all(&conn);\n     let organizations_json: Vec<Value> = organizations.iter().map(|o| {\n-        let mut org = o.to_json();\n-        org[\"user_count\"] = json!(UserOrganization::count_by_org(&o.uuid, &conn));\n-        org[\"cipher_count\"] = json!(Cipher::count_by_org(&o.uuid, &conn));\n-        org[\"attachment_count\"] = json!(Attachment::count_by_org(&o.uuid, &conn));\n-        org[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_org(&o.uuid, &conn) as i32));\n-        org\n+            let mut org = o.to_json();\n+            org[\"user_count\"] = json!(UserOrganization::count_by_org(&o.uuid, &conn));\n+            org[\"cipher_count\"] = json!(Cipher::count_by_org(&o.uuid, &conn));\n+            org[\"attachment_count\"] = json!(Attachment::count_by_org(&o.uuid, &conn));\n+            org[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_org(&o.uuid, &conn) as i32));\n+            org\n     }).collect();\n \n     let text = AdminTemplateData::organizations(organizations_json).render()?;\n@@ -373,7 +401,7 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n                 Ok(mut c) => {\n                     c.sha.truncate(8);\n                     c.sha\n-                },\n+            },\n                 _ => \"-\".to_string()\n             },\n             match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {\n@@ -384,7 +412,7 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n     } else {\n         (\"-\".to_string(), \"-\".to_string(), \"-\".to_string())\n     };\n-    \n+\n     // Run the date check as the last item right before filling the json.\n     // This should ensure that the time difference between the browser and the server is as minimal as possible.\n     let dt = Utc::now();\n",
            "comment_added_diff": [
                [
                    82,
                    "    // If we get a referer use that to make it work when, DOMAIN is not set"
                ],
                [
                    91,
                    "        // Don't use CONFIG.domain() directly, since the user may want to keep a"
                ],
                [
                    92,
                    "        // trailing slash there, particularly when running under a subpath."
                ],
                [
                    95,
                    "        // Last case, when no referer or domain set, technically invalid but better than nothing"
                ]
            ]
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 7,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -15,7 +15,7 @@ use crate::{\n     api::{ApiResult, EmptyResult, JsonResult},\n     auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp},\n     config::ConfigBuilder,\n-    db::{backup_database, models::*, DbConn},\n+    db::{backup_database, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n     util::get_display_size,\n@@ -48,8 +48,12 @@ pub fn routes() -> Vec<Route> {\n     ]\n }\n \n-static CAN_BACKUP: Lazy<bool> =\n-    Lazy::new(|| cfg!(feature = \"sqlite\") && Command::new(\"sqlite3\").arg(\"-version\").status().is_ok());\n+static CAN_BACKUP: Lazy<bool> = Lazy::new(|| {\n+    DbConnType::from_url(&CONFIG.database_url())\n+        .map(|t| t == DbConnType::sqlite)\n+        .unwrap_or(false)\n+        && Command::new(\"sqlite3\").arg(\"-version\").status().is_ok()\n+});\n \n #[get(\"/\")]\n fn admin_disabled() -> &'static str {\n",
            "comment_added_diff": []
        },
        {
            "commit": "043aa27aa36f3918ad273eb67068cc0dc925dfb4",
            "timestamp": "2020-11-30T23:12:56+01:00",
            "author": "janost",
            "commit_message": "Implement admin ability to enable/disable users",
            "additions": 21,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -36,6 +36,8 @@ pub fn routes() -> Vec<Route> {\n         logout,\n         delete_user,\n         deauth_user,\n+        disable_user,\n+        enable_user,\n         remove_2fa,\n         update_revision_users,\n         post_config,\n@@ -297,6 +299,7 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n             usr[\"cipher_count\"] = json!(Cipher::count_owned_by_user(&u.uuid, &conn));\n             usr[\"attachment_count\"] = json!(Attachment::count_by_user(&u.uuid, &conn));\n             usr[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_user(&u.uuid, &conn) as i32));\n+            usr[\"user_enabled\"] = json!(u.enabled);\n             usr\n     }).collect();\n \n@@ -319,6 +322,24 @@ fn deauth_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n     user.save(&conn)\n }\n \n+#[post(\"/users/<uuid>/disable\")]\n+fn disable_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n+    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    Device::delete_all_by_user(&user.uuid, &conn)?;\n+    user.reset_security_stamp();\n+    user.enabled = false;\n+\n+    user.save(&conn)\n+}\n+\n+#[post(\"/users/<uuid>/enable\")]\n+fn enable_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n+    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    user.enabled = true;\n+\n+    user.save(&conn)\n+}\n+\n #[post(\"/users/<uuid>/remove-2fa\")]\n fn remove_2fa(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n     let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "1eb5495802e8447649c054b59843762b15b82b56",
            "timestamp": "2020-12-03T17:07:32+01:00",
            "author": "janost",
            "commit_message": "Show latest active device as last active on admin page",
            "additions": 5,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -297,6 +297,11 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n             usr[\"cipher_count\"] = json!(Cipher::count_owned_by_user(&u.uuid, &conn));\n             usr[\"attachment_count\"] = json!(Attachment::count_by_user(&u.uuid, &conn));\n             usr[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_user(&u.uuid, &conn) as i32));\n+            usr[\"created_at\"] = json!(&u.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string());\n+            usr[\"last_active\"] = match u.last_active(&conn) {\n+                Some(timestamp) => json!(timestamp.format(\"%Y-%m-%d %H:%M:%S\").to_string()),\n+                None => json!(\"Never\")\n+            };\n             usr\n     }).collect();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "455a23361f9071b7c16048ce320ecfc26adccc2d",
            "timestamp": "2020-12-13T19:49:22-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up datetime output and code\n\n* For clarity, add `UTC` suffix for datetimes in the `Diagnostics` admin tab.\n* Format datetimes in the local timezone in the `Users` admin tab.\n* Refactor some datetime code and add doc comments.",
            "additions": 5,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -18,7 +18,7 @@ use crate::{\n     db::{backup_database, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n-    util::get_display_size,\n+    util::{get_display_size, format_naive_datetime_local},\n     CONFIG,\n };\n \n@@ -293,6 +293,7 @@ fn get_users_json(_token: AdminToken, conn: DbConn) -> JsonResult {\n #[get(\"/users/overview\")]\n fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let users = User::get_all(&conn);\n+    let dt_fmt = \"%Y-%m-%d %H:%M:%S %Z\";\n     let users_json: Vec<Value> = users.iter()\n         .map(|u| {\n             let mut usr = u.to_json(&conn);\n@@ -300,9 +301,9 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n             usr[\"attachment_count\"] = json!(Attachment::count_by_user(&u.uuid, &conn));\n             usr[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_user(&u.uuid, &conn) as i32));\n             usr[\"user_enabled\"] = json!(u.enabled);\n-            usr[\"created_at\"] = json!(&u.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string());\n+            usr[\"created_at\"] = json!(format_naive_datetime_local(&u.created_at, dt_fmt));\n             usr[\"last_active\"] = match u.last_active(&conn) {\n-                Some(timestamp) => json!(timestamp.format(\"%Y-%m-%d %H:%M:%S\").to_string()),\n+                Some(dt) => json!(format_naive_datetime_local(&dt, dt_fmt)),\n                 None => json!(\"Never\")\n             };\n             usr\n@@ -446,7 +447,7 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n     // Run the date check as the last item right before filling the json.\n     // This should ensure that the time difference between the browser and the server is as minimal as possible.\n     let dt = Utc::now();\n-    let server_time = dt.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n+    let server_time = dt.format(\"%Y-%m-%d %H:%M:%S UTC\").to_string();\n \n     let diagnostics_json = json!({\n         \"dns_resolved\": dns_resolved,\n",
            "comment_added_diff": []
        },
        {
            "commit": "235ff447367ec37adcef52921350271b3c5b9378",
            "timestamp": "2021-01-19T17:55:21+01:00",
            "author": "BlackDex",
            "commit_message": "Updated the admin interface\n\nMostly updated the admin interface, also some small other items.\n\n- Added more diagnostic information to (hopefully) decrease issue\n  reporting, or at least solve them quicker.\n- Added an option to generate a support string which can be used to\n  copy/paste on the forum or during the creation of an issue. It will\ntry to hide the sensitive information automatically.\n- Changed the `Created At` and `Last Active` info to be in a column and\n  able to sort them in the users overview.\n- Some small layout changes.\n- Updated javascript and css files to the latest versions available.\n- Decreased the png file sizes using `oxipng`\n- Updated target='_blank' links to have rel='noreferrer' to prevent\n  javascript window.opener modifications.",
            "additions": 71,
            "deletions": 29,
            "change_type": "MODIFY",
            "diff": "@@ -1,8 +1,9 @@\n use once_cell::sync::Lazy;\n use serde::de::DeserializeOwned;\n use serde_json::Value;\n-use std::process::Command;\n+use std::{env, process::Command, time::Duration};\n \n+use reqwest::{blocking::Client, header::USER_AGENT};\n use rocket::{\n     http::{Cookie, Cookies, SameSite},\n     request::{self, FlashMessage, Form, FromRequest, Outcome, Request},\n@@ -18,7 +19,7 @@ use crate::{\n     db::{backup_database, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n-    util::{get_display_size, format_naive_datetime_local},\n+    util::{format_naive_datetime_local, get_display_size},\n     CONFIG,\n };\n \n@@ -47,9 +48,20 @@ pub fn routes() -> Vec<Route> {\n         users_overview,\n         organizations_overview,\n         diagnostics,\n+        get_diagnostics_config\n     ]\n }\n \n+static DB_TYPE: Lazy<&str> = Lazy::new(|| {\n+    DbConnType::from_url(&CONFIG.database_url())\n+        .map(|t| match t {\n+            DbConnType::sqlite => \"SQLite\",\n+            DbConnType::mysql => \"MySQL\",\n+            DbConnType::postgresql => \"PostgreSQL\",\n+        })\n+        .unwrap_or(\"Unknown\")\n+});\n+\n static CAN_BACKUP: Lazy<bool> = Lazy::new(|| {\n     DbConnType::from_url(&CONFIG.database_url())\n         .map(|t| t == DbConnType::sqlite)\n@@ -307,7 +319,8 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n                 None => json!(\"Never\")\n             };\n             usr\n-    }).collect();\n+        })\n+        .collect();\n \n     let text = AdminTemplateData::users(users_json).render()?;\n     Ok(Html(text))\n@@ -362,14 +375,16 @@ fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n #[get(\"/organizations/overview\")]\n fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let organizations = Organization::get_all(&conn);\n-    let organizations_json: Vec<Value> = organizations.iter().map(|o| {\n+    let organizations_json: Vec<Value> = organizations.iter()\n+        .map(|o| {\n             let mut org = o.to_json();\n             org[\"user_count\"] = json!(UserOrganization::count_by_org(&o.uuid, &conn));\n             org[\"cipher_count\"] = json!(Cipher::count_by_org(&o.uuid, &conn));\n             org[\"attachment_count\"] = json!(Attachment::count_by_org(&o.uuid, &conn));\n             org[\"attachment_size\"] = json!(get_display_size(Attachment::size_by_org(&o.uuid, &conn) as i32));\n             org\n-    }).collect();\n+        })\n+        .collect();\n \n     let text = AdminTemplateData::organizations(organizations_json).render()?;\n     Ok(Html(text))\n@@ -391,77 +406,104 @@ struct GitCommit {\n }\n \n fn get_github_api<T: DeserializeOwned>(url: &str) -> Result<T, Error> {\n-    use reqwest::{blocking::Client, header::USER_AGENT};\n-    use std::time::Duration;\n     let github_api = Client::builder().build()?;\n \n-    Ok(\n-        github_api.get(url)\n+    Ok(github_api\n+        .get(url)\n         .timeout(Duration::from_secs(10))\n         .header(USER_AGENT, \"Bitwarden_RS\")\n         .send()?\n         .error_for_status()?\n-        .json::<T>()?\n-    )\n+        .json::<T>()?)\n+}\n+\n+fn has_http_access() -> bool {\n+    let http_access = Client::builder().build().unwrap();\n+\n+    match http_access\n+        .head(\"https://github.com/dani-garcia/bitwarden_rs\")\n+        .timeout(Duration::from_secs(10))\n+        .header(USER_AGENT, \"Bitwarden_RS\")\n+        .send()\n+    {\n+        Ok(r) => r.status().is_success(),\n+        _ => false,\n+    }\n }\n \n #[get(\"/diagnostics\")]\n fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n-    use std::net::ToSocketAddrs;\n-    use chrono::prelude::*;\n     use crate::util::read_file_string;\n+    use chrono::prelude::*;\n+    use std::net::ToSocketAddrs;\n \n+    // Get current running versions\n     let vault_version_path = format!(\"{}/{}\", CONFIG.web_vault_folder(), \"version.json\");\n     let vault_version_str = read_file_string(&vault_version_path)?;\n     let web_vault_version: WebVaultVersion = serde_json::from_str(&vault_version_str)?;\n \n-    let github_ips = (\"github.com\", 0).to_socket_addrs().map(|mut i| i.next());\n-    let (dns_resolved, dns_ok) = match github_ips {\n-        Ok(Some(a)) => (a.ip().to_string(), true),\n-        _ => (\"Could not resolve domain name.\".to_string(), false),\n+    // Execute some environment checks\n+    let running_within_docker = std::path::Path::new(\"/.dockerenv\").exists();\n+    let has_http_access = has_http_access();\n+    let uses_proxy = env::var_os(\"HTTP_PROXY\").is_some()\n+        || env::var_os(\"http_proxy\").is_some()\n+        || env::var_os(\"HTTPS_PROXY\").is_some()\n+        || env::var_os(\"https_proxy\").is_some();\n+\n+    // Check if we are able to resolve DNS entries\n+    let dns_resolved = match (\"github.com\", 0).to_socket_addrs().map(|mut i| i.next()) {\n+        Ok(Some(a)) => a.ip().to_string(),\n+        _ => \"Could not resolve domain name.\".to_string(),\n     };\n \n-    // If the DNS Check failed, do not even attempt to check for new versions since we were not able to resolve github.com\n-    let (latest_release, latest_commit, latest_web_build) = if dns_ok {\n+    // If the HTTP Check failed, do not even attempt to check for new versions since we were not able to connect with github.com anyway.\n+    // TODO: Maybe we need to cache this using a LazyStatic or something. Github only allows 60 requests per hour, and we use 3 here already.\n+    let (latest_release, latest_commit, latest_web_build) = if has_http_access {\n         (\n             match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\") {\n                 Ok(r) => r.tag_name,\n-                _ => \"-\".to_string()\n+                _ => \"-\".to_string(),\n             },\n             match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\") {\n                 Ok(mut c) => {\n                     c.sha.truncate(8);\n                     c.sha\n-            },\n-                _ => \"-\".to_string()\n+                }\n+                _ => \"-\".to_string(),\n             },\n             match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {\n                 Ok(r) => r.tag_name.trim_start_matches('v').to_string(),\n-                _ => \"-\".to_string()\n+                _ => \"-\".to_string(),\n             },\n         )\n     } else {\n         (\"-\".to_string(), \"-\".to_string(), \"-\".to_string())\n     };\n \n-    // Run the date check as the last item right before filling the json.\n-    // This should ensure that the time difference between the browser and the server is as minimal as possible.\n-    let dt = Utc::now();\n-    let server_time = dt.format(\"%Y-%m-%d %H:%M:%S UTC\").to_string();\n-\n     let diagnostics_json = json!({\n         \"dns_resolved\": dns_resolved,\n-        \"server_time\": server_time,\n         \"web_vault_version\": web_vault_version.version,\n         \"latest_release\": latest_release,\n         \"latest_commit\": latest_commit,\n         \"latest_web_build\": latest_web_build,\n+        \"running_within_docker\": running_within_docker,\n+        \"has_http_access\": has_http_access,\n+        \"uses_proxy\": uses_proxy,\n+        \"db_type\": *DB_TYPE,\n+        \"admin_url\": format!(\"{}/diagnostics\", admin_url(Referer(None))),\n+        \"server_time\": Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\").to_string(), // Run the date/time check as the last item to minimize the difference\n     });\n \n     let text = AdminTemplateData::diagnostics(diagnostics_json).render()?;\n     Ok(Html(text))\n }\n \n+#[get(\"/diagnostics/config\")]\n+fn get_diagnostics_config(_token: AdminToken) -> JsonResult {\n+    let support_json = CONFIG.get_support_json();\n+    Ok(Json(support_json))\n+}\n+\n #[post(\"/config\", data = \"<data>\")]\n fn post_config(data: Json<ConfigBuilder>, _token: AdminToken) -> EmptyResult {\n     let data: ConfigBuilder = data.into_inner();\n",
            "comment_added_diff": [
                [
                    424,
                    "        .head(\"https://github.com/dani-garcia/bitwarden_rs\")"
                ],
                [
                    440,
                    "    // Get current running versions"
                ],
                [
                    445,
                    "    // Execute some environment checks"
                ],
                [
                    453,
                    "    // Check if we are able to resolve DNS entries"
                ],
                [
                    459,
                    "    // If the HTTP Check failed, do not even attempt to check for new versions since we were not able to connect with github.com anyway."
                ],
                [
                    460,
                    "    // TODO: Maybe we need to cache this using a LazyStatic or something. Github only allows 60 requests per hour, and we use 3 here already."
                ],
                [
                    494,
                    "        \"server_time\": Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\").to_string(), // Run the date/time check as the last item to minimize the difference"
                ]
            ]
        },
        {
            "commit": "705d840ea3271738db43e096a1c45d1c9a694d6f",
            "timestamp": "2021-02-03T18:43:54+01:00",
            "author": "BlackDex",
            "commit_message": "Extra features for admin interface.\n\n- Able to modify the user type per organization\n- Able to remove a whole organization\n- Added podman detection\n- Only show web-vault update when not running a containerized\n  bitwarden_rs\n\nSolves #936",
            "additions": 54,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -13,7 +13,7 @@ use rocket::{\n use rocket_contrib::json::Json;\n \n use crate::{\n-    api::{ApiResult, EmptyResult, JsonResult},\n+    api::{ApiResult, EmptyResult, JsonResult, NumberOrString},\n     auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp},\n     config::ConfigBuilder,\n     db::{backup_database, models::*, DbConn, DbConnType},\n@@ -40,6 +40,7 @@ pub fn routes() -> Vec<Route> {\n         disable_user,\n         enable_user,\n         remove_2fa,\n+        update_user_org_type,\n         update_revision_users,\n         post_config,\n         delete_config,\n@@ -47,6 +48,7 @@ pub fn routes() -> Vec<Route> {\n         test_smtp,\n         users_overview,\n         organizations_overview,\n+        delete_organization,\n         diagnostics,\n         get_diagnostics_config\n     ]\n@@ -367,6 +369,41 @@ fn remove_2fa(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n     user.save(&conn)\n }\n \n+#[derive(Deserialize, Debug)]\n+struct UserOrgTypeData {\n+    user_type: NumberOrString,\n+    user_uuid: String,\n+    org_uuid: String,\n+}\n+\n+#[post(\"/users/org_type\", data = \"<data>\")]\n+fn update_user_org_type(data: Json<UserOrgTypeData>, _token: AdminToken, conn: DbConn) -> EmptyResult {\n+    let data: UserOrgTypeData = data.into_inner();\n+\n+    let mut user_to_edit = match UserOrganization::find_by_user_and_org(&data.user_uuid, &data.org_uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"The specified user isn't member of the organization\"),\n+    };\n+\n+    let new_type = match UserOrgType::from_str(&data.user_type.into_string()) {\n+        Some(new_type) => new_type as i32,\n+        None => err!(\"Invalid type\"),\n+    };\n+\n+    if user_to_edit.atype == UserOrgType::Owner && new_type != UserOrgType::Owner {\n+        // Removing owner permmission, check that there are at least another owner\n+        let num_owners = UserOrganization::find_by_org_and_type(&data.org_uuid, UserOrgType::Owner as i32, &conn).len();\n+\n+        if num_owners <= 1 {\n+            err!(\"Can't change the type of the last owner\")\n+        }\n+    }\n+\n+    user_to_edit.atype = new_type as i32;\n+    user_to_edit.save(&conn)\n+}\n+\n+\n #[post(\"/users/update_revision\")]\n fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n     User::update_all_revisions(&conn)\n@@ -390,6 +427,12 @@ fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<St\n     Ok(Html(text))\n }\n \n+#[post(\"/organizations/<uuid>/delete\")]\n+fn delete_organization(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n+    let org = Organization::find_by_uuid(&uuid, &conn).map_res(\"Organization doesn't exist\")?;\n+    org.delete(&conn)\n+}\n+\n #[derive(Deserialize)]\n struct WebVaultVersion {\n     version: String,\n@@ -443,7 +486,7 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n     let web_vault_version: WebVaultVersion = serde_json::from_str(&vault_version_str)?;\n \n     // Execute some environment checks\n-    let running_within_docker = std::path::Path::new(\"/.dockerenv\").exists();\n+    let running_within_docker = std::path::Path::new(\"/.dockerenv\").exists() || std::path::Path::new(\"/run/.containerenv\").exists();\n     let has_http_access = has_http_access();\n     let uses_proxy = env::var_os(\"HTTP_PROXY\").is_some()\n         || env::var_os(\"http_proxy\").is_some()\n@@ -471,9 +514,15 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n                 }\n                 _ => \"-\".to_string(),\n             },\n-            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {\n-                Ok(r) => r.tag_name.trim_start_matches('v').to_string(),\n-                _ => \"-\".to_string(),\n+            // Do not fetch the web-vault version when running within Docker.\n+            // The web-vault version is embedded within the container it self, and should not be updated manually\n+            if running_within_docker {\n+                \"-\".to_string()\n+            } else {\n+                match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {\n+                    Ok(r) => r.tag_name.trim_start_matches('v').to_string(),\n+                    _ => \"-\".to_string(),\n+                }\n             },\n         )\n     } else {\n",
            "comment_added_diff": [
                [
                    394,
                    "        // Removing owner permmission, check that there are at least another owner"
                ],
                [
                    517,
                    "            // Do not fetch the web-vault version when running within Docker."
                ],
                [
                    518,
                    "            // The web-vault version is embedded within the container it self, and should not be updated manually"
                ],
                [
                    522,
                    "                match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {"
                ]
            ]
        },
        {
            "commit": "513056f7118da82c8011710b65c569080e1fc2ca",
            "timestamp": "2021-02-28T01:45:05-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Check for data folder on startup\n\nCurrently, when starting up for the first time (running standalone, outside\nof Docker), bitwarden_rs panics when the `openssl` tool isn't able to create\n`data/rsa_key.pem` due to the `data` dir not existing. Instead, print a more\nhelpful error message telling the user to create the directory.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -19,7 +19,7 @@ use crate::{\n     db::{backup_database, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n-    util::{format_naive_datetime_local, get_display_size},\n+    util::{format_naive_datetime_local, get_display_size, is_running_in_docker},\n     CONFIG,\n };\n \n@@ -486,7 +486,7 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n     let web_vault_version: WebVaultVersion = serde_json::from_str(&vault_version_str)?;\n \n     // Execute some environment checks\n-    let running_within_docker = std::path::Path::new(\"/.dockerenv\").exists() || std::path::Path::new(\"/run/.containerenv\").exists();\n+    let running_within_docker = is_running_in_docker();\n     let has_http_access = has_http_access();\n     let uses_proxy = env::var_os(\"HTTP_PROXY\").is_some()\n         || env::var_os(\"http_proxy\").is_some()\n",
            "comment_added_diff": []
        },
        {
            "commit": "3e5971b9dbfa0eabe69b682d848009741b435758",
            "timestamp": "2021-03-27T15:07:26+00:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary result return types",
            "additions": 7,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -13,7 +13,7 @@ use rocket::{\n use rocket_contrib::json::Json;\n \n use crate::{\n-    api::{ApiResult, EmptyResult, JsonResult, NumberOrString},\n+    api::{ApiResult, EmptyResult, NumberOrString},\n     auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp},\n     config::ConfigBuilder,\n     db::{backup_database, models::*, DbConn, DbConnType},\n@@ -291,17 +291,17 @@ fn test_smtp(data: Json<InviteData>, _token: AdminToken) -> EmptyResult {\n }\n \n #[get(\"/logout\")]\n-fn logout(mut cookies: Cookies, referer: Referer) -> Result<Redirect, ()> {\n+fn logout(mut cookies: Cookies, referer: Referer) -> Redirect {\n     cookies.remove(Cookie::named(COOKIE_NAME));\n-    Ok(Redirect::to(admin_url(referer)))\n+    Redirect::to(admin_url(referer))\n }\n \n #[get(\"/users\")]\n-fn get_users_json(_token: AdminToken, conn: DbConn) -> JsonResult {\n+fn get_users_json(_token: AdminToken, conn: DbConn) -> Json<Value> {\n     let users = User::get_all(&conn);\n     let users_json: Vec<Value> = users.iter().map(|u| u.to_json(&conn)).collect();\n \n-    Ok(Json(Value::Array(users_json)))\n+    Json(Value::Array(users_json))\n }\n \n #[get(\"/users/overview\")]\n@@ -548,9 +548,9 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n }\n \n #[get(\"/diagnostics/config\")]\n-fn get_diagnostics_config(_token: AdminToken) -> JsonResult {\n+fn get_diagnostics_config(_token: AdminToken) -> Json<Value> {\n     let support_json = CONFIG.get_support_json();\n-    Ok(Json(support_json))\n+    Json(support_json)\n }\n \n #[post(\"/config\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "57e17d064813162b1a1017368ce651ea89ea8aad",
            "timestamp": "2021-03-28T00:10:01+01:00",
            "author": "BlackDex",
            "commit_message": "Updated diagnostics page\n\n- Added reverse proxy check\n- Better deffinition of internet proxy\n- Added SQL Server version detection",
            "additions": 33,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -16,7 +16,7 @@ use crate::{\n     api::{ApiResult, EmptyResult, JsonResult, NumberOrString},\n     auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp},\n     config::ConfigBuilder,\n-    db::{backup_database, models::*, DbConn, DbConnType},\n+    db::{backup_database, get_sql_server_version, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n     util::{format_naive_datetime_local, get_display_size, is_running_in_docker},\n@@ -96,6 +96,27 @@ impl<'a, 'r> FromRequest<'a, 'r> for Referer {\n     }\n }\n \n+#[derive(Debug)]\n+struct IpHeader(Option<String>);\n+\n+impl<'a, 'r> FromRequest<'a, 'r> for IpHeader {\n+    type Error = ();\n+\n+    fn from_request(req: &'a Request<'r>) -> Outcome<Self, Self::Error> {\n+        if req.headers().get_one(&CONFIG.ip_header()).is_some() {\n+            Outcome::Success(IpHeader(Some(CONFIG.ip_header())))\n+        } else if req.headers().get_one(\"X-Client-IP\").is_some() {\n+            Outcome::Success(IpHeader(Some(String::from(\"X-Client-IP\"))))\n+        } else if req.headers().get_one(\"X-Real-IP\").is_some() {\n+            Outcome::Success(IpHeader(Some(String::from(\"X-Real-IP\"))))\n+        } else if req.headers().get_one(\"X-Forwarded-For\").is_some() {\n+            Outcome::Success(IpHeader(Some(String::from(\"X-Forwarded-For\"))))\n+        } else {\n+            Outcome::Success(IpHeader(None))\n+        }\n+    }\n+}\n+\n /// Used for `Location` response headers, which must specify an absolute URI\n /// (see https://tools.ietf.org/html/rfc2616#section-14.30).\n fn admin_url(referer: Referer) -> String {\n@@ -475,7 +496,7 @@ fn has_http_access() -> bool {\n }\n \n #[get(\"/diagnostics\")]\n-fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n+fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResult<Html<String>> {\n     use crate::util::read_file_string;\n     use chrono::prelude::*;\n     use std::net::ToSocketAddrs;\n@@ -529,6 +550,11 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n         (\"-\".to_string(), \"-\".to_string(), \"-\".to_string())\n     };\n \n+    let ip_header_name = match &ip_header.0 {\n+        Some(h) => h,\n+        _ => \"\"\n+    };\n+\n     let diagnostics_json = json!({\n         \"dns_resolved\": dns_resolved,\n         \"web_vault_version\": web_vault_version.version,\n@@ -537,8 +563,13 @@ fn diagnostics(_token: AdminToken, _conn: DbConn) -> ApiResult<Html<String>> {\n         \"latest_web_build\": latest_web_build,\n         \"running_within_docker\": running_within_docker,\n         \"has_http_access\": has_http_access,\n+        \"ip_header_exists\": &ip_header.0.is_some(),\n+        \"ip_header_match\": ip_header_name == &CONFIG.ip_header(),\n+        \"ip_header_name\": ip_header_name,\n+        \"ip_header_config\": &CONFIG.ip_header(),\n         \"uses_proxy\": uses_proxy,\n         \"db_type\": *DB_TYPE,\n+        \"db_version\": get_sql_server_version(&conn),\n         \"admin_url\": format!(\"{}/diagnostics\", admin_url(Referer(None))),\n         \"server_time\": Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\").to_string(), // Run the date/time check as the last item to minimize the difference\n     });\n",
            "comment_added_diff": []
        },
        {
            "commit": "81fa33ebb5089e6d9a610622dfdfd4551658f081",
            "timestamp": "2021-03-28T10:59:49+01:00",
            "author": "Jake Howard",
            "commit_message": "Remove unnecessary reference",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -564,7 +564,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n         \"running_within_docker\": running_within_docker,\n         \"has_http_access\": has_http_access,\n         \"ip_header_exists\": &ip_header.0.is_some(),\n-        \"ip_header_match\": ip_header_name == &CONFIG.ip_header(),\n+        \"ip_header_match\": ip_header_name == CONFIG.ip_header(),\n         \"ip_header_name\": ip_header_name,\n         \"ip_header_config\": &CONFIG.ip_header(),\n         \"uses_proxy\": uses_proxy,\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 13,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -142,7 +142,8 @@ fn admin_url(referer: Referer) -> String {\n fn admin_login(flash: Option<FlashMessage>) -> ApiResult<Html<String>> {\n     // If there is an error, show it\n     let msg = flash.map(|msg| format!(\"{}: {}\", msg.name(), msg.msg()));\n-    let json = json!({\"page_content\": \"admin/login\", \"version\": VERSION, \"error\": msg, \"urlpath\": CONFIG.domain_path()});\n+    let json =\n+        json!({\"page_content\": \"admin/login\", \"version\": VERSION, \"error\": msg, \"urlpath\": CONFIG.domain_path()});\n \n     // Return the page\n     let text = CONFIG.render_template(BASE_TEMPLATE, &json)?;\n@@ -329,7 +330,8 @@ fn get_users_json(_token: AdminToken, conn: DbConn) -> Json<Value> {\n fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let users = User::get_all(&conn);\n     let dt_fmt = \"%Y-%m-%d %H:%M:%S %Z\";\n-    let users_json: Vec<Value> = users.iter()\n+    let users_json: Vec<Value> = users\n+        .iter()\n         .map(|u| {\n             let mut usr = u.to_json(&conn);\n             usr[\"cipher_count\"] = json!(Cipher::count_owned_by_user(&u.uuid, &conn));\n@@ -339,7 +341,7 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n             usr[\"created_at\"] = json!(format_naive_datetime_local(&u.created_at, dt_fmt));\n             usr[\"last_active\"] = match u.last_active(&conn) {\n                 Some(dt) => json!(format_naive_datetime_local(&dt, dt_fmt)),\n-                None => json!(\"Never\")\n+                None => json!(\"Never\"),\n             };\n             usr\n         })\n@@ -424,7 +426,6 @@ fn update_user_org_type(data: Json<UserOrgTypeData>, _token: AdminToken, conn: D\n     user_to_edit.save(&conn)\n }\n \n-\n #[post(\"/users/update_revision\")]\n fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n     User::update_all_revisions(&conn)\n@@ -433,7 +434,8 @@ fn update_revision_users(_token: AdminToken, conn: DbConn) -> EmptyResult {\n #[get(\"/organizations/overview\")]\n fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     let organizations = Organization::get_all(&conn);\n-    let organizations_json: Vec<Value> = organizations.iter()\n+    let organizations_json: Vec<Value> = organizations\n+        .iter()\n         .map(|o| {\n             let mut org = o.to_json();\n             org[\"user_count\"] = json!(UserOrganization::count_by_org(&o.uuid, &conn));\n@@ -524,7 +526,8 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n     // TODO: Maybe we need to cache this using a LazyStatic or something. Github only allows 60 requests per hour, and we use 3 here already.\n     let (latest_release, latest_commit, latest_web_build) = if has_http_access {\n         (\n-            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\") {\n+            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\")\n+            {\n                 Ok(r) => r.tag_name,\n                 _ => \"-\".to_string(),\n             },\n@@ -540,7 +543,9 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n             if running_within_docker {\n                 \"-\".to_string()\n             } else {\n-                match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\") {\n+                match get_github_api::<GitRelease>(\n+                    \"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\",\n+                ) {\n                     Ok(r) => r.tag_name.trim_start_matches('v').to_string(),\n                     _ => \"-\".to_string(),\n                 }\n@@ -552,7 +557,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n \n     let ip_header_name = match &ip_header.0 {\n         Some(h) => h,\n-        _ => \"\"\n+        _ => \"\",\n     };\n \n     let diagnostics_json = json!({\n",
            "comment_added_diff": [
                [
                    529,
                    "            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\")"
                ],
                [
                    547,
                    "                    \"https://api.github.com/repos/dani-garcia/bw_web_builds/releases/latest\","
                ]
            ]
        },
        {
            "commit": "93c881a7a9abf30c1d2cfea961d5637de2757b86",
            "timestamp": "2021-03-31T21:45:05+01:00",
            "author": "Jake Howard",
            "commit_message": "Reflow some lines manually",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -142,8 +142,12 @@ fn admin_url(referer: Referer) -> String {\n fn admin_login(flash: Option<FlashMessage>) -> ApiResult<Html<String>> {\n     // If there is an error, show it\n     let msg = flash.map(|msg| format!(\"{}: {}\", msg.name(), msg.msg()));\n-    let json =\n-        json!({\"page_content\": \"admin/login\", \"version\": VERSION, \"error\": msg, \"urlpath\": CONFIG.domain_path()});\n+    let json = json!({\n+        \"page_content\": \"admin/login\",\n+        \"version\": VERSION,\n+        \"error\": msg,\n+        \"urlpath\": CONFIG.domain_path()\n+    });\n \n     // Return the page\n     let text = CONFIG.render_template(BASE_TEMPLATE, &json)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "95fc88ae5bef5f4d1e9a8da4f5de7c955fb75a19",
            "timestamp": "2021-04-05T15:09:16+02:00",
            "author": "BlackDex",
            "commit_message": "Some admin interface updates.\n\n- Fixed bug when web-vault is disabled.\n- Updated sql-server version check to be simpler thx to @weiznich ( https://github.com/dani-garcia/bitwarden_rs/pull/1548#discussion_r604767196 )\n- Use `VACUUM INTO` to create a SQLite backup instead of using the external sqlite3 application.\n  - This also removes the dependancy of having the sqlite3 packages installed on the final image unnecessary, and thus removed it.\n- Updated backup filename to also have the current time.\n- Add specific bitwarden_rs web-vault version check (to match letter patched versions)\n  Will work when https://github.com/dani-garcia/bw_web_builds/pull/33 is build (But still works without it also).",
            "additions": 18,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,7 @@\n use once_cell::sync::Lazy;\n use serde::de::DeserializeOwned;\n use serde_json::Value;\n-use std::{env, process::Command, time::Duration};\n+use std::{env, time::Duration};\n \n use reqwest::{blocking::Client, header::USER_AGENT};\n use rocket::{\n@@ -68,7 +68,6 @@ static CAN_BACKUP: Lazy<bool> = Lazy::new(|| {\n     DbConnType::from_url(&CONFIG.database_url())\n         .map(|t| t == DbConnType::sqlite)\n         .unwrap_or(false)\n-        && Command::new(\"sqlite3\").arg(\"-version\").status().is_ok()\n });\n \n #[get(\"/\")]\n@@ -502,9 +501,17 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n     use std::net::ToSocketAddrs;\n \n     // Get current running versions\n-    let vault_version_path = format!(\"{}/{}\", CONFIG.web_vault_folder(), \"version.json\");\n-    let vault_version_str = read_file_string(&vault_version_path)?;\n-    let web_vault_version: WebVaultVersion = serde_json::from_str(&vault_version_str)?;\n+    let web_vault_version: WebVaultVersion = match read_file_string(&format!(\"{}/{}\", CONFIG.web_vault_folder(), \"bwrs-version.json\")) {\n+        Ok(s) => serde_json::from_str(&s)?,\n+        _ => {\n+            match read_file_string(&format!(\"{}/{}\", CONFIG.web_vault_folder(), \"version.json\")) {\n+                Ok(s) => serde_json::from_str(&s)?,\n+                _ => {\n+                    WebVaultVersion{version: String::from(\"Version file missing\")}\n+                },\n+            }\n+        },\n+    };\n \n     // Execute some environment checks\n     let running_within_docker = is_running_in_docker();\n@@ -557,9 +564,10 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n \n     let diagnostics_json = json!({\n         \"dns_resolved\": dns_resolved,\n-        \"web_vault_version\": web_vault_version.version,\n         \"latest_release\": latest_release,\n         \"latest_commit\": latest_commit,\n+        \"web_vault_enabled\": &CONFIG.web_vault_enabled(),\n+        \"web_vault_version\": web_vault_version.version,\n         \"latest_web_build\": latest_web_build,\n         \"running_within_docker\": running_within_docker,\n         \"has_http_access\": has_http_access,\n@@ -571,6 +579,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n         \"db_type\": *DB_TYPE,\n         \"db_version\": get_sql_server_version(&conn),\n         \"admin_url\": format!(\"{}/diagnostics\", admin_url(Referer(None))),\n+        \"server_time_local\": Local::now().format(\"%Y-%m-%d %H:%M:%S %Z\").to_string(),\n         \"server_time\": Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\").to_string(), // Run the date/time check as the last item to minimize the difference\n     });\n \n@@ -596,11 +605,11 @@ fn delete_config(_token: AdminToken) -> EmptyResult {\n }\n \n #[post(\"/config/backup_db\")]\n-fn backup_db(_token: AdminToken) -> EmptyResult {\n+fn backup_db(_token: AdminToken, conn: DbConn) -> EmptyResult {\n     if *CAN_BACKUP {\n-        backup_database()\n+        backup_database(&conn)\n     } else {\n-        err!(\"Can't back up current DB (either it's not SQLite or the 'sqlite' binary is not present)\");\n+        err!(\"Can't back up current DB (Only SQLite supports this feature)\");\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "155109dea120e109e1e027d4e1312b6adad4c231",
            "timestamp": "2021-04-06T21:04:37+01:00",
            "author": "Jake Howard",
            "commit_message": "Extract client creation to a single place",
            "additions": 4,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -3,7 +3,7 @@ use serde::de::DeserializeOwned;\n use serde_json::Value;\n use std::{env, time::Duration};\n \n-use reqwest::{blocking::Client, header::USER_AGENT};\n+\n use rocket::{\n     http::{Cookie, Cookies, SameSite},\n     request::{self, FlashMessage, Form, FromRequest, Outcome, Request},\n@@ -19,7 +19,7 @@ use crate::{\n     db::{backup_database, get_sql_server_version, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n-    util::{format_naive_datetime_local, get_display_size, is_running_in_docker},\n+    util::{format_naive_datetime_local, get_display_size, is_running_in_docker, get_reqwest_client},\n     CONFIG,\n };\n \n@@ -469,24 +469,22 @@ struct GitCommit {\n }\n \n fn get_github_api<T: DeserializeOwned>(url: &str) -> Result<T, Error> {\n-    let github_api = Client::builder().build()?;\n+    let github_api = get_reqwest_client();\n \n     Ok(github_api\n         .get(url)\n         .timeout(Duration::from_secs(10))\n-        .header(USER_AGENT, \"Bitwarden_RS\")\n         .send()?\n         .error_for_status()?\n         .json::<T>()?)\n }\n \n fn has_http_access() -> bool {\n-    let http_access = Client::builder().build().unwrap();\n+    let http_access = get_reqwest_client();\n \n     match http_access\n         .head(\"https://github.com/dani-garcia/bitwarden_rs\")\n         .timeout(Duration::from_secs(10))\n-        .header(USER_AGENT, \"Bitwarden_RS\")\n         .send()\n     {\n         Ok(r) => r.status().is_success(),\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 2,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -65,9 +65,7 @@ static DB_TYPE: Lazy<&str> = Lazy::new(|| {\n });\n \n static CAN_BACKUP: Lazy<bool> = Lazy::new(|| {\n-    DbConnType::from_url(&CONFIG.database_url())\n-        .map(|t| t == DbConnType::sqlite)\n-        .unwrap_or(false)\n+    DbConnType::from_url(&CONFIG.database_url()).map(|t| t == DbConnType::sqlite).unwrap_or(false)\n         && Command::new(\"sqlite3\").arg(\"-version\").status().is_ok()\n });\n \n@@ -171,10 +169,7 @@ fn post_admin_login(\n     // If the token is invalid, redirect to login page\n     if !_validate_token(&data.token) {\n         error!(\"Invalid admin token. IP: {}\", ip.ip);\n-        Err(Flash::error(\n-            Redirect::to(admin_url(referer)),\n-            \"Invalid admin token, please try again.\",\n-        ))\n+        Err(Flash::error(Redirect::to(admin_url(referer)), \"Invalid admin token, please try again.\"))\n     } else {\n         // If the token received is valid, generate JWT and save it as a cookie\n         let claims = generate_admin_claims();\n",
            "comment_added_diff": []
        },
        {
            "commit": "305de2e2cd820ae6651a6442d88f5ca637263fae",
            "timestamp": "2021-04-15T18:30:23+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Format the changes from merge to master",
            "additions": 3,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -3,7 +3,6 @@ use serde::de::DeserializeOwned;\n use serde_json::Value;\n use std::{env, time::Duration};\n \n-\n use rocket::{\n     http::{Cookie, Cookies, SameSite},\n     request::{self, FlashMessage, Form, FromRequest, Outcome, Request},\n@@ -19,7 +18,7 @@ use crate::{\n     db::{backup_database, get_sql_server_version, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n-    util::{format_naive_datetime_local, get_display_size, is_running_in_docker, get_reqwest_client},\n+    util::{format_naive_datetime_local, get_display_size, get_reqwest_client, is_running_in_docker},\n     CONFIG,\n };\n \n@@ -471,22 +470,13 @@ struct GitCommit {\n fn get_github_api<T: DeserializeOwned>(url: &str) -> Result<T, Error> {\n     let github_api = get_reqwest_client();\n \n-    Ok(github_api\n-        .get(url)\n-        .timeout(Duration::from_secs(10))\n-        .send()?\n-        .error_for_status()?\n-        .json::<T>()?)\n+    Ok(github_api.get(url).timeout(Duration::from_secs(10)).send()?.error_for_status()?.json::<T>()?)\n }\n \n fn has_http_access() -> bool {\n     let http_access = get_reqwest_client();\n \n-    match http_access\n-        .head(\"https://github.com/dani-garcia/bitwarden_rs\")\n-        .timeout(Duration::from_secs(10))\n-        .send()\n-    {\n+    match http_access.head(\"https://github.com/dani-garcia/bitwarden_rs\").timeout(Duration::from_secs(10)).send() {\n         Ok(r) => r.status().is_success(),\n         _ => false,\n     }\n",
            "comment_added_diff": [
                [
                    479,
                    "    match http_access.head(\"https://github.com/dani-garcia/bitwarden_rs\").timeout(Duration::from_secs(10)).send() {"
                ]
            ]
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -476,7 +476,7 @@ fn get_github_api<T: DeserializeOwned>(url: &str) -> Result<T, Error> {\n fn has_http_access() -> bool {\n     let http_access = get_reqwest_client();\n \n-    match http_access.head(\"https://github.com/dani-garcia/bitwarden_rs\").timeout(Duration::from_secs(10)).send() {\n+    match http_access.head(\"https://github.com/dani-garcia/vaultwarden\").timeout(Duration::from_secs(10)).send() {\n         Ok(r) => r.status().is_success(),\n         _ => false,\n     }\n@@ -518,12 +518,12 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n     // TODO: Maybe we need to cache this using a LazyStatic or something. Github only allows 60 requests per hour, and we use 3 here already.\n     let (latest_release, latest_commit, latest_web_build) = if has_http_access {\n         (\n-            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/releases/latest\")\n+            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/vaultwarden/releases/latest\")\n             {\n                 Ok(r) => r.tag_name,\n                 _ => \"-\".to_string(),\n             },\n-            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/bitwarden_rs/commits/master\") {\n+            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/vaultwarden/commits/master\") {\n                 Ok(mut c) => {\n                     c.sha.truncate(8);\n                     c.sha\n",
            "comment_added_diff": [
                [
                    479,
                    "    match http_access.head(\"https://github.com/dani-garcia/vaultwarden\").timeout(Duration::from_secs(10)).send() {"
                ],
                [
                    521,
                    "            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/vaultwarden/releases/latest\")"
                ],
                [
                    526,
                    "            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/vaultwarden/commits/master\") {"
                ]
            ]
        },
        {
            "commit": "3da44a8d30e76f48b84f5b888e0b33427037037c",
            "timestamp": "2021-04-27T23:39:36+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix formatting",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -518,8 +518,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n     // TODO: Maybe we need to cache this using a LazyStatic or something. Github only allows 60 requests per hour, and we use 3 here already.\n     let (latest_release, latest_commit, latest_web_build) = if has_http_access {\n         (\n-            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/vaultwarden/releases/latest\")\n-            {\n+            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/vaultwarden/releases/latest\") {\n                 Ok(r) => r.tag_name,\n                 _ => \"-\".to_string(),\n             },\n",
            "comment_added_diff": [
                [
                    521,
                    "            match get_github_api::<GitRelease>(\"https://api.github.com/repos/dani-garcia/vaultwarden/releases/latest\") {"
                ]
            ]
        },
        {
            "commit": "2b4dd6f137730abe48506affbe5c8f36a86772fb",
            "timestamp": "2021-04-28T21:46:20+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix branch name",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -522,7 +522,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n                 Ok(r) => r.tag_name,\n                 _ => \"-\".to_string(),\n             },\n-            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/vaultwarden/commits/master\") {\n+            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/vaultwarden/commits/main\") {\n                 Ok(mut c) => {\n                     c.sha.truncate(8);\n                     c.sha\n",
            "comment_added_diff": [
                [
                    525,
                    "            match get_github_api::<GitCommit>(\"https://api.github.com/repos/dani-garcia/vaultwarden/commits/main\") {"
                ]
            ]
        },
        {
            "commit": "5f458b288a7a7892f075087348ebcd3dab9a771b",
            "timestamp": "2021-05-10T11:47:41-04:00",
            "author": "Carl Dong",
            "commit_message": "admin: Return newly-created user in invite_user\n\nInstead of having the caller dig through /admin/users for the right one,\njust return the user upon creation.",
            "additions": 7,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -12,7 +12,7 @@ use rocket::{\n use rocket_contrib::json::Json;\n \n use crate::{\n-    api::{ApiResult, EmptyResult, NumberOrString},\n+    api::{ApiResult, EmptyResult, JsonResult, NumberOrString},\n     auth::{decode_admin, encode_jwt, generate_admin_claims, ClientIp},\n     config::ConfigBuilder,\n     db::{backup_database, get_sql_server_version, models::*, DbConn, DbConnType},\n@@ -279,7 +279,7 @@ struct InviteData {\n }\n \n #[post(\"/invite\", data = \"<data>\")]\n-fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> EmptyResult {\n+fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> JsonResult {\n     let data: InviteData = data.into_inner();\n     let email = data.email.clone();\n     if User::find_by_mail(&data.email, &conn).is_some() {\n@@ -287,14 +287,16 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Empt\n     }\n \n     let mut user = User::new(email);\n-    user.save(&conn)?;\n \n     if CONFIG.mail_enabled() {\n-        mail::send_invite(&user.email, &user.uuid, None, None, &CONFIG.invitation_org_name(), None)\n+        mail::send_invite(&user.email, &user.uuid, None, None, &CONFIG.invitation_org_name(), None)?;\n     } else {\n         let invitation = Invitation::new(data.email);\n-        invitation.save(&conn)\n+        invitation.save(&conn)?;\n     }\n+\n+    user.save(&conn)?;\n+    Ok(Json(user.to_json(&conn)))\n }\n \n #[post(\"/test/smtp\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "68e5d95d251ded79a019f681a2a6c1665aef751b",
            "timestamp": "2021-05-10T11:47:41-04:00",
            "author": "Carl Dong",
            "commit_message": "admin: Specifically return 404 for user not found\n\n- Modify err_code to accept an expr for err_code\n- Add get_user_or_404, properly returning 404 instead of a generic 400\n  for cases where user is not found\n- Use get_user_or_404 where appropriate.",
            "additions": 15,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use serde_json::Value;\n use std::{env, time::Duration};\n \n use rocket::{\n-    http::{Cookie, Cookies, SameSite},\n+    http::{Cookie, Cookies, SameSite, Status},\n     request::{self, FlashMessage, Form, FromRequest, Outcome, Request},\n     response::{content::Html, Flash, Redirect},\n     Route,\n@@ -279,6 +279,14 @@ struct InviteData {\n     email: String,\n }\n \n+fn get_user_or_404(uuid: &str, conn: &DbConn) -> ApiResult<User> {\n+    if let Some(user) = User::find_by_uuid(uuid, conn) {\n+        Ok(user)\n+    } else {\n+        err_code!(\"User doesn't exist\", Status::NotFound.code);\n+    }\n+}\n+\n #[post(\"/invite\", data = \"<data>\")]\n fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> JsonResult {\n     let data: InviteData = data.into_inner();\n@@ -352,20 +360,20 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n \n #[get(\"/users/<uuid>\")]\n fn get_user_json(uuid: String, _token: AdminToken, conn: DbConn) -> JsonResult {\n-    let user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    let user = get_user_or_404(&uuid, &conn)?;\n \n     Ok(Json(user.to_json(&conn)))\n }\n \n #[post(\"/users/<uuid>/delete\")]\n fn delete_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    let user = get_user_or_404(&uuid, &conn)?;\n     user.delete(&conn)\n }\n \n #[post(\"/users/<uuid>/deauth\")]\n fn deauth_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    let mut user = get_user_or_404(&uuid, &conn)?;\n     Device::delete_all_by_user(&user.uuid, &conn)?;\n     user.reset_security_stamp();\n \n@@ -374,7 +382,7 @@ fn deauth_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n \n #[post(\"/users/<uuid>/disable\")]\n fn disable_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    let mut user = get_user_or_404(&uuid, &conn)?;\n     Device::delete_all_by_user(&user.uuid, &conn)?;\n     user.reset_security_stamp();\n     user.enabled = false;\n@@ -384,7 +392,7 @@ fn disable_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n \n #[post(\"/users/<uuid>/enable\")]\n fn enable_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    let mut user = get_user_or_404(&uuid, &conn)?;\n     user.enabled = true;\n \n     user.save(&conn)\n@@ -392,7 +400,7 @@ fn enable_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n \n #[post(\"/users/<uuid>/remove-2fa\")]\n fn remove_2fa(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n-    let mut user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+    let mut user = get_user_or_404(&uuid, &conn)?;\n     TwoFactor::delete_all_by_user(&user.uuid, &conn)?;\n     user.totp_recover = None;\n     user.save(&conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "cccd8262fa78dabc8e1949c4dcb490b99fb0cd84",
            "timestamp": "2021-05-10T11:47:41-04:00",
            "author": "Carl Dong",
            "commit_message": "admin: Add /users/<uuid> route\n\nIndividual user information can now be looked up by UUID.",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -30,6 +30,7 @@ pub fn routes() -> Vec<Route> {\n     routes![\n         admin_login,\n         get_users_json,\n+        get_user_json,\n         post_admin_login,\n         admin_page,\n         invite_user,\n@@ -349,6 +350,13 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n     Ok(Html(text))\n }\n \n+#[get(\"/users/<uuid>\")]\n+fn get_user_json(uuid: String, _token: AdminToken, conn: DbConn) -> JsonResult {\n+    let user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n+\n+    Ok(Json(user.to_json(&conn)))\n+}\n+\n #[post(\"/users/<uuid>/delete\")]\n fn delete_user(uuid: String, _token: AdminToken, conn: DbConn) -> EmptyResult {\n     let user = User::find_by_uuid(&uuid, &conn).map_res(\"User doesn't exist\")?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "e60bdc7efe247e6b93c7c99b1a44e7147cddbf31",
            "timestamp": "2021-05-10T11:47:41-04:00",
            "author": "Carl Dong",
            "commit_message": "admin: Make invite_user error codes more specific\n\n- Return 409 Conflict for when a user with that email already exists\n- Return 500 InternalServerError for everything else",
            "additions": 13,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -292,19 +292,24 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Json\n     let data: InviteData = data.into_inner();\n     let email = data.email.clone();\n     if User::find_by_mail(&data.email, &conn).is_some() {\n-        err!(\"User already exists\")\n+        err_code!(\"User already exists\", Status::Conflict.code)\n     }\n \n     let mut user = User::new(email);\n \n-    if CONFIG.mail_enabled() {\n-        mail::send_invite(&user.email, &user.uuid, None, None, &CONFIG.invitation_org_name(), None)?;\n-    } else {\n-        let invitation = Invitation::new(data.email);\n-        invitation.save(&conn)?;\n-    }\n+    // TODO: After try_blocks is stabilized, this can be made more readable\n+    // See: https://github.com/rust-lang/rust/issues/31436\n+    (|| {\n+        if CONFIG.mail_enabled() {\n+            mail::send_invite(&user.email, &user.uuid, None, None, &CONFIG.invitation_org_name(), None)?;\n+        } else {\n+            let invitation = Invitation::new(data.email);\n+            invitation.save(&conn)?;\n+        }\n+\n+        user.save(&conn)\n+    })().map_err(|e| e.with_code(Status::InternalServerError.code))?;\n \n-    user.save(&conn)?;\n     Ok(Json(user.to_json(&conn)))\n }\n \n",
            "comment_added_diff": [
                [
                    300,
                    "    // TODO: After try_blocks is stabilized, this can be made more readable"
                ],
                [
                    301,
                    "    // See: https://github.com/rust-lang/rust/issues/31436"
                ]
            ]
        },
        {
            "commit": "38104ba7cfdf6583b3efd3a67134d88d81af3f41",
            "timestamp": "2021-05-15T22:46:37-07:00",
            "author": "Jeremy Lin",
            "commit_message": "`cargo fmt` changes\n\nThe PR build seems to fail without this...",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -308,7 +308,8 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Json\n         }\n \n         user.save(&conn)\n-    })().map_err(|e| e.with_code(Status::InternalServerError.code))?;\n+    })()\n+    .map_err(|e| e.with_code(Status::InternalServerError.code))?;\n \n     Ok(Json(user.to_json(&conn)))\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "8615736e84f802833d0581b1d7f58e7daddc6340",
            "timestamp": "2021-06-19T19:22:19+02:00",
            "author": "BlackDex",
            "commit_message": "Multiple Admin Interface fixes and some others.\n\nMisc:\n- Fixed hadolint workflow, new git cli needs some extra arguments.\n- Add ignore paths to all specific on triggers.\n- Updated hadolint version.\n- Made SMTP_DEBUG read-only, since it can't be changed at runtime.\n\nAdmin:\n- Migrated from Bootstrap v4 to v5\n- Updated jquery to v3.6.0\n- Updated Datatables\n- Made Javascript strict\n- Added a way to show which ENV Vars are overridden.\n- Changed the way to provide data for handlebars.\n- Fixed date/time check.\n- Made support string use details and summary feature of markdown/github.",
            "additions": 9,
            "deletions": 42,
            "change_type": "MODIFY",
            "diff": "@@ -196,9 +196,7 @@ fn _validate_token(token: &str) -> bool {\n struct AdminTemplateData {\n     page_content: String,\n     version: Option<&'static str>,\n-    users: Option<Vec<Value>>,\n-    organizations: Option<Vec<Value>>,\n-    diagnostics: Option<Value>,\n+    page_data: Option<Value>,\n     config: Value,\n     can_backup: bool,\n     logged_in: bool,\n@@ -214,51 +212,19 @@ impl AdminTemplateData {\n             can_backup: *CAN_BACKUP,\n             logged_in: true,\n             urlpath: CONFIG.domain_path(),\n-            users: None,\n-            organizations: None,\n-            diagnostics: None,\n+            page_data: None,\n         }\n     }\n \n-    fn users(users: Vec<Value>) -> Self {\n+    fn with_data(page_content: &str, page_data: Value) -> Self {\n         Self {\n-            page_content: String::from(\"admin/users\"),\n+            page_content: String::from(page_content),\n             version: VERSION,\n-            users: Some(users),\n+            page_data: Some(page_data),\n             config: CONFIG.prepare_json(),\n             can_backup: *CAN_BACKUP,\n             logged_in: true,\n             urlpath: CONFIG.domain_path(),\n-            organizations: None,\n-            diagnostics: None,\n-        }\n-    }\n-\n-    fn organizations(organizations: Vec<Value>) -> Self {\n-        Self {\n-            page_content: String::from(\"admin/organizations\"),\n-            version: VERSION,\n-            organizations: Some(organizations),\n-            config: CONFIG.prepare_json(),\n-            can_backup: *CAN_BACKUP,\n-            logged_in: true,\n-            urlpath: CONFIG.domain_path(),\n-            users: None,\n-            diagnostics: None,\n-        }\n-    }\n-\n-    fn diagnostics(diagnostics: Value) -> Self {\n-        Self {\n-            page_content: String::from(\"admin/diagnostics\"),\n-            version: VERSION,\n-            organizations: None,\n-            config: CONFIG.prepare_json(),\n-            can_backup: *CAN_BACKUP,\n-            logged_in: true,\n-            urlpath: CONFIG.domain_path(),\n-            users: None,\n-            diagnostics: Some(diagnostics),\n         }\n     }\n \n@@ -360,7 +326,7 @@ fn users_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<String>> {\n         })\n         .collect();\n \n-    let text = AdminTemplateData::users(users_json).render()?;\n+    let text = AdminTemplateData::with_data(\"admin/users\", json!(users_json)).render()?;\n     Ok(Html(text))\n }\n \n@@ -466,7 +432,7 @@ fn organizations_overview(_token: AdminToken, conn: DbConn) -> ApiResult<Html<St\n         })\n         .collect();\n \n-    let text = AdminTemplateData::organizations(organizations_json).render()?;\n+    let text = AdminTemplateData::with_data(\"admin/organizations\", json!(organizations_json)).render()?;\n     Ok(Html(text))\n }\n \n@@ -592,11 +558,12 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n         \"db_type\": *DB_TYPE,\n         \"db_version\": get_sql_server_version(&conn),\n         \"admin_url\": format!(\"{}/diagnostics\", admin_url(Referer(None))),\n+        \"overrides\": &CONFIG.get_overrides().join(\", \"),\n         \"server_time_local\": Local::now().format(\"%Y-%m-%d %H:%M:%S %Z\").to_string(),\n         \"server_time\": Utc::now().format(\"%Y-%m-%d %H:%M:%S UTC\").to_string(), // Run the date/time check as the last item to minimize the difference\n     });\n \n-    let text = AdminTemplateData::diagnostics(diagnostics_json).render()?;\n+    let text = AdminTemplateData::with_data(\"admin/diagnostics\", diagnostics_json).render()?;\n     Ok(Html(text))\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "10d5c7738afad9f81958e24baa923530314a587f",
            "timestamp": "2021-09-09T13:52:39+02:00",
            "author": "BlackDex",
            "commit_message": "Fix issue when using uppercase chars in emails\n\nIn the case when SMTP is disabled and.\nwhen inviting new users either via the admin interface or into an\norganization and using uppercase letters, this would fail for those\nusers to be able to register since the checks which were done are\ncase-sensitive and never matched.\n\nThis PR fixes that issue by ensuring everything is lowercase.\nFixes #1963",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -269,7 +269,7 @@ fn invite_user(data: Json<InviteData>, _token: AdminToken, conn: DbConn) -> Json\n         if CONFIG.mail_enabled() {\n             mail::send_invite(&user.email, &user.uuid, None, None, &CONFIG.invitation_org_name(), None)?;\n         } else {\n-            let invitation = Invitation::new(data.email);\n+            let invitation = Invitation::new(user.email.clone());\n             invitation.save(&conn)?;\n         }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "338756550a27d1084ae947a1a108482abb8f473b",
            "timestamp": "2021-10-08T00:01:24+02:00",
            "author": "BlackDex",
            "commit_message": "Fix error reporting in admin and some small fixes\n\n- Fixed a bug in JavaScript which caused no messages to be shown to the\nuser in-case of an error send by the server.\n- Changed mail error handling for better error messages\n- Changed user/org actions from a to buttons, this should prevent\nstrange issues in-case of javascript issues and the page does re-load.\n- Added Alpine and Debian info for the running docker image\n\nDuring the mail error testing i encountered a bug which caused lettre to\npanic. This panic only happens on debug builds and not release builds,\nso no need to update anything on that part. This bug is also already\nfixed. See https://github.com/lettre/lettre/issues/678 and https://github.com/lettre/lettre/pull/679\n\nResolves #2021\nCould also fix the issue reported here #2022, or at least no hash `#` in\nthe url.",
            "additions": 5,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -18,7 +18,9 @@ use crate::{\n     db::{backup_database, get_sql_server_version, models::*, DbConn, DbConnType},\n     error::{Error, MapResult},\n     mail,\n-    util::{format_naive_datetime_local, get_display_size, get_reqwest_client, is_running_in_docker},\n+    util::{\n+        docker_base_image, format_naive_datetime_local, get_display_size, get_reqwest_client, is_running_in_docker,\n+    },\n     CONFIG,\n };\n \n@@ -492,6 +494,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n \n     // Execute some environment checks\n     let running_within_docker = is_running_in_docker();\n+    let docker_base_image = docker_base_image();\n     let has_http_access = has_http_access();\n     let uses_proxy = env::var_os(\"HTTP_PROXY\").is_some()\n         || env::var_os(\"http_proxy\").is_some()\n@@ -549,6 +552,7 @@ fn diagnostics(_token: AdminToken, ip_header: IpHeader, conn: DbConn) -> ApiResu\n         \"web_vault_version\": web_vault_version.version,\n         \"latest_web_build\": latest_web_build,\n         \"running_within_docker\": running_within_docker,\n+        \"docker_base_image\": docker_base_image,\n         \"has_http_access\": has_http_access,\n         \"ip_header_exists\": &ip_header.0.is_some(),\n         \"ip_header_match\": ip_header_name == CONFIG.ip_header(),\n",
            "comment_added_diff": []
        }
    ],
    "base.hbs": [],
    "login.hbs": [],
    "page.hbs": [],
    "error.rs": [
        {
            "commit": "8d1b72b9512b90775e671b7ba08cd552a0aabd13",
            "timestamp": "2019-12-06T22:46:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Collapsed log messages from 3 lines per request to 2 and hidden the ones valued as less informative.\nUse LOG_LEVEL debug or trace to recover them.\n\nRemoved LOG_MOUNTS and bundled it with LOG_LEVEL debug and trace.\n\nRemoved duplicate error messages\n\nMade websocket not proxied message more prominent, but only print it once.",
            "additions": 8,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -86,7 +86,7 @@ impl std::fmt::Debug for Error {\n     fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n         match self.source() {\n             Some(e) => write!(f, \"{}.\\n[CAUSE] {:#?}\", self.message, e),\n-            None => write!(f, \"{}. {}\", self.message, self.error),\n+            None => write!(f, \"{}\", self.message),\n         }\n     }\n }\n@@ -170,15 +170,17 @@ use rocket::response::{self, Responder, Response};\n \n impl<'r> Responder<'r> for Error {\n     fn respond_to(self, _: &Request) -> response::Result<'r> {\n-        let usr_msg = format!(\"{}\", self);\n-        error!(\"{:#?}\", self);\n+        match self.error {\n+            ErrorKind::EmptyError(_) => {} // Don't print the error in this situation\n+            _ => error!(target: \"error\", \"{:#?}\", self),\n+        };\n \n         let code = Status::from_code(self.error_code).unwrap_or(Status::BadRequest);\n \n         Response::build()\n             .status(code)\n             .header(ContentType::JSON)\n-            .sized_body(Cursor::new(usr_msg))\n+            .sized_body(Cursor::new(format!(\"{}\", self)))\n             .ok()\n     }\n }\n@@ -206,11 +208,11 @@ macro_rules! err_json {\n #[macro_export]\n macro_rules! err_handler {\n     ($expr:expr) => {{\n-        error!(\"Unauthorized Error: {}\", $expr);\n+        error!(target: \"auth\", \"Unauthorized Error: {}\", $expr);\n         return rocket::Outcome::Failure((rocket::http::Status::Unauthorized, $expr));\n     }};\n     ($usr_msg:expr, $log_value:expr) => {{\n-        error!(\"Unauthorized Error: {}. {}\", $usr_msg, $log_value);\n+        error!(target: \"auth\", \"Unauthorized Error: {}. {}\", $usr_msg, $log_value);\n         return rocket::Outcome::Failure((rocket::http::Status::Unauthorized, $usr_msg));\n     }};\n }\n",
            "comment_added_diff": [
                [
                    174,
                    "            ErrorKind::EmptyError(_) => {} // Don't print the error in this situation"
                ]
            ]
        },
        {
            "commit": "5cabf4d0400e0db3dffabc2cdafb803d811a01de",
            "timestamp": "2019-12-07T14:38:32+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix IP not shown when failed login (Fixes #761)",
            "additions": 14,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -86,7 +86,18 @@ impl std::fmt::Debug for Error {\n     fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n         match self.source() {\n             Some(e) => write!(f, \"{}.\\n[CAUSE] {:#?}\", self.message, e),\n-            None => write!(f, \"{}\", self.message),\n+            None => match self.error {\n+                ErrorKind::EmptyError(_) => Ok(()),\n+                ErrorKind::SimpleError(ref s) => {\n+                    if &self.message == s {\n+                        write!(f, \"{}\", self.message)\n+                    } else {\n+                        write!(f, \"{}. {}\", self.message, s)\n+                    }\n+                },\n+                ErrorKind::JsonError(_) => write!(f, \"{}\", self.message),\n+                _ => unreachable!(),\n+            },\n         }\n     }\n }\n@@ -200,8 +211,8 @@ macro_rules! err {\n \n #[macro_export]\n macro_rules! err_json {\n-    ($expr:expr) => {{\n-        return Err(crate::error::Error::from($expr));\n+    ($expr:expr, $log_value:expr) => {{\n+        return Err(($log_value, $expr).into());\n     }};\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -94,7 +94,7 @@ impl std::fmt::Debug for Error {\n                     } else {\n                         write!(f, \"{}. {}\", self.message, s)\n                     }\n-                },\n+                }\n                 ErrorKind::JsonError(_) => write!(f, \"{}\", self.message),\n                 _ => unreachable!(),\n             },\n",
            "comment_added_diff": []
        },
        {
            "commit": "ff7b4a3d38f07eb5687ae9beaa044777f07dadba",
            "timestamp": "2020-01-26T15:29:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update handlebars to 3.0 which included performance improvements.\nUpdated lettre to newer git revision, which should give better error messages now.",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -46,6 +46,7 @@ use std::option::NoneError as NoneErr;\n use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n+use lettre::smtp::error::Error as LettreErr;\n \n #[derive(Display, Serialize)]\n pub struct Empty {}\n@@ -73,6 +74,7 @@ make_error! {\n     ReqError(ReqErr):     _has_source, _api_error,\n     RegexError(RegexErr): _has_source, _api_error,\n     YubiError(YubiErr):   _has_source, _api_error,\n+    LetreErr(LettreErr):  _has_source, _api_error,\n }\n \n // This is implemented by hand because NoneError doesn't implement neither Display nor Error\n",
            "comment_added_diff": []
        },
        {
            "commit": "325039c31695ac981da3b88dbbe6c6f40c6a180d",
            "timestamp": "2020-02-17T22:56:26+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Attachment size limits, per-user and per-organization",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -211,6 +211,18 @@ macro_rules! err {\n     }};\n }\n \n+#[macro_export]\n+macro_rules! err_discard {\n+    ($msg:expr, $data:expr) => {{\n+        std::io::copy(&mut $data.open(), &mut std::io::sink()).ok();\n+        return Err(crate::error::Error::new($msg, $msg));\n+    }};\n+    ($usr_msg:expr, $log_value:expr, $data:expr) => {{\n+        std::io::copy(&mut $data.open(), &mut std::io::sink()).ok();\n+        return Err(crate::error::Error::new($usr_msg, $log_value));\n+    }};\n+}\n+\n #[macro_export]\n macro_rules! err_json {\n     ($expr:expr, $log_value:expr) => {{\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 3,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -7,7 +7,6 @@ macro_rules! make_error {\n     ( $( $name:ident ( $ty:ty ): $src_fn:expr, $usr_msg_fun:expr ),+ $(,)? ) => {\n         const BAD_REQUEST: u16 = 400;\n \n-        #[derive(Display)]\n         pub enum ErrorKind { $($name( $ty )),+ }\n         pub struct Error { message: String, error: ErrorKind, error_code: u16 }\n \n@@ -48,7 +47,7 @@ use u2f::u2ferror::U2fError as U2fErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n use lettre::smtp::error::Error as LettreErr;\n \n-#[derive(Display, Serialize)]\n+#[derive(Serialize)]\n pub struct Empty {}\n \n // Error struct\n@@ -118,7 +117,7 @@ impl Error {\n         self\n     }\n \n-    pub fn with_code(mut self, code: u16) -> Self {\n+    pub const fn with_code(mut self, code: u16) -> Self {\n         self.error_code = code;\n         self\n     }\n@@ -146,7 +145,7 @@ impl<S> MapResult<S> for Option<S> {\n     }\n }\n \n-fn _has_source<T>(e: T) -> Option<T> {\n+const fn _has_source<T>(e: T) -> Option<T> {\n     Some(e)\n }\n fn _no_source<T, S>(_: T) -> Option<S> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "63cbd9ef9c23ff7a13dfbbb7723fbb6ed4c5dc13",
            "timestamp": "2020-05-03T17:41:53+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update lettre to latest master",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -45,7 +45,9 @@ use std::option::NoneError as NoneErr;\n use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n-use lettre::smtp::error::Error as LettreErr;\n+use lettre::error::Error as LettreErr;\n+use lettre::address::AddressError as AddrErr;\n+use lettre::transport::smtp::error::Error as SmtpErr;\n \n #[derive(Serialize)]\n pub struct Empty {}\n@@ -73,7 +75,9 @@ make_error! {\n     ReqError(ReqErr):     _has_source, _api_error,\n     RegexError(RegexErr): _has_source, _api_error,\n     YubiError(YubiErr):   _has_source, _api_error,\n-    LetreErr(LettreErr):  _has_source, _api_error,\n+    LetreError(LettreErr):_has_source, _api_error,\n+    AddressError(AddrErr):_has_source, _api_error,\n+    SmtpError(SmtpErr):   _has_source, _api_error,\n }\n \n // This is implemented by hand because NoneError doesn't implement neither Display nor Error\n",
            "comment_added_diff": []
        },
        {
            "commit": "6c5e35ce5c549b82629350dfe9f56f21dc2bc27e",
            "timestamp": "2020-05-07T00:51:46+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Change the mails content types to more closely match what we sent before",
            "additions": 8,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -45,8 +45,10 @@ use std::option::NoneError as NoneErr;\n use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n-use lettre::error::Error as LettreErr;\n+\n use lettre::address::AddressError as AddrErr;\n+use lettre::error::Error as LettreErr;\n+use lettre::message::mime::FromStrError as FromStrErr;\n use lettre::transport::smtp::error::Error as SmtpErr;\n \n #[derive(Serialize)]\n@@ -75,9 +77,11 @@ make_error! {\n     ReqError(ReqErr):     _has_source, _api_error,\n     RegexError(RegexErr): _has_source, _api_error,\n     YubiError(YubiErr):   _has_source, _api_error,\n-    LetreError(LettreErr):_has_source, _api_error,\n-    AddressError(AddrErr):_has_source, _api_error,\n-    SmtpError(SmtpErr):   _has_source, _api_error,\n+\n+    LetreError(LettreErr):    _has_source, _api_error,\n+    AddressError(AddrErr):    _has_source, _api_error,\n+    SmtpError(SmtpErr):       _has_source, _api_error,\n+    FromStrError(FromStrErr): _has_source, _api_error,\n }\n \n // This is implemented by hand because NoneError doesn't implement neither Display nor Error\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 0,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -41,7 +41,6 @@ use reqwest::Error as ReqErr;\n use serde_json::{Error as SerdeErr, Value};\n use std::io::Error as IOErr;\n \n-use std::option::NoneError as NoneErr;\n use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n@@ -84,13 +83,6 @@ make_error! {\n     FromStrError(FromStrErr): _has_source, _api_error,\n }\n \n-// This is implemented by hand because NoneError doesn't implement neither Display nor Error\n-impl From<NoneErr> for Error {\n-    fn from(_: NoneErr) -> Self {\n-        Error::from((\"NoneError\", String::new()))\n-    }\n-}\n-\n impl std::fmt::Debug for Error {\n     fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n         match self.source() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "32cfaab5eefa1564b31819685a7b51f4a5025a59",
            "timestamp": "2020-07-23T21:07:04+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Updated dependencies and changed rocket request imports",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -233,10 +233,10 @@ macro_rules! err_json {\n macro_rules! err_handler {\n     ($expr:expr) => {{\n         error!(target: \"auth\", \"Unauthorized Error: {}\", $expr);\n-        return rocket::Outcome::Failure((rocket::http::Status::Unauthorized, $expr));\n+        return ::rocket::request::Outcome::Failure((rocket::http::Status::Unauthorized, $expr));\n     }};\n     ($usr_msg:expr, $log_value:expr) => {{\n         error!(target: \"auth\", \"Unauthorized Error: {}. {}\", $usr_msg, $log_value);\n-        return rocket::Outcome::Failure((rocket::http::Status::Unauthorized, $usr_msg));\n+        return ::rocket::request::Outcome::Failure((rocket::http::Status::Unauthorized, $usr_msg));\n     }};\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -34,6 +34,7 @@ macro_rules! make_error {\n }\n \n use diesel::result::Error as DieselErr;\n+use diesel::r2d2::PoolError as R2d2Err;\n use handlebars::RenderError as HbErr;\n use jsonwebtoken::errors::Error as JWTErr;\n use regex::Error as RegexErr;\n@@ -66,6 +67,7 @@ make_error! {\n     // Used for special return values, like 2FA errors\n     JsonError(Value):     _no_source,  _serialize,\n     DbError(DieselErr):   _has_source, _api_error,\n+    R2d2Error(R2d2Err):   _has_source, _api_error,\n     U2fError(U2fErr):     _has_source, _api_error,\n     SerdeError(SerdeErr): _has_source, _api_error,\n     JWTError(JWTErr):     _has_source, _api_error,\n",
            "comment_added_diff": []
        },
        {
            "commit": "844cf70345733fbcf2bd0a15cc45aa0040b7638d",
            "timestamp": "2020-09-11T23:52:20+02:00",
            "author": "BlackDex",
            "commit_message": "Updated lettre (and other crates) and workflow.\n\nGeneral:\n- Updated several dependancies\n\nLettre:\n- Updateded lettere and the workflow\n- Changed encoding to base64\n- Convert unix newlines to dos newlines for e-mails.\n- Created custom e-mail boundary (auto generated could cause errors)\n\nTested the e-mails sent using several clients (Linux, Windows, MacOS, Web).\nRun msglint (https://tools.ietf.org/tools/msglint/) on the generated e-mails until all errors were gone.\n\nLettre has changed quite some stuff compared between alpha.1 and alpha.2, i haven't noticed any issues sending e-mails during my tests.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -49,7 +49,7 @@ use yubico::yubicoerror::YubicoError as YubiErr;\n use lettre::address::AddressError as AddrErr;\n use lettre::error::Error as LettreErr;\n use lettre::message::mime::FromStrError as FromStrErr;\n-use lettre::transport::smtp::error::Error as SmtpErr;\n+use lettre::transport::smtp::Error as SmtpErr;\n \n #[derive(Serialize)]\n pub struct Empty {}\n",
            "comment_added_diff": []
        },
        {
            "commit": "6a0d024c69dc6c0a060191085f66c5dc25f1426e",
            "timestamp": "2020-09-14T20:47:46+02:00",
            "author": "BlackDex",
            "commit_message": "Format some common Lettre errors a bit simpler\n\nCurrently when for example using the admin interface to send out a test e-mail just\nreturns `SmtpError`. This is not very helpful. What i have done.\n\n- Match some common Lettre errors to return the error message.\n- Other errors will just be passed on as before.\n\nSome small other changes:\n- Fixed a clippy warning about using clone().\n- Fixed a typo where Lettere was spelled with one t.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -79,7 +79,7 @@ make_error! {\n     RegexError(RegexErr): _has_source, _api_error,\n     YubiError(YubiErr):   _has_source, _api_error,\n \n-    LetreError(LettreErr):    _has_source, _api_error,\n+    LettreError(LettreErr):   _has_source, _api_error,\n     AddressError(AddrErr):    _has_source, _api_error,\n     SmtpError(SmtpErr):       _has_source, _api_error,\n     FromStrError(FromStrErr): _has_source, _api_error,\n",
            "comment_added_diff": []
        },
        {
            "commit": "729c9cff41cc74055f8397fae7f60084dcf4b71b",
            "timestamp": "2020-10-03T22:32:00+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Retry initial db connection, with adjustable option",
            "additions": 5,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -34,6 +34,8 @@ macro_rules! make_error {\n }\n \n use diesel::result::Error as DieselErr;\n+use diesel::ConnectionError as DieselConErr;\n+use diesel_migrations::RunMigrationsError as DieselMigErr;\n use diesel::r2d2::PoolError as R2d2Err;\n use handlebars::RenderError as HbErr;\n use jsonwebtoken::errors::Error as JWTErr;\n@@ -83,6 +85,9 @@ make_error! {\n     AddressError(AddrErr):    _has_source, _api_error,\n     SmtpError(SmtpErr):       _has_source, _api_error,\n     FromStrError(FromStrErr): _has_source, _api_error,\n+\n+    DieselConError(DieselConErr): _has_source, _api_error,\n+    DieselMigError(DieselMigErr): _has_source, _api_error,\n }\n \n impl std::fmt::Debug for Error {\n",
            "comment_added_diff": []
        },
        {
            "commit": "caddf21fca66c8339d01ef238c6cf060eb2090d4",
            "timestamp": "2020-11-22T00:09:45+01:00",
            "author": "janost",
            "commit_message": "Log proper namespace in the err!() macro",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -191,6 +191,7 @@ impl<'r> Responder<'r> for Error {\n     fn respond_to(self, _: &Request) -> response::Result<'r> {\n         match self.error {\n             ErrorKind::EmptyError(_) => {} // Don't print the error in this situation\n+            ErrorKind::SimpleError(_) => {} // Don't print the error in this situation\n             _ => error!(target: \"error\", \"{:#?}\", self),\n         };\n \n@@ -210,9 +211,11 @@ impl<'r> Responder<'r> for Error {\n #[macro_export]\n macro_rules! err {\n     ($msg:expr) => {{\n+        error!(\"{}\", $msg);\n         return Err(crate::error::Error::new($msg, $msg));\n     }};\n     ($usr_msg:expr, $log_value:expr) => {{\n+        error!(\"{}. {}\", $usr_msg, $log_value);\n         return Err(crate::error::Error::new($usr_msg, $log_value));\n     }};\n }\n",
            "comment_added_diff": [
                [
                    194,
                    "            ErrorKind::SimpleError(_) => {} // Don't print the error in this situation"
                ]
            ]
        },
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -220,6 +220,18 @@ macro_rules! err {\n     }};\n }\n \n+#[macro_export]\n+macro_rules! err_code {\n+    ($msg:expr, $err_code: literal) => {{\n+        error!(\"{}\", $msg);\n+        return Err(crate::error::Error::new($msg, $msg).with_code($err_code));\n+    }};\n+    ($usr_msg:expr, $log_value:expr, $err_code: literal) => {{\n+        error!(\"{}. {}\", $usr_msg, $log_value);\n+        return Err(crate::error::Error::new($usr_msg, $log_value).with_code($err_code));\n+    }};\n+}\n+\n #[macro_export]\n macro_rules! err_discard {\n     ($msg:expr, $data:expr) => {{\n",
            "comment_added_diff": []
        },
        {
            "commit": "49af9cf4f5f8264384c7fa9063299f44e7536068",
            "timestamp": "2021-03-27T14:26:32+00:00",
            "author": "Jake Howard",
            "commit_message": "Correctly camelCase acronyms\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#upper_case_acronyms",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -38,11 +38,11 @@ use diesel::ConnectionError as DieselConErr;\n use diesel_migrations::RunMigrationsError as DieselMigErr;\n use diesel::r2d2::PoolError as R2d2Err;\n use handlebars::RenderError as HbErr;\n-use jsonwebtoken::errors::Error as JWTErr;\n+use jsonwebtoken::errors::Error as JwtErr;\n use regex::Error as RegexErr;\n use reqwest::Error as ReqErr;\n use serde_json::{Error as SerdeErr, Value};\n-use std::io::Error as IOErr;\n+use std::io::Error as IoErr;\n \n use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n@@ -72,10 +72,10 @@ make_error! {\n     R2d2Error(R2d2Err):   _has_source, _api_error,\n     U2fError(U2fErr):     _has_source, _api_error,\n     SerdeError(SerdeErr): _has_source, _api_error,\n-    JWTError(JWTErr):     _has_source, _api_error,\n+    JWtError(JwtErr):     _has_source, _api_error,\n     TemplError(HbErr):    _has_source, _api_error,\n     //WsError(ws::Error): _has_source, _api_error,\n-    IOError(IOErr):       _has_source, _api_error,\n+    IoError(IoErr):       _has_source, _api_error,\n     TimeError(TimeErr):   _has_source, _api_error,\n     ReqError(ReqErr):     _has_source, _api_error,\n     RegexError(RegexErr): _has_source, _api_error,\n",
            "comment_added_diff": []
        },
        {
            "commit": "47c2625d38f902c200e083da4ea58fc40bfe3775",
            "timestamp": "2021-03-27T14:36:50+00:00",
            "author": "Jake Howard",
            "commit_message": "Prevent `clippy` complaining at method\n\nIt's not incorrectly wrapped. We care about the return type being `Option`.",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -152,6 +152,7 @@ impl<S> MapResult<S> for Option<S> {\n     }\n }\n \n+#[allow(clippy::unnecessary_wraps)]\n const fn _has_source<T>(e: T) -> Option<T> {\n     Some(e)\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -33,10 +33,10 @@ macro_rules! make_error {\n     };\n }\n \n+use diesel::r2d2::PoolError as R2d2Err;\n use diesel::result::Error as DieselErr;\n use diesel::ConnectionError as DieselConErr;\n use diesel_migrations::RunMigrationsError as DieselMigErr;\n-use diesel::r2d2::PoolError as R2d2Err;\n use handlebars::RenderError as HbErr;\n use jsonwebtoken::errors::Error as JwtErr;\n use regex::Error as RegexErr;\n@@ -191,7 +191,7 @@ use rocket::response::{self, Responder, Response};\n impl<'r> Responder<'r> for Error {\n     fn respond_to(self, _: &Request) -> response::Result<'r> {\n         match self.error {\n-            ErrorKind::EmptyError(_) => {} // Don't print the error in this situation\n+            ErrorKind::EmptyError(_) => {}  // Don't print the error in this situation\n             ErrorKind::SimpleError(_) => {} // Don't print the error in this situation\n             _ => error!(target: \"error\", \"{:#?}\", self),\n         };\n",
            "comment_added_diff": [
                [
                    194,
                    "            ErrorKind::EmptyError(_) => {}  // Don't print the error in this situation"
                ]
            ]
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 1,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -198,11 +198,7 @@ impl<'r> Responder<'r> for Error {\n \n         let code = Status::from_code(self.error_code).unwrap_or(Status::BadRequest);\n \n-        Response::build()\n-            .status(code)\n-            .header(ContentType::JSON)\n-            .sized_body(Cursor::new(format!(\"{}\", self)))\n-            .ok()\n+        Response::build().status(code).header(ContentType::JSON).sized_body(Cursor::new(format!(\"{}\", self))).ok()\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "1db37bf3d06543c890612ff88193813035763034",
            "timestamp": "2021-04-12T21:54:57-04:00",
            "author": "Olivier Martin",
            "commit_message": "make error toast display detailed message\nreplace invite accept error message with the one from upstream\ncheck if config mail is enabled",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -166,7 +166,7 @@ fn _serialize(e: &impl serde::Serialize, _msg: &str) -> String {\n \n fn _api_error(_: &impl std::any::Any, msg: &str) -> String {\n     let json = json!({\n-        \"Message\": \"\",\n+        \"Message\": msg,\n         \"error\": \"\",\n         \"error_description\": \"\",\n         \"ValidationErrors\": {\"\": [ msg ]},\n",
            "comment_added_diff": []
        },
        {
            "commit": "7cb19ef767142b773ab44a457940844589432a74",
            "timestamp": "2021-05-08T17:46:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated branding, email and crates\n\n- Updated branding for admin and emails\n- Updated crates and some deprications\n- Removed newline-converter because this is built-in into lettre\n- Updated email templates to use a shared header and footer template\n- Also trigger SMTP SSL When TLS is selected without SSL\n  Resolves #1641",
            "additions": 0,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -50,7 +50,6 @@ use yubico::yubicoerror::YubicoError as YubiErr;\n \n use lettre::address::AddressError as AddrErr;\n use lettre::error::Error as LettreErr;\n-use lettre::message::mime::FromStrError as FromStrErr;\n use lettre::transport::smtp::Error as SmtpErr;\n \n #[derive(Serialize)]\n@@ -84,7 +83,6 @@ make_error! {\n     LettreError(LettreErr):   _has_source, _api_error,\n     AddressError(AddrErr):    _has_source, _api_error,\n     SmtpError(SmtpErr):       _has_source, _api_error,\n-    FromStrError(FromStrErr): _has_source, _api_error,\n \n     DieselConError(DieselConErr): _has_source, _api_error,\n     DieselMigError(DieselMigErr): _has_source, _api_error,\n",
            "comment_added_diff": []
        },
        {
            "commit": "68e5d95d251ded79a019f681a2a6c1665aef751b",
            "timestamp": "2021-05-10T11:47:41-04:00",
            "author": "Carl Dong",
            "commit_message": "admin: Specifically return 404 for user not found\n\n- Modify err_code to accept an expr for err_code\n- Add get_user_or_404, properly returning 404 instead of a generic 400\n  for cases where user is not found\n- Use get_user_or_404 where appropriate.",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -217,11 +217,11 @@ macro_rules! err {\n \n #[macro_export]\n macro_rules! err_code {\n-    ($msg:expr, $err_code: literal) => {{\n+    ($msg:expr, $err_code: expr) => {{\n         error!(\"{}\", $msg);\n         return Err(crate::error::Error::new($msg, $msg).with_code($err_code));\n     }};\n-    ($usr_msg:expr, $log_value:expr, $err_code: literal) => {{\n+    ($usr_msg:expr, $log_value:expr, $err_code: expr) => {{\n         error!(\"{}. {}\", $usr_msg, $log_value);\n         return Err(crate::error::Error::new($usr_msg, $log_value).with_code($err_code));\n     }};\n",
            "comment_added_diff": []
        },
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 5,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -39,19 +39,18 @@ use diesel::ConnectionError as DieselConErr;\n use diesel_migrations::RunMigrationsError as DieselMigErr;\n use handlebars::RenderError as HbErr;\n use jsonwebtoken::errors::Error as JwtErr;\n+use lettre::address::AddressError as AddrErr;\n+use lettre::error::Error as LettreErr;\n+use lettre::transport::smtp::Error as SmtpErr;\n use regex::Error as RegexErr;\n use reqwest::Error as ReqErr;\n use serde_json::{Error as SerdeErr, Value};\n use std::io::Error as IoErr;\n-\n use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n+use webauthn_rs::error::WebauthnError as WebauthnErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n \n-use lettre::address::AddressError as AddrErr;\n-use lettre::error::Error as LettreErr;\n-use lettre::transport::smtp::Error as SmtpErr;\n-\n #[derive(Serialize)]\n pub struct Empty {}\n \n@@ -86,6 +85,7 @@ make_error! {\n \n     DieselConError(DieselConErr): _has_source, _api_error,\n     DieselMigError(DieselMigErr): _has_source, _api_error,\n+    WebauthnError(WebauthnErr):   _has_source, _api_error,\n }\n \n impl std::fmt::Debug for Error {\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 25,
            "deletions": 25,
            "change_type": "MODIFY",
            "diff": "@@ -61,31 +61,31 @@ pub struct Empty {}\n // The second one contains the function used to obtain the response sent to the client\n make_error! {\n     // Just an empty error\n-    EmptyError(Empty):     _no_source, _serialize,\n+    Empty(Empty):     _no_source, _serialize,\n     // Used to represent err! calls\n-    SimpleError(String):  _no_source,  _api_error,\n+    Simple(String):  _no_source,  _api_error,\n     // Used for special return values, like 2FA errors\n-    JsonError(Value):     _no_source,  _serialize,\n-    DbError(DieselErr):   _has_source, _api_error,\n-    R2d2Error(R2d2Err):   _has_source, _api_error,\n-    U2fError(U2fErr):     _has_source, _api_error,\n-    SerdeError(SerdeErr): _has_source, _api_error,\n-    JWtError(JwtErr):     _has_source, _api_error,\n-    TemplError(HbErr):    _has_source, _api_error,\n+    Json(Value):     _no_source,  _serialize,\n+    Db(DieselErr):   _has_source, _api_error,\n+    R2d2(R2d2Err):   _has_source, _api_error,\n+    U2f(U2fErr):     _has_source, _api_error,\n+    Serde(SerdeErr): _has_source, _api_error,\n+    JWt(JwtErr):     _has_source, _api_error,\n+    Handlebars(HbErr): _has_source, _api_error,\n     //WsError(ws::Error): _has_source, _api_error,\n-    IoError(IoErr):       _has_source, _api_error,\n-    TimeError(TimeErr):   _has_source, _api_error,\n-    ReqError(ReqErr):     _has_source, _api_error,\n-    RegexError(RegexErr): _has_source, _api_error,\n-    YubiError(YubiErr):   _has_source, _api_error,\n+    Io(IoErr):       _has_source, _api_error,\n+    Time(TimeErr):   _has_source, _api_error,\n+    Req(ReqErr):     _has_source, _api_error,\n+    Regex(RegexErr): _has_source, _api_error,\n+    Yubico(YubiErr): _has_source, _api_error,\n \n-    LettreError(LettreErr):   _has_source, _api_error,\n-    AddressError(AddrErr):    _has_source, _api_error,\n-    SmtpError(SmtpErr):       _has_source, _api_error,\n+    Lettre(LettreErr): _has_source, _api_error,\n+    Address(AddrErr):  _has_source, _api_error,\n+    Smtp(SmtpErr):     _has_source, _api_error,\n \n-    DieselConError(DieselConErr): _has_source, _api_error,\n-    DieselMigError(DieselMigErr): _has_source, _api_error,\n-    WebauthnError(WebauthnErr):   _has_source, _api_error,\n+    DieselCon(DieselConErr): _has_source, _api_error,\n+    DieselMig(DieselMigErr): _has_source, _api_error,\n+    Webauthn(WebauthnErr):   _has_source, _api_error,\n }\n \n impl std::fmt::Debug for Error {\n@@ -93,15 +93,15 @@ impl std::fmt::Debug for Error {\n         match self.source() {\n             Some(e) => write!(f, \"{}.\\n[CAUSE] {:#?}\", self.message, e),\n             None => match self.error {\n-                ErrorKind::EmptyError(_) => Ok(()),\n-                ErrorKind::SimpleError(ref s) => {\n+                ErrorKind::Empty(_) => Ok(()),\n+                ErrorKind::Simple(ref s) => {\n                     if &self.message == s {\n                         write!(f, \"{}\", self.message)\n                     } else {\n                         write!(f, \"{}. {}\", self.message, s)\n                     }\n                 }\n-                ErrorKind::JsonError(_) => write!(f, \"{}\", self.message),\n+                ErrorKind::Json(_) => write!(f, \"{}\", self.message),\n                 _ => unreachable!(),\n             },\n         }\n@@ -189,8 +189,8 @@ use rocket::response::{self, Responder, Response};\n impl<'r> Responder<'r> for Error {\n     fn respond_to(self, _: &Request) -> response::Result<'r> {\n         match self.error {\n-            ErrorKind::EmptyError(_) => {}  // Don't print the error in this situation\n-            ErrorKind::SimpleError(_) => {} // Don't print the error in this situation\n+            ErrorKind::Empty(_) => {}  // Don't print the error in this situation\n+            ErrorKind::Simple(_) => {} // Don't print the error in this situation\n             _ => error!(target: \"error\", \"{:#?}\", self),\n         };\n \n",
            "comment_added_diff": [
                [
                    192,
                    "            ErrorKind::Empty(_) => {}  // Don't print the error in this situation"
                ],
                [
                    193,
                    "            ErrorKind::Simple(_) => {} // Don't print the error in this situation"
                ]
            ]
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -50,6 +50,7 @@ use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n use webauthn_rs::error::WebauthnError as WebauthnErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n+use openssl::error::ErrorStack as SSLErr;\n \n #[derive(Serialize)]\n pub struct Empty {}\n@@ -82,6 +83,7 @@ make_error! {\n     Lettre(LettreErr): _has_source, _api_error,\n     Address(AddrErr):  _has_source, _api_error,\n     Smtp(SmtpErr):     _has_source, _api_error,\n+    OpenSSL(SSLErr):   _has_source, _api_error,\n \n     DieselCon(DieselConErr): _has_source, _api_error,\n     DieselMig(DieselMigErr): _has_source, _api_error,\n",
            "comment_added_diff": []
        },
        {
            "commit": "e3a2dfffab7d8af64bb0c964fc740988979eb1a0",
            "timestamp": "2021-06-26T14:21:58+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -42,6 +42,7 @@ use jsonwebtoken::errors::Error as JwtErr;\n use lettre::address::AddressError as AddrErr;\n use lettre::error::Error as LettreErr;\n use lettre::transport::smtp::Error as SmtpErr;\n+use openssl::error::ErrorStack as SSLErr;\n use regex::Error as RegexErr;\n use reqwest::Error as ReqErr;\n use serde_json::{Error as SerdeErr, Value};\n@@ -50,7 +51,6 @@ use std::time::SystemTimeError as TimeErr;\n use u2f::u2ferror::U2fError as U2fErr;\n use webauthn_rs::error::WebauthnError as WebauthnErr;\n use yubico::yubicoerror::YubicoError as YubiErr;\n-use openssl::error::ErrorStack as SSLErr;\n \n #[derive(Serialize)]\n pub struct Empty {}\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -174,6 +174,9 @@ fn _api_error(_: &impl std::any::Any, msg: &str) -> String {\n             \"Message\": msg,\n             \"Object\": \"error\"\n         },\n+        \"ExceptionMessage\": null,\n+        \"ExceptionStackTrace\": null,\n+        \"InnerExceptionMessage\": null,\n         \"Object\": \"error\"\n     });\n     _serialize(&json, \"\")\n",
            "comment_added_diff": []
        },
        {
            "commit": "9375d5b8c212956f3469b86e62e5d7f057194ea2",
            "timestamp": "2021-09-24T18:27:52+02:00",
            "author": "BlackDex",
            "commit_message": "Updated icon downloading\n\n- Unicode websites could break (www.post.japanpost.jp for example).\n  regex would fail because it was missing the unicode-perl feature.\n- Be less verbose in logging with icon downloads\n- Removed duplicate info/error messages\n- Added err_silent! macro to help with the less verbose error/info messages.",
            "additions": 9,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -220,6 +220,15 @@ macro_rules! err {\n     }};\n }\n \n+macro_rules! err_silent {\n+    ($msg:expr) => {{\n+        return Err(crate::error::Error::new($msg, $msg));\n+    }};\n+    ($usr_msg:expr, $log_value:expr) => {{\n+        return Err(crate::error::Error::new($usr_msg, $log_value));\n+    }};\n+}\n+\n #[macro_export]\n macro_rules! err_code {\n     ($msg:expr, $err_code: expr) => {{\n",
            "comment_added_diff": []
        }
    ],
    "util.rs": [
        {
            "commit": "8d1b72b9512b90775e671b7ba08cd552a0aabd13",
            "timestamp": "2019-12-06T22:46:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Collapsed log messages from 3 lines per request to 2 and hidden the ones valued as less informative.\nUse LOG_LEVEL debug or trace to recover them.\n\nRemoved LOG_MOUNTS and bundled it with LOG_LEVEL debug and trace.\n\nRemoved duplicate error messages\n\nMade websocket not proxied message more prominent, but only print it once.",
            "additions": 65,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -2,9 +2,9 @@\n // Web Headers and caching\n //\n use rocket::fairing::{Fairing, Info, Kind};\n+use rocket::http::{ContentType, Header, HeaderMap, Method, Status};\n use rocket::response::{self, Responder};\n-use rocket::{Request, Response};\n-use rocket::http::{Header, HeaderMap, ContentType, Method, Status};\n+use rocket::{Data, Request, Response, Rocket};\n use std::io::Cursor;\n \n pub struct AppHeaders();\n@@ -55,7 +55,7 @@ impl Fairing for CORS {\n     fn info(&self) -> Info {\n         Info {\n             name: \"CORS\",\n-            kind: Kind::Response\n+            kind: Kind::Response,\n         }\n     }\n \n@@ -69,7 +69,7 @@ impl Fairing for CORS {\n \n         if request.method() == Method::Options {\n             let req_allow_headers = CORS::get_header(&req_headers, \"Access-Control-Request-Headers\");\n-            let req_allow_method = CORS::get_header(&req_headers,\"Access-Control-Request-Method\");\n+            let req_allow_method = CORS::get_header(&req_headers, \"Access-Control-Request-Method\");\n \n             response.set_header(Header::new(\"Access-Control-Allow-Methods\", req_allow_method));\n             response.set_header(Header::new(\"Access-Control-Allow-Headers\", req_allow_headers));\n@@ -107,6 +107,67 @@ impl<'r, R: Responder<'r>> Responder<'r> for Cached<R> {\n     }\n }\n \n+// Log all the routes from the main base paths list, and the attachments endoint\n+// Effectively ignores, any static file route, and the alive endpoint\n+const LOGGED_ROUTES: [&str; 6] = [\n+    \"/api\",\n+    \"/admin\",\n+    \"/identity\",\n+    \"/icons\",\n+    \"/notifications/hub/negotiate\",\n+    \"/attachments\",\n+];\n+\n+// Boolean is extra debug, when true, we ignore the whitelist above and also print the mounts\n+pub struct BetterLogging(pub bool);\n+impl Fairing for BetterLogging {\n+    fn info(&self) -> Info {\n+        Info {\n+            name: \"Better Logging\",\n+            kind: Kind::Launch | Kind::Request | Kind::Response,\n+        }\n+    }\n+\n+    fn on_launch(&self, rocket: &Rocket) {\n+        if self.0 {\n+            info!(target: \"routes\", \"Routes loaded:\");\n+            for route in rocket.routes() {\n+                if route.rank < 0 {\n+                    info!(target: \"routes\", \"{:<6} {}\", route.method, route.uri);\n+                } else {\n+                    info!(target: \"routes\", \"{:<6} {} [{}]\", route.method, route.uri, route.rank);\n+                }\n+            }\n+        }\n+\n+        let config = rocket.config();\n+        let scheme = if config.tls_enabled() { \"https\" } else { \"http\" };\n+        let addr = format!(\"{}://{}:{}\", &scheme, &config.address, &config.port);\n+        info!(target: \"start\", \"Rocket has launched from {}\", addr);\n+    }\n+\n+    fn on_request(&self, request: &mut Request<'_>, _data: &Data) {\n+        let mut uri = request.uri().to_string();\n+        uri.truncate(50);\n+\n+        if self.0 || LOGGED_ROUTES.iter().any(|r| uri.starts_with(r)) {\n+            info!(target: \"request\", \"{} {}\", request.method(), uri);\n+        }\n+    }\n+\n+    fn on_response(&self, request: &Request, response: &mut Response) {\n+        let uri = request.uri().to_string();\n+        if self.0 || LOGGED_ROUTES.iter().any(|r| uri.starts_with(r)) {\n+            let status = response.status();\n+            if let Some(ref route) = request.route() {\n+                info!(target: \"response\", \"{} => {} {}\", route, status.code, status.reason)\n+            } else {\n+                info!(target: \"response\", \"{} {}\", status.code, status.reason)\n+            }\n+        }\n+    }\n+}\n+\n //\n // File handling\n //\n",
            "comment_added_diff": [
                [
                    110,
                    "// Log all the routes from the main base paths list, and the attachments endoint"
                ],
                [
                    111,
                    "// Effectively ignores, any static file route, and the alive endpoint"
                ],
                [
                    121,
                    "// Boolean is extra debug, when true, we ignore the whitelist above and also print the mounts"
                ],
                [
                    145,
                    "        let addr = format!(\"{}://{}:{}\", &scheme, &config.address, &config.port);"
                ]
            ]
        },
        {
            "commit": "a03db6d2241dfc6e138136c5ffaa840a7680e872",
            "timestamp": "2019-12-06T22:55:29+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Also hide options requests, unless using debug or trace",
            "additions": 8,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -147,15 +147,22 @@ impl Fairing for BetterLogging {\n     }\n \n     fn on_request(&self, request: &mut Request<'_>, _data: &Data) {\n+        let method = request.method();\n+        if !self.0 && method == Method::Options {\n+            return;\n+        }\n         let mut uri = request.uri().to_string();\n         uri.truncate(50);\n \n         if self.0 || LOGGED_ROUTES.iter().any(|r| uri.starts_with(r)) {\n-            info!(target: \"request\", \"{} {}\", request.method(), uri);\n+            info!(target: \"request\", \"{} {}\", method, uri);\n         }\n     }\n \n     fn on_response(&self, request: &Request, response: &mut Response) {\n+        if !self.0 && request.method() == Method::Options {\n+            return;\n+        }\n         let uri = request.uri().to_string();\n         if self.0 || LOGGED_ROUTES.iter().any(|r| uri.starts_with(r)) {\n             let status = response.status();\n",
            "comment_added_diff": []
        },
        {
            "commit": "25454697130a2bcbb76f7f29cdf8d1d382de96c7",
            "timestamp": "2019-12-19T00:37:16+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix crash when page URL points to huge file",
            "additions": 27,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -216,6 +216,33 @@ pub fn delete_file(path: &str) -> IOResult<()> {\n     res\n }\n \n+pub struct LimitedReader<'a> {\n+    reader: &'a mut dyn std::io::Read,\n+    limit: usize, // In bytes\n+    count: usize,\n+}\n+impl<'a> LimitedReader<'a> {\n+    pub fn new(reader: &'a mut dyn std::io::Read, limit: usize) -> LimitedReader<'a> {\n+        LimitedReader {\n+            reader,\n+            limit,\n+            count: 0,\n+        }\n+    }\n+}\n+\n+impl<'a> std::io::Read for LimitedReader<'a> {\n+    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n+        self.count += buf.len();\n+\n+        if self.count > self.limit {\n+            Ok(0) // End of the read\n+        } else {\n+            self.reader.read(buf)\n+        }\n+    }\n+}\n+\n const UNITS: [&str; 6] = [\"bytes\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"];\n \n pub fn get_display_size(size: i32) -> String {\n",
            "comment_added_diff": [
                [
                    221,
                    "    limit: usize, // In bytes"
                ],
                [
                    239,
                    "            Ok(0) // End of the read"
                ]
            ]
        },
        {
            "commit": "36ae946655ac0e885268bd7502738412508d9ce2",
            "timestamp": "2019-12-29T15:34:22+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Avoid some to_string in the request logging and include message to disable web vault when not found.",
            "additions": 9,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -151,11 +151,13 @@ impl Fairing for BetterLogging {\n         if !self.0 && method == Method::Options {\n             return;\n         }\n-        let mut uri = request.uri().to_string();\n-        uri.truncate(50);\n-\n-        if self.0 || LOGGED_ROUTES.iter().any(|r| uri.starts_with(r)) {\n-            info!(target: \"request\", \"{} {}\", method, uri);\n+        let uri = request.uri();\n+        let uri_path = uri.path();\n+        if self.0 || LOGGED_ROUTES.iter().any(|r| uri_path.starts_with(r)) {\n+            match uri.query() {\n+                Some(q) => info!(target: \"request\", \"{} {}?{}\", method, uri_path, &q[..q.len().min(30)]),\n+                None => info!(target: \"request\", \"{} {}\", method, uri_path),\n+            };\n         }\n     }\n \n@@ -163,8 +165,8 @@ impl Fairing for BetterLogging {\n         if !self.0 && request.method() == Method::Options {\n             return;\n         }\n-        let uri = request.uri().to_string();\n-        if self.0 || LOGGED_ROUTES.iter().any(|r| uri.starts_with(r)) {\n+        let uri_path = request.uri().path();\n+        if self.0 || LOGGED_ROUTES.iter().any(|r| uri_path.starts_with(r)) {\n             let status = response.status();\n             if let Some(ref route) = request.route() {\n                 info!(target: \"response\", \"{} => {} {}\", route, status.code, status.reason)\n",
            "comment_added_diff": []
        },
        {
            "commit": "d212dfe735e59128667a4c579e52ce7e86b53a94",
            "timestamp": "2020-01-20T22:28:54+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Accept y/n, True/False, 1/0 as booleans in environment vars",
            "additions": 11,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -309,6 +309,17 @@ where\n     try_parse_string(env::var(key))\n }\n \n+const TRUE_VALUES: &[&str] = &[\"true\", \"t\", \"yes\", \"y\", \"1\"];\n+const FALSE_VALUES: &[&str] = &[\"false\", \"f\", \"no\", \"n\", \"0\"];\n+\n+pub fn get_env_bool(key: &str) -> Option<bool> {\n+    match env::var(key) {\n+        Ok(val) if TRUE_VALUES.contains(&val.to_lowercase().as_ref()) => Some(true),\n+        Ok(val) if FALSE_VALUES.contains(&val.to_lowercase().as_ref()) => Some(false),\n+        _ => None,\n+    }\n+}\n+\n //\n // Date util methods\n //\n",
            "comment_added_diff": []
        },
        {
            "commit": "8867626de898bb8416ed8319806b1c220d57dcb1",
            "timestamp": "2020-02-04T22:14:50+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add option to change invitation org name, fixes #825\nAdd option to allow additional iframe ancestors, fixes #843\nSort the rocket routes before printing them",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -7,6 +7,8 @@ use rocket::response::{self, Responder};\n use rocket::{Data, Request, Response, Rocket};\n use std::io::Cursor;\n \n+use crate::CONFIG;\n+\n pub struct AppHeaders();\n \n impl Fairing for AppHeaders {\n@@ -23,7 +25,7 @@ impl Fairing for AppHeaders {\n         res.set_raw_header(\"X-Frame-Options\", \"SAMEORIGIN\");\n         res.set_raw_header(\"X-Content-Type-Options\", \"nosniff\");\n         res.set_raw_header(\"X-XSS-Protection\", \"1; mode=block\");\n-        let csp = \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://*;\";\n+        let csp = format!(\"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://* {};\", CONFIG.allowed_iframe_ancestors());\n         res.set_raw_header(\"Content-Security-Policy\", csp);\n \n         // Disable cache unless otherwise specified\n@@ -131,7 +133,9 @@ impl Fairing for BetterLogging {\n     fn on_launch(&self, rocket: &Rocket) {\n         if self.0 {\n             info!(target: \"routes\", \"Routes loaded:\");\n-            for route in rocket.routes() {\n+            let mut routes: Vec<_> = rocket.routes().collect();\n+            routes.sort_by_key(|r| r.uri.path());\n+            for route in routes {\n                 if route.rank < 0 {\n                     info!(target: \"routes\", \"{:<6} {}\", route.method, route.uri);\n                 } else {\n",
            "comment_added_diff": [
                [
                    28,
                    "        let csp = format!(\"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://* {};\", CONFIG.allowed_iframe_ancestors());"
                ]
            ]
        },
        {
            "commit": "29a079521974027d12d6f504f37dcb42cc6a03d9",
            "timestamp": "2020-02-18T21:27:00-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add backend support for alternate base dir (subdir/subpath) hosting\n\nTo use this, include a path in the `DOMAIN` URL, e.g.:\n\n* `DOMAIN=https://example.com/custom-path`\n* `DOMAIN=https://example.com/multiple/levels/are/ok`",
            "additions": 9,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -109,7 +109,7 @@ impl<'r, R: Responder<'r>> Responder<'r> for Cached<R> {\n     }\n }\n \n-// Log all the routes from the main base paths list, and the attachments endoint\n+// Log all the routes from the main paths list, and the attachments endpoint\n // Effectively ignores, any static file route, and the alive endpoint\n const LOGGED_ROUTES: [&str; 6] = [\n     \"/api\",\n@@ -157,7 +157,10 @@ impl Fairing for BetterLogging {\n         }\n         let uri = request.uri();\n         let uri_path = uri.path();\n-        if self.0 || LOGGED_ROUTES.iter().any(|r| uri_path.starts_with(r)) {\n+        // FIXME: trim_start_matches() could result in over-trimming in pathological cases;\n+        // strip_prefix() would be a better option once it's stable.\n+        let uri_subpath = uri_path.trim_start_matches(&CONFIG.domain_path());\n+        if self.0 || LOGGED_ROUTES.iter().any(|r| uri_subpath.starts_with(r)) {\n             match uri.query() {\n                 Some(q) => info!(target: \"request\", \"{} {}?{}\", method, uri_path, &q[..q.len().min(30)]),\n                 None => info!(target: \"request\", \"{} {}\", method, uri_path),\n@@ -169,8 +172,10 @@ impl Fairing for BetterLogging {\n         if !self.0 && request.method() == Method::Options {\n             return;\n         }\n-        let uri_path = request.uri().path();\n-        if self.0 || LOGGED_ROUTES.iter().any(|r| uri_path.starts_with(r)) {\n+        // FIXME: trim_start_matches() could result in over-trimming in pathological cases;\n+        // strip_prefix() would be a better option once it's stable.\n+        let uri_subpath = request.uri().path().trim_start_matches(&CONFIG.domain_path());\n+        if self.0 || LOGGED_ROUTES.iter().any(|r| uri_subpath.starts_with(r)) {\n             let status = response.status();\n             if let Some(ref route) = request.route() {\n                 info!(target: \"response\", \"{} => {} {}\", route, status.code, status.reason)\n",
            "comment_added_diff": [
                [
                    112,
                    "// Log all the routes from the main paths list, and the attachments endpoint"
                ],
                [
                    160,
                    "        // FIXME: trim_start_matches() could result in over-trimming in pathological cases;"
                ],
                [
                    161,
                    "        // strip_prefix() would be a better option once it's stable."
                ],
                [
                    175,
                    "        // FIXME: trim_start_matches() could result in over-trimming in pathological cases;"
                ],
                [
                    176,
                    "        // strip_prefix() would be a better option once it's stable."
                ]
            ]
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 8,
            "deletions": 35,
            "change_type": "MODIFY",
            "diff": "@@ -65,13 +65,13 @@ impl Fairing for CORS {\n         let req_headers = request.headers();\n \n         // We need to explicitly get the Origin header for Access-Control-Allow-Origin\n-        let req_allow_origin = CORS::valid_url(CORS::get_header(&req_headers, \"Origin\"));\n+        let req_allow_origin = CORS::valid_url(CORS::get_header(req_headers, \"Origin\"));\n \n         response.set_header(Header::new(\"Access-Control-Allow-Origin\", req_allow_origin));\n \n         if request.method() == Method::Options {\n-            let req_allow_headers = CORS::get_header(&req_headers, \"Access-Control-Request-Headers\");\n-            let req_allow_method = CORS::get_header(&req_headers, \"Access-Control-Request-Method\");\n+            let req_allow_headers = CORS::get_header(req_headers, \"Access-Control-Request-Headers\");\n+            let req_allow_method = CORS::get_header(req_headers, \"Access-Control-Request-Method\");\n \n             response.set_header(Header::new(\"Access-Control-Allow-Methods\", req_allow_method));\n             response.set_header(Header::new(\"Access-Control-Allow-Headers\", req_allow_headers));\n@@ -86,14 +86,14 @@ impl Fairing for CORS {\n pub struct Cached<R>(R, &'static str);\n \n impl<R> Cached<R> {\n-    pub fn long(r: R) -> Cached<R> {\n+    pub const fn long(r: R) -> Cached<R> {\n         // 7 days\n-        Cached(r, \"public, max-age=604800\")\n+        Self(r, \"public, max-age=604800\")\n     }\n \n-    pub fn short(r: R) -> Cached<R> {\n+    pub const fn short(r: R) -> Cached<R> {\n         // 10 minutes\n-        Cached(r, \"public, max-age=600\")\n+        Self(r, \"public, max-age=600\")\n     }\n }\n \n@@ -177,7 +177,7 @@ impl Fairing for BetterLogging {\n         let uri_subpath = request.uri().path().trim_start_matches(&CONFIG.domain_path());\n         if self.0 || LOGGED_ROUTES.iter().any(|r| uri_subpath.starts_with(r)) {\n             let status = response.status();\n-            if let Some(ref route) = request.route() {\n+            if let Some(route) = request.route() {\n                 info!(target: \"response\", \"{} => {} {}\", route, status.code, status.reason)\n             } else {\n                 info!(target: \"response\", \"{} {}\", status.code, status.reason)\n@@ -227,33 +227,6 @@ pub fn delete_file(path: &str) -> IOResult<()> {\n     res\n }\n \n-pub struct LimitedReader<'a> {\n-    reader: &'a mut dyn std::io::Read,\n-    limit: usize, // In bytes\n-    count: usize,\n-}\n-impl<'a> LimitedReader<'a> {\n-    pub fn new(reader: &'a mut dyn std::io::Read, limit: usize) -> LimitedReader<'a> {\n-        LimitedReader {\n-            reader,\n-            limit,\n-            count: 0,\n-        }\n-    }\n-}\n-\n-impl<'a> std::io::Read for LimitedReader<'a> {\n-    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n-        self.count += buf.len();\n-\n-        if self.count > self.limit {\n-            Ok(0) // End of the read\n-        } else {\n-            self.reader.read(buf)\n-        }\n-    }\n-}\n-\n const UNITS: [&str; 6] = [\"bytes\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"];\n \n pub fn get_display_size(size: i32) -> String {\n",
            "comment_added_diff": []
        },
        {
            "commit": "a8870eef0db11b4856b60b12c975d9187e2cf341",
            "timestamp": "2020-05-20T17:58:39+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Convert to f32 before rounding to fix arm issue",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -243,7 +243,7 @@ pub fn get_display_size(size: i32) -> String {\n     }\n \n     // Round to two decimals\n-    size = (size * 100.).round() / 100.;\n+    let size = ((size * 100.) as f32).round() / 100.;\n     format!(\"{} {}\", size, UNITS[unit_counter])\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "4c3727b4a3a5bae04843a16fd676fc81b7f27cd4",
            "timestamp": "2020-05-22T12:10:56+02:00",
            "author": "fde\u0109",
            "commit_message": "use format! for rounding to fix arm issue",
            "additions": 1,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -242,9 +242,7 @@ pub fn get_display_size(size: i32) -> String {\n         }\n     }\n \n-    // Round to two decimals\n-    let size = ((size * 100.) as f32).round() / 100.;\n-    format!(\"{} {}\", size, UNITS[unit_counter])\n+    format!(\"{:.2} {}\", size, UNITS[unit_counter])\n }\n \n pub fn get_uuid() -> String {\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 15,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -1,12 +1,15 @@\n //\n // Web Headers and caching\n //\n-use rocket::fairing::{Fairing, Info, Kind};\n-use rocket::http::{ContentType, Header, HeaderMap, Method, Status};\n-use rocket::response::{self, Responder};\n-use rocket::{Data, Request, Response, Rocket};\n use std::io::Cursor;\n \n+use rocket::{\n+    fairing::{Fairing, Info, Kind},\n+    http::{ContentType, Header, HeaderMap, Method, Status},\n+    response::{self, Responder},\n+    Data, Request, Response, Rocket,\n+};\n+\n use crate::CONFIG;\n \n pub struct AppHeaders();\n@@ -189,9 +192,11 @@ impl Fairing for BetterLogging {\n //\n // File handling\n //\n-use std::fs::{self, File};\n-use std::io::{Read, Result as IOResult};\n-use std::path::Path;\n+use std::{\n+    fs::{self, File},\n+    io::{Read, Result as IOResult},\n+    path::Path,\n+};\n \n pub fn file_exists(path: &str) -> bool {\n     Path::new(path).exists()\n@@ -253,7 +258,6 @@ pub fn get_uuid() -> String {\n // String util methods\n //\n \n-use std::ops::Try;\n use std::str::FromStr;\n \n pub fn upcase_first(s: &str) -> String {\n@@ -264,12 +268,12 @@ pub fn upcase_first(s: &str) -> String {\n     }\n }\n \n-pub fn try_parse_string<S, T, U>(string: impl Try<Ok = S, Error = U>) -> Option<T>\n+pub fn try_parse_string<S, T>(string: Option<S>) -> Option<T>\n where\n     S: AsRef<str>,\n     T: FromStr,\n {\n-    if let Ok(Ok(value)) = string.into_result().map(|s| s.as_ref().parse::<T>()) {\n+    if let Some(Ok(value)) = string.map(|s| s.as_ref().parse::<T>()) {\n         Some(value)\n     } else {\n         None\n@@ -286,7 +290,7 @@ pub fn get_env<V>(key: &str) -> Option<V>\n where\n     V: FromStr,\n {\n-    try_parse_string(env::var(key))\n+    try_parse_string(env::var(key).ok())\n }\n \n const TRUE_VALUES: &[&str] = &[\"true\", \"t\", \"yes\", \"y\", \"1\"];\n",
            "comment_added_diff": []
        },
        {
            "commit": "de70fbf88a762836bc7c97da9474870172b45221",
            "timestamp": "2020-07-20T22:33:13-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Use `strip_prefix()` instead of `trim_start_matches()` as appropriate\n\nAs of Rust 1.45.0, `strip_prefix()` is now stable.",
            "additions": 3,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -160,9 +160,7 @@ impl Fairing for BetterLogging {\n         }\n         let uri = request.uri();\n         let uri_path = uri.path();\n-        // FIXME: trim_start_matches() could result in over-trimming in pathological cases;\n-        // strip_prefix() would be a better option once it's stable.\n-        let uri_subpath = uri_path.trim_start_matches(&CONFIG.domain_path());\n+        let uri_subpath = uri_path.strip_prefix(&CONFIG.domain_path()).unwrap_or(uri_path);\n         if self.0 || LOGGED_ROUTES.iter().any(|r| uri_subpath.starts_with(r)) {\n             match uri.query() {\n                 Some(q) => info!(target: \"request\", \"{} {}?{}\", method, uri_path, &q[..q.len().min(30)]),\n@@ -175,9 +173,8 @@ impl Fairing for BetterLogging {\n         if !self.0 && request.method() == Method::Options {\n             return;\n         }\n-        // FIXME: trim_start_matches() could result in over-trimming in pathological cases;\n-        // strip_prefix() would be a better option once it's stable.\n-        let uri_subpath = request.uri().path().trim_start_matches(&CONFIG.domain_path());\n+        let uri_path = request.uri().path();\n+        let uri_subpath = uri_path.strip_prefix(&CONFIG.domain_path()).unwrap_or(uri_path);\n         if self.0 || LOGGED_ROUTES.iter().any(|r| uri_subpath.starts_with(r)) {\n             let status = response.status();\n             if let Some(route) = request.route() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "729c9cff41cc74055f8397fae7f60084dcf4b71b",
            "timestamp": "2020-10-03T22:32:00+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Retry initial db connection, with adjustable option",
            "additions": 27,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -410,7 +410,7 @@ fn _process_key(key: &str) -> String {\n // Retry methods\n //\n \n-pub fn retry<F, T, E>(func: F, max_tries: i32) -> Result<T, E>\n+pub fn retry<F, T, E>(func: F, max_tries: u32) -> Result<T, E>\n where\n     F: Fn() -> Result<T, E>,\n {\n@@ -432,3 +432,29 @@ where\n         }\n     }\n }\n+\n+pub fn retry_db<F, T, E>(func: F, max_tries: u32) -> Result<T, E>\n+where\n+    F: Fn() -> Result<T, E>,\n+    E: std::error::Error,\n+{\n+    use std::{thread::sleep, time::Duration};\n+    let mut tries = 0;\n+\n+    loop {\n+        match func() {\n+            ok @ Ok(_) => return ok,\n+            Err(e) => {\n+                tries += 1;\n+\n+                if tries >= max_tries && max_tries > 0 {\n+                    return Err(e);\n+                }\n+\n+                warn!(\"Can't connect to database, retrying: {:?}\", e);\n+\n+                sleep(Duration::from_millis(1_000));\n+            }\n+        }\n+    }\n+}\n",
            "comment_added_diff": []
        },
        {
            "commit": "e8ef76b8f928c8898bcd84c819d616094f123f21",
            "timestamp": "2020-11-29T02:31:49+01:00",
            "author": "janost",
            "commit_message": "Read config vars from files",
            "additions": 21,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -283,20 +283,37 @@ where\n \n use std::env;\n \n+pub fn get_env_str_value(key: &str) -> Option<String>\n+{\n+    let key_file = format!(\"{}_FILE\", key);\n+    let value_from_env = env::var(key);\n+    let value_file = env::var(&key_file);\n+\n+    match (value_from_env, value_file) {\n+        (Ok(_), Ok(_)) => panic!(\"You should not define both {} and {}!\", key, key_file),\n+        (Ok(v_env), Err(_)) => Some(v_env),\n+        (Err(_), Ok(v_file)) => match fs::read_to_string(v_file) {\n+            Ok(content) => Some(content.trim().to_string()),\n+            Err(e) => panic!(\"Failed to load {}: {:?}\", key, e)\n+        },\n+        _ => None\n+    }\n+}\n+\n pub fn get_env<V>(key: &str) -> Option<V>\n where\n     V: FromStr,\n {\n-    try_parse_string(env::var(key).ok())\n+    try_parse_string(get_env_str_value(key))\n }\n \n const TRUE_VALUES: &[&str] = &[\"true\", \"t\", \"yes\", \"y\", \"1\"];\n const FALSE_VALUES: &[&str] = &[\"false\", \"f\", \"no\", \"n\", \"0\"];\n \n pub fn get_env_bool(key: &str) -> Option<bool> {\n-    match env::var(key) {\n-        Ok(val) if TRUE_VALUES.contains(&val.to_lowercase().as_ref()) => Some(true),\n-        Ok(val) if FALSE_VALUES.contains(&val.to_lowercase().as_ref()) => Some(false),\n+    match get_env_str_value(key) {\n+        Some(val) if TRUE_VALUES.contains(&val.to_lowercase().as_ref()) => Some(true),\n+        Some(val) if FALSE_VALUES.contains(&val.to_lowercase().as_ref()) => Some(false),\n         _ => None,\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "455a23361f9071b7c16048ce320ecfc26adccc2d",
            "timestamp": "2020-12-13T19:49:22-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up datetime output and code\n\n* For clarity, add `UTC` suffix for datetimes in the `Diagnostics` admin tab.\n* Format datetimes in the local timezone in the `Users` admin tab.\n* Refactor some datetime code and add doc comments.",
            "additions": 32,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -322,12 +322,40 @@ pub fn get_env_bool(key: &str) -> Option<bool> {\n // Date util methods\n //\n \n-use chrono::NaiveDateTime;\n+use chrono::{DateTime, Local, NaiveDateTime, TimeZone};\n+use chrono_tz::Tz;\n \n-const DATETIME_FORMAT: &str = \"%Y-%m-%dT%H:%M:%S%.6fZ\";\n+/// Formats a UTC-offset `NaiveDateTime` in the format used by Bitwarden API\n+/// responses with \"date\" fields (`CreationDate`, `RevisionDate`, etc.).\n+pub fn format_date(dt: &NaiveDateTime) -> String {\n+    dt.format(\"%Y-%m-%dT%H:%M:%S%.6fZ\").to_string()\n+}\n+\n+/// Formats a `DateTime<Local>` using the specified format string.\n+///\n+/// For a `DateTime<Local>`, the `%Z` specifier normally formats as the\n+/// time zone's UTC offset (e.g., `+00:00`). In this function, if the\n+/// `TZ` environment variable is set, then `%Z` instead formats as the\n+/// abbreviation for that time zone (e.g., `UTC`).\n+pub fn format_datetime_local(dt: &DateTime<Local>, fmt: &str) -> String {\n+    // Try parsing the `TZ` environment variable to enable formatting `%Z` as\n+    // a time zone abbreviation.\n+    if let Ok(tz) = env::var(\"TZ\") {\n+        if let Ok(tz) = tz.parse::<Tz>() {\n+            return dt.with_timezone(&tz).format(fmt).to_string();\n+        }\n+    }\n+\n+    // Otherwise, fall back to formatting `%Z` as a UTC offset.\n+    dt.format(fmt).to_string()\n+}\n \n-pub fn format_date(date: &NaiveDateTime) -> String {\n-    date.format(DATETIME_FORMAT).to_string()\n+/// Formats a UTC-offset `NaiveDateTime` as a datetime in the local time zone.\n+///\n+/// This function basically converts the `NaiveDateTime` to a `DateTime<Local>`,\n+/// and then calls [format_datetime_local](crate::util::format_datetime_local).\n+pub fn format_naive_datetime_local(dt: &NaiveDateTime, fmt: &str) -> String {\n+    format_datetime_local(&Local.from_utc_datetime(dt), fmt)\n }\n \n //\n",
            "comment_added_diff": [
                [
                    328,
                    "/// Formats a UTC-offset `NaiveDateTime` in the format used by Bitwarden API"
                ],
                [
                    329,
                    "/// responses with \"date\" fields (`CreationDate`, `RevisionDate`, etc.)."
                ],
                [
                    334,
                    "/// Formats a `DateTime<Local>` using the specified format string."
                ],
                [
                    335,
                    "///"
                ],
                [
                    336,
                    "/// For a `DateTime<Local>`, the `%Z` specifier normally formats as the"
                ],
                [
                    337,
                    "/// time zone's UTC offset (e.g., `+00:00`). In this function, if the"
                ],
                [
                    338,
                    "/// `TZ` environment variable is set, then `%Z` instead formats as the"
                ],
                [
                    339,
                    "/// abbreviation for that time zone (e.g., `UTC`)."
                ],
                [
                    341,
                    "    // Try parsing the `TZ` environment variable to enable formatting `%Z` as"
                ],
                [
                    342,
                    "    // a time zone abbreviation."
                ],
                [
                    349,
                    "    // Otherwise, fall back to formatting `%Z` as a UTC offset."
                ],
                [
                    353,
                    "/// Formats a UTC-offset `NaiveDateTime` as a datetime in the local time zone."
                ],
                [
                    354,
                    "///"
                ],
                [
                    355,
                    "/// This function basically converts the `NaiveDateTime` to a `DateTime<Local>`,"
                ],
                [
                    356,
                    "/// and then calls [format_datetime_local](crate::util::format_datetime_local)."
                ]
            ]
        },
        {
            "commit": "e37ff6061704d7998fb3df56dde502e5c8325337",
            "timestamp": "2021-02-23T18:51:07-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Change `twofactorauth.org` to `2fa.directory`\n\nThe `twofactorauth.org` has apparently been sold to some company for\nmarketing purposes.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -23,7 +23,7 @@ impl Fairing for AppHeaders {\n     }\n \n     fn on_response(&self, _req: &Request, res: &mut Response) {\n-        res.set_raw_header(\"Feature-Policy\", \"accelerometer 'none'; ambient-light-sensor 'none'; autoplay 'none'; camera 'none'; encrypted-media 'none'; fullscreen 'none'; geolocation 'none'; gyroscope 'none'; magnetometer 'none'; microphone 'none'; midi 'none'; payment 'none'; picture-in-picture 'none'; sync-xhr 'self' https://haveibeenpwned.com https://twofactorauth.org; usb 'none'; vr 'none'\");\n+        res.set_raw_header(\"Feature-Policy\", \"accelerometer 'none'; ambient-light-sensor 'none'; autoplay 'none'; camera 'none'; encrypted-media 'none'; fullscreen 'none'; geolocation 'none'; gyroscope 'none'; magnetometer 'none'; microphone 'none'; midi 'none'; payment 'none'; picture-in-picture 'none'; sync-xhr 'self' https://haveibeenpwned.com https://2fa.directory; usb 'none'; vr 'none'\");\n         res.set_raw_header(\"Referrer-Policy\", \"same-origin\");\n         res.set_raw_header(\"X-Frame-Options\", \"SAMEORIGIN\");\n         res.set_raw_header(\"X-Content-Type-Options\", \"nosniff\");\n",
            "comment_added_diff": [
                [
                    26,
                    "        res.set_raw_header(\"Feature-Policy\", \"accelerometer 'none'; ambient-light-sensor 'none'; autoplay 'none'; camera 'none'; encrypted-media 'none'; fullscreen 'none'; geolocation 'none'; gyroscope 'none'; magnetometer 'none'; microphone 'none'; midi 'none'; payment 'none'; picture-in-picture 'none'; sync-xhr 'self' https://haveibeenpwned.com https://2fa.directory; usb 'none'; vr 'none'\");"
                ]
            ]
        },
        {
            "commit": "513056f7118da82c8011710b65c569080e1fc2ca",
            "timestamp": "2021-02-28T01:45:05-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Check for data folder on startup\n\nCurrently, when starting up for the first time (running standalone, outside\nof Docker), bitwarden_rs panics when the `openssl` tool isn't able to create\n`data/rsa_key.pem` due to the `data` dir not existing. Instead, print a more\nhelpful error message telling the user to create the directory.",
            "additions": 9,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -358,6 +358,15 @@ pub fn format_naive_datetime_local(dt: &NaiveDateTime, fmt: &str) -> String {\n     format_datetime_local(&Local.from_utc_datetime(dt), fmt)\n }\n \n+//\n+// Deployment environment methods\n+//\n+\n+/// Returns true if the program is running in Docker or Podman.\n+pub fn is_running_in_docker() -> bool {\n+    Path::new(\"/.dockerenv\").exists() || Path::new(\"/run/.containerenv\").exists()\n+}\n+\n //\n // Deserialization methods\n //\n",
            "comment_added_diff": [
                [
                    361,
                    "//"
                ],
                [
                    362,
                    "// Deployment environment methods"
                ],
                [
                    363,
                    "//"
                ],
                [
                    365,
                    "/// Returns true if the program is running in Docker or Podman."
                ]
            ]
        },
        {
            "commit": "7d0e234b34c830eae63a713177f4bea310a8ae2d",
            "timestamp": "2021-03-07T00:35:08-08:00",
            "author": "Jeremy Lin",
            "commit_message": "CORS fixes\n\n* The Safari extension apparently now uses the origin `file://` and expects\n  that to be returned (see bitwarden/browser#1311, bitwarden/server#800).\n\n* The `Access-Control-Allow-Origin` header was reflecting the value of the\n  `Origin` header without checking whether the origin was actually allowed.\n  This effectively allows any origin to interact with the server, which\n  defeats the purpose of CORS.",
            "additions": 14,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -48,10 +48,16 @@ impl CORS {\n         }\n     }\n \n-    fn valid_url(url: String) -> String {\n-        match url.as_ref() {\n-            \"file://\" => \"*\".to_string(),\n-            _ => url,\n+    // Check a request's `Origin` header against the list of allowed origins.\n+    // If a match exists, return it. Otherwise, return None.\n+    fn get_allowed_origin(headers: &HeaderMap) -> Option<String> {\n+        let origin = CORS::get_header(headers, \"Origin\");\n+        let domain_origin = CONFIG.domain_origin();\n+        let safari_extension_origin = \"file://\";\n+        if origin == domain_origin || origin == safari_extension_origin {\n+            Some(origin)\n+        } else {\n+            None\n         }\n     }\n }\n@@ -67,11 +73,11 @@ impl Fairing for CORS {\n     fn on_response(&self, request: &Request, response: &mut Response) {\n         let req_headers = request.headers();\n \n-        // We need to explicitly get the Origin header for Access-Control-Allow-Origin\n-        let req_allow_origin = CORS::valid_url(CORS::get_header(req_headers, \"Origin\"));\n-\n-        response.set_header(Header::new(\"Access-Control-Allow-Origin\", req_allow_origin));\n+        if let Some(origin) = CORS::get_allowed_origin(req_headers) {\n+            response.set_header(Header::new(\"Access-Control-Allow-Origin\", origin));\n+        }\n \n+        // Preflight request\n         if request.method() == Method::Options {\n             let req_allow_headers = CORS::get_header(req_headers, \"Access-Control-Request-Headers\");\n             let req_allow_method = CORS::get_header(req_headers, \"Access-Control-Request-Method\");\n",
            "comment_added_diff": [
                [
                    51,
                    "    // Check a request's `Origin` header against the list of allowed origins."
                ],
                [
                    52,
                    "    // If a match exists, return it. Otherwise, return None."
                ],
                [
                    56,
                    "        let safari_extension_origin = \"file://\";"
                ],
                [
                    80,
                    "        // Preflight request"
                ]
            ]
        },
        {
            "commit": "b22564cb000febe9a871f2121d96993ff5569c7b",
            "timestamp": "2021-03-27T13:30:40+00:00",
            "author": "Jake Howard",
            "commit_message": "Cache icons on the client\n\nThis should make the vault pages load much faster, and massively reduce the number of requests.",
            "additions": 9,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -92,17 +92,21 @@ impl Fairing for CORS {\n     }\n }\n \n-pub struct Cached<R>(R, &'static str);\n+pub struct Cached<R>(R, String);\n \n impl<R> Cached<R> {\n-    pub const fn long(r: R) -> Cached<R> {\n+    pub fn long(r: R) -> Cached<R> {\n         // 7 days\n-        Self(r, \"public, max-age=604800\")\n+        Self(r, String::from(\"public, max-age=604800\"))\n     }\n \n-    pub const fn short(r: R) -> Cached<R> {\n+    pub fn short(r: R) -> Cached<R> {\n         // 10 minutes\n-        Self(r, \"public, max-age=600\")\n+        Self(r, String::from(\"public, max-age=600\"))\n+    }\n+\n+    pub fn ttl(r: R, ttl: u64) -> Cached<R> {\n+        Self(r, format!(\"public, immutable, max-age={}\", ttl))\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "131348a49fd94f3fd63758c8419e70968464d4a0",
            "timestamp": "2021-03-27T13:37:56+00:00",
            "author": "Jake Howard",
            "commit_message": "Add immutable caching for vault assets\n\nThe URLs are cachebusted, so updates will still be applied cleanly and immediately",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -97,7 +97,7 @@ pub struct Cached<R>(R, String);\n impl<R> Cached<R> {\n     pub fn long(r: R) -> Cached<R> {\n         // 7 days\n-        Self(r, String::from(\"public, max-age=604800\"))\n+        Self::ttl(r, 604800)\n     }\n \n     pub fn short(r: R) -> Cached<R> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "49af9cf4f5f8264384c7fa9063299f44e7536068",
            "timestamp": "2021-03-27T14:26:32+00:00",
            "author": "Jake Howard",
            "commit_message": "Correctly camelCase acronyms\n\nhttps://rust-lang.github.io/rust-clippy/master/index.html#upper_case_acronyms",
            "additions": 8,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -38,9 +38,9 @@ impl Fairing for AppHeaders {\n     }\n }\n \n-pub struct CORS();\n+pub struct Cors();\n \n-impl CORS {\n+impl Cors {\n     fn get_header(headers: &HeaderMap, name: &str) -> String {\n         match headers.get_one(name) {\n             Some(h) => h.to_string(),\n@@ -51,7 +51,7 @@ impl CORS {\n     // Check a request's `Origin` header against the list of allowed origins.\n     // If a match exists, return it. Otherwise, return None.\n     fn get_allowed_origin(headers: &HeaderMap) -> Option<String> {\n-        let origin = CORS::get_header(headers, \"Origin\");\n+        let origin = Cors::get_header(headers, \"Origin\");\n         let domain_origin = CONFIG.domain_origin();\n         let safari_extension_origin = \"file://\";\n         if origin == domain_origin || origin == safari_extension_origin {\n@@ -62,10 +62,10 @@ impl CORS {\n     }\n }\n \n-impl Fairing for CORS {\n+impl Fairing for Cors {\n     fn info(&self) -> Info {\n         Info {\n-            name: \"CORS\",\n+            name: \"Cors\",\n             kind: Kind::Response,\n         }\n     }\n@@ -73,14 +73,14 @@ impl Fairing for CORS {\n     fn on_response(&self, request: &Request, response: &mut Response) {\n         let req_headers = request.headers();\n \n-        if let Some(origin) = CORS::get_allowed_origin(req_headers) {\n+        if let Some(origin) = Cors::get_allowed_origin(req_headers) {\n             response.set_header(Header::new(\"Access-Control-Allow-Origin\", origin));\n         }\n \n         // Preflight request\n         if request.method() == Method::Options {\n-            let req_allow_headers = CORS::get_header(req_headers, \"Access-Control-Request-Headers\");\n-            let req_allow_method = CORS::get_header(req_headers, \"Access-Control-Request-Method\");\n+            let req_allow_headers = Cors::get_header(req_headers, \"Access-Control-Request-Headers\");\n+            let req_allow_method = Cors::get_header(req_headers, \"Access-Control-Request-Method\");\n \n             response.set_header(Header::new(\"Access-Control-Allow-Methods\", req_allow_method));\n             response.set_header(Header::new(\"Access-Control-Allow-Headers\", req_allow_headers));\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 7,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -28,7 +28,10 @@ impl Fairing for AppHeaders {\n         res.set_raw_header(\"X-Frame-Options\", \"SAMEORIGIN\");\n         res.set_raw_header(\"X-Content-Type-Options\", \"nosniff\");\n         res.set_raw_header(\"X-XSS-Protection\", \"1; mode=block\");\n-        let csp = format!(\"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://* {};\", CONFIG.allowed_iframe_ancestors());\n+        let csp = format!(\n+            \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://* {};\",\n+            CONFIG.allowed_iframe_ancestors()\n+        );\n         res.set_raw_header(\"Content-Security-Policy\", csp);\n \n         // Disable cache unless otherwise specified\n@@ -293,8 +296,7 @@ where\n \n use std::env;\n \n-pub fn get_env_str_value(key: &str) -> Option<String>\n-{\n+pub fn get_env_str_value(key: &str) -> Option<String> {\n     let key_file = format!(\"{}_FILE\", key);\n     let value_from_env = env::var(key);\n     let value_file = env::var(&key_file);\n@@ -304,9 +306,9 @@ pub fn get_env_str_value(key: &str) -> Option<String>\n         (Ok(v_env), Err(_)) => Some(v_env),\n         (Err(_), Ok(v_file)) => match fs::read_to_string(v_file) {\n             Ok(content) => Some(content.trim().to_string()),\n-            Err(e) => panic!(\"Failed to load {}: {:?}\", key, e)\n+            Err(e) => panic!(\"Failed to load {}: {:?}\", key, e),\n         },\n-        _ => None\n+        _ => None,\n     }\n }\n \n",
            "comment_added_diff": [
                [
                    32,
                    "            \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://* {};\","
                ]
            ]
        },
        {
            "commit": "155109dea120e109e1e027d4e1312b6adad4c231",
            "timestamp": "2021-04-06T21:04:37+01:00",
            "author": "Jake Howard",
            "commit_message": "Extract client creation to a single place",
            "additions": 17,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -478,7 +478,6 @@ pub fn retry<F, T, E>(func: F, max_tries: u32) -> Result<T, E>\n where\n     F: Fn() -> Result<T, E>,\n {\n-    use std::{thread::sleep, time::Duration};\n     let mut tries = 0;\n \n     loop {\n@@ -497,12 +496,13 @@ where\n     }\n }\n \n+use std::{thread::sleep, time::Duration};\n+\n pub fn retry_db<F, T, E>(func: F, max_tries: u32) -> Result<T, E>\n where\n     F: Fn() -> Result<T, E>,\n     E: std::error::Error,\n {\n-    use std::{thread::sleep, time::Duration};\n     let mut tries = 0;\n \n     loop {\n@@ -522,3 +522,18 @@ where\n         }\n     }\n }\n+\n+use reqwest::{blocking::{Client, ClientBuilder}, header};\n+\n+pub fn get_reqwest_client() -> Client {\n+    get_reqwest_client_builder().build().expect(\"Failed to build client\")\n+}\n+\n+pub fn get_reqwest_client_builder() -> ClientBuilder {\n+    let mut headers = header::HeaderMap::new();\n+    headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Bitwarden_RS\"));\n+    Client::builder()\n+        .default_headers(headers)\n+        .timeout(Duration::from_secs(10))\n+\n+}\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 7,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -127,14 +127,8 @@ impl<'r, R: Responder<'r>> Responder<'r> for Cached<R> {\n \n // Log all the routes from the main paths list, and the attachments endpoint\n // Effectively ignores, any static file route, and the alive endpoint\n-const LOGGED_ROUTES: [&str; 6] = [\n-    \"/api\",\n-    \"/admin\",\n-    \"/identity\",\n-    \"/icons\",\n-    \"/notifications/hub/negotiate\",\n-    \"/attachments\",\n-];\n+const LOGGED_ROUTES: [&str; 6] =\n+    [\"/api\", \"/admin\", \"/identity\", \"/icons\", \"/notifications/hub/negotiate\", \"/attachments\"];\n \n // Boolean is extra debug, when true, we ignore the whitelist above and also print the mounts\n pub struct BetterLogging(pub bool);\n@@ -161,7 +155,11 @@ impl Fairing for BetterLogging {\n         }\n \n         let config = rocket.config();\n-        let scheme = if config.tls_enabled() { \"https\" } else { \"http\" };\n+        let scheme = if config.tls_enabled() {\n+            \"https\"\n+        } else {\n+            \"http\"\n+        };\n         let addr = format!(\"{}://{}:{}\", &scheme, &config.address, &config.port);\n         info!(target: \"start\", \"Rocket has launched from {}\", addr);\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "305de2e2cd820ae6651a6442d88f5ca637263fae",
            "timestamp": "2021-04-15T18:30:23+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Format the changes from merge to master",
            "additions": 5,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -523,7 +523,10 @@ where\n     }\n }\n \n-use reqwest::{blocking::{Client, ClientBuilder}, header};\n+use reqwest::{\n+    blocking::{Client, ClientBuilder},\n+    header,\n+};\n \n pub fn get_reqwest_client() -> Client {\n     get_reqwest_client_builder().build().expect(\"Failed to build client\")\n@@ -532,8 +535,5 @@ pub fn get_reqwest_client() -> Client {\n pub fn get_reqwest_client_builder() -> ClientBuilder {\n     let mut headers = header::HeaderMap::new();\n     headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Bitwarden_RS\"));\n-    Client::builder()\n-        .default_headers(headers)\n-        .timeout(Duration::from_secs(10))\n-\n+    Client::builder().default_headers(headers).timeout(Duration::from_secs(10))\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -534,6 +534,6 @@ pub fn get_reqwest_client() -> Client {\n \n pub fn get_reqwest_client_builder() -> ClientBuilder {\n     let mut headers = header::HeaderMap::new();\n-    headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Bitwarden_RS\"));\n+    headers.insert(header::USER_AGENT, header::HeaderValue::from_static(\"Vaultwarden\"));\n     Client::builder().default_headers(headers).timeout(Duration::from_secs(10))\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "46e0f3c43a81ce9411612c152e414162a9c220ac",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Load RSA keys as pem format directly, and using openssl crate, backported from async branch",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -219,6 +219,14 @@ pub fn read_file(path: &str) -> IOResult<Vec<u8>> {\n     Ok(contents)\n }\n \n+pub fn write_file(path: &str, content: &[u8]) -> Result<(), crate::error::Error> {\n+    use std::io::Write;\n+    let mut f = File::create(path)?;\n+    f.write_all(content)?;\n+    f.flush()?;\n+    Ok(())\n+}\n+\n pub fn read_file_string(path: &str) -> IOResult<String> {\n     let mut contents = String::new();\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "a622b4d2fb3134f94f156c09365d3cd243d6b4f0",
            "timestamp": "2021-07-08T01:19:52+09:00",
            "author": "Kaito Udagawa",
            "commit_message": "Add Edge's frame-ancestors\n\nEdge's frame-ancestors are required for Edge extension to do WebAuthn.",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -29,7 +29,7 @@ impl Fairing for AppHeaders {\n         res.set_raw_header(\"X-Content-Type-Options\", \"nosniff\");\n         res.set_raw_header(\"X-XSS-Protection\", \"1; mode=block\");\n         let csp = format!(\n-            \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb moz-extension://* {};\",\n+            \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb chrome-extension://jbkfoedolllekgbhcbcoahefnbanhhlh moz-extension://* {};\",\n             CONFIG.allowed_iframe_ancestors()\n         );\n         res.set_raw_header(\"Content-Security-Policy\", csp);\n",
            "comment_added_diff": [
                [
                    32,
                    "            \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb chrome-extension://jbkfoedolllekgbhcbcoahefnbanhhlh moz-extension://* {};\","
                ]
            ]
        },
        {
            "commit": "13598c098f5c941c8dd4d0452ea67750d6a5020a",
            "timestamp": "2021-07-08T02:52:45+09:00",
            "author": "Kaito Udagawa",
            "commit_message": "Add links to browser extensions",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -29,6 +29,9 @@ impl Fairing for AppHeaders {\n         res.set_raw_header(\"X-Content-Type-Options\", \"nosniff\");\n         res.set_raw_header(\"X-XSS-Protection\", \"1; mode=block\");\n         let csp = format!(\n+            // Chrome Web Store: https://chrome.google.com/webstore/detail/bitwarden-free-password-m/nngceckbapebfimnlniiiahkandclblb\n+            // Edge Add-ons: https://microsoftedge.microsoft.com/addons/detail/bitwarden-free-password/jbkfoedolllekgbhcbcoahefnbanhhlh?hl=en-US\n+            // Firefox Browser Add-ons: https://addons.mozilla.org/ja/firefox/addon/bitwarden-password-manager/\n             \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb chrome-extension://jbkfoedolllekgbhcbcoahefnbanhhlh moz-extension://* {};\",\n             CONFIG.allowed_iframe_ancestors()\n         );\n",
            "comment_added_diff": [
                [
                    32,
                    "            // Chrome Web Store: https://chrome.google.com/webstore/detail/bitwarden-free-password-m/nngceckbapebfimnlniiiahkandclblb"
                ],
                [
                    33,
                    "            // Edge Add-ons: https://microsoftedge.microsoft.com/addons/detail/bitwarden-free-password/jbkfoedolllekgbhcbcoahefnbanhhlh?hl=en-US"
                ],
                [
                    34,
                    "            // Firefox Browser Add-ons: https://addons.mozilla.org/ja/firefox/addon/bitwarden-password-manager/"
                ]
            ]
        },
        {
            "commit": "c640abbcd71bfb9758cfe1be597a63323f6afef0",
            "timestamp": "2021-07-08T02:55:58+09:00",
            "author": "Kaito Udagawa",
            "commit_message": "Update src/util.rs\n\nCo-authored-by: William Desportes <williamdes@wdes.fr>",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -31,7 +31,7 @@ impl Fairing for AppHeaders {\n         let csp = format!(\n             // Chrome Web Store: https://chrome.google.com/webstore/detail/bitwarden-free-password-m/nngceckbapebfimnlniiiahkandclblb\n             // Edge Add-ons: https://microsoftedge.microsoft.com/addons/detail/bitwarden-free-password/jbkfoedolllekgbhcbcoahefnbanhhlh?hl=en-US\n-            // Firefox Browser Add-ons: https://addons.mozilla.org/ja/firefox/addon/bitwarden-password-manager/\n+            // Firefox Browser Add-ons: https://addons.mozilla.org/en-US/firefox/addon/bitwarden-password-manager/\n             \"frame-ancestors 'self' chrome-extension://nngceckbapebfimnlniiiahkandclblb chrome-extension://jbkfoedolllekgbhcbcoahefnbanhhlh moz-extension://* {};\",\n             CONFIG.allowed_iframe_ancestors()\n         );\n",
            "comment_added_diff": [
                [
                    34,
                    "            // Firefox Browser Add-ons: https://addons.mozilla.org/en-US/firefox/addon/bitwarden-password-manager/"
                ]
            ]
        },
        {
            "commit": "e5ec245626e4a4d232b6a709338fe1e9811845e7",
            "timestamp": "2021-07-15T19:15:55+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Protect namedfile against path traversal, rocket only does it for pathbuf",
            "additions": 32,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,8 @@ use std::io::Cursor;\n \n use rocket::{\n     fairing::{Fairing, Info, Kind},\n-    http::{ContentType, Header, HeaderMap, Method, Status},\n+    http::{ContentType, Header, HeaderMap, Method, RawStr, Status},\n+    request::FromParam,\n     response::{self, Responder},\n     Data, Request, Response, Rocket,\n };\n@@ -125,6 +126,36 @@ impl<'r, R: Responder<'r>> Responder<'r> for Cached<R> {\n     }\n }\n \n+pub struct SafeString(String);\n+\n+impl std::fmt::Display for SafeString {\n+    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n+        self.0.fmt(f)\n+    }\n+}\n+\n+impl AsRef<Path> for SafeString {\n+    #[inline]\n+    fn as_ref(&self) -> &Path {\n+        Path::new(&self.0)\n+    }\n+}\n+\n+impl<'r> FromParam<'r> for SafeString {\n+    type Error = ();\n+\n+    #[inline(always)]\n+    fn from_param(param: &'r RawStr) -> Result<Self, Self::Error> {\n+        let s = param.percent_decode().map(|cow| cow.into_owned()).map_err(|_| ())?;\n+\n+        if s.chars().all(|c| matches!(c, 'a'..='z' | 'A'..='Z' |'0'..='9' | '-')) {\n+            Ok(SafeString(s))\n+        } else {\n+            Err(())\n+        }\n+    }\n+}\n+\n // Log all the routes from the main paths list, and the attachments endpoint\n // Effectively ignores, any static file route, and the alive endpoint\n const LOGGED_ROUTES: [&str; 6] =\n",
            "comment_added_diff": []
        },
        {
            "commit": "338756550a27d1084ae947a1a108482abb8f473b",
            "timestamp": "2021-10-08T00:01:24+02:00",
            "author": "BlackDex",
            "commit_message": "Fix error reporting in admin and some small fixes\n\n- Fixed a bug in JavaScript which caused no messages to be shown to the\nuser in-case of an error send by the server.\n- Changed mail error handling for better error messages\n- Changed user/org actions from a to buttons, this should prevent\nstrange issues in-case of javascript issues and the page does re-load.\n- Added Alpine and Debian info for the running docker image\n\nDuring the mail error testing i encountered a bug which caused lettre to\npanic. This panic only happens on debug builds and not release builds,\nso no need to update anything on that part. This bug is also already\nfixed. See https://github.com/lettre/lettre/issues/678 and https://github.com/lettre/lettre/pull/679\n\nResolves #2021\nCould also fix the issue reported here #2022, or at least no hash `#` in\nthe url.",
            "additions": 12,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -419,6 +419,18 @@ pub fn is_running_in_docker() -> bool {\n     Path::new(\"/.dockerenv\").exists() || Path::new(\"/run/.containerenv\").exists()\n }\n \n+/// Simple check to determine on which docker base image vaultwarden is running.\n+/// We build images based upon Debian or Alpine, so these we check here.\n+pub fn docker_base_image() -> String {\n+    if Path::new(\"/etc/debian_version\").exists() {\n+        \"Debian\".to_string()\n+    } else if Path::new(\"/etc/alpine-release\").exists() {\n+        \"Alpine\".to_string()\n+    } else {\n+        \"Unknown\".to_string()\n+    }\n+}\n+\n //\n // Deserialization methods\n //\n",
            "comment_added_diff": [
                [
                    422,
                    "/// Simple check to determine on which docker base image vaultwarden is running."
                ],
                [
                    423,
                    "/// We build images based upon Debian or Alpine, so these we check here."
                ]
            ]
        }
    ],
    "rustfmt.toml": [],
    "yubikey.rs": [
        {
            "commit": "a0ece3754b8315ec0d220168f2dc31a2c88ffce1",
            "timestamp": "2019-12-27T18:37:14+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Formatting",
            "additions": 1,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -16,11 +16,7 @@ use crate::error::{Error, MapResult};\n use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n-    routes![\n-        generate_yubikey,\n-        activate_yubikey,\n-        activate_yubikey_put,\n-    ]\n+    routes![generate_yubikey, activate_yubikey, activate_yubikey_put,]\n }\n \n #[derive(Deserialize, Debug)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,5 @@\n use rocket::Route;\n use rocket_contrib::json::Json;\n-use serde_json;\n use serde_json::Value;\n use yubico::config::Config;\n use yubico::verify;\n",
            "comment_added_diff": []
        },
        {
            "commit": "668d5c23dc084b778496b655e93196bdfe007953",
            "timestamp": "2020-07-14T18:34:22+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Removed try_trait and some formatting, particularly around imports",
            "additions": 11,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -1,18 +1,18 @@\n use rocket::Route;\n use rocket_contrib::json::Json;\n use serde_json::Value;\n-use yubico::config::Config;\n-use yubico::verify;\n-\n-use crate::api::core::two_factor::_generate_recover_code;\n-use crate::api::{EmptyResult, JsonResult, JsonUpcase, PasswordData};\n-use crate::auth::Headers;\n-use crate::db::{\n-    models::{TwoFactor, TwoFactorType},\n-    DbConn,\n+use yubico::{config::Config, verify};\n+\n+use crate::{\n+    api::{core::two_factor::_generate_recover_code, EmptyResult, JsonResult, JsonUpcase, PasswordData},\n+    auth::Headers,\n+    db::{\n+        models::{TwoFactor, TwoFactorType},\n+        DbConn,\n+    },\n+    error::{Error, MapResult},\n+    CONFIG,\n };\n-use crate::error::{Error, MapResult};\n-use crate::CONFIG;\n \n pub fn routes() -> Vec<Route> {\n     routes![generate_yubikey, activate_yubikey, activate_yubikey_put,]\n",
            "comment_added_diff": []
        }
    ],
    "Dockerfile.j2": [],
    "attachment.rs": [
        {
            "commit": "325039c31695ac981da3b88dbbe6c6f40c6a180d",
            "timestamp": "2020-02-17T22:56:26+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Attachment size limits, per-user and per-organization",
            "additions": 23,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -49,7 +49,7 @@ impl Attachment {\n     }\n }\n \n-use crate::db::schema::attachments;\n+use crate::db::schema::{attachments, ciphers};\n use crate::db::DbConn;\n use diesel;\n use diesel::prelude::*;\n@@ -118,4 +118,26 @@ impl Attachment {\n             .load::<Self>(&**conn)\n             .expect(\"Error loading attachments\")\n     }\n+\n+    pub fn size_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n+        let result: Option<i64> = attachments::table\n+            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+            .filter(ciphers::user_uuid.eq(user_uuid))\n+            .select(diesel::dsl::sum(attachments::file_size))\n+            .first(&**conn)\n+            .expect(\"Error loading user attachment total size\");\n+\n+        result.unwrap_or(0)\n+    }\n+\n+    pub fn size_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n+        let result: Option<i64> = attachments::table\n+            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+            .filter(ciphers::organization_uuid.eq(org_uuid))\n+            .select(diesel::dsl::sum(attachments::file_size))\n+            .first(&**conn)\n+            .expect(\"Error loading user attachment total size\");\n+\n+        result.unwrap_or(0)\n+    }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "1ee8e44912a02feb77fd9640a5cc4782b494820b",
            "timestamp": "2020-04-15T16:49:33+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #965\n\nPostgreSQL updates/inserts ignored None/null values.\nThis is nice for new entries, but not for updates.\nAdded derive option to allways add these none/null values for Option<>\nvariables.\n\nThis solves issue #965",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -5,6 +5,7 @@ use crate::CONFIG;\n \n #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n #[table_name = \"attachments\"]\n+#[changeset_options(treat_none_as_null=\"true\")]\n #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n #[primary_key(id)]\n pub struct Attachment {\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -18,7 +18,7 @@ pub struct Attachment {\n \n /// Local methods\n impl Attachment {\n-    pub fn new(id: String, cipher_uuid: String, file_name: String, file_size: i32) -> Self {\n+    pub const fn new(id: String, cipher_uuid: String, file_name: String, file_size: i32) -> Self {\n         Self {\n             id,\n             cipher_uuid,\n@@ -52,7 +52,6 @@ impl Attachment {\n \n use crate::db::schema::{attachments, ciphers};\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n",
            "comment_added_diff": []
        },
        {
            "commit": "2fffaec226e2dcfb9b013aa985049e368b88f368",
            "timestamp": "2020-06-03T17:57:03+02:00",
            "author": "BlackDex",
            "commit_message": "Added attachment info per user and some layout fix\n\n- Added the amount and size of the attachments per user\n- Changed the items count function a bit\n- Some small layout changes",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -130,6 +130,16 @@ impl Attachment {\n         result.unwrap_or(0)\n     }\n \n+    pub fn count_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n+        attachments::table\n+            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+            .filter(ciphers::user_uuid.eq(user_uuid))\n+            .count()\n+            .first::<i64>(&**conn)\n+            .ok()\n+            .unwrap_or(0)\n+    }\n+\n     pub fn size_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n         let result: Option<i64> = attachments::table\n             .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n",
            "comment_added_diff": []
        },
        {
            "commit": "ac2723f898c45120ec023bbb2e0e66b26ad71a01",
            "timestamp": "2020-06-03T20:37:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated Organizations overview\n\n- Changed HTML to match users overview\n- Added User count\n- Added Org cipher amount\n- Added Attachment count and size",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -150,4 +150,14 @@ impl Attachment {\n \n         result.unwrap_or(0)\n     }\n+\n+    pub fn count_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n+        attachments::table\n+            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+            .filter(ciphers::organization_uuid.eq(org_uuid))\n+            .count()\n+            .first(&**conn)\n+            .ok()\n+            .unwrap_or(0)\n+    }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 96,
            "deletions": 80,
            "change_type": "MODIFY",
            "diff": "@@ -3,17 +3,19 @@ use serde_json::Value;\n use super::Cipher;\n use crate::CONFIG;\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"attachments\"]\n-#[changeset_options(treat_none_as_null=\"true\")]\n-#[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n-#[primary_key(id)]\n-pub struct Attachment {\n-    pub id: String,\n-    pub cipher_uuid: String,\n-    pub file_name: String,\n-    pub file_size: i32,\n-    pub akey: Option<String>,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"attachments\"]\n+    #[changeset_options(treat_none_as_null=\"true\")]\n+    #[belongs_to(super::Cipher, foreign_key = \"cipher_uuid\")]\n+    #[primary_key(id)]\n+    pub struct Attachment {\n+        pub id: String,\n+        pub cipher_uuid: String,\n+        pub file_name: String,\n+        pub file_size: i32,\n+        pub akey: Option<String>,\n+    }\n }\n \n /// Local methods\n@@ -50,43 +52,46 @@ impl Attachment {\n     }\n }\n \n-use crate::db::schema::{attachments, ciphers};\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n \n /// Database methods\n impl Attachment {\n-    #[cfg(feature = \"postgresql\")]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        diesel::insert_into(attachments::table)\n-            .values(self)\n-            .on_conflict(attachments::id)\n-            .do_update()\n-            .set(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving attachment\")\n-    }\n \n-    #[cfg(not(feature = \"postgresql\"))]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        diesel::replace_into(attachments::table)\n-            .values(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving attachment\")\n+        db_run! { conn:\n+            sqlite, mysql {\n+                diesel::replace_into(attachments::table)\n+                    .values(AttachmentDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving attachment\")\n+            }\n+            postgresql {\n+                let value = AttachmentDb::to_db(self);\n+                diesel::insert_into(attachments::table)\n+                    .values(&value)\n+                    .on_conflict(attachments::id)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving attachment\")\n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        crate::util::retry(\n-            || diesel::delete(attachments::table.filter(attachments::id.eq(&self.id))).execute(&**conn),\n-            10,\n-        )\n-        .map_res(\"Error deleting attachment\")?;\n-\n-        crate::util::delete_file(&self.get_file_path())?;\n-        Ok(())\n+        db_run! { conn: {\n+            crate::util::retry(\n+                || diesel::delete(attachments::table.filter(attachments::id.eq(&self.id))).execute(conn),\n+                10,\n+            )\n+            .map_res(\"Error deleting attachment\")?;\n+\n+            crate::util::delete_file(&self.get_file_path())?;\n+            Ok(())\n+        }}\n     }\n \n     pub fn delete_all_by_cipher(cipher_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -97,67 +102,78 @@ impl Attachment {\n     }\n \n     pub fn find_by_id(id: &str, conn: &DbConn) -> Option<Self> {\n-        let id = id.to_lowercase();\n-\n-        attachments::table\n-            .filter(attachments::id.eq(id))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            attachments::table\n+                .filter(attachments::id.eq(id.to_lowercase()))\n+                .first::<AttachmentDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_cipher(cipher_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        attachments::table\n-            .filter(attachments::cipher_uuid.eq(cipher_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading attachments\")\n+        db_run! { conn: {\n+            attachments::table\n+                .filter(attachments::cipher_uuid.eq(cipher_uuid))\n+                .load::<AttachmentDb>(conn)\n+                .expect(\"Error loading attachments\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_ciphers(cipher_uuids: Vec<String>, conn: &DbConn) -> Vec<Self> {\n-        attachments::table\n-            .filter(attachments::cipher_uuid.eq_any(cipher_uuids))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading attachments\")\n+        db_run! { conn: {\n+            attachments::table\n+                .filter(attachments::cipher_uuid.eq_any(cipher_uuids))\n+                .load::<AttachmentDb>(conn)\n+                .expect(\"Error loading attachments\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn size_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n-        let result: Option<i64> = attachments::table\n-            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n-            .filter(ciphers::user_uuid.eq(user_uuid))\n-            .select(diesel::dsl::sum(attachments::file_size))\n-            .first(&**conn)\n-            .expect(\"Error loading user attachment total size\");\n-\n-        result.unwrap_or(0)\n+        db_run! { conn: {\n+            let result: Option<i64> = attachments::table\n+                .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+                .filter(ciphers::user_uuid.eq(user_uuid))\n+                .select(diesel::dsl::sum(attachments::file_size))\n+                .first(conn)\n+                .expect(\"Error loading user attachment total size\");\n+            result.unwrap_or(0)\n+        }}\n     }\n \n     pub fn count_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n-        attachments::table\n-            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n-            .filter(ciphers::user_uuid.eq(user_uuid))\n-            .count()\n-            .first::<i64>(&**conn)\n-            .ok()\n-            .unwrap_or(0)\n+        db_run! { conn: {\n+            attachments::table\n+                .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+                .filter(ciphers::user_uuid.eq(user_uuid))\n+                .count()\n+                .first(conn)\n+                .unwrap_or(0)\n+        }}\n     }\n \n     pub fn size_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n-        let result: Option<i64> = attachments::table\n-            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n-            .filter(ciphers::organization_uuid.eq(org_uuid))\n-            .select(diesel::dsl::sum(attachments::file_size))\n-            .first(&**conn)\n-            .expect(\"Error loading user attachment total size\");\n-\n-        result.unwrap_or(0)\n+        db_run! { conn: {\n+            let result: Option<i64> = attachments::table\n+                .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+                .filter(ciphers::organization_uuid.eq(org_uuid))\n+                .select(diesel::dsl::sum(attachments::file_size))\n+                .first(conn)\n+                .expect(\"Error loading user attachment total size\");\n+            result.unwrap_or(0)\n+        }}\n     }\n \n     pub fn count_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n-        attachments::table\n-            .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n-            .filter(ciphers::organization_uuid.eq(org_uuid))\n-            .count()\n-            .first(&**conn)\n-            .ok()\n-            .unwrap_or(0)\n+        db_run! { conn: {\n+            attachments::table\n+                .left_join(ciphers::table.on(ciphers::uuid.eq(attachments::cipher_uuid)))\n+                .filter(ciphers::organization_uuid.eq(org_uuid))\n+                .count()\n+                .first(conn)\n+                .unwrap_or(0)\n+        }}\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 13,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -63,10 +63,21 @@ impl Attachment {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(attachments::table)\n+                match diesel::replace_into(attachments::table)\n                     .values(AttachmentDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving attachment\")\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(attachments::table)\n+                            .filter(attachments::id.eq(&self.id))\n+                            .set(AttachmentDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving attachment\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving attachment\")\n             }\n             postgresql {\n                 let value = AttachmentDb::to_db(self);\n",
            "comment_added_diff": [
                [
                    71,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use super::Cipher;\n use crate::CONFIG;\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"attachments\"]\n     #[changeset_options(treat_none_as_null=\"true\")]\n     #[belongs_to(super::Cipher, foreign_key = \"cipher_uuid\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -59,7 +59,6 @@ use crate::error::MapResult;\n \n /// Database methods\n impl Attachment {\n-\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         db_run! { conn:\n             sqlite, mysql {\n",
            "comment_added_diff": []
        },
        {
            "commit": "29ed82a3595e0cdd39deb914dc38002478f89f97",
            "timestamp": "2021-05-25T04:14:51-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for v2 attachment upload APIs\n\nUpstream PR: https://github.com/bitwarden/server/pull/1229",
            "additions": 10,
            "deletions": 11,
            "change_type": "MODIFY",
            "diff": "@@ -12,7 +12,7 @@ db_object! {\n     pub struct Attachment {\n         pub id: String,\n         pub cipher_uuid: String,\n-        pub file_name: String,\n+        pub file_name: String, // encrypted\n         pub file_size: i32,\n         pub akey: Option<String>,\n     }\n@@ -20,13 +20,13 @@ db_object! {\n \n /// Local methods\n impl Attachment {\n-    pub const fn new(id: String, cipher_uuid: String, file_name: String, file_size: i32) -> Self {\n+    pub const fn new(id: String, cipher_uuid: String, file_name: String, file_size: i32, akey: Option<String>) -> Self {\n         Self {\n             id,\n             cipher_uuid,\n             file_name,\n             file_size,\n-            akey: None,\n+            akey,\n         }\n     }\n \n@@ -34,18 +34,17 @@ impl Attachment {\n         format!(\"{}/{}/{}\", CONFIG.attachments_folder(), self.cipher_uuid, self.id)\n     }\n \n-    pub fn to_json(&self, host: &str) -> Value {\n-        use crate::util::get_display_size;\n-\n-        let web_path = format!(\"{}/attachments/{}/{}\", host, self.cipher_uuid, self.id);\n-        let display_size = get_display_size(self.file_size);\n+    pub fn get_url(&self, host: &str) -> String {\n+        format!(\"{}/attachments/{}/{}\", host, self.cipher_uuid, self.id)\n+    }\n \n+    pub fn to_json(&self, host: &str) -> Value {\n         json!({\n             \"Id\": self.id,\n-            \"Url\": web_path,\n+            \"Url\": self.get_url(host),\n             \"FileName\": self.file_name,\n             \"Size\": self.file_size.to_string(),\n-            \"SizeName\": display_size,\n+            \"SizeName\": crate::util::get_display_size(self.file_size),\n             \"Key\": self.akey,\n             \"Object\": \"attachment\"\n         })\n@@ -91,7 +90,7 @@ impl Attachment {\n         }\n     }\n \n-    pub fn delete(self, conn: &DbConn) -> EmptyResult {\n+    pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n         db_run! { conn: {\n             crate::util::retry(\n                 || diesel::delete(attachments::table.filter(attachments::id.eq(&self.id))).execute(conn),\n",
            "comment_added_diff": [
                [
                    15,
                    "        pub file_name: String, // encrypted"
                ]
            ]
        },
        {
            "commit": "5fef7983f4e3bc942ec0f029037454edfb057cad",
            "timestamp": "2021-05-25T22:13:04-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Clean up attachment error handling",
            "additions": 15,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -1,3 +1,5 @@\n+use std::io::ErrorKind;\n+\n use serde_json::Value;\n \n use super::Cipher;\n@@ -98,8 +100,19 @@ impl Attachment {\n             )\n             .map_res(\"Error deleting attachment\")?;\n \n-            crate::util::delete_file(&self.get_file_path())?;\n-            Ok(())\n+            let file_path = &self.get_file_path();\n+\n+            match crate::util::delete_file(file_path) {\n+                // Ignore \"file not found\" errors. This can happen when the\n+                // upstream caller has already cleaned up the file as part of\n+                // its own error handling.\n+                Err(e) if e.kind() == ErrorKind::NotFound => {\n+                    debug!(\"File '{}' already deleted.\", file_path);\n+                    Ok(())\n+                }\n+                Err(e) => Err(e.into()),\n+                _ => Ok(()),\n+            }\n         }}\n     }\n \n",
            "comment_added_diff": [
                [
                    106,
                    "                // Ignore \"file not found\" errors. This can happen when the"
                ],
                [
                    107,
                    "                // upstream caller has already cleaned up the file as part of"
                ],
                [
                    108,
                    "                // its own error handling."
                ]
            ]
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -117,8 +117,8 @@ impl Attachment {\n     }\n \n     pub fn delete_all_by_cipher(cipher_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for attachment in Attachment::find_by_cipher(&cipher_uuid, &conn) {\n-            attachment.delete(&conn)?;\n+        for attachment in Attachment::find_by_cipher(cipher_uuid, conn) {\n+            attachment.delete(conn)?;\n         }\n         Ok(())\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "56b4f46d7d9c818a392d3ab62322302ed8b0c723",
            "timestamp": "2021-08-16T22:23:33-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix limitation on sharing ciphers with attachments\n\nThis check is several years old, so maybe there was a valid reason\nfor having it before, but it's not correct anymore.",
            "additions": 0,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -143,16 +143,6 @@ impl Attachment {\n         }}\n     }\n \n-    pub fn find_by_ciphers(cipher_uuids: Vec<String>, conn: &DbConn) -> Vec<Self> {\n-        db_run! { conn: {\n-            attachments::table\n-                .filter(attachments::cipher_uuid.eq_any(cipher_uuids))\n-                .load::<AttachmentDb>(conn)\n-                .expect(\"Error loading attachments\")\n-                .from_db()\n-        }}\n-    }\n-\n     pub fn size_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n         db_run! { conn: {\n             let result: Option<i64> = attachments::table\n",
            "comment_added_diff": []
        }
    ],
    "invite_accepted.hbs": [],
    "invite_accepted.html.hbs": [],
    "invite_confirmed.hbs": [],
    "invite_confirmed.html.hbs": [],
    "new_device_logged_in.hbs": [],
    "new_device_logged_in.html.hbs": [],
    "smtp_test.hbs": [],
    "smtp_test.html.hbs": [],
    "org_policy.rs": [
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 142,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,142 @@\n+use diesel;\n+use diesel::prelude::*;\n+use serde_json::Value;\n+\n+use crate::api::EmptyResult;\n+use crate::db::schema::org_policies;\n+use crate::db::DbConn;\n+use crate::error::MapResult;\n+\n+use super::Organization;\n+\n+#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+#[table_name = \"org_policies\"]\n+#[belongs_to(Organization, foreign_key = \"org_uuid\")]\n+#[primary_key(uuid)]\n+pub struct OrgPolicy {\n+    pub uuid: String,\n+    pub org_uuid: String,\n+    pub atype: i32,\n+    pub enabled: bool,\n+    pub data: String,\n+}\n+\n+#[allow(dead_code)]\n+#[derive(FromPrimitive)]\n+pub enum OrgPolicyType {\n+    TwoFactorAuthentication = 0,\n+    MasterPassword = 1,\n+    PasswordGenerator = 2,\n+}\n+\n+/// Local methods\n+impl OrgPolicy {\n+    pub fn new(org_uuid: String, atype: OrgPolicyType, data: String) -> Self {\n+        Self {\n+            uuid: crate::util::get_uuid(),\n+            org_uuid,\n+            atype: atype as i32,\n+            enabled: false,\n+            data,\n+        }\n+    }\n+\n+    pub fn to_json(&self) -> Value {\n+        let data_json: Value = serde_json::from_str(&self.data).unwrap_or(Value::Null);\n+        json!({\n+            \"Id\": self.uuid,\n+            \"OrganizationId\": self.org_uuid,\n+            \"Type\": self.atype,\n+            \"Data\": data_json,\n+            \"Enabled\": self.enabled,\n+            \"Object\": \"policy\",\n+        })\n+    }\n+}\n+\n+/// Database methods\n+impl OrgPolicy {\n+    #[cfg(feature = \"postgresql\")]\n+    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n+        // We need to make sure we're not going to violate the unique constraint on org_uuid and atype.\n+        // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n+        // not support multiple constraints on ON CONFLICT clauses.\n+        diesel::delete(\n+            org_policies::table\n+                .filter(org_policies::org_uuid.eq(&self.org_uuid))\n+                .filter(org_policies::atype.eq(&self.atype)),\n+        )\n+        .execute(&**conn)\n+        .map_res(\"Error deleting org_policy for insert\")?;\n+\n+        diesel::insert_into(org_policies::table)\n+            .values(self)\n+            .on_conflict(org_policies::uuid)\n+            .do_update()\n+            .set(self)\n+            .execute(&**conn)\n+            .map_res(\"Error saving org_policy\")\n+    }\n+\n+    #[cfg(not(feature = \"postgresql\"))]\n+    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n+        diesel::replace_into(org_policies::table)\n+            .values(&*self)\n+            .execute(&**conn)\n+            .map_res(\"Error saving org_policy\")\n+    }\n+\n+    pub fn delete(self, conn: &DbConn) -> EmptyResult {\n+        diesel::delete(org_policies::table.filter(org_policies::uuid.eq(self.uuid)))\n+            .execute(&**conn)\n+            .map_res(\"Error deleting org_policy\")\n+    }\n+\n+    pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n+        org_policies::table\n+            .filter(org_policies::uuid.eq(uuid))\n+            .first::<Self>(&**conn)\n+            .ok()\n+    }\n+\n+    pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        org_policies::table\n+            .filter(org_policies::org_uuid.eq(org_uuid))\n+            .load::<Self>(&**conn)\n+            .expect(\"Error loading org_policy\")\n+    }\n+\n+    pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        use crate::db::schema::users_organizations;\n+\n+        org_policies::table\n+            .left_join(\n+                users_organizations::table.on(\n+                    users_organizations::org_uuid.eq(org_policies::org_uuid)\n+                        .and(users_organizations::user_uuid.eq(user_uuid)))\n+            )\n+            .select(org_policies::all_columns)\n+            .load::<Self>(&**conn)\n+            .expect(\"Error loading org_policy\")\n+    }\n+\n+    pub fn find_by_org_and_type(org_uuid: &str, atype: i32, conn: &DbConn) -> Option<Self> {\n+        org_policies::table\n+            .filter(org_policies::org_uuid.eq(org_uuid))\n+            .filter(org_policies::atype.eq(atype))\n+            .first::<Self>(&**conn)\n+            .ok()\n+    }\n+\n+    pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        diesel::delete(org_policies::table.filter(org_policies::org_uuid.eq(org_uuid)))\n+            .execute(&**conn)\n+            .map_res(\"Error deleting org_policy\")\n+    }\n+\n+    /*pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n+            .execute(&**conn)\n+            .map_res(\"Error deleting twofactors\")\n+    }*/\n+}\n",
            "comment_added_diff": [
                [
                    32,
                    "/// Local methods"
                ],
                [
                    57,
                    "/// Database methods"
                ],
                [
                    61,
                    "        // We need to make sure we're not going to violate the unique constraint on org_uuid and atype."
                ],
                [
                    62,
                    "        // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does"
                ],
                [
                    63,
                    "        // not support multiple constraints on ON CONFLICT clauses."
                ]
            ]
        },
        {
            "commit": "819f340f394f5e88afc54d214f9cc74fe17f59eb",
            "timestamp": "2020-03-14T23:35:34+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix issue with postgres",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -57,14 +57,14 @@ impl OrgPolicy {\n /// Database methods\n impl OrgPolicy {\n     #[cfg(feature = \"postgresql\")]\n-    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n+    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         // We need to make sure we're not going to violate the unique constraint on org_uuid and atype.\n         // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n         // not support multiple constraints on ON CONFLICT clauses.\n         diesel::delete(\n             org_policies::table\n-                .filter(org_policies::org_uuid.eq(&self.org_uuid))\n-                .filter(org_policies::atype.eq(&self.atype)),\n+                .filter(org_policies::org_uuid.eq(self.org_uuid))\n+                .filter(org_policies::atype.eq(self.atype)),\n         )\n         .execute(&**conn)\n         .map_res(\"Error deleting org_policy for insert\")?;\n@@ -79,7 +79,7 @@ impl OrgPolicy {\n     }\n \n     #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n+    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         diesel::replace_into(org_policies::table)\n             .values(&*self)\n             .execute(&**conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "40c339db9bf197e4711f4a0438a0d06af44b919b",
            "timestamp": "2020-03-14T23:53:12+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix postgres policies, second try",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -63,8 +63,8 @@ impl OrgPolicy {\n         // not support multiple constraints on ON CONFLICT clauses.\n         diesel::delete(\n             org_policies::table\n-                .filter(org_policies::org_uuid.eq(self.org_uuid))\n-                .filter(org_policies::atype.eq(self.atype)),\n+                .filter(org_policies::org_uuid.eq(&self.org_uuid))\n+                .filter(org_policies::atype.eq(&self.atype)),\n         )\n         .execute(&**conn)\n         .map_res(\"Error deleting org_policy for insert\")?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,3 @@\n-use diesel;\n use diesel::prelude::*;\n use serde_json::Value;\n \n@@ -22,7 +21,7 @@ pub struct OrgPolicy {\n }\n \n #[allow(dead_code)]\n-#[derive(FromPrimitive)]\n+#[derive(num_derive::FromPrimitive)]\n pub enum OrgPolicyType {\n     TwoFactorAuthentication = 0,\n     MasterPassword = 1,\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 90,
            "deletions": 72,
            "change_type": "MODIFY",
            "diff": "@@ -1,23 +1,23 @@\n-use diesel::prelude::*;\n use serde_json::Value;\n \n use crate::api::EmptyResult;\n-use crate::db::schema::org_policies;\n use crate::db::DbConn;\n use crate::error::MapResult;\n \n use super::Organization;\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"org_policies\"]\n-#[belongs_to(Organization, foreign_key = \"org_uuid\")]\n-#[primary_key(uuid)]\n-pub struct OrgPolicy {\n-    pub uuid: String,\n-    pub org_uuid: String,\n-    pub atype: i32,\n-    pub enabled: bool,\n-    pub data: String,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"org_policies\"]\n+    #[belongs_to(Organization, foreign_key = \"org_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct OrgPolicy {\n+        pub uuid: String,\n+        pub org_uuid: String,\n+        pub atype: i32,\n+        pub enabled: bool,\n+        pub data: String,\n+    }\n }\n \n #[allow(dead_code)]\n@@ -55,87 +55,105 @@ impl OrgPolicy {\n \n /// Database methods\n impl OrgPolicy {\n-    #[cfg(feature = \"postgresql\")]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        // We need to make sure we're not going to violate the unique constraint on org_uuid and atype.\n-        // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n-        // not support multiple constraints on ON CONFLICT clauses.\n-        diesel::delete(\n-            org_policies::table\n-                .filter(org_policies::org_uuid.eq(&self.org_uuid))\n-                .filter(org_policies::atype.eq(&self.atype)),\n-        )\n-        .execute(&**conn)\n-        .map_res(\"Error deleting org_policy for insert\")?;\n-\n-        diesel::insert_into(org_policies::table)\n-            .values(self)\n-            .on_conflict(org_policies::uuid)\n-            .do_update()\n-            .set(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving org_policy\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        diesel::replace_into(org_policies::table)\n-            .values(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving org_policy\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(org_policies::table)\n+                    .values(OrgPolicyDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving org_policy\")      \n+            }\n+            postgresql {\n+                let value = OrgPolicyDb::to_db(self);\n+                // We need to make sure we're not going to violate the unique constraint on org_uuid and atype.\n+                // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does\n+                // not support multiple constraints on ON CONFLICT clauses.\n+                diesel::delete(\n+                    org_policies::table\n+                        .filter(org_policies::org_uuid.eq(&self.org_uuid))\n+                        .filter(org_policies::atype.eq(&self.atype)),\n+                )\n+                .execute(conn)\n+                .map_res(\"Error deleting org_policy for insert\")?;\n+\n+                diesel::insert_into(org_policies::table)\n+                    .values(&value)\n+                    .on_conflict(org_policies::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving org_policy\")\n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(org_policies::table.filter(org_policies::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting org_policy\")\n+        db_run! { conn: {\n+            diesel::delete(org_policies::table.filter(org_policies::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting org_policy\")\n+        }}\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        org_policies::table\n-            .filter(org_policies::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            org_policies::table\n+                .filter(org_policies::uuid.eq(uuid))\n+                .first::<OrgPolicyDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        org_policies::table\n-            .filter(org_policies::org_uuid.eq(org_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading org_policy\")\n+        db_run! { conn: {\n+            org_policies::table\n+                .filter(org_policies::org_uuid.eq(org_uuid))\n+                .load::<OrgPolicyDb>(conn)\n+                .expect(\"Error loading org_policy\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        use crate::db::schema::users_organizations;\n-\n-        org_policies::table\n-            .left_join(\n-                users_organizations::table.on(\n-                    users_organizations::org_uuid.eq(org_policies::org_uuid)\n-                        .and(users_organizations::user_uuid.eq(user_uuid)))\n-            )\n-            .select(org_policies::all_columns)\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading org_policy\")\n+        db_run! { conn: {\n+            org_policies::table\n+                .left_join(\n+                    users_organizations::table.on(\n+                        users_organizations::org_uuid.eq(org_policies::org_uuid)\n+                            .and(users_organizations::user_uuid.eq(user_uuid)))\n+                )\n+                .select(org_policies::all_columns)\n+                .load::<OrgPolicyDb>(conn)\n+                .expect(\"Error loading org_policy\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_org_and_type(org_uuid: &str, atype: i32, conn: &DbConn) -> Option<Self> {\n-        org_policies::table\n-            .filter(org_policies::org_uuid.eq(org_uuid))\n-            .filter(org_policies::atype.eq(atype))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            org_policies::table\n+                .filter(org_policies::org_uuid.eq(org_uuid))\n+                .filter(org_policies::atype.eq(atype))\n+                .first::<OrgPolicyDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(org_policies::table.filter(org_policies::org_uuid.eq(org_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting org_policy\")\n+        db_run! { conn: {\n+            diesel::delete(org_policies::table.filter(org_policies::org_uuid.eq(org_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting org_policy\")\n+        }}\n     }\n \n     /*pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting twofactors\")\n+        db_run! { conn: {\n+            diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting twofactors\")\n+        }}\n     }*/\n }\n",
            "comment_added_diff": [
                [
                    68,
                    "                // We need to make sure we're not going to violate the unique constraint on org_uuid and atype."
                ],
                [
                    69,
                    "                // This happens automatically on other DBMS backends due to replace_into(). PostgreSQL does"
                ],
                [
                    70,
                    "                // not support multiple constraints on ON CONFLICT clauses."
                ]
            ]
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 14,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -56,12 +56,23 @@ impl OrgPolicy {\n /// Database methods\n impl OrgPolicy {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(org_policies::table)\n+                match diesel::replace_into(org_policies::table)\n                     .values(OrgPolicyDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving org_policy\")      \n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(org_policies::table)\n+                            .filter(org_policies::uuid.eq(&self.uuid))\n+                            .set(OrgPolicyDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving org_policy\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving org_policy\")\n             }\n             postgresql {\n                 let value = OrgPolicyDb::to_db(self);\n",
            "comment_added_diff": [
                [
                    66,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ]
            ]
        },
        {
            "commit": "013d4c28b2e06dc654b7f2a1f21b56b1c8a7838d",
            "timestamp": "2020-11-07T23:01:56+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Try to fix #1218",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -129,7 +129,7 @@ impl OrgPolicy {\n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         db_run! { conn: {\n             org_policies::table\n-                .left_join(\n+                .inner_join(\n                     users_organizations::table.on(\n                         users_organizations::org_uuid.eq(org_policies::org_uuid)\n                             .and(users_organizations::user_uuid.eq(user_uuid)))\n",
            "comment_added_diff": []
        },
        {
            "commit": "fa364c3f2ce47ab78f970d1fa27ffe6c11d0545d",
            "timestamp": "2020-11-08T01:14:17+03:00",
            "author": "Ave",
            "commit_message": "Ensure that a user is actually in an org when applying policies",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use crate::api::EmptyResult;\n use crate::db::DbConn;\n use crate::error::MapResult;\n \n-use super::Organization;\n+use super::{Organization, UserOrgStatus};\n \n db_object! {\n     #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n@@ -134,6 +134,9 @@ impl OrgPolicy {\n                         users_organizations::org_uuid.eq(org_policies::org_uuid)\n                             .and(users_organizations::user_uuid.eq(user_uuid)))\n                 )\n+                .filter(\n+                    users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n+                )\n                 .select(org_policies::all_columns)\n                 .load::<OrgPolicyDb>(conn)\n                 .expect(\"Error loading org_policy\")\n",
            "comment_added_diff": []
        },
        {
            "commit": "9f86196a9d537ce8295add4c4fe682d5565e63fe",
            "timestamp": "2021-01-23T20:50:06-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Personal Ownership policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1013\n* https://bitwarden.com/help/article/policies/#personal-ownership",
            "additions": 7,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -26,6 +26,9 @@ pub enum OrgPolicyType {\n     TwoFactorAuthentication = 0,\n     MasterPassword = 1,\n     PasswordGenerator = 2,\n+    // SingleOrg = 3, // Not currently supported.\n+    // RequireSso = 4, // Not currently supported.\n+    PersonalOwnership = 5,\n }\n \n /// Local methods\n@@ -40,6 +43,10 @@ impl OrgPolicy {\n         }\n     }\n \n+    pub fn has_type(&self, policy_type: OrgPolicyType) -> bool {\n+        self.atype == policy_type as i32\n+    }\n+\n     pub fn to_json(&self) -> Value {\n         let data_json: Value = serde_json::from_str(&self.data).unwrap_or(Value::Null);\n         json!({\n",
            "comment_added_diff": [
                [
                    29,
                    "    // SingleOrg = 3, // Not currently supported."
                ],
                [
                    30,
                    "    // RequireSso = 4, // Not currently supported."
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -7,7 +7,7 @@ use crate::error::MapResult;\n use super::{Organization, UserOrgStatus};\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"org_policies\"]\n     #[belongs_to(Organization, foreign_key = \"org_uuid\")]\n     #[primary_key(uuid)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "424d666a505c3e41bc1e77937a682e120e130423",
            "timestamp": "2021-03-16T02:07:45-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Disable Send policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1130\n* https://bitwarden.com/help/article/policies/#disable-send",
            "additions": 20,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use crate::api::EmptyResult;\n use crate::db::DbConn;\n use crate::error::MapResult;\n \n-use super::{Organization, UserOrgStatus};\n+use super::{Organization, UserOrganization, UserOrgStatus, UserOrgType};\n \n db_object! {\n     #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n@@ -20,7 +20,7 @@ db_object! {\n     }\n }\n \n-#[allow(dead_code)]\n+#[derive(Copy, Clone)]\n #[derive(num_derive::FromPrimitive)]\n pub enum OrgPolicyType {\n     TwoFactorAuthentication = 0,\n@@ -29,6 +29,7 @@ pub enum OrgPolicyType {\n     // SingleOrg = 3, // Not currently supported.\n     // RequireSso = 4, // Not currently supported.\n     PersonalOwnership = 5,\n+    DisableSend = 6,\n }\n \n /// Local methods\n@@ -170,6 +171,23 @@ impl OrgPolicy {\n         }}\n     }\n \n+    /// Returns true if the user belongs to an org that has enabled the specified policy type,\n+    /// and the user is not an owner or admin of that org. This is only useful for checking\n+    /// applicability of policy types that have these particular semantics.\n+    pub fn is_applicable_to_user(user_uuid: &str, policy_type: OrgPolicyType, conn: &DbConn) -> bool {\n+        for policy in OrgPolicy::find_by_user(user_uuid, conn) { // Returns confirmed users only.\n+            if policy.enabled && policy.has_type(policy_type) {\n+                let org_uuid = &policy.org_uuid;\n+                if let Some(user) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n+                    if user.atype < UserOrgType::Admin {\n+                        return true;\n+                    }\n+                }\n+            }\n+        }\n+        false\n+    }\n+\n     /*pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n         db_run! { conn: {\n             diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n",
            "comment_added_diff": [
                [
                    174,
                    "    /// Returns true if the user belongs to an org that has enabled the specified policy type,"
                ],
                [
                    175,
                    "    /// and the user is not an owner or admin of that org. This is only useful for checking"
                ],
                [
                    176,
                    "    /// applicability of policy types that have these particular semantics."
                ],
                [
                    178,
                    "        for policy in OrgPolicy::find_by_user(user_uuid, conn) { // Returns confirmed users only."
                ]
            ]
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use crate::api::EmptyResult;\n use crate::db::DbConn;\n use crate::error::MapResult;\n \n-use super::{Organization, UserOrganization, UserOrgStatus, UserOrgType};\n+use super::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n \n db_object! {\n     #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n@@ -20,8 +20,7 @@ db_object! {\n     }\n }\n \n-#[derive(Copy, Clone)]\n-#[derive(num_derive::FromPrimitive)]\n+#[derive(Copy, Clone, num_derive::FromPrimitive)]\n pub enum OrgPolicyType {\n     TwoFactorAuthentication = 0,\n     MasterPassword = 1,\n@@ -175,7 +174,8 @@ impl OrgPolicy {\n     /// and the user is not an owner or admin of that org. This is only useful for checking\n     /// applicability of policy types that have these particular semantics.\n     pub fn is_applicable_to_user(user_uuid: &str, policy_type: OrgPolicyType, conn: &DbConn) -> bool {\n-        for policy in OrgPolicy::find_by_user(user_uuid, conn) { // Returns confirmed users only.\n+        for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n+            // Returns confirmed users only.\n             if policy.enabled && policy.has_type(policy_type) {\n                 let org_uuid = &policy.org_uuid;\n                 if let Some(user) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n",
            "comment_added_diff": [
                [
                    178,
                    "            // Returns confirmed users only."
                ]
            ]
        },
        {
            "commit": "93c881a7a9abf30c1d2cfea961d5637de2757b86",
            "timestamp": "2021-03-31T21:45:05+01:00",
            "author": "Jake Howard",
            "commit_message": "Reflow some lines manually",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -174,8 +174,8 @@ impl OrgPolicy {\n     /// and the user is not an owner or admin of that org. This is only useful for checking\n     /// applicability of policy types that have these particular semantics.\n     pub fn is_applicable_to_user(user_uuid: &str, policy_type: OrgPolicyType, conn: &DbConn) -> bool {\n+        // Returns confirmed users only.\n         for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n-            // Returns confirmed users only.\n             if policy.enabled && policy.has_type(policy_type) {\n                 let org_uuid = &policy.org_uuid;\n                 if let Some(user) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n",
            "comment_added_diff": [
                [
                    177,
                    "        // Returns confirmed users only."
                ]
            ]
        },
        {
            "commit": "d75a80bd2dbe21e5a1eb2b0a6b18a9422441e071",
            "timestamp": "2021-04-11T22:57:17-04:00",
            "author": "Olivier Martin",
            "commit_message": "Resolves dani-garcia/bitwarden_rs#981\n* a user without 2fa trying to join a 2fa org will fail, but user gets an email to enable 2fa\n* a user disabling 2fa will be removed from 2fa orgs; user gets an email for each org\n* an org enabling 2fa policy will remove users without 2fa; users get an email",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -22,6 +22,7 @@ db_object! {\n \n #[derive(Copy, Clone)]\n #[derive(num_derive::FromPrimitive)]\n+#[derive(PartialEq)]\n pub enum OrgPolicyType {\n     TwoFactorAuthentication = 0,\n     MasterPassword = 1,\n",
            "comment_added_diff": []
        },
        {
            "commit": "029008bad519186d1528526f523c0220aa58ac2a",
            "timestamp": "2021-05-12T01:22:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the `Send Options` policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1234\n* https://bitwarden.com/help/article/policies/#send-options",
            "additions": 34,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -1,8 +1,10 @@\n+use serde::Deserialize;\n use serde_json::Value;\n \n use crate::api::EmptyResult;\n use crate::db::DbConn;\n use crate::error::MapResult;\n+use crate::util::UpCase;\n \n use super::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n \n@@ -29,6 +31,14 @@ pub enum OrgPolicyType {\n     // RequireSso = 4, // Not currently supported.\n     PersonalOwnership = 5,\n     DisableSend = 6,\n+    SendOptions = 7,\n+}\n+\n+// https://github.com/bitwarden/server/blob/master/src/Core/Models/Data/SendOptionsPolicyData.cs\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct SendOptionsPolicyData {\n+    pub DisableHideEmail: bool,\n }\n \n /// Local methods\n@@ -188,6 +198,30 @@ impl OrgPolicy {\n         false\n     }\n \n+    /// Returns true if the user belongs to an org that has enabled the `DisableHideEmail`\n+    /// option of the `Send Options` policy, and the user is not an owner or admin of that org.\n+    pub fn is_hide_email_disabled(user_uuid: &str, conn: &DbConn) -> bool {\n+        // Returns confirmed users only.\n+        for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n+            if policy.enabled && policy.has_type(OrgPolicyType::SendOptions) {\n+                let org_uuid = &policy.org_uuid;\n+                if let Some(user) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n+                    if user.atype < UserOrgType::Admin {\n+                        match serde_json::from_str::<UpCase<SendOptionsPolicyData>>(&policy.data) {\n+                            Ok(opts) => {\n+                                if opts.data.DisableHideEmail {\n+                                    return true;\n+                                }\n+                            }\n+                            _ => error!(\"Failed to deserialize policy data: {}\", policy.data),\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        false\n+    }\n+\n     /*pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n         db_run! { conn: {\n             diesel::delete(twofactor::table.filter(twofactor::user_uuid.eq(user_uuid)))\n",
            "comment_added_diff": [
                [
                    37,
                    "// https://github.com/bitwarden/server/blob/master/src/Core/Models/Data/SendOptionsPolicyData.cs"
                ],
                [
                    201,
                    "    /// Returns true if the user belongs to an org that has enabled the `DisableHideEmail`"
                ],
                [
                    202,
                    "    /// option of the `Send Options` policy, and the user is not an owner or admin of that org."
                ],
                [
                    204,
                    "        // Returns confirmed users only."
                ]
            ]
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 5,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -27,7 +27,7 @@ pub enum OrgPolicyType {\n     TwoFactorAuthentication = 0,\n     MasterPassword = 1,\n     PasswordGenerator = 2,\n-    // SingleOrg = 3, // Not currently supported.\n+    SingleOrg = 3,\n     // RequireSso = 4, // Not currently supported.\n     PersonalOwnership = 5,\n     DisableSend = 6,\n@@ -143,7 +143,7 @@ impl OrgPolicy {\n         }}\n     }\n \n-    pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+    pub fn find_confirmed_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         db_run! { conn: {\n             org_policies::table\n                 .inner_join(\n@@ -184,8 +184,8 @@ impl OrgPolicy {\n     /// and the user is not an owner or admin of that org. This is only useful for checking\n     /// applicability of policy types that have these particular semantics.\n     pub fn is_applicable_to_user(user_uuid: &str, policy_type: OrgPolicyType, conn: &DbConn) -> bool {\n-        // Returns confirmed users only.\n-        for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n+        // TODO: Should check confirmed and accepted users\n+        for policy in OrgPolicy::find_confirmed_by_user(user_uuid, conn) {\n             if policy.enabled && policy.has_type(policy_type) {\n                 let org_uuid = &policy.org_uuid;\n                 if let Some(user) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n@@ -201,8 +201,7 @@ impl OrgPolicy {\n     /// Returns true if the user belongs to an org that has enabled the `DisableHideEmail`\n     /// option of the `Send Options` policy, and the user is not an owner or admin of that org.\n     pub fn is_hide_email_disabled(user_uuid: &str, conn: &DbConn) -> bool {\n-        // Returns confirmed users only.\n-        for policy in OrgPolicy::find_by_user(user_uuid, conn) {\n+        for policy in OrgPolicy::find_confirmed_by_user(user_uuid, conn) {\n             if policy.enabled && policy.has_type(OrgPolicyType::SendOptions) {\n                 let org_uuid = &policy.org_uuid;\n                 if let Some(user) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n",
            "comment_added_diff": [
                [
                    187,
                    "        // TODO: Should check confirmed and accepted users"
                ]
            ]
        }
    ],
    "organization.rs": [
        {
            "commit": "3fa78e7bb141979d6f6fdfa20aecc70493b80842",
            "timestamp": "2020-03-14T13:32:28+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial version of policies",
            "additions": 7,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,8 @@\n use serde_json::Value;\n use std::cmp::Ordering;\n+use num_traits::FromPrimitive;\n \n-use super::{CollectionUser, User};\n+use super::{CollectionUser, User, OrgPolicy};\n \n #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n #[table_name = \"organizations\"]\n@@ -33,6 +34,7 @@ pub enum UserOrgStatus {\n }\n \n #[derive(Copy, Clone, PartialEq, Eq)]\n+#[derive(FromPrimitive)]\n pub enum UserOrgType {\n     Owner = 0,\n     Admin = 1,\n@@ -135,16 +137,6 @@ impl UserOrgType {\n             _ => None,\n         }\n     }\n-\n-    pub fn from_i32(i: i32) -> Option<Self> {\n-        match i {\n-            0 => Some(UserOrgType::Owner),\n-            1 => Some(UserOrgType::Admin),\n-            2 => Some(UserOrgType::User),\n-            3 => Some(UserOrgType::Manager),\n-            _ => None,\n-        }\n-    }\n }\n \n /// Local methods\n@@ -170,6 +162,7 @@ impl Organization {\n             \"UseEvents\": false,\n             \"UseGroups\": false,\n             \"UseTotp\": true,\n+            \"UsePolicies\": true,\n \n             \"BusinessName\": null,\n             \"BusinessAddress1\":\tnull,\n@@ -250,6 +243,7 @@ impl Organization {\n         Cipher::delete_all_by_organization(&self.uuid, &conn)?;\n         Collection::delete_all_by_organization(&self.uuid, &conn)?;\n         UserOrganization::delete_all_by_organization(&self.uuid, &conn)?;\n+        OrgPolicy::delete_all_by_organization(&self.uuid, &conn)?;\n \n         diesel::delete(organizations::table.filter(organizations::uuid.eq(self.uuid)))\n             .execute(&**conn)\n@@ -267,7 +261,7 @@ impl Organization {\n impl UserOrganization {\n     pub fn to_json(&self, conn: &DbConn) -> Value {\n         let org = Organization::find_by_uuid(&self.org_uuid, conn).unwrap();\n-\n+        \n         json!({\n             \"Id\": self.org_uuid,\n             \"Name\": org.name,\n@@ -280,6 +274,7 @@ impl UserOrganization {\n             \"UseEvents\": false,\n             \"UseGroups\": false,\n             \"UseTotp\": true,\n+            \"UsePolicies\": true,\n \n             \"MaxStorageGb\": 10, // The value doesn't matter, we don't check server-side\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 1,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -34,7 +34,7 @@ pub enum UserOrgStatus {\n }\n \n #[derive(Copy, Clone, PartialEq, Eq)]\n-#[derive(FromPrimitive)]\n+#[derive(num_derive::FromPrimitive)]\n pub enum UserOrgType {\n     Owner = 0,\n     Admin = 1,\n@@ -198,7 +198,6 @@ impl UserOrganization {\n \n use crate::db::schema::{ciphers_collections, organizations, users_collections, users_organizations};\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n",
            "comment_added_diff": []
        },
        {
            "commit": "632f4d545367b5ab1cefce66bc526e5dc0a786de",
            "timestamp": "2020-05-07T18:02:37-04:00",
            "author": "theycallmesteve",
            "commit_message": "Whitespace fixes",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -165,9 +165,9 @@ impl Organization {\n             \"UsePolicies\": true,\n \n             \"BusinessName\": null,\n-            \"BusinessAddress1\":\tnull,\n-            \"BusinessAddress2\":\tnull,\n-            \"BusinessAddress3\":\tnull,\n+            \"BusinessAddress1\": null,\n+            \"BusinessAddress2\": null,\n+            \"BusinessAddress3\": null,\n             \"BusinessCountry\": null,\n             \"BusinessTaxNumber\": null,\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "6a8c65493f2194c065705bfd180b4106e9db6478",
            "timestamp": "2020-05-08T13:37:40-04:00",
            "author": "theycallmesteve",
            "commit_message": "Rename collection_user_details to collection_read_only to reflect the response model",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -304,7 +304,7 @@ impl UserOrganization {\n         })\n     }\n \n-    pub fn to_json_collection_user_details(&self, read_only: bool) -> Value {\n+    pub fn to_json_read_only(&self, read_only: bool) -> Value {\n         json!({\n             \"Id\": self.uuid,\n             \"ReadOnly\": read_only\n",
            "comment_added_diff": []
        },
        {
            "commit": "08afc312c392fefba2088eb5910e6b985afb5daf",
            "timestamp": "2020-05-08T13:39:17-04:00",
            "author": "theycallmesteve",
            "commit_message": "Add missing items to profileOrganization response model",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -274,6 +274,8 @@ impl UserOrganization {\n             \"UseGroups\": false,\n             \"UseTotp\": true,\n             \"UsePolicies\": true,\n+            \"UseApi\": false,\n+            \"SelfHost\": true,\n \n             \"MaxStorageGb\": 10, // The value doesn't matter, we don't check server-side\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "3c66deb5cc7a4387e4176d2a5bdd3f321f09a6bd",
            "timestamp": "2020-05-28T10:46:25+02:00",
            "author": "BlackDex",
            "commit_message": "Redesign of the admin interface.\n\nMain changes:\n - Splitted up settings and users into two separate pages.\n - Added verified shield when the e-mail address has been verified.\n - Added the amount of personal items in the database to the users overview.\n - Added Organizations and Diagnostics pages.\n   - Shows if DNS resolving works.\n   - Shows if there is a posible time drift.\n   - Shows current versions of server and web-vault.\n - Optimized logo-gray.png using optipng\n\nItems which can be added later:\n - Amount of cipher items accessible for a user, not only his personal items.\n - Amount of users per Org\n - Version update check in the diagnostics overview.\n - Copy/Pasteable runtime config which has sensitive data changed or removed for support questions either on the forum or github issues.\n - Option to delete Orgs and all its passwords (when there are no members anymore).\n - Etc....",
            "additions": 4,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -255,6 +255,10 @@ impl Organization {\n             .first::<Self>(&**conn)\n             .ok()\n     }\n+\n+    pub fn get_all(conn: &DbConn) -> Vec<Self> {\n+        organizations::table.load::<Self>(&**conn).expect(\"Error loading organizations\")\n+    }\n }\n \n impl UserOrganization {\n",
            "comment_added_diff": []
        },
        {
            "commit": "ac2723f898c45120ec023bbb2e0e66b26ad71a01",
            "timestamp": "2020-06-03T20:37:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated Organizations overview\n\n- Changed HTML to match users overview\n- Added User count\n- Added Org cipher amount\n- Added Attachment count and size",
            "additions": 9,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -437,6 +437,15 @@ impl UserOrganization {\n             .expect(\"Error loading user organizations\")\n     }\n \n+    pub fn count_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n+        users_organizations::table\n+            .filter(users_organizations::org_uuid.eq(org_uuid))\n+            .count()\n+            .first::<i64>(&**conn)\n+            .ok()\n+            .unwrap_or(0)\n+    }\n+\n     pub fn find_by_org_and_type(org_uuid: &str, atype: i32, conn: &DbConn) -> Vec<Self> {\n         users_organizations::table\n             .filter(users_organizations::org_uuid.eq(org_uuid))\n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 8,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -310,10 +310,11 @@ impl UserOrganization {\n         })\n     }\n \n-    pub fn to_json_read_only(&self, read_only: bool) -> Value {\n+    pub fn to_json_user_access_restrictions(&self, col_user: &CollectionUser) -> Value {\n         json!({\n             \"Id\": self.uuid,\n-            \"ReadOnly\": read_only\n+            \"ReadOnly\": col_user.read_only,\n+            \"HidePasswords\": col_user.hide_passwords,\n         })\n     }\n \n@@ -324,7 +325,11 @@ impl UserOrganization {\n             let collections = CollectionUser::find_by_organization_and_user_uuid(&self.org_uuid, &self.user_uuid, conn);\n             collections\n                 .iter()\n-                .map(|c| json!({\"Id\": c.collection_uuid, \"ReadOnly\": c.read_only}))\n+                .map(|c| json!({\n+                    \"Id\": c.collection_uuid,\n+                    \"ReadOnly\": c.read_only,\n+                    \"HidePasswords\": c.hide_passwords,\n+                }))\n                 .collect()\n         };\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "f9a73a9bbecbcc4ef858413c58081cfe92ecde45",
            "timestamp": "2020-07-03T10:49:10-07:00",
            "author": "Jeremy Lin",
            "commit_message": "More cipher optimization/cleanup",
            "additions": 6,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -393,8 +393,13 @@ impl UserOrganization {\n         Ok(())\n     }\n \n+    pub fn has_status(self, status: UserOrgStatus) -> bool {\n+        self.status == status as i32\n+    }\n+\n     pub fn has_full_access(self) -> bool {\n-        self.access_all || self.atype >= UserOrgType::Admin\n+        (self.access_all || self.atype >= UserOrgType::Admin) &&\n+            self.has_status(UserOrgStatus::Confirmed)\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 171,
            "deletions": 145,
            "change_type": "MODIFY",
            "diff": "@@ -4,27 +4,29 @@ use num_traits::FromPrimitive;\n \n use super::{CollectionUser, User, OrgPolicy};\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n-#[table_name = \"organizations\"]\n-#[primary_key(uuid)]\n-pub struct Organization {\n-    pub uuid: String,\n-    pub name: String,\n-    pub billing_email: String,\n-}\n-\n-#[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n-#[table_name = \"users_organizations\"]\n-#[primary_key(uuid)]\n-pub struct UserOrganization {\n-    pub uuid: String,\n-    pub user_uuid: String,\n-    pub org_uuid: String,\n-\n-    pub access_all: bool,\n-    pub akey: String,\n-    pub status: i32,\n-    pub atype: i32,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n+    #[table_name = \"organizations\"]\n+    #[primary_key(uuid)]\n+    pub struct Organization {\n+        pub uuid: String,\n+        pub name: String,\n+        pub billing_email: String,\n+    }\n+\n+    #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n+    #[table_name = \"users_organizations\"]\n+    #[primary_key(uuid)]\n+    pub struct UserOrganization {\n+        pub uuid: String,\n+        pub user_uuid: String,\n+        pub org_uuid: String,\n+\n+        pub access_all: bool,\n+        pub akey: String,\n+        pub status: i32,\n+        pub atype: i32,\n+    }\n }\n \n pub enum UserOrgStatus {\n@@ -196,16 +198,13 @@ impl UserOrganization {\n     }\n }\n \n-use crate::db::schema::{ciphers_collections, organizations, users_collections, users_organizations};\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n \n /// Database methods\n impl Organization {\n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         UserOrganization::find_by_org(&self.uuid, conn)\n             .iter()\n@@ -213,27 +212,24 @@ impl Organization {\n                 User::update_uuid_revision(&user_org.user_uuid, conn);\n             });\n \n-        diesel::insert_into(organizations::table)\n-            .values(self)\n-            .on_conflict(organizations::uuid)\n-            .do_update()\n-            .set(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving organization\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        UserOrganization::find_by_org(&self.uuid, conn)\n-            .iter()\n-            .for_each(|user_org| {\n-                User::update_uuid_revision(&user_org.user_uuid, conn);\n-            });\n-\n-        diesel::replace_into(organizations::table)\n-            .values(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving organization\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(organizations::table)\n+                    .values(OrganizationDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving organization\")            \n+            }\n+            postgresql {\n+                let value = OrganizationDb::to_db(self);\n+                diesel::insert_into(organizations::table)\n+                    .values(&value)\n+                    .on_conflict(organizations::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving organization\")                \n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n@@ -244,20 +240,27 @@ impl Organization {\n         UserOrganization::delete_all_by_organization(&self.uuid, &conn)?;\n         OrgPolicy::delete_all_by_organization(&self.uuid, &conn)?;\n \n-        diesel::delete(organizations::table.filter(organizations::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error saving organization\")\n+\n+        db_run! { conn: {\n+            diesel::delete(organizations::table.filter(organizations::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error saving organization\")\n+        }}\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        organizations::table\n-            .filter(organizations::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            organizations::table\n+                .filter(organizations::uuid.eq(uuid))\n+                .first::<OrganizationDb>(conn)\n+                .ok().from_db()\n+        }}\n     }\n \n     pub fn get_all(conn: &DbConn) -> Vec<Self> {\n-        organizations::table.load::<Self>(&**conn).expect(\"Error loading organizations\")\n+        db_run! { conn: {\n+            organizations::table.load::<OrganizationDb>(conn).expect(\"Error loading organizations\").from_db()\n+        }}\n     }\n }\n \n@@ -345,28 +348,27 @@ impl UserOrganization {\n             \"Object\": \"organizationUserDetails\",\n         })\n     }\n-\n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n \n-        diesel::insert_into(users_organizations::table)\n-            .values(self)\n-            .on_conflict(users_organizations::uuid)\n-            .do_update()\n-            .set(self)\n-            .execute(&**conn)\n-            .map_res(\"Error adding user to organization\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        User::update_uuid_revision(&self.user_uuid, conn);\n-\n-        diesel::replace_into(users_organizations::table)\n-            .values(self)\n-            .execute(&**conn)\n-            .map_res(\"Error adding user to organization\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(users_organizations::table)\n+                    .values(UserOrganizationDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error adding user to organization\")        \n+            }\n+            postgresql {\n+                let value = UserOrganizationDb::to_db(self);\n+                diesel::insert_into(users_organizations::table)\n+                    .values(&value)\n+                    .on_conflict(users_organizations::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error adding user to organization\")            \n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n@@ -374,9 +376,11 @@ impl UserOrganization {\n \n         CollectionUser::delete_all_by_user(&self.user_uuid, &conn)?;\n \n-        diesel::delete(users_organizations::table.filter(users_organizations::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing user from organization\")\n+        db_run! { conn: {\n+            diesel::delete(users_organizations::table.filter(users_organizations::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing user from organization\")\n+        }}\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -403,107 +407,129 @@ impl UserOrganization {\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::uuid.eq(uuid))\n+                .first::<UserOrganizationDb>(conn)\n+                .ok().from_db()\n+        }}\n     }\n \n     pub fn find_by_uuid_and_org(uuid: &str, org_uuid: &str, conn: &DbConn) -> Option<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::uuid.eq(uuid))\n-            .filter(users_organizations::org_uuid.eq(org_uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::uuid.eq(uuid))\n+                .filter(users_organizations::org_uuid.eq(org_uuid))\n+                .first::<UserOrganizationDb>(conn)\n+                .ok().from_db()\n+        }}\n     }\n \n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::user_uuid.eq(user_uuid))\n-            .filter(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))\n-            .load::<Self>(&**conn)\n-            .unwrap_or_default()\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::user_uuid.eq(user_uuid))\n+                .filter(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))\n+                .load::<UserOrganizationDb>(conn)\n+                .unwrap_or_default().from_db()\n+        }}\n     }\n \n     pub fn find_invited_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::user_uuid.eq(user_uuid))\n-            .filter(users_organizations::status.eq(UserOrgStatus::Invited as i32))\n-            .load::<Self>(&**conn)\n-            .unwrap_or_default()\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::user_uuid.eq(user_uuid))\n+                .filter(users_organizations::status.eq(UserOrgStatus::Invited as i32))\n+                .load::<UserOrganizationDb>(conn)\n+                .unwrap_or_default().from_db()\n+        }}\n     }\n \n     pub fn find_any_state_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::user_uuid.eq(user_uuid))\n-            .load::<Self>(&**conn)\n-            .unwrap_or_default()\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::user_uuid.eq(user_uuid))\n+                .load::<UserOrganizationDb>(conn)\n+                .unwrap_or_default().from_db()\n+        }}\n     }\n \n     pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::org_uuid.eq(org_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading user organizations\")\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::org_uuid.eq(org_uuid))\n+                .load::<UserOrganizationDb>(conn)\n+                .expect(\"Error loading user organizations\").from_db()\n+        }}\n     }\n \n     pub fn count_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n-        users_organizations::table\n-            .filter(users_organizations::org_uuid.eq(org_uuid))\n-            .count()\n-            .first::<i64>(&**conn)\n-            .ok()\n-            .unwrap_or(0)\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::org_uuid.eq(org_uuid))\n+                .count()\n+                .first::<i64>(conn)\n+                .ok()\n+                .unwrap_or(0)\n+        }}\n     }\n \n     pub fn find_by_org_and_type(org_uuid: &str, atype: i32, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::org_uuid.eq(org_uuid))\n-            .filter(users_organizations::atype.eq(atype))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading user organizations\")\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::org_uuid.eq(org_uuid))\n+                .filter(users_organizations::atype.eq(atype))\n+                .load::<UserOrganizationDb>(conn)\n+                .expect(\"Error loading user organizations\").from_db()\n+        }}\n     }\n \n     pub fn find_by_user_and_org(user_uuid: &str, org_uuid: &str, conn: &DbConn) -> Option<Self> {\n-        users_organizations::table\n-            .filter(users_organizations::user_uuid.eq(user_uuid))\n-            .filter(users_organizations::org_uuid.eq(org_uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            users_organizations::table\n+                .filter(users_organizations::user_uuid.eq(user_uuid))\n+                .filter(users_organizations::org_uuid.eq(org_uuid))\n+                .first::<UserOrganizationDb>(conn)\n+                .ok().from_db()\n+        }}\n     }\n \n     pub fn find_by_cipher_and_org(cipher_uuid: &str, org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-        .filter(users_organizations::org_uuid.eq(org_uuid))\n-        .left_join(users_collections::table.on(\n-            users_collections::user_uuid.eq(users_organizations::user_uuid)\n-        ))\n-        .left_join(ciphers_collections::table.on(\n-            ciphers_collections::collection_uuid.eq(users_collections::collection_uuid).and(\n-                ciphers_collections::cipher_uuid.eq(&cipher_uuid)\n-            )\n-        ))\n-        .filter(\n-            users_organizations::access_all.eq(true).or( // AccessAll..\n-                ciphers_collections::cipher_uuid.eq(&cipher_uuid) // ..or access to collection with cipher\n+        db_run! { conn: {\n+            users_organizations::table\n+            .filter(users_organizations::org_uuid.eq(org_uuid))\n+            .left_join(users_collections::table.on(\n+                users_collections::user_uuid.eq(users_organizations::user_uuid)\n+            ))\n+            .left_join(ciphers_collections::table.on(\n+                ciphers_collections::collection_uuid.eq(users_collections::collection_uuid).and(\n+                    ciphers_collections::cipher_uuid.eq(&cipher_uuid)\n+                )\n+            ))\n+            .filter(\n+                users_organizations::access_all.eq(true).or( // AccessAll..\n+                    ciphers_collections::cipher_uuid.eq(&cipher_uuid) // ..or access to collection with cipher\n+                )\n             )\n-        )\n-        .select(users_organizations::all_columns)\n-        .load::<Self>(&**conn).expect(\"Error loading user organizations\")\n+            .select(users_organizations::all_columns)\n+            .load::<UserOrganizationDb>(conn).expect(\"Error loading user organizations\").from_db()\n+        }}\n     }\n \n     pub fn find_by_collection_and_org(collection_uuid: &str, org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_organizations::table\n-        .filter(users_organizations::org_uuid.eq(org_uuid))\n-        .left_join(users_collections::table.on(\n-            users_collections::user_uuid.eq(users_organizations::user_uuid)\n-        ))\n-        .filter(\n-            users_organizations::access_all.eq(true).or( // AccessAll..\n-                users_collections::collection_uuid.eq(&collection_uuid) // ..or access to collection with cipher\n+        db_run! { conn: {\n+            users_organizations::table\n+            .filter(users_organizations::org_uuid.eq(org_uuid))\n+            .left_join(users_collections::table.on(\n+                users_collections::user_uuid.eq(users_organizations::user_uuid)\n+            ))\n+            .filter(\n+                users_organizations::access_all.eq(true).or( // AccessAll..\n+                    users_collections::collection_uuid.eq(&collection_uuid) // ..or access to collection with cipher\n+                )\n             )\n-        )\n-        .select(users_organizations::all_columns)\n-        .load::<Self>(&**conn).expect(\"Error loading user organizations\")\n+            .select(users_organizations::all_columns)\n+            .load::<UserOrganizationDb>(conn).expect(\"Error loading user organizations\").from_db()\n+        }}\n     }\n }\n",
            "comment_added_diff": [
                [
                    510,
                    "                users_organizations::access_all.eq(true).or( // AccessAll.."
                ],
                [
                    511,
                    "                    ciphers_collections::cipher_uuid.eq(&cipher_uuid) // ..or access to collection with cipher"
                ],
                [
                    527,
                    "                users_organizations::access_all.eq(true).or( // AccessAll.."
                ],
                [
                    528,
                    "                    users_collections::collection_uuid.eq(&collection_uuid) // ..or access to collection with cipher"
                ]
            ]
        },
        {
            "commit": "0eee907c883a4e219816253cc86a0eac233c0c57",
            "timestamp": "2020-09-13T02:03:16-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Simplify implementation of `UserOrgType::cmp()`\n\nAlso move `UserOrgType::from_str()` closer to the definition of `UserOrgType`\nsince it references specific enum values.",
            "additions": 33,
            "deletions": 28,
            "change_type": "MODIFY",
            "diff": "@@ -44,24 +44,28 @@ pub enum UserOrgType {\n     Manager = 3,\n }\n \n+impl UserOrgType {\n+    pub fn from_str(s: &str) -> Option<Self> {\n+        match s {\n+            \"0\" | \"Owner\" => Some(UserOrgType::Owner),\n+            \"1\" | \"Admin\" => Some(UserOrgType::Admin),\n+            \"2\" | \"User\" => Some(UserOrgType::User),\n+            \"3\" | \"Manager\" => Some(UserOrgType::Manager),\n+            _ => None,\n+        }\n+    }\n+}\n+\n impl Ord for UserOrgType {\n     fn cmp(&self, other: &UserOrgType) -> Ordering {\n-        if self == other {\n-            Ordering::Equal\n-        } else {\n-            match self {\n-                UserOrgType::Owner => Ordering::Greater,\n-                UserOrgType::Admin => match other {\n-                    UserOrgType::Owner => Ordering::Less,\n-                    _ => Ordering::Greater,\n-                },\n-                UserOrgType::Manager => match other {\n-                    UserOrgType::Owner | UserOrgType::Admin => Ordering::Less,\n-                    _ => Ordering::Greater,\n-                },\n-                UserOrgType::User => Ordering::Less,\n-            }\n-        }\n+        // For easy comparison, map each variant to an access level (where 0 is lowest).\n+        static ACCESS_LEVEL: [i32; 4] = [\n+            3, // Owner\n+            2, // Admin\n+            0, // User\n+            1, // Manager\n+        ];\n+        ACCESS_LEVEL[*self as usize].cmp(&ACCESS_LEVEL[*other as usize])\n     }\n }\n \n@@ -129,18 +133,6 @@ impl PartialOrd<UserOrgType> for i32 {\n     }\n }\n \n-impl UserOrgType {\n-    pub fn from_str(s: &str) -> Option<Self> {\n-        match s {\n-            \"0\" | \"Owner\" => Some(UserOrgType::Owner),\n-            \"1\" | \"Admin\" => Some(UserOrgType::Admin),\n-            \"2\" | \"User\" => Some(UserOrgType::User),\n-            \"3\" | \"Manager\" => Some(UserOrgType::Manager),\n-            _ => None,\n-        }\n-    }\n-}\n-\n /// Local methods\n impl Organization {\n     pub fn new(name: String, billing_email: String) -> Self {\n@@ -533,3 +525,16 @@ impl UserOrganization {\n         }}\n     }\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+\n+    #[test]\n+    #[allow(non_snake_case)]\n+    fn partial_cmp_UserOrgType() {\n+        assert!(UserOrgType::Owner > UserOrgType::Admin);\n+        assert!(UserOrgType::Admin > UserOrgType::Manager);\n+        assert!(UserOrgType::Manager > UserOrgType::User);\n+    }\n+}\n",
            "comment_added_diff": [
                [
                    61,
                    "        // For easy comparison, map each variant to an access level (where 0 is lowest)."
                ],
                [
                    63,
                    "            3, // Owner"
                ],
                [
                    64,
                    "            2, // Admin"
                ],
                [
                    65,
                    "            0, // User"
                ],
                [
                    66,
                    "            1, // Manager"
                ]
            ]
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 32,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -204,12 +204,24 @@ impl Organization {\n                 User::update_uuid_revision(&user_org.user_uuid, conn);\n             });\n \n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(organizations::table)\n+                match diesel::replace_into(organizations::table)\n                     .values(OrganizationDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving organization\")            \n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(organizations::table)\n+                            .filter(organizations::uuid.eq(&self.uuid))\n+                            .set(OrganizationDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving organization\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving organization\")\n+\n             }\n             postgresql {\n                 let value = OrganizationDb::to_db(self);\n@@ -219,7 +231,7 @@ impl Organization {\n                     .do_update()\n                     .set(&value)\n                     .execute(conn)\n-                    .map_res(\"Error saving organization\")                \n+                    .map_res(\"Error saving organization\")\n             }\n         }\n     }\n@@ -259,7 +271,7 @@ impl Organization {\n impl UserOrganization {\n     pub fn to_json(&self, conn: &DbConn) -> Value {\n         let org = Organization::find_by_uuid(&self.org_uuid, conn).unwrap();\n-        \n+\n         json!({\n             \"Id\": self.org_uuid,\n             \"Name\": org.name,\n@@ -343,12 +355,23 @@ impl UserOrganization {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n \n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(users_organizations::table)\n+                match diesel::replace_into(users_organizations::table)\n                     .values(UserOrganizationDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error adding user to organization\")        \n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(users_organizations::table)\n+                            .filter(users_organizations::uuid.eq(&self.uuid))\n+                            .set(UserOrganizationDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error adding user to organization\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error adding user to organization\")\n             }\n             postgresql {\n                 let value = UserOrganizationDb::to_db(self);\n@@ -358,7 +381,7 @@ impl UserOrganization {\n                     .do_update()\n                     .set(&value)\n                     .execute(conn)\n-                    .map_res(\"Error adding user to organization\")            \n+                    .map_res(\"Error adding user to organization\")\n             }\n         }\n     }\n",
            "comment_added_diff": [
                [
                    214,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    365,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ]
            ]
        },
        {
            "commit": "b5f9fe4d3bb57cada7fa01371efc3978a5937173",
            "timestamp": "2020-11-07T23:03:02+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix #1206",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -389,7 +389,7 @@ impl UserOrganization {\n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n \n-        CollectionUser::delete_all_by_user(&self.user_uuid, &conn)?;\n+        CollectionUser::delete_all_by_user_and_org(&self.user_uuid, &self.org_uuid, &conn)?;\n \n         db_run! { conn: {\n             diesel::delete(users_organizations::table.filter(users_organizations::uuid.eq(self.uuid)))\n",
            "comment_added_diff": []
        },
        {
            "commit": "9f86196a9d537ce8295add4c4fe682d5565e63fe",
            "timestamp": "2021-01-23T20:50:06-08:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Personal Ownership policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1013\n* https://bitwarden.com/help/article/policies/#personal-ownership",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -412,11 +412,15 @@ impl UserOrganization {\n         Ok(())\n     }\n \n-    pub fn has_status(self, status: UserOrgStatus) -> bool {\n+    pub fn has_status(&self, status: UserOrgStatus) -> bool {\n         self.status == status as i32\n     }\n \n-    pub fn has_full_access(self) -> bool {\n+    pub fn has_type(&self, user_type: UserOrgType) -> bool {\n+        self.atype == user_type as i32\n+    }\n+\n+    pub fn has_full_access(&self) -> bool {\n         (self.access_all || self.atype >= UserOrgType::Admin) &&\n             self.has_status(UserOrgStatus::Confirmed)\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "7dff8c01dd86f69761f4822b8b0c41709f03f271",
            "timestamp": "2021-01-31T21:46:37+01:00",
            "author": "BlackDex",
            "commit_message": "JSON Response updates and small fixes\n\nUpdated several json response models.\nAlso fixed a few small bugs.\n\nciphers.rs:\n  - post_ciphers_create:\n    * Prevent cipher creation to organization without a collection.\n  - update_cipher_from_data:\n    * ~~Fixed removal of user_uuid which prevent user-owned shared-cipher to be not editable anymore when set to read-only.~~\n    * Cleanup the json_data by removing the `Response` key/values from several objects.\n  - delete_all:\n    * Do not delete all Collections during the Purge of an Organization (same as upstream).\n\ncipher.rs:\n  - Cipher::to_json:\n    * Updated json response to match upstream.\n    * Return empty json object if there is no type_data instead of values which should not be set for the type_data.\n\norganizations.rs:\n  * Added two new endpoints to prevent Javascript errors regarding tax\n\norganization.rs:\n  - Organization::to_json:\n    * Updated response model to match upstream\n  - UserOrganization::to_json:\n    * Updated response model to match upstream\n\ncollection.rs:\n  - Collection::{to_json, to_json_details}:\n    * Updated the json response model, and added a detailed version used during the sync\n  - hide_passwords_for_user:\n    * Added this function to return if the passwords should be hidden or not for the user at the specific collection (used by `to_json_details`)\n\nUpdate 1: Some small changes after comments from @jjlin.\nUpdate 2: Fixed vault purge by user to make sure the cipher is not part of an organization.\n\nResolves #971\nCloses #990, Closes #991",
            "additions": 32,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -147,9 +147,10 @@ impl Organization {\n     pub fn to_json(&self) -> Value {\n         json!({\n             \"Id\": self.uuid,\n+            \"Identifier\": null, // not supported by us\n             \"Name\": self.name,\n-            \"Seats\": 10,\n-            \"MaxCollections\": 10,\n+            \"Seats\": 10, // The value doesn't matter, we don't check server-side\n+            \"MaxCollections\": 10, // The value doesn't matter, we don't check server-side\n             \"MaxStorageGb\": 10, // The value doesn't matter, we don't check server-side\n             \"Use2fa\": true,\n             \"UseDirectory\": false,\n@@ -157,6 +158,9 @@ impl Organization {\n             \"UseGroups\": false,\n             \"UseTotp\": true,\n             \"UsePolicies\": true,\n+            \"UseSso\": false, // We do not support SSO\n+            \"SelfHost\": true,\n+            \"UseApi\": false, // not supported by us\n \n             \"BusinessName\": null,\n             \"BusinessAddress1\": null,\n@@ -274,9 +278,10 @@ impl UserOrganization {\n \n         json!({\n             \"Id\": self.org_uuid,\n+            \"Identifier\": null, // not supported by us\n             \"Name\": org.name,\n-            \"Seats\": 10,\n-            \"MaxCollections\": 10,\n+            \"Seats\": 10, // The value doesn't matter, we don't check server-side\n+            \"MaxCollections\": 10, // The value doesn't matter, we don't check server-side\n             \"UsersGetPremium\": true,\n \n             \"Use2fa\": true,\n@@ -285,8 +290,30 @@ impl UserOrganization {\n             \"UseGroups\": false,\n             \"UseTotp\": true,\n             \"UsePolicies\": true,\n-            \"UseApi\": false,\n+            \"UseApi\": false, // not supported by us\n             \"SelfHost\": true,\n+            \"SsoBound\": false, // We do not support SSO\n+            \"UseSso\": false, // We do not support SSO\n+            // TODO: Add support for Business Portal\n+            // Upstream is moving Policies and SSO management outside of the web-vault to /portal\n+            // For now they still have that code also in the web-vault, but they will remove it at some point.\n+            // https://github.com/bitwarden/server/tree/master/bitwarden_license/src/\n+            \"UseBusinessPortal\": false, // Disable BusinessPortal Button\n+\n+            // TODO: Add support for Custom User Roles\n+            // See: https://bitwarden.com/help/article/user-types-access-control/#custom-role\n+            // \"Permissions\": {\n+            //     \"AccessBusinessPortal\": false,\n+            //     \"AccessEventLogs\": false,\n+            //     \"AccessImportExport\": false,\n+            //     \"AccessReports\": false,\n+            //     \"ManageAllCollections\": false,\n+            //     \"ManageAssignedCollections\": false,\n+            //     \"ManageGroups\": false,\n+            //     \"ManagePolicies\": false,\n+            //     \"ManageSso\": false,\n+            //     \"ManageUsers\": false\n+            // },\n \n             \"MaxStorageGb\": 10, // The value doesn't matter, we don't check server-side\n \n",
            "comment_added_diff": [
                [
                    150,
                    "            \"Identifier\": null, // not supported by us"
                ],
                [
                    152,
                    "            \"Seats\": 10, // The value doesn't matter, we don't check server-side"
                ],
                [
                    153,
                    "            \"MaxCollections\": 10, // The value doesn't matter, we don't check server-side"
                ],
                [
                    161,
                    "            \"UseSso\": false, // We do not support SSO"
                ],
                [
                    163,
                    "            \"UseApi\": false, // not supported by us"
                ],
                [
                    281,
                    "            \"Identifier\": null, // not supported by us"
                ],
                [
                    283,
                    "            \"Seats\": 10, // The value doesn't matter, we don't check server-side"
                ],
                [
                    284,
                    "            \"MaxCollections\": 10, // The value doesn't matter, we don't check server-side"
                ],
                [
                    293,
                    "            \"UseApi\": false, // not supported by us"
                ],
                [
                    295,
                    "            \"SsoBound\": false, // We do not support SSO"
                ],
                [
                    296,
                    "            \"UseSso\": false, // We do not support SSO"
                ],
                [
                    297,
                    "            // TODO: Add support for Business Portal"
                ],
                [
                    298,
                    "            // Upstream is moving Policies and SSO management outside of the web-vault to /portal"
                ],
                [
                    299,
                    "            // For now they still have that code also in the web-vault, but they will remove it at some point."
                ],
                [
                    300,
                    "            // https://github.com/bitwarden/server/tree/master/bitwarden_license/src/"
                ],
                [
                    301,
                    "            \"UseBusinessPortal\": false, // Disable BusinessPortal Button"
                ],
                [
                    303,
                    "            // TODO: Add support for Custom User Roles"
                ],
                [
                    304,
                    "            // See: https://bitwarden.com/help/article/user-types-access-control/#custom-role"
                ],
                [
                    305,
                    "            // \"Permissions\": {"
                ],
                [
                    306,
                    "            //     \"AccessBusinessPortal\": false,"
                ],
                [
                    307,
                    "            //     \"AccessEventLogs\": false,"
                ],
                [
                    308,
                    "            //     \"AccessImportExport\": false,"
                ],
                [
                    309,
                    "            //     \"AccessReports\": false,"
                ],
                [
                    310,
                    "            //     \"ManageAllCollections\": false,"
                ],
                [
                    311,
                    "            //     \"ManageAssignedCollections\": false,"
                ],
                [
                    312,
                    "            //     \"ManageGroups\": false,"
                ],
                [
                    313,
                    "            //     \"ManagePolicies\": false,"
                ],
                [
                    314,
                    "            //     \"ManageSso\": false,"
                ],
                [
                    315,
                    "            //     \"ManageUsers\": false"
                ],
                [
                    316,
                    "            // },"
                ]
            ]
        },
        {
            "commit": "85e3c73525d327042c1ad142e48c044a5dbdd89c",
            "timestamp": "2021-02-06T20:15:42+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Basic experimental ldap import support with the official directory connector",
            "additions": 10,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -439,6 +439,16 @@ impl UserOrganization {\n         Ok(())\n     }\n \n+    pub fn find_by_email_and_org(email: &str, org_id: &str, conn: &DbConn) -> Option<UserOrganization> {\n+        if let Some(user) = super::User::find_by_mail(email, conn) {\n+            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user.uuid, org_id, &conn) {\n+                return Some(user_org);\n+            }\n+        }\n+\n+        None\n+    }\n+\n     pub fn has_status(&self, status: UserOrgStatus) -> bool {\n         self.status == status as i32\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -5,7 +5,7 @@ use num_traits::FromPrimitive;\n use super::{CollectionUser, User, OrgPolicy};\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, AsChangeset)]\n     #[table_name = \"organizations\"]\n     #[primary_key(uuid)]\n     pub struct Organization {\n@@ -14,7 +14,7 @@ db_object! {\n         pub billing_email: String,\n     }\n \n-    #[derive(Debug, Identifiable, Queryable, Insertable, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, AsChangeset)]\n     #[table_name = \"users_organizations\"]\n     #[primary_key(uuid)]\n     pub struct UserOrganization {\n",
            "comment_added_diff": []
        },
        {
            "commit": "ea57dc3bc9253b8db8e0815bac344f2cf981894b",
            "timestamp": "2021-03-27T14:03:07+00:00",
            "author": "Jake Howard",
            "commit_message": "Use `matches` macro",
            "additions": 4,
            "deletions": 16,
            "change_type": "MODIFY",
            "diff": "@@ -90,17 +90,11 @@ impl PartialOrd<i32> for UserOrgType {\n     }\n \n     fn gt(&self, other: &i32) -> bool {\n-        match self.partial_cmp(other) {\n-            Some(Ordering::Less) | Some(Ordering::Equal) => false,\n-            _ => true,\n-        }\n+        !matches!(self.partial_cmp(other), Some(Ordering::Less) | Some(Ordering::Equal))\n     }\n \n     fn ge(&self, other: &i32) -> bool {\n-        match self.partial_cmp(other) {\n-            Some(Ordering::Less) => false,\n-            _ => true,\n-        }\n+        !matches!(self.partial_cmp(other), Some(Ordering::Less))\n     }\n }\n \n@@ -119,17 +113,11 @@ impl PartialOrd<UserOrgType> for i32 {\n     }\n \n     fn lt(&self, other: &UserOrgType) -> bool {\n-        match self.partial_cmp(other) {\n-            Some(Ordering::Less) | None => true,\n-            _ => false,\n-        }\n+        matches!(self.partial_cmp(other), Some(Ordering::Less) | None)\n     }\n \n     fn le(&self, other: &UserOrgType) -> bool {\n-        match self.partial_cmp(other) {\n-            Some(Ordering::Less) | Some(Ordering::Equal) | None => true,\n-            _ => false,\n-        }\n+        matches!(self.partial_cmp(other), Some(Ordering::Less) | Some(Ordering::Equal) | None)\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0bf0125e8271e7c8449da50d0572de5147043ca7",
            "timestamp": "2021-03-28T10:49:29+01:00",
            "author": "Jake Howard",
            "commit_message": "Reverse negation on ordering\n\nCo-authored-by: Daniel Garc\u00eda <dani-garcia@users.noreply.github.com>",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -90,11 +90,11 @@ impl PartialOrd<i32> for UserOrgType {\n     }\n \n     fn gt(&self, other: &i32) -> bool {\n-        !matches!(self.partial_cmp(other), Some(Ordering::Less) | Some(Ordering::Equal))\n+        matches!(self.partial_cmp(other), Some(Ordering::Greater))\n     }\n \n     fn ge(&self, other: &i32) -> bool {\n-        !matches!(self.partial_cmp(other), Some(Ordering::Less))\n+        matches!(self.partial_cmp(other), Some(Ordering::Greater) | Some(Ordering::Equal))\n     }\n }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 15,
            "deletions": 13,
            "change_type": "MODIFY",
            "diff": "@@ -1,8 +1,8 @@\n+use num_traits::FromPrimitive;\n use serde_json::Value;\n use std::cmp::Ordering;\n-use num_traits::FromPrimitive;\n \n-use super::{CollectionUser, User, OrgPolicy};\n+use super::{CollectionUser, OrgPolicy, User};\n \n db_object! {\n     #[derive(Identifiable, Queryable, Insertable, AsChangeset)]\n@@ -35,8 +35,7 @@ pub enum UserOrgStatus {\n     Confirmed = 2,\n }\n \n-#[derive(Copy, Clone, PartialEq, Eq)]\n-#[derive(num_derive::FromPrimitive)]\n+#[derive(Copy, Clone, PartialEq, Eq, num_derive::FromPrimitive)]\n pub enum UserOrgType {\n     Owner = 0,\n     Admin = 1,\n@@ -117,7 +116,10 @@ impl PartialOrd<UserOrgType> for i32 {\n     }\n \n     fn le(&self, other: &UserOrgType) -> bool {\n-        matches!(self.partial_cmp(other), Some(Ordering::Less) | Some(Ordering::Equal) | None)\n+        matches!(\n+            self.partial_cmp(other),\n+            Some(Ordering::Less) | Some(Ordering::Equal) | None\n+        )\n     }\n }\n \n@@ -236,7 +238,6 @@ impl Organization {\n         UserOrganization::delete_all_by_organization(&self.uuid, &conn)?;\n         OrgPolicy::delete_all_by_organization(&self.uuid, &conn)?;\n \n-\n         db_run! { conn: {\n             diesel::delete(organizations::table.filter(organizations::uuid.eq(self.uuid)))\n                 .execute(conn)\n@@ -347,11 +348,13 @@ impl UserOrganization {\n             let collections = CollectionUser::find_by_organization_and_user_uuid(&self.org_uuid, &self.user_uuid, conn);\n             collections\n                 .iter()\n-                .map(|c| json!({\n-                    \"Id\": c.collection_uuid,\n-                    \"ReadOnly\": c.read_only,\n-                    \"HidePasswords\": c.hide_passwords,\n-                }))\n+                .map(|c| {\n+                    json!({\n+                        \"Id\": c.collection_uuid,\n+                        \"ReadOnly\": c.read_only,\n+                        \"HidePasswords\": c.hide_passwords,\n+                    })\n+                })\n                 .collect()\n         };\n \n@@ -446,8 +449,7 @@ impl UserOrganization {\n     }\n \n     pub fn has_full_access(&self) -> bool {\n-        (self.access_all || self.atype >= UserOrgType::Admin) &&\n-            self.has_status(UserOrgStatus::Confirmed)\n+        (self.access_all || self.atype >= UserOrgType::Admin) && self.has_status(UserOrgStatus::Confirmed)\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 4,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -116,10 +116,7 @@ impl PartialOrd<UserOrgType> for i32 {\n     }\n \n     fn le(&self, other: &UserOrgType) -> bool {\n-        matches!(\n-            self.partial_cmp(other),\n-            Some(Ordering::Less) | Some(Ordering::Equal) | None\n-        )\n+        matches!(self.partial_cmp(other), Some(Ordering::Less) | Some(Ordering::Equal) | None)\n     }\n }\n \n@@ -192,11 +189,9 @@ use crate::error::MapResult;\n /// Database methods\n impl Organization {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        UserOrganization::find_by_org(&self.uuid, conn)\n-            .iter()\n-            .for_each(|user_org| {\n-                User::update_uuid_revision(&user_org.user_uuid, conn);\n-            });\n+        UserOrganization::find_by_org(&self.uuid, conn).iter().for_each(|user_org| {\n+            User::update_uuid_revision(&user_org.user_uuid, conn);\n+        });\n \n         db_run! { conn:\n             sqlite, mysql {\n",
            "comment_added_diff": []
        },
        {
            "commit": "d75a80bd2dbe21e5a1eb2b0a6b18a9422441e071",
            "timestamp": "2021-04-11T22:57:17-04:00",
            "author": "Olivier Martin",
            "commit_message": "Resolves dani-garcia/bitwarden_rs#981\n* a user without 2fa trying to join a 2fa org will fail, but user gets an email to enable 2fa\n* a user disabling 2fa will be removed from 2fa orgs; user gets an email for each org\n* an org enabling 2fa policy will remove users without 2fa; users get an email",
            "additions": 20,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -2,7 +2,7 @@ use serde_json::Value;\n use std::cmp::Ordering;\n use num_traits::FromPrimitive;\n \n-use super::{CollectionUser, User, OrgPolicy};\n+use super::{CollectionUser, User, OrgPolicy, OrgPolicyType};\n \n db_object! {\n     #[derive(Identifiable, Queryable, Insertable, AsChangeset)]\n@@ -538,6 +538,25 @@ impl UserOrganization {\n         }}\n     }\n \n+    pub fn find_by_user_and_policy(user_uuid: &str, policy_type: OrgPolicyType, conn: &DbConn) -> Vec<Self> {\n+        db_run! { conn: {\n+            users_organizations::table\n+                .inner_join(\n+                    org_policies::table.on(\n+                        org_policies::org_uuid.eq(users_organizations::org_uuid)\n+                            .and(users_organizations::user_uuid.eq(user_uuid))\n+                            .and(org_policies::atype.eq(policy_type as i32))\n+                            .and(org_policies::enabled.eq(true)))\n+                )\n+                .filter(\n+                    users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n+                )\n+                .select(users_organizations::all_columns)\n+                .load::<UserOrganizationDb>(conn)\n+                .unwrap_or_default().from_db()\n+        }}\n+    }\n+\n     pub fn find_by_cipher_and_org(cipher_uuid: &str, org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         db_run! { conn: {\n             users_organizations::table\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 10,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -228,10 +228,10 @@ impl Organization {\n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n         use super::{Cipher, Collection};\n \n-        Cipher::delete_all_by_organization(&self.uuid, &conn)?;\n-        Collection::delete_all_by_organization(&self.uuid, &conn)?;\n-        UserOrganization::delete_all_by_organization(&self.uuid, &conn)?;\n-        OrgPolicy::delete_all_by_organization(&self.uuid, &conn)?;\n+        Cipher::delete_all_by_organization(&self.uuid, conn)?;\n+        Collection::delete_all_by_organization(&self.uuid, conn)?;\n+        UserOrganization::delete_all_by_organization(&self.uuid, conn)?;\n+        OrgPolicy::delete_all_by_organization(&self.uuid, conn)?;\n \n         db_run! { conn: {\n             diesel::delete(organizations::table.filter(organizations::uuid.eq(self.uuid)))\n@@ -402,7 +402,7 @@ impl UserOrganization {\n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n \n-        CollectionUser::delete_all_by_user_and_org(&self.user_uuid, &self.org_uuid, &conn)?;\n+        CollectionUser::delete_all_by_user_and_org(&self.user_uuid, &self.org_uuid, conn)?;\n \n         db_run! { conn: {\n             diesel::delete(users_organizations::table.filter(users_organizations::uuid.eq(self.uuid)))\n@@ -412,22 +412,22 @@ impl UserOrganization {\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for user_org in Self::find_by_org(&org_uuid, &conn) {\n-            user_org.delete(&conn)?;\n+        for user_org in Self::find_by_org(org_uuid, conn) {\n+            user_org.delete(conn)?;\n         }\n         Ok(())\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for user_org in Self::find_any_state_by_user(&user_uuid, &conn) {\n-            user_org.delete(&conn)?;\n+        for user_org in Self::find_any_state_by_user(user_uuid, conn) {\n+            user_org.delete(conn)?;\n         }\n         Ok(())\n     }\n \n     pub fn find_by_email_and_org(email: &str, org_id: &str, conn: &DbConn) -> Option<UserOrganization> {\n         if let Some(user) = super::User::find_by_mail(email, conn) {\n-            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user.uuid, org_id, &conn) {\n+            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user.uuid, org_id, conn) {\n                 return Some(user_org);\n             }\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 18,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -12,6 +12,8 @@ db_object! {\n         pub uuid: String,\n         pub name: String,\n         pub billing_email: String,\n+        pub private_key: Option<String>,\n+        pub public_key: Option<String>,\n     }\n \n     #[derive(Identifiable, Queryable, Insertable, AsChangeset)]\n@@ -122,12 +124,13 @@ impl PartialOrd<UserOrgType> for i32 {\n \n /// Local methods\n impl Organization {\n-    pub fn new(name: String, billing_email: String) -> Self {\n+    pub fn new(name: String, billing_email: String, private_key: Option<String>, public_key: Option<String>) -> Self {\n         Self {\n             uuid: crate::util::get_uuid(),\n-\n             name,\n             billing_email,\n+            private_key,\n+            public_key,\n         }\n     }\n \n@@ -140,14 +143,16 @@ impl Organization {\n             \"MaxCollections\": 10, // The value doesn't matter, we don't check server-side\n             \"MaxStorageGb\": 10, // The value doesn't matter, we don't check server-side\n             \"Use2fa\": true,\n-            \"UseDirectory\": false,\n-            \"UseEvents\": false,\n-            \"UseGroups\": false,\n+            \"UseDirectory\": false, // Is supported, but this value isn't checked anywhere (yet)\n+            \"UseEvents\": false, // not supported by us\n+            \"UseGroups\": false, // not supported by us\n             \"UseTotp\": true,\n             \"UsePolicies\": true,\n             \"UseSso\": false, // We do not support SSO\n             \"SelfHost\": true,\n             \"UseApi\": false, // not supported by us\n+            \"HasPublicAndPrivateKeys\": self.private_key.is_some() && self.public_key.is_some(),\n+            \"ResetPasswordEnrolled\": false, // not supported by us\n \n             \"BusinessName\": null,\n             \"BusinessAddress1\": null,\n@@ -269,13 +274,15 @@ impl UserOrganization {\n             \"UsersGetPremium\": true,\n \n             \"Use2fa\": true,\n-            \"UseDirectory\": false,\n-            \"UseEvents\": false,\n-            \"UseGroups\": false,\n+            \"UseDirectory\": false, // Is supported, but this value isn't checked anywhere (yet)\n+            \"UseEvents\": false, // not supported by us\n+            \"UseGroups\": false, // not supported by us\n             \"UseTotp\": true,\n             \"UsePolicies\": true,\n             \"UseApi\": false, // not supported by us\n             \"SelfHost\": true,\n+            \"HasPublicAndPrivateKeys\": org.private_key.is_some() && org.public_key.is_some(),\n+            \"ResetPasswordEnrolled\": false, // not supported by us\n             \"SsoBound\": false, // We do not support SSO\n             \"UseSso\": false, // We do not support SSO\n             // TODO: Add support for Business Portal\n@@ -293,10 +300,12 @@ impl UserOrganization {\n             //     \"AccessReports\": false,\n             //     \"ManageAllCollections\": false,\n             //     \"ManageAssignedCollections\": false,\n+            //     \"ManageCiphers\": false,\n             //     \"ManageGroups\": false,\n             //     \"ManagePolicies\": false,\n+            //     \"ManageResetPassword\": false,\n             //     \"ManageSso\": false,\n-            //     \"ManageUsers\": false\n+            //     \"ManageUsers\": false,\n             // },\n \n             \"MaxStorageGb\": 10, // The value doesn't matter, we don't check server-side\n",
            "comment_added_diff": [
                [
                    146,
                    "            \"UseDirectory\": false, // Is supported, but this value isn't checked anywhere (yet)"
                ],
                [
                    147,
                    "            \"UseEvents\": false, // not supported by us"
                ],
                [
                    148,
                    "            \"UseGroups\": false, // not supported by us"
                ],
                [
                    155,
                    "            \"ResetPasswordEnrolled\": false, // not supported by us"
                ],
                [
                    277,
                    "            \"UseDirectory\": false, // Is supported, but this value isn't checked anywhere (yet)"
                ],
                [
                    278,
                    "            \"UseEvents\": false, // not supported by us"
                ],
                [
                    279,
                    "            \"UseGroups\": false, // not supported by us"
                ],
                [
                    285,
                    "            \"ResetPasswordEnrolled\": false, // not supported by us"
                ],
                [
                    303,
                    "            //     \"ManageCiphers\": false,"
                ],
                [
                    306,
                    "            //     \"ManageResetPassword\": false,"
                ],
                [
                    308,
                    "            //     \"ManageUsers\": false,"
                ]
            ]
        },
        {
            "commit": "58b046fd10f4cd953ba5a0e5a816df480f98061f",
            "timestamp": "2021-08-21T10:36:08+02:00",
            "author": "BlackDex",
            "commit_message": "Fix syncing with Bitwarden Desktop v1.28.0\n\nSyncing with the latest desktop client (v1.28.0) fails because it expects some json key/values to be there.\n\nThis PR adds those key/value pairs.\n\nResolves #1924",
            "additions": 2,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -290,6 +290,8 @@ impl UserOrganization {\n             // For now they still have that code also in the web-vault, but they will remove it at some point.\n             // https://github.com/bitwarden/server/tree/master/bitwarden_license/src/\n             \"UseBusinessPortal\": false, // Disable BusinessPortal Button\n+            \"ProviderId\": null,\n+            \"ProviderName\": null,\n \n             // TODO: Add support for Custom User Roles\n             // See: https://bitwarden.com/help/article/user-types-access-control/#custom-role\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -477,7 +477,7 @@ impl UserOrganization {\n         }}\n     }\n \n-    pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+    pub fn find_confirmed_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         db_run! { conn: {\n             users_organizations::table\n                 .filter(users_organizations::user_uuid.eq(user_uuid))\n",
            "comment_added_diff": []
        }
    ],
    "build.rs": [
        {
            "commit": "7a6a3e4160d2a472febd2122248f21ae7dfb0c90",
            "timestamp": "2020-03-22T16:13:34+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Set the cargo version and allow changing it during build time with BWRS_VERSION.\nAlso renamed GIT_VERSION because that's not the only source anymore.",
            "additions": 12,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -1,4 +1,5 @@\n use std::process::Command;\n+use std::env;\n \n fn main() {\n     #[cfg(all(feature = \"sqlite\", feature = \"mysql\"))]\n@@ -10,8 +11,13 @@ fn main() {\n \n     #[cfg(not(any(feature = \"sqlite\", feature = \"mysql\", feature = \"postgresql\")))]\n     compile_error!(\"You need to enable one DB backend. To build with previous defaults do: cargo build --features sqlite\");\n-\n-    read_git_info().ok();\n+    \n+    if let Ok(version) = env::var(\"BWRS_VERSION\") {\n+        println!(\"cargo:rustc-env=BWRS_VERSION={}\", version);\n+        println!(\"cargo:rustc-env=CARGO_PKG_VERSION={}\", version);\n+    } else {\n+        read_git_info().ok();\n+    }\n }\n \n fn run(args: &[&str]) -> Result<String, std::io::Error> {\n@@ -54,14 +60,16 @@ fn read_git_info() -> Result<(), std::io::Error> {\n     } else {\n         format!(\"{}-{}\", last_tag, rev_short)\n     };\n-    println!(\"cargo:rustc-env=GIT_VERSION={}\", version);\n+    \n+    println!(\"cargo:rustc-env=BWRS_VERSION={}\", version);\n+    println!(\"cargo:rustc-env=CARGO_PKG_VERSION={}\", version);\n \n     // To access these values, use:\n     //    env!(\"GIT_EXACT_TAG\")\n     //    env!(\"GIT_LAST_TAG\")\n     //    env!(\"GIT_BRANCH\")\n     //    env!(\"GIT_REV\")\n-    //    env!(\"GIT_VERSION\")\n+    //    env!(\"BWRS_VERSION\")\n \n     Ok(())\n }\n",
            "comment_added_diff": [
                [
                    72,
                    "    //    env!(\"BWRS_VERSION\")"
                ]
            ]
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 8,
            "deletions": 7,
            "change_type": "MODIFY",
            "diff": "@@ -1,13 +1,14 @@\n use std::process::Command;\n use std::env;\n \n-fn main() {\n-    #[cfg(all(feature = \"sqlite\", feature = \"mysql\"))]\n-    compile_error!(\"Can't enable both sqlite and mysql at the same time\");\n-    #[cfg(all(feature = \"sqlite\", feature = \"postgresql\"))]\n-    compile_error!(\"Can't enable both sqlite and postgresql at the same time\");\n-    #[cfg(all(feature = \"mysql\", feature = \"postgresql\"))]\n-    compile_error!(\"Can't enable both mysql and postgresql at the same time\");\n+fn main() { \n+    // This allow using #[cfg(sqlite)] instead of #[cfg(feature = \"sqlite\")], which helps when trying to add them through macros\n+    #[cfg(feature = \"sqlite\")]\n+    println!(\"cargo:rustc-cfg=sqlite\");\n+    #[cfg(feature = \"mysql\")]\n+    println!(\"cargo:rustc-cfg=mysql\");\n+    #[cfg(feature = \"postgresql\")]\n+    println!(\"cargo:rustc-cfg=postgresql\");\n \n     #[cfg(not(any(feature = \"sqlite\", feature = \"mysql\", feature = \"postgresql\")))]\n     compile_error!(\"You need to enable one DB backend. To build with previous defaults do: cargo build --features sqlite\");\n",
            "comment_added_diff": [
                [
                    5,
                    "    // This allow using #[cfg(sqlite)] instead of #[cfg(feature = \"sqlite\")], which helps when trying to add them through macros"
                ]
            ]
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 7,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,7 @@\n-use std::process::Command;\n use std::env;\n+use std::process::Command;\n \n-fn main() { \n+fn main() {\n     // This allow using #[cfg(sqlite)] instead of #[cfg(feature = \"sqlite\")], which helps when trying to add them through macros\n     #[cfg(feature = \"sqlite\")]\n     println!(\"cargo:rustc-cfg=sqlite\");\n@@ -11,8 +11,10 @@ fn main() {\n     println!(\"cargo:rustc-cfg=postgresql\");\n \n     #[cfg(not(any(feature = \"sqlite\", feature = \"mysql\", feature = \"postgresql\")))]\n-    compile_error!(\"You need to enable one DB backend. To build with previous defaults do: cargo build --features sqlite\");\n-    \n+    compile_error!(\n+        \"You need to enable one DB backend. To build with previous defaults do: cargo build --features sqlite\"\n+    );\n+\n     if let Ok(version) = env::var(\"BWRS_VERSION\") {\n         println!(\"cargo:rustc-env=BWRS_VERSION={}\", version);\n         println!(\"cargo:rustc-env=CARGO_PKG_VERSION={}\", version);\n@@ -61,7 +63,7 @@ fn read_git_info() -> Result<(), std::io::Error> {\n     } else {\n         format!(\"{}-{}\", last_tag, rev_short)\n     };\n-    \n+\n     println!(\"cargo:rustc-env=BWRS_VERSION={}\", version);\n     println!(\"cargo:rustc-env=CARGO_PKG_VERSION={}\", version);\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "2b4dd6f137730abe48506affbe5c8f36a86772fb",
            "timestamp": "2021-04-28T21:46:20+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix branch name",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -58,7 +58,7 @@ fn read_git_info() -> Result<(), std::io::Error> {\n     // Combined version\n     let version = if let Some(exact) = exact_tag {\n         exact\n-    } else if &branch != \"master\" {\n+    } else if &branch != \"main\" && &branch != \"master\" {\n         format!(\"{}-{} ({})\", last_tag, rev_short, branch)\n     } else {\n         format!(\"{}-{}\", last_tag, rev_short)\n",
            "comment_added_diff": []
        }
    ],
    "cipher.rs": [
        {
            "commit": "adf47827c98b09dc5cc0564f790f5f6c4a1906f8",
            "timestamp": "2020-03-30T22:19:50+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Make sure the data field is always returned, otherwise the mobile apps seem to have issues",
            "additions": 13,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -80,7 +80,19 @@ impl Cipher {\n         let fields_json = self.fields.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n         let password_history_json = self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n \n-        let mut data_json: Value = serde_json::from_str(&self.data).unwrap_or(Value::Null);\n+        // Get the data or a default empty value to avoid issues with the mobile apps\n+        let mut data_json: Value = serde_json::from_str(&self.data).unwrap_or_else(|_| json!({\n+            \"Fields\":null,\n+            \"Name\": self.name,\n+            \"Notes\":null,\n+            \"Password\":null,\n+            \"PasswordHistory\":null,\n+            \"PasswordRevisionDate\":null,\n+            \"Response\":null,\n+            \"Totp\":null,\n+            \"Uris\":null,\n+            \"Username\":null\n+        }));\n \n         // TODO: ******* Backwards compat start **********\n         // To remove backwards compatibility, just remove this entire section\n",
            "comment_added_diff": [
                [
                    83,
                    "        // Get the data or a default empty value to avoid issues with the mobile apps"
                ]
            ]
        },
        {
            "commit": "1ee8e44912a02feb77fd9640a5cc4782b494820b",
            "timestamp": "2020-04-15T16:49:33+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed issue #965\n\nPostgreSQL updates/inserts ignored None/null values.\nThis is nice for new entries, but not for updates.\nAdded derive option to allways add these none/null values for Option<>\nvariables.\n\nThis solves issue #965",
            "additions": 1,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -7,6 +7,7 @@ use super::{\n \n #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n #[table_name = \"ciphers\"]\n+#[changeset_options(treat_none_as_null=\"true\")]\n #[belongs_to(User, foreign_key = \"user_uuid\")]\n #[belongs_to(Organization, foreign_key = \"organization_uuid\")]\n #[primary_key(uuid)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "e3b00b59a7db760848f6b357fc4328081574aeac",
            "timestamp": "2020-04-17T22:35:27+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Initial support for soft deletes",
            "additions": 3,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -34,6 +34,7 @@ pub struct Cipher {\n \n     pub favorite: bool,\n     pub password_history: Option<String>,\n+    pub deleted_at: Option<NaiveDateTime>,\n }\n \n /// Local methods\n@@ -58,6 +59,7 @@ impl Cipher {\n \n             data: String::new(),\n             password_history: None,\n+            deleted_at: None,\n         }\n     }\n }\n@@ -108,6 +110,7 @@ impl Cipher {\n             \"Id\": self.uuid,\n             \"Type\": self.atype,\n             \"RevisionDate\": format_date(&self.updated_at),\n+            \"DeletedDate\": self.deleted_at.map_or(Value::Null, |d| Value::String(format_date(&d))),\n             \"FolderId\": self.get_folder_uuid(&user_uuid, &conn),\n             \"Favorite\": self.favorite,\n             \"OrganizationId\": self.organization_uuid,\n",
            "comment_added_diff": []
        },
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -66,7 +66,6 @@ impl Cipher {\n \n use crate::db::schema::*;\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n",
            "comment_added_diff": []
        },
        {
            "commit": "3c66deb5cc7a4387e4176d2a5bdd3f321f09a6bd",
            "timestamp": "2020-05-28T10:46:25+02:00",
            "author": "BlackDex",
            "commit_message": "Redesign of the admin interface.\n\nMain changes:\n - Splitted up settings and users into two separate pages.\n - Added verified shield when the e-mail address has been verified.\n - Added the amount of personal items in the database to the users overview.\n - Added Organizations and Diagnostics pages.\n   - Shows if DNS resolving works.\n   - Shows if there is a posible time drift.\n   - Shows current versions of server and web-vault.\n - Optimized logo-gray.png using optipng\n\nItems which can be added later:\n - Amount of cipher items accessible for a user, not only his personal items.\n - Amount of users per Org\n - Version update check in the diagnostics overview.\n - Copy/Pasteable runtime config which has sensitive data changed or removed for support questions either on the forum or github issues.\n - Option to delete Orgs and all its passwords (when there are no members anymore).\n - Etc....",
            "additions": 8,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -355,6 +355,14 @@ impl Cipher {\n         .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n     }\n \n+    pub fn count_owned_by_user(user_uuid: &str, conn: &DbConn) -> Option<i64> {\n+        ciphers::table\n+        .filter(ciphers::user_uuid.eq(user_uuid))\n+        .count()\n+        .first::<i64>(&**conn)\n+        .ok()\n+    }\n+\n     pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         ciphers::table\n             .filter(ciphers::organization_uuid.eq(org_uuid))\n",
            "comment_added_diff": []
        },
        {
            "commit": "2fffaec226e2dcfb9b013aa985049e368b88f368",
            "timestamp": "2020-06-03T17:57:03+02:00",
            "author": "BlackDex",
            "commit_message": "Added attachment info per user and some layout fix\n\n- Added the amount and size of the attachments per user\n- Changed the items count function a bit\n- Some small layout changes",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -355,12 +355,13 @@ impl Cipher {\n         .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n     }\n \n-    pub fn count_owned_by_user(user_uuid: &str, conn: &DbConn) -> Option<i64> {\n+    pub fn count_owned_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n         ciphers::table\n         .filter(ciphers::user_uuid.eq(user_uuid))\n         .count()\n         .first::<i64>(&**conn)\n         .ok()\n+        .unwrap_or(0)\n     }\n \n     pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n",
            "comment_added_diff": []
        },
        {
            "commit": "ac2723f898c45120ec023bbb2e0e66b26ad71a01",
            "timestamp": "2020-06-03T20:37:31+02:00",
            "author": "BlackDex",
            "commit_message": "Updated Organizations overview\n\n- Changed HTML to match users overview\n- Added User count\n- Added Org cipher amount\n- Added Attachment count and size",
            "additions": 9,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -370,6 +370,15 @@ impl Cipher {\n             .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n     }\n \n+    pub fn count_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n+        ciphers::table\n+            .filter(ciphers::organization_uuid.eq(org_uuid))\n+            .count()\n+            .first::<i64>(&**conn)\n+            .ok()\n+            .unwrap_or(0)\n+    }\n+\n     pub fn find_by_folder(folder_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         folders_ciphers::table.inner_join(ciphers::table)\n             .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 102,
            "deletions": 49,
            "change_type": "MODIFY",
            "diff": "@@ -82,6 +82,15 @@ impl Cipher {\n         let fields_json = self.fields.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n         let password_history_json = self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n \n+        let (read_only, hide_passwords) =\n+            match self.get_access_restrictions(&user_uuid, &conn) {\n+                Some((ro, hp)) => (ro, hp),\n+                None => {\n+                    error!(\"Cipher ownership assertion failure\");\n+                    (true, true)\n+                },\n+            };\n+\n         // Get the data or a default empty value to avoid issues with the mobile apps\n         let mut data_json: Value = serde_json::from_str(&self.data).unwrap_or_else(|_| json!({\n             \"Fields\":null,\n@@ -105,7 +114,15 @@ impl Cipher {\n         }\n         // TODO: ******* Backwards compat end **********\n \n+        // There are three types of cipher response models in upstream\n+        // Bitwarden: \"cipherMini\", \"cipher\", and \"cipherDetails\" (in order\n+        // of increasing level of detail). bitwarden_rs currently only\n+        // supports the \"cipherDetails\" type, though it seems like the\n+        // Bitwarden clients will ignore extra fields.\n+        //\n+        // Ref: https://github.com/bitwarden/server/blob/master/src/Core/Models/Api/Response/CipherResponseModel.cs\n         let mut json_object = json!({\n+            \"Object\": \"cipherDetails\",\n             \"Id\": self.uuid,\n             \"Type\": self.atype,\n             \"RevisionDate\": format_date(&self.updated_at),\n@@ -115,6 +132,8 @@ impl Cipher {\n             \"OrganizationId\": self.organization_uuid,\n             \"Attachments\": attachments_json,\n             \"OrganizationUseTotp\": true,\n+\n+            // This field is specific to the cipherDetails type.\n             \"CollectionIds\": self.get_collections(user_uuid, &conn),\n \n             \"Name\": self.name,\n@@ -123,8 +142,11 @@ impl Cipher {\n \n             \"Data\": data_json,\n \n-            \"Object\": \"cipher\",\n-            \"Edit\": true,\n+            // These values are true by default, but can be false if the\n+            // cipher belongs to a collection where the org owner has enabled\n+            // the \"Read Only\" or \"Hide Passwords\" restrictions for the user.\n+            \"Edit\": !read_only,\n+            \"ViewPassword\": !hide_passwords,\n \n             \"PasswordHistory\": password_history_json,\n         });\n@@ -241,66 +263,97 @@ impl Cipher {\n         }\n     }\n \n-    pub fn is_write_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n+    /// Returns whether this cipher is directly owned by the user.\n+    pub fn is_owned_by_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n         ciphers::table\n             .filter(ciphers::uuid.eq(&self.uuid))\n-            .left_join(\n-                users_organizations::table.on(ciphers::organization_uuid\n-                    .eq(users_organizations::org_uuid.nullable())\n-                    .and(users_organizations::user_uuid.eq(user_uuid))),\n-            )\n-            .left_join(ciphers_collections::table)\n-            .left_join(\n-                users_collections::table\n-                    .on(ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)),\n-            )\n-            .filter(ciphers::user_uuid.eq(user_uuid).or(\n-                // Cipher owner\n-                users_organizations::access_all.eq(true).or(\n-                    // access_all in Organization\n-                    users_organizations::atype.le(UserOrgType::Admin as i32).or(\n-                        // Org admin or owner\n-                        users_collections::user_uuid.eq(user_uuid).and(\n-                            users_collections::read_only.eq(false), //R/W access to collection\n-                        ),\n-                    ),\n-                ),\n-            ))\n-            .select(ciphers::all_columns)\n+            .filter(ciphers::user_uuid.eq(&user_uuid))\n             .first::<Self>(&**conn)\n             .ok()\n             .is_some()\n     }\n \n-    pub fn is_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n+    /// Returns whether this cipher is owned by an org in which the user has full access.\n+    pub fn is_in_full_access_org(&self, user_uuid: &str, conn: &DbConn) -> bool {\n         ciphers::table\n             .filter(ciphers::uuid.eq(&self.uuid))\n-            .left_join(\n-                users_organizations::table.on(ciphers::organization_uuid\n-                    .eq(users_organizations::org_uuid.nullable())\n-                    .and(users_organizations::user_uuid.eq(user_uuid))),\n-            )\n-            .left_join(ciphers_collections::table)\n-            .left_join(\n-                users_collections::table\n-                    .on(ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)),\n-            )\n-            .filter(ciphers::user_uuid.eq(user_uuid).or(\n-                // Cipher owner\n-                users_organizations::access_all.eq(true).or(\n-                    // access_all in Organization\n-                    users_organizations::atype.le(UserOrgType::Admin as i32).or(\n-                        // Org admin or owner\n-                        users_collections::user_uuid.eq(user_uuid), // Access to Collection\n-                    ),\n-                ),\n-            ))\n-            .select(ciphers::all_columns)\n-            .first::<Self>(&**conn)\n+            .inner_join(ciphers_collections::table.on(\n+                ciphers::uuid.eq(ciphers_collections::cipher_uuid)))\n+            .inner_join(users_organizations::table.on(\n+                ciphers::organization_uuid.eq(users_organizations::org_uuid.nullable())\n+                    .and(users_organizations::user_uuid.eq(user_uuid))\n+                    .and(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))))\n+            // The user is an org admin or higher.\n+            .filter(users_organizations::atype.le(UserOrgType::Admin as i32))\n+            // The user was granted full access to the org by an org owner/admin.\n+            .or_filter(users_organizations::access_all.eq(true))\n+            .select(ciphers::uuid)\n+            .first::<String>(&**conn)\n             .ok()\n             .is_some()\n     }\n \n+    /// Returns the user's access restrictions to this cipher. A return value\n+    /// of None means that this cipher does not belong to the user, and is\n+    /// not in any collection the user has access to. Otherwise, the user has\n+    /// access to this cipher, and Some(read_only, hide_passwords) represents\n+    /// the access restrictions.\n+    pub fn get_access_restrictions(&self, user_uuid: &str, conn: &DbConn) -> Option<(bool, bool)> {\n+        // Check whether this cipher is directly owned by the user, or is in\n+        // a collection that the user has full access to. If so, there are no\n+        // access restrictions.\n+        if self.is_owned_by_user(&user_uuid, &conn) || self.is_in_full_access_org(&user_uuid, &conn) {\n+            return Some((false, false));\n+        }\n+\n+        // Check whether this cipher is in any collections accessible to the\n+        // user. If so, retrieve the access flags for each collection.\n+        let query = ciphers::table\n+            .filter(ciphers::uuid.eq(&self.uuid))\n+            .inner_join(ciphers_collections::table.on(\n+                ciphers::uuid.eq(ciphers_collections::cipher_uuid)))\n+            .inner_join(users_collections::table.on(\n+                ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)\n+                    .and(users_collections::user_uuid.eq(user_uuid))))\n+            .select((users_collections::read_only, users_collections::hide_passwords));\n+\n+        // There's an edge case where a cipher can be in multiple collections\n+        // with inconsistent access flags. For example, a cipher could be in\n+        // one collection where the user has read-only access, but also in\n+        // another collection where the user has read/write access. To handle\n+        // this, we do a boolean OR of all values in each of the `read_only`\n+        // and `hide_passwords` columns. This could ideally be done as part\n+        // of the query, but Diesel doesn't support a max() or bool_or()\n+        // function on booleans and this behavior isn't portable anyway.\n+        match query.load::<(bool, bool)>(&**conn).ok() {\n+            Some(vec) => {\n+                let mut read_only = false;\n+                let mut hide_passwords = false;\n+                for (ro, hp) in vec.iter() {\n+                    read_only |= ro;\n+                    hide_passwords |= hp;\n+                }\n+\n+                Some((read_only, hide_passwords))\n+            },\n+            None => {\n+                // This cipher isn't in any collections accessible to the user.\n+                None\n+            }\n+        }\n+    }\n+\n+    pub fn is_write_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n+        match self.get_access_restrictions(&user_uuid, &conn) {\n+            Some((read_only, _hide_passwords)) => !read_only,\n+            None => false,\n+        }\n+    }\n+\n+    pub fn is_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n+        self.get_access_restrictions(&user_uuid, &conn).is_some()\n+    }\n+\n     pub fn get_folder_uuid(&self, user_uuid: &str, conn: &DbConn) -> Option<String> {\n         folders_ciphers::table\n             .inner_join(folders::table)\n",
            "comment_added_diff": [
                [
                    117,
                    "        // There are three types of cipher response models in upstream"
                ],
                [
                    118,
                    "        // Bitwarden: \"cipherMini\", \"cipher\", and \"cipherDetails\" (in order"
                ],
                [
                    119,
                    "        // of increasing level of detail). bitwarden_rs currently only"
                ],
                [
                    120,
                    "        // supports the \"cipherDetails\" type, though it seems like the"
                ],
                [
                    121,
                    "        // Bitwarden clients will ignore extra fields."
                ],
                [
                    122,
                    "        //"
                ],
                [
                    123,
                    "        // Ref: https://github.com/bitwarden/server/blob/master/src/Core/Models/Api/Response/CipherResponseModel.cs"
                ],
                [
                    136,
                    "            // This field is specific to the cipherDetails type."
                ],
                [
                    145,
                    "            // These values are true by default, but can be false if the"
                ],
                [
                    146,
                    "            // cipher belongs to a collection where the org owner has enabled"
                ],
                [
                    147,
                    "            // the \"Read Only\" or \"Hide Passwords\" restrictions for the user."
                ],
                [
                    266,
                    "    /// Returns whether this cipher is directly owned by the user."
                ],
                [
                    276,
                    "    /// Returns whether this cipher is owned by an org in which the user has full access."
                ],
                [
                    286,
                    "            // The user is an org admin or higher."
                ],
                [
                    288,
                    "            // The user was granted full access to the org by an org owner/admin."
                ],
                [
                    296,
                    "    /// Returns the user's access restrictions to this cipher. A return value"
                ],
                [
                    297,
                    "    /// of None means that this cipher does not belong to the user, and is"
                ],
                [
                    298,
                    "    /// not in any collection the user has access to. Otherwise, the user has"
                ],
                [
                    299,
                    "    /// access to this cipher, and Some(read_only, hide_passwords) represents"
                ],
                [
                    300,
                    "    /// the access restrictions."
                ],
                [
                    302,
                    "        // Check whether this cipher is directly owned by the user, or is in"
                ],
                [
                    303,
                    "        // a collection that the user has full access to. If so, there are no"
                ],
                [
                    304,
                    "        // access restrictions."
                ],
                [
                    309,
                    "        // Check whether this cipher is in any collections accessible to the"
                ],
                [
                    310,
                    "        // user. If so, retrieve the access flags for each collection."
                ],
                [
                    320,
                    "        // There's an edge case where a cipher can be in multiple collections"
                ],
                [
                    321,
                    "        // with inconsistent access flags. For example, a cipher could be in"
                ],
                [
                    322,
                    "        // one collection where the user has read-only access, but also in"
                ],
                [
                    323,
                    "        // another collection where the user has read/write access. To handle"
                ],
                [
                    324,
                    "        // this, we do a boolean OR of all values in each of the `read_only`"
                ],
                [
                    325,
                    "        // and `hide_passwords` columns. This could ideally be done as part"
                ],
                [
                    326,
                    "        // of the query, but Diesel doesn't support a max() or bool_or()"
                ],
                [
                    327,
                    "        // function on booleans and this behavior isn't portable anyway."
                ],
                [
                    340,
                    "                // This cipher isn't in any collections accessible to the user."
                ]
            ]
        },
        {
            "commit": "35868dd72c4335c27bd1736bc748e8f85cd6c7eb",
            "timestamp": "2020-07-03T09:00:33-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Optimize cipher queries",
            "additions": 22,
            "deletions": 23,
            "change_type": "MODIFY",
            "diff": "@@ -264,33 +264,32 @@ impl Cipher {\n     }\n \n     /// Returns whether this cipher is directly owned by the user.\n-    pub fn is_owned_by_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        ciphers::table\n-            .filter(ciphers::uuid.eq(&self.uuid))\n-            .filter(ciphers::user_uuid.eq(&user_uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n-            .is_some()\n+    pub fn is_owned_by_user(&self, user_uuid: &str) -> bool {\n+        self.user_uuid.is_some() && self.user_uuid.as_ref().unwrap() == user_uuid\n     }\n \n     /// Returns whether this cipher is owned by an org in which the user has full access.\n     pub fn is_in_full_access_org(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        ciphers::table\n-            .filter(ciphers::uuid.eq(&self.uuid))\n-            .inner_join(ciphers_collections::table.on(\n-                ciphers::uuid.eq(ciphers_collections::cipher_uuid)))\n-            .inner_join(users_organizations::table.on(\n-                ciphers::organization_uuid.eq(users_organizations::org_uuid.nullable())\n-                    .and(users_organizations::user_uuid.eq(user_uuid))\n-                    .and(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))))\n-            // The user is an org admin or higher.\n-            .filter(users_organizations::atype.le(UserOrgType::Admin as i32))\n-            // The user was granted full access to the org by an org owner/admin.\n-            .or_filter(users_organizations::access_all.eq(true))\n-            .select(ciphers::uuid)\n-            .first::<String>(&**conn)\n+        if self.organization_uuid.is_none() {\n+            return false;\n+        }\n+        let org_uuid = self.organization_uuid.as_ref().unwrap();\n+        let rows = users_organizations::table\n+            .filter(users_organizations::user_uuid.eq(user_uuid))\n+            .filter(users_organizations::org_uuid.eq(org_uuid))\n+            .filter(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))\n+            .filter(\n+                // The user is an org admin or higher.\n+                users_organizations::atype.le(UserOrgType::Admin as i32)\n+                // The user was granted full access to the org by an org owner/admin.\n+                    .or(users_organizations::access_all.eq(true))\n+            )\n+            .count()\n+            .first(&**conn)\n             .ok()\n-            .is_some()\n+            .unwrap_or(0);\n+\n+        rows != 0\n     }\n \n     /// Returns the user's access restrictions to this cipher. A return value\n@@ -302,7 +301,7 @@ impl Cipher {\n         // Check whether this cipher is directly owned by the user, or is in\n         // a collection that the user has full access to. If so, there are no\n         // access restrictions.\n-        if self.is_owned_by_user(&user_uuid, &conn) || self.is_in_full_access_org(&user_uuid, &conn) {\n+        if self.is_owned_by_user(&user_uuid) || self.is_in_full_access_org(&user_uuid, &conn) {\n             return Some((false, false));\n         }\n \n",
            "comment_added_diff": [
                [
                    282,
                    "                // The user is an org admin or higher."
                ],
                [
                    284,
                    "                // The user was granted full access to the org by an org owner/admin."
                ]
            ]
        },
        {
            "commit": "f9a73a9bbecbcc4ef858413c58081cfe92ecde45",
            "timestamp": "2020-07-03T10:49:10-07:00",
            "author": "Jeremy Lin",
            "commit_message": "More cipher optimization/cleanup",
            "additions": 16,
            "deletions": 32,
            "change_type": "MODIFY",
            "diff": "@@ -270,26 +270,13 @@ impl Cipher {\n \n     /// Returns whether this cipher is owned by an org in which the user has full access.\n     pub fn is_in_full_access_org(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        if self.organization_uuid.is_none() {\n-            return false;\n+        if let Some(ref org_uuid) = self.organization_uuid {\n+            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user_uuid, &org_uuid, &conn) {\n+                return user_org.has_full_access();\n+            }\n         }\n-        let org_uuid = self.organization_uuid.as_ref().unwrap();\n-        let rows = users_organizations::table\n-            .filter(users_organizations::user_uuid.eq(user_uuid))\n-            .filter(users_organizations::org_uuid.eq(org_uuid))\n-            .filter(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))\n-            .filter(\n-                // The user is an org admin or higher.\n-                users_organizations::atype.le(UserOrgType::Admin as i32)\n-                // The user was granted full access to the org by an org owner/admin.\n-                    .or(users_organizations::access_all.eq(true))\n-            )\n-            .count()\n-            .first(&**conn)\n-            .ok()\n-            .unwrap_or(0);\n \n-        rows != 0\n+        false\n     }\n \n     /// Returns the user's access restrictions to this cipher. A return value\n@@ -324,21 +311,18 @@ impl Cipher {\n         // and `hide_passwords` columns. This could ideally be done as part\n         // of the query, but Diesel doesn't support a max() or bool_or()\n         // function on booleans and this behavior isn't portable anyway.\n-        match query.load::<(bool, bool)>(&**conn).ok() {\n-            Some(vec) => {\n-                let mut read_only = false;\n-                let mut hide_passwords = false;\n-                for (ro, hp) in vec.iter() {\n-                    read_only |= ro;\n-                    hide_passwords |= hp;\n-                }\n-\n-                Some((read_only, hide_passwords))\n-            },\n-            None => {\n-                // This cipher isn't in any collections accessible to the user.\n-                None\n+        if let Some(vec) = query.load::<(bool, bool)>(&**conn).ok() {\n+            let mut read_only = false;\n+            let mut hide_passwords = false;\n+            for (ro, hp) in vec.iter() {\n+                read_only |= ro;\n+                hide_passwords |= hp;\n             }\n+\n+            Some((read_only, hide_passwords))\n+        } else {\n+            // This cipher isn't in any collections accessible to the user.\n+            None\n         }\n     }\n \n",
            "comment_added_diff": [
                [
                    324,
                    "            // This cipher isn't in any collections accessible to the user."
                ]
            ]
        },
        {
            "commit": "f83a8a36d16eb14c4d2f68f7edf7989bbf7973cb",
            "timestamp": "2020-08-19T02:32:58-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Track favorites on a per-user basis\n\nCurrently, favorites are tracked at the cipher level. For org-owned ciphers,\nthis means that if one user sets it as a favorite, it automatically becomes a\nfavorite for all other users that the cipher has been shared with.",
            "additions": 45,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -32,7 +32,6 @@ pub struct Cipher {\n \n     pub data: String,\n \n-    pub favorite: bool,\n     pub password_history: Option<String>,\n     pub deleted_at: Option<NaiveDateTime>,\n }\n@@ -51,7 +50,6 @@ impl Cipher {\n             organization_uuid: None,\n \n             atype,\n-            favorite: false,\n             name,\n \n             notes: None,\n@@ -128,7 +126,7 @@ impl Cipher {\n             \"RevisionDate\": format_date(&self.updated_at),\n             \"DeletedDate\": self.deleted_at.map_or(Value::Null, |d| Value::String(format_date(&d))),\n             \"FolderId\": self.get_folder_uuid(&user_uuid, &conn),\n-            \"Favorite\": self.favorite,\n+            \"Favorite\": self.is_favorite(&user_uuid, &conn),\n             \"OrganizationId\": self.organization_uuid,\n             \"Attachments\": attachments_json,\n             \"OrganizationUseTotp\": true,\n@@ -337,6 +335,50 @@ impl Cipher {\n         self.get_access_restrictions(&user_uuid, &conn).is_some()\n     }\n \n+    // Returns whether this cipher is a favorite of the specified user.\n+    pub fn is_favorite(&self, user_uuid: &str, conn: &DbConn) -> bool {\n+        let query = favorites::table\n+            .filter(favorites::user_uuid.eq(user_uuid))\n+            .filter(favorites::cipher_uuid.eq(&self.uuid))\n+            .count();\n+\n+        query.first::<i64>(&**conn).ok().unwrap_or(0) != 0\n+    }\n+\n+    // Updates whether this cipher is a favorite of the specified user.\n+    pub fn set_favorite(&self, favorite: Option<bool>, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        if favorite.is_none() {\n+            // No change requested.\n+            return Ok(());\n+        }\n+\n+        let (old, new) = (self.is_favorite(user_uuid, &conn), favorite.unwrap());\n+        match (old, new) {\n+            (false, true) => {\n+                User::update_uuid_revision(user_uuid, &conn);\n+                diesel::insert_into(favorites::table)\n+                    .values((\n+                        favorites::user_uuid.eq(user_uuid),\n+                        favorites::cipher_uuid.eq(&self.uuid),\n+                    ))\n+                    .execute(&**conn)\n+                    .map_res(\"Error adding favorite\")\n+            }\n+            (true, false) => {\n+                User::update_uuid_revision(user_uuid, &conn);\n+                diesel::delete(\n+                    favorites::table\n+                        .filter(favorites::user_uuid.eq(user_uuid))\n+                        .filter(favorites::cipher_uuid.eq(&self.uuid))\n+                )\n+                .execute(&**conn)\n+                .map_res(\"Error removing favorite\")\n+            }\n+            // Otherwise, the favorite status is already what it should be.\n+            _ => Ok(())\n+        }\n+    }\n+\n     pub fn get_folder_uuid(&self, user_uuid: &str, conn: &DbConn) -> Option<String> {\n         folders_ciphers::table\n             .inner_join(folders::table)\n",
            "comment_added_diff": [
                [
                    338,
                    "    // Returns whether this cipher is a favorite of the specified user."
                ],
                [
                    348,
                    "    // Updates whether this cipher is a favorite of the specified user."
                ],
                [
                    351,
                    "            // No change requested."
                ],
                [
                    377,
                    "            // Otherwise, the favorite status is already what it should be."
                ]
            ]
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 229,
            "deletions": 201,
            "change_type": "MODIFY",
            "diff": "@@ -5,35 +5,37 @@ use super::{\n     Attachment, CollectionCipher, FolderCipher, Organization, User, UserOrgStatus, UserOrgType, UserOrganization,\n };\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"ciphers\"]\n-#[changeset_options(treat_none_as_null=\"true\")]\n-#[belongs_to(User, foreign_key = \"user_uuid\")]\n-#[belongs_to(Organization, foreign_key = \"organization_uuid\")]\n-#[primary_key(uuid)]\n-pub struct Cipher {\n-    pub uuid: String,\n-    pub created_at: NaiveDateTime,\n-    pub updated_at: NaiveDateTime,\n-\n-    pub user_uuid: Option<String>,\n-    pub organization_uuid: Option<String>,\n-\n-    /*\n-    Login = 1,\n-    SecureNote = 2,\n-    Card = 3,\n-    Identity = 4\n-    */\n-    pub atype: i32,\n-    pub name: String,\n-    pub notes: Option<String>,\n-    pub fields: Option<String>,\n-\n-    pub data: String,\n-\n-    pub password_history: Option<String>,\n-    pub deleted_at: Option<NaiveDateTime>,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"ciphers\"]\n+    #[changeset_options(treat_none_as_null=\"true\")]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[belongs_to(Organization, foreign_key = \"organization_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct Cipher {\n+        pub uuid: String,\n+        pub created_at: NaiveDateTime,\n+        pub updated_at: NaiveDateTime,\n+\n+        pub user_uuid: Option<String>,\n+        pub organization_uuid: Option<String>,\n+\n+        /*\n+        Login = 1,\n+        SecureNote = 2,\n+        Card = 3,\n+        Identity = 4\n+        */\n+        pub atype: i32,\n+        pub name: String,\n+        pub notes: Option<String>,\n+        pub fields: Option<String>,\n+\n+        pub data: String,\n+\n+        pub password_history: Option<String>,\n+        pub deleted_at: Option<NaiveDateTime>,\n+    }\n }\n \n /// Local methods\n@@ -62,9 +64,7 @@ impl Cipher {\n     }\n }\n \n-use crate::db::schema::*;\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n@@ -81,7 +81,7 @@ impl Cipher {\n         let password_history_json = self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n \n         let (read_only, hide_passwords) =\n-            match self.get_access_restrictions(&user_uuid, &conn) {\n+            match self.get_access_restrictions(&user_uuid, conn) {\n                 Some((ro, hp)) => (ro, hp),\n                 None => {\n                     error!(\"Cipher ownership assertion failure\");\n@@ -125,14 +125,14 @@ impl Cipher {\n             \"Type\": self.atype,\n             \"RevisionDate\": format_date(&self.updated_at),\n             \"DeletedDate\": self.deleted_at.map_or(Value::Null, |d| Value::String(format_date(&d))),\n-            \"FolderId\": self.get_folder_uuid(&user_uuid, &conn),\n-            \"Favorite\": self.is_favorite(&user_uuid, &conn),\n+            \"FolderId\": self.get_folder_uuid(&user_uuid, conn),\n+            \"Favorite\": self.is_favorite(&user_uuid, conn),\n             \"OrganizationId\": self.organization_uuid,\n             \"Attachments\": attachments_json,\n             \"OrganizationUseTotp\": true,\n \n             // This field is specific to the cipherDetails type.\n-            \"CollectionIds\": self.get_collections(user_uuid, &conn),\n+            \"CollectionIds\": self.get_collections(user_uuid, conn),\n \n             \"Name\": self.name,\n             \"Notes\": self.notes,\n@@ -183,41 +183,42 @@ impl Cipher {\n         user_uuids\n     }\n \n-    #[cfg(feature = \"postgresql\")]\n-    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n-        self.update_users_revision(conn);\n-        self.updated_at = Utc::now().naive_utc();\n-\n-        diesel::insert_into(ciphers::table)\n-            .values(&*self)\n-            .on_conflict(ciphers::uuid)\n-            .do_update()\n-            .set(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving cipher\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n         self.updated_at = Utc::now().naive_utc();\n-\n-        diesel::replace_into(ciphers::table)\n-            .values(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving cipher\")\n+        \n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(ciphers::table)\n+                    .values(CipherDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving cipher\")\n+                }\n+            postgresql {\n+                let value = CipherDb::to_db(self);\n+                diesel::insert_into(ciphers::table)\n+                    .values(&value)\n+                    .on_conflict(ciphers::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving cipher\")\n+            }\n+        }\n     }\n \n     pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n \n-        FolderCipher::delete_all_by_cipher(&self.uuid, &conn)?;\n-        CollectionCipher::delete_all_by_cipher(&self.uuid, &conn)?;\n-        Attachment::delete_all_by_cipher(&self.uuid, &conn)?;\n+        FolderCipher::delete_all_by_cipher(&self.uuid, conn)?;\n+        CollectionCipher::delete_all_by_cipher(&self.uuid, conn)?;\n+        Attachment::delete_all_by_cipher(&self.uuid, conn)?;\n \n-        diesel::delete(ciphers::table.filter(ciphers::uuid.eq(&self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting cipher\")\n+        db_run! { conn: {\n+            diesel::delete(ciphers::table.filter(ciphers::uuid.eq(&self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting cipher\")\n+        }}\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -235,28 +236,28 @@ impl Cipher {\n     }\n \n     pub fn move_to_folder(&self, folder_uuid: Option<String>, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        User::update_uuid_revision(user_uuid, &conn);\n+        User::update_uuid_revision(user_uuid, conn);\n \n-        match (self.get_folder_uuid(&user_uuid, &conn), folder_uuid) {\n+        match (self.get_folder_uuid(&user_uuid, conn), folder_uuid) {\n             // No changes\n             (None, None) => Ok(()),\n             (Some(ref old), Some(ref new)) if old == new => Ok(()),\n \n             // Add to folder\n-            (None, Some(new)) => FolderCipher::new(&new, &self.uuid).save(&conn),\n+            (None, Some(new)) => FolderCipher::new(&new, &self.uuid).save(conn),\n \n             // Remove from folder\n-            (Some(old), None) => match FolderCipher::find_by_folder_and_cipher(&old, &self.uuid, &conn) {\n-                Some(old) => old.delete(&conn),\n+            (Some(old), None) => match FolderCipher::find_by_folder_and_cipher(&old, &self.uuid, conn) {\n+                Some(old) => old.delete(conn),\n                 None => err!(\"Couldn't move from previous folder\"),\n             },\n \n             // Move to another folder\n             (Some(old), Some(new)) => {\n-                if let Some(old) = FolderCipher::find_by_folder_and_cipher(&old, &self.uuid, &conn) {\n-                    old.delete(&conn)?;\n+                if let Some(old) = FolderCipher::find_by_folder_and_cipher(&old, &self.uuid, conn) {\n+                    old.delete(conn)?;\n                 }\n-                FolderCipher::new(&new, &self.uuid).save(&conn)\n+                FolderCipher::new(&new, &self.uuid).save(conn)\n             }\n         }\n     }\n@@ -269,7 +270,7 @@ impl Cipher {\n     /// Returns whether this cipher is owned by an org in which the user has full access.\n     pub fn is_in_full_access_org(&self, user_uuid: &str, conn: &DbConn) -> bool {\n         if let Some(ref org_uuid) = self.organization_uuid {\n-            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user_uuid, &org_uuid, &conn) {\n+            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user_uuid, &org_uuid, conn) {\n                 return user_org.has_full_access();\n             }\n         }\n@@ -290,38 +291,40 @@ impl Cipher {\n             return Some((false, false));\n         }\n \n-        // Check whether this cipher is in any collections accessible to the\n-        // user. If so, retrieve the access flags for each collection.\n-        let query = ciphers::table\n-            .filter(ciphers::uuid.eq(&self.uuid))\n-            .inner_join(ciphers_collections::table.on(\n-                ciphers::uuid.eq(ciphers_collections::cipher_uuid)))\n-            .inner_join(users_collections::table.on(\n-                ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)\n-                    .and(users_collections::user_uuid.eq(user_uuid))))\n-            .select((users_collections::read_only, users_collections::hide_passwords));\n-\n-        // There's an edge case where a cipher can be in multiple collections\n-        // with inconsistent access flags. For example, a cipher could be in\n-        // one collection where the user has read-only access, but also in\n-        // another collection where the user has read/write access. To handle\n-        // this, we do a boolean OR of all values in each of the `read_only`\n-        // and `hide_passwords` columns. This could ideally be done as part\n-        // of the query, but Diesel doesn't support a max() or bool_or()\n-        // function on booleans and this behavior isn't portable anyway.\n-        if let Some(vec) = query.load::<(bool, bool)>(&**conn).ok() {\n-            let mut read_only = false;\n-            let mut hide_passwords = false;\n-            for (ro, hp) in vec.iter() {\n-                read_only |= ro;\n-                hide_passwords |= hp;\n-            }\n+        db_run! {conn: {\n+            // Check whether this cipher is in any collections accessible to the\n+            // user. If so, retrieve the access flags for each collection.\n+            let query = ciphers::table\n+                .filter(ciphers::uuid.eq(&self.uuid))\n+                .inner_join(ciphers_collections::table.on(\n+                    ciphers::uuid.eq(ciphers_collections::cipher_uuid)))\n+                .inner_join(users_collections::table.on(\n+                    ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)\n+                        .and(users_collections::user_uuid.eq(user_uuid))))\n+                .select((users_collections::read_only, users_collections::hide_passwords));\n+\n+            // There's an edge case where a cipher can be in multiple collections\n+            // with inconsistent access flags. For example, a cipher could be in\n+            // one collection where the user has read-only access, but also in\n+            // another collection where the user has read/write access. To handle\n+            // this, we do a boolean OR of all values in each of the `read_only`\n+            // and `hide_passwords` columns. This could ideally be done as part\n+            // of the query, but Diesel doesn't support a max() or bool_or()\n+            // function on booleans and this behavior isn't portable anyway.\n+            if let Some(vec) = query.load::<(bool, bool)>(conn).ok() {\n+                let mut read_only = false;\n+                let mut hide_passwords = false;\n+                for (ro, hp) in vec.iter() {\n+                    read_only |= ro;\n+                    hide_passwords |= hp;\n+                }\n \n-            Some((read_only, hide_passwords))\n-        } else {\n-            // This cipher isn't in any collections accessible to the user.\n-            None\n-        }\n+                Some((read_only, hide_passwords))\n+            } else {\n+                // This cipher isn't in any collections accessible to the user.\n+                None\n+            }\n+        }}\n     }\n \n     pub fn is_write_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n@@ -337,12 +340,14 @@ impl Cipher {\n \n     // Returns whether this cipher is a favorite of the specified user.\n     pub fn is_favorite(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        let query = favorites::table\n-            .filter(favorites::user_uuid.eq(user_uuid))\n-            .filter(favorites::cipher_uuid.eq(&self.uuid))\n-            .count();\n-\n-        query.first::<i64>(&**conn).ok().unwrap_or(0) != 0\n+        db_run!{ conn: {\n+            let query = favorites::table\n+                .filter(favorites::user_uuid.eq(user_uuid))\n+                .filter(favorites::cipher_uuid.eq(&self.uuid))\n+                .count();\n+\n+            query.first::<i64>(conn).ok().unwrap_or(0) != 0\n+        }}\n     }\n \n     // Updates whether this cipher is a favorite of the specified user.\n@@ -356,23 +361,27 @@ impl Cipher {\n         match (old, new) {\n             (false, true) => {\n                 User::update_uuid_revision(user_uuid, &conn);\n-                diesel::insert_into(favorites::table)\n-                    .values((\n-                        favorites::user_uuid.eq(user_uuid),\n-                        favorites::cipher_uuid.eq(&self.uuid),\n-                    ))\n-                    .execute(&**conn)\n-                    .map_res(\"Error adding favorite\")\n+                db_run!{ conn: {\n+                    diesel::insert_into(favorites::table)\n+                        .values((\n+                            favorites::user_uuid.eq(user_uuid),\n+                            favorites::cipher_uuid.eq(&self.uuid),\n+                        ))\n+                        .execute(conn)\n+                        .map_res(\"Error adding favorite\")\n+                    }}\n             }\n             (true, false) => {\n                 User::update_uuid_revision(user_uuid, &conn);\n-                diesel::delete(\n-                    favorites::table\n-                        .filter(favorites::user_uuid.eq(user_uuid))\n-                        .filter(favorites::cipher_uuid.eq(&self.uuid))\n-                )\n-                .execute(&**conn)\n-                .map_res(\"Error removing favorite\")\n+                db_run!{ conn: {\n+                    diesel::delete(\n+                        favorites::table\n+                            .filter(favorites::user_uuid.eq(user_uuid))\n+                            .filter(favorites::cipher_uuid.eq(&self.uuid))\n+                    )\n+                    .execute(conn)\n+                    .map_res(\"Error removing favorite\")\n+                }}\n             }\n             // Otherwise, the favorite status is already what it should be.\n             _ => Ok(())\n@@ -380,112 +389,131 @@ impl Cipher {\n     }\n \n     pub fn get_folder_uuid(&self, user_uuid: &str, conn: &DbConn) -> Option<String> {\n-        folders_ciphers::table\n-            .inner_join(folders::table)\n-            .filter(folders::user_uuid.eq(&user_uuid))\n-            .filter(folders_ciphers::cipher_uuid.eq(&self.uuid))\n-            .select(folders_ciphers::folder_uuid)\n-            .first::<String>(&**conn)\n-            .ok()\n+        db_run! {conn: {\n+            folders_ciphers::table\n+                .inner_join(folders::table)\n+                .filter(folders::user_uuid.eq(&user_uuid))\n+                .filter(folders_ciphers::cipher_uuid.eq(&self.uuid))\n+                .select(folders_ciphers::folder_uuid)\n+                .first::<String>(conn)\n+                .ok()\n+        }}\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        ciphers::table\n-            .filter(ciphers::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! {conn: {\n+            ciphers::table\n+                .filter(ciphers::uuid.eq(uuid))\n+                .first::<CipherDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     // Find all ciphers accessible to user\n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        ciphers::table\n-        .left_join(users_organizations::table.on(\n-            ciphers::organization_uuid.eq(users_organizations::org_uuid.nullable()).and(\n-                users_organizations::user_uuid.eq(user_uuid).and(\n-                    users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n-                )\n-            )\n-        ))\n-        .left_join(ciphers_collections::table.on(\n-            ciphers::uuid.eq(ciphers_collections::cipher_uuid)\n-        ))\n-        .left_join(users_collections::table.on(\n-            ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)\n-        ))\n-        .filter(ciphers::user_uuid.eq(user_uuid).or( // Cipher owner\n-            users_organizations::access_all.eq(true).or( // access_all in Organization\n-                users_organizations::atype.le(UserOrgType::Admin as i32).or( // Org admin or owner\n-                    users_collections::user_uuid.eq(user_uuid).and( // Access to Collection\n-                        users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n+        db_run! {conn: {\n+            ciphers::table\n+                .left_join(users_organizations::table.on(\n+                    ciphers::organization_uuid.eq(users_organizations::org_uuid.nullable()).and(\n+                        users_organizations::user_uuid.eq(user_uuid).and(\n+                            users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n+                        )\n                     )\n-                )\n-            )\n-        ))\n-        .select(ciphers::all_columns)\n-        .distinct()\n-        .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n+                ))\n+                .left_join(ciphers_collections::table.on(\n+                    ciphers::uuid.eq(ciphers_collections::cipher_uuid)\n+                ))\n+                .left_join(users_collections::table.on(\n+                    ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)\n+                ))\n+                .filter(ciphers::user_uuid.eq(user_uuid).or( // Cipher owner\n+                    users_organizations::access_all.eq(true).or( // access_all in Organization\n+                        users_organizations::atype.le(UserOrgType::Admin as i32).or( // Org admin or owner\n+                            users_collections::user_uuid.eq(user_uuid).and( // Access to Collection\n+                                users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n+                            )\n+                        )\n+                    )\n+                ))\n+                .select(ciphers::all_columns)\n+                .distinct()\n+                .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n+        }}\n     }\n \n     // Find all ciphers directly owned by user\n     pub fn find_owned_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        ciphers::table\n-        .filter(ciphers::user_uuid.eq(user_uuid))\n-        .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n+        db_run! {conn: {\n+            ciphers::table\n+                .filter(ciphers::user_uuid.eq(user_uuid))\n+                .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n+        }}\n     }\n \n     pub fn count_owned_by_user(user_uuid: &str, conn: &DbConn) -> i64 {\n-        ciphers::table\n-        .filter(ciphers::user_uuid.eq(user_uuid))\n-        .count()\n-        .first::<i64>(&**conn)\n-        .ok()\n-        .unwrap_or(0)\n+        db_run! {conn: {\n+            ciphers::table\n+                .filter(ciphers::user_uuid.eq(user_uuid))\n+                .count()\n+                .first::<i64>(conn)\n+                .ok()\n+                .unwrap_or(0)\n+        }}\n     }\n \n     pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        ciphers::table\n-            .filter(ciphers::organization_uuid.eq(org_uuid))\n-            .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n+        db_run! {conn: {\n+            ciphers::table\n+                .filter(ciphers::organization_uuid.eq(org_uuid))\n+                .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n+        }}\n     }\n \n     pub fn count_by_org(org_uuid: &str, conn: &DbConn) -> i64 {\n-        ciphers::table\n-            .filter(ciphers::organization_uuid.eq(org_uuid))\n-            .count()\n-            .first::<i64>(&**conn)\n-            .ok()\n-            .unwrap_or(0)\n+        db_run! {conn: {\n+            ciphers::table\n+                .filter(ciphers::organization_uuid.eq(org_uuid))\n+                .count()\n+                .first::<i64>(conn)\n+                .ok()\n+                .unwrap_or(0)\n+        }}\n     }\n \n     pub fn find_by_folder(folder_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        folders_ciphers::table.inner_join(ciphers::table)\n-            .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n-            .select(ciphers::all_columns)\n-            .load::<Self>(&**conn).expect(\"Error loading ciphers\")\n+        db_run! {conn: {\n+            folders_ciphers::table.inner_join(ciphers::table)\n+                .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n+                .select(ciphers::all_columns)\n+                .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n+        }}\n     }\n \n     pub fn get_collections(&self, user_id: &str, conn: &DbConn) -> Vec<String> {\n-        ciphers_collections::table\n-        .inner_join(collections::table.on(\n-            collections::uuid.eq(ciphers_collections::collection_uuid)\n-        ))\n-        .inner_join(users_organizations::table.on(\n-            users_organizations::org_uuid.eq(collections::org_uuid).and(\n-                users_organizations::user_uuid.eq(user_id)\n-            )\n-        ))\n-        .left_join(users_collections::table.on(\n-            users_collections::collection_uuid.eq(ciphers_collections::collection_uuid).and(\n-                users_collections::user_uuid.eq(user_id)\n-            )\n-        ))\n-        .filter(ciphers_collections::cipher_uuid.eq(&self.uuid))\n-        .filter(users_collections::user_uuid.eq(user_id).or( // User has access to collection\n-            users_organizations::access_all.eq(true).or( // User has access all\n-                users_organizations::atype.le(UserOrgType::Admin as i32) // User is admin or owner\n-            )\n-        ))\n-        .select(ciphers_collections::collection_uuid)\n-        .load::<String>(&**conn).unwrap_or_default()\n+        db_run! {conn: {\n+            ciphers_collections::table\n+            .inner_join(collections::table.on(\n+                collections::uuid.eq(ciphers_collections::collection_uuid)\n+            ))\n+            .inner_join(users_organizations::table.on(\n+                users_organizations::org_uuid.eq(collections::org_uuid).and(\n+                    users_organizations::user_uuid.eq(user_id)\n+                )\n+            ))\n+            .left_join(users_collections::table.on(\n+                users_collections::collection_uuid.eq(ciphers_collections::collection_uuid).and(\n+                    users_collections::user_uuid.eq(user_id)\n+                )\n+            ))\n+            .filter(ciphers_collections::cipher_uuid.eq(&self.uuid))\n+            .filter(users_collections::user_uuid.eq(user_id).or( // User has access to collection\n+                users_organizations::access_all.eq(true).or( // User has access all\n+                    users_organizations::atype.le(UserOrgType::Admin as i32) // User is admin or owner\n+                )\n+            ))\n+            .select(ciphers_collections::collection_uuid)\n+            .load::<String>(conn).unwrap_or_default()\n+        }}\n     }\n }\n",
            "comment_added_diff": [
                [
                    295,
                    "            // Check whether this cipher is in any collections accessible to the"
                ],
                [
                    296,
                    "            // user. If so, retrieve the access flags for each collection."
                ],
                [
                    306,
                    "            // There's an edge case where a cipher can be in multiple collections"
                ],
                [
                    307,
                    "            // with inconsistent access flags. For example, a cipher could be in"
                ],
                [
                    308,
                    "            // one collection where the user has read-only access, but also in"
                ],
                [
                    309,
                    "            // another collection where the user has read/write access. To handle"
                ],
                [
                    310,
                    "            // this, we do a boolean OR of all values in each of the `read_only`"
                ],
                [
                    311,
                    "            // and `hide_passwords` columns. This could ideally be done as part"
                ],
                [
                    312,
                    "            // of the query, but Diesel doesn't support a max() or bool_or()"
                ],
                [
                    313,
                    "            // function on booleans and this behavior isn't portable anyway."
                ],
                [
                    324,
                    "                // This cipher isn't in any collections accessible to the user."
                ],
                [
                    430,
                    "                .filter(ciphers::user_uuid.eq(user_uuid).or( // Cipher owner"
                ],
                [
                    431,
                    "                    users_organizations::access_all.eq(true).or( // access_all in Organization"
                ],
                [
                    432,
                    "                        users_organizations::atype.le(UserOrgType::Admin as i32).or( // Org admin or owner"
                ],
                [
                    433,
                    "                            users_collections::user_uuid.eq(user_uuid).and( // Access to Collection"
                ],
                [
                    510,
                    "            .filter(users_collections::user_uuid.eq(user_id).or( // User has access to collection"
                ],
                [
                    511,
                    "                users_organizations::access_all.eq(true).or( // User has access all"
                ],
                [
                    512,
                    "                    users_organizations::atype.le(UserOrgType::Admin as i32) // User is admin or owner"
                ]
            ]
        },
        {
            "commit": "175d647e47fbd9abec4134c708199ba8aa1ec682",
            "timestamp": "2020-08-26T01:27:38-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Delete associated favorites when deleting a cipher or user\n\nThis prevents foreign key constraint violations.",
            "additions": 15,
            "deletions": 43,
            "change_type": "MODIFY",
            "diff": "@@ -2,7 +2,15 @@ use chrono::{NaiveDateTime, Utc};\n use serde_json::Value;\n \n use super::{\n-    Attachment, CollectionCipher, FolderCipher, Organization, User, UserOrgStatus, UserOrgType, UserOrganization,\n+    Attachment,\n+    CollectionCipher,\n+    Favorite,\n+    FolderCipher,\n+    Organization,\n+    User,\n+    UserOrgStatus,\n+    UserOrgType,\n+    UserOrganization,\n };\n \n db_object! {\n@@ -213,6 +221,7 @@ impl Cipher {\n         FolderCipher::delete_all_by_cipher(&self.uuid, conn)?;\n         CollectionCipher::delete_all_by_cipher(&self.uuid, conn)?;\n         Attachment::delete_all_by_cipher(&self.uuid, conn)?;\n+        Favorite::delete_all_by_cipher(&self.uuid, conn)?;\n \n         db_run! { conn: {\n             diesel::delete(ciphers::table.filter(ciphers::uuid.eq(&self.uuid)))\n@@ -340,51 +349,14 @@ impl Cipher {\n \n     // Returns whether this cipher is a favorite of the specified user.\n     pub fn is_favorite(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        db_run!{ conn: {\n-            let query = favorites::table\n-                .filter(favorites::user_uuid.eq(user_uuid))\n-                .filter(favorites::cipher_uuid.eq(&self.uuid))\n-                .count();\n-\n-            query.first::<i64>(conn).ok().unwrap_or(0) != 0\n-        }}\n+        Favorite::is_favorite(&self.uuid, user_uuid, conn)\n     }\n \n-    // Updates whether this cipher is a favorite of the specified user.\n+    // Sets whether this cipher is a favorite of the specified user.\n     pub fn set_favorite(&self, favorite: Option<bool>, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        if favorite.is_none() {\n-            // No change requested.\n-            return Ok(());\n-        }\n-\n-        let (old, new) = (self.is_favorite(user_uuid, &conn), favorite.unwrap());\n-        match (old, new) {\n-            (false, true) => {\n-                User::update_uuid_revision(user_uuid, &conn);\n-                db_run!{ conn: {\n-                    diesel::insert_into(favorites::table)\n-                        .values((\n-                            favorites::user_uuid.eq(user_uuid),\n-                            favorites::cipher_uuid.eq(&self.uuid),\n-                        ))\n-                        .execute(conn)\n-                        .map_res(\"Error adding favorite\")\n-                    }}\n-            }\n-            (true, false) => {\n-                User::update_uuid_revision(user_uuid, &conn);\n-                db_run!{ conn: {\n-                    diesel::delete(\n-                        favorites::table\n-                            .filter(favorites::user_uuid.eq(user_uuid))\n-                            .filter(favorites::cipher_uuid.eq(&self.uuid))\n-                    )\n-                    .execute(conn)\n-                    .map_res(\"Error removing favorite\")\n-                }}\n-            }\n-            // Otherwise, the favorite status is already what it should be.\n-            _ => Ok(())\n+        match favorite {\n+            None => Ok(()), // No change requested.\n+            Some(status) => Favorite::set_favorite(status, &self.uuid, user_uuid, conn),\n         }\n     }\n \n",
            "comment_added_diff": [
                [
                    355,
                    "    // Sets whether this cipher is a favorite of the specified user."
                ],
                [
                    358,
                    "            None => Ok(()), // No change requested."
                ]
            ]
        },
        {
            "commit": "aaba1e836838a6dd75d65d83d47346d733e3e752",
            "timestamp": "2020-08-28T22:10:28+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix some clippy warnings and remove unused function",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -320,7 +320,7 @@ impl Cipher {\n             // and `hide_passwords` columns. This could ideally be done as part\n             // of the query, but Diesel doesn't support a max() or bool_or()\n             // function on booleans and this behavior isn't portable anyway.\n-            if let Some(vec) = query.load::<(bool, bool)>(conn).ok() {\n+            if let Ok(vec) = query.load::<(bool, bool)>(conn) {\n                 let mut read_only = false;\n                 let mut hide_passwords = false;\n                 for (ro, hp) in vec.iter() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "4c3b328aca359ebf6211f53509c15b6c94d70e3f",
            "timestamp": "2020-09-01T02:20:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Hide ciphers from non-selected collections for org owners/admins\n\nIf org owners/admins set their org access to only include selected\ncollections, then ciphers from non-selected collections shouldn't\nappear in \"My Vault\". This matches the upstream behavior.",
            "additions": 39,
            "deletions": 20,
            "change_type": "MODIFY",
            "diff": "@@ -382,39 +382,58 @@ impl Cipher {\n         }}\n     }\n \n-    // Find all ciphers accessible to user\n-    pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+    // Find all ciphers accessible or visible to the specified user.\n+    //\n+    // \"Accessible\" means the user has read access to the cipher, either via\n+    // direct ownership or via collection access.\n+    //\n+    // \"Visible\" usually means the same as accessible, except when an org\n+    // owner/admin sets their account to have access to only selected\n+    // collections in the org (presumably because they aren't interested in\n+    // the other collections in the org). In this case, if `visible_only` is\n+    // true, then the non-interesting ciphers will not be returned. As a\n+    // result, those ciphers will not appear in \"My Vault\" for the org\n+    // owner/admin, but they can still be accessed via the org vault view.\n+    pub fn find_by_user(user_uuid: &str, visible_only: bool, conn: &DbConn) -> Vec<Self> {\n         db_run! {conn: {\n-            ciphers::table\n-                .left_join(users_organizations::table.on(\n-                    ciphers::organization_uuid.eq(users_organizations::org_uuid.nullable()).and(\n-                        users_organizations::user_uuid.eq(user_uuid).and(\n-                            users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n-                        )\n-                    )\n-                ))\n+            let mut query = ciphers::table\n                 .left_join(ciphers_collections::table.on(\n                     ciphers::uuid.eq(ciphers_collections::cipher_uuid)\n                 ))\n+                .left_join(users_organizations::table.on(\n+                    ciphers::organization_uuid.eq(users_organizations::org_uuid.nullable())\n+                        .and(users_organizations::user_uuid.eq(user_uuid))\n+                        .and(users_organizations::status.eq(UserOrgStatus::Confirmed as i32))\n+                ))\n                 .left_join(users_collections::table.on(\n                     ciphers_collections::collection_uuid.eq(users_collections::collection_uuid)\n+                        // Ensure that users_collections::user_uuid is NULL for unconfirmed users.\n+                        .and(users_organizations::user_uuid.eq(users_collections::user_uuid))\n                 ))\n-                .filter(ciphers::user_uuid.eq(user_uuid).or( // Cipher owner\n-                    users_organizations::access_all.eq(true).or( // access_all in Organization\n-                        users_organizations::atype.le(UserOrgType::Admin as i32).or( // Org admin or owner\n-                            users_collections::user_uuid.eq(user_uuid).and( // Access to Collection\n-                                users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n-                            )\n-                        )\n-                    )\n-                ))\n+                .filter(ciphers::user_uuid.eq(user_uuid)) // Cipher owner\n+                .or_filter(users_organizations::access_all.eq(true)) // access_all in org\n+                .or_filter(users_collections::user_uuid.eq(user_uuid)) // Access to collection\n+                .into_boxed();\n+\n+            if !visible_only {\n+                query = query.or_filter(\n+                    users_organizations::atype.le(UserOrgType::Admin as i32) // Org admin/owner\n+                );\n+            }\n+\n+            query\n                 .select(ciphers::all_columns)\n                 .distinct()\n                 .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n         }}\n     }\n \n-    // Find all ciphers directly owned by user\n+    // Find all ciphers visible to the specified user.\n+    pub fn find_by_user_visible(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        Self::find_by_user(user_uuid, true, conn)\n+    }\n+\n+    // Find all ciphers directly owned by the specified user.\n     pub fn find_owned_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         db_run! {conn: {\n             ciphers::table\n",
            "comment_added_diff": [
                [
                    385,
                    "    // Find all ciphers accessible or visible to the specified user."
                ],
                [
                    386,
                    "    //"
                ],
                [
                    387,
                    "    // \"Accessible\" means the user has read access to the cipher, either via"
                ],
                [
                    388,
                    "    // direct ownership or via collection access."
                ],
                [
                    389,
                    "    //"
                ],
                [
                    390,
                    "    // \"Visible\" usually means the same as accessible, except when an org"
                ],
                [
                    391,
                    "    // owner/admin sets their account to have access to only selected"
                ],
                [
                    392,
                    "    // collections in the org (presumably because they aren't interested in"
                ],
                [
                    393,
                    "    // the other collections in the org). In this case, if `visible_only` is"
                ],
                [
                    394,
                    "    // true, then the non-interesting ciphers will not be returned. As a"
                ],
                [
                    395,
                    "    // result, those ciphers will not appear in \"My Vault\" for the org"
                ],
                [
                    396,
                    "    // owner/admin, but they can still be accessed via the org vault view."
                ],
                [
                    410,
                    "                        // Ensure that users_collections::user_uuid is NULL for unconfirmed users."
                ],
                [
                    413,
                    "                .filter(ciphers::user_uuid.eq(user_uuid)) // Cipher owner"
                ],
                [
                    414,
                    "                .or_filter(users_organizations::access_all.eq(true)) // access_all in org"
                ],
                [
                    415,
                    "                .or_filter(users_collections::user_uuid.eq(user_uuid)) // Access to collection"
                ],
                [
                    420,
                    "                    users_organizations::atype.le(UserOrgType::Admin as i32) // Org admin/owner"
                ],
                [
                    431,
                    "    // Find all ciphers visible to the specified user."
                ],
                [
                    436,
                    "    // Find all ciphers directly owned by the specified user."
                ]
            ]
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 16,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -194,14 +194,25 @@ impl Cipher {\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n         self.updated_at = Utc::now().naive_utc();\n-        \n-        db_run! { conn: \n+\n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(ciphers::table)\n+                match diesel::replace_into(ciphers::table)\n                     .values(CipherDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving cipher\")\n-                }\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(ciphers::table)\n+                            .filter(ciphers::uuid.eq(&self.uuid))\n+                            .set(CipherDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving cipher\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving cipher\")\n+            }\n             postgresql {\n                 let value = CipherDb::to_db(self);\n                 diesel::insert_into(ciphers::table)\n",
            "comment_added_diff": [
                [
                    205,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ]
            ]
        },
        {
            "commit": "7dff8c01dd86f69761f4822b8b0c41709f03f271",
            "timestamp": "2021-01-31T21:46:37+01:00",
            "author": "BlackDex",
            "commit_message": "JSON Response updates and small fixes\n\nUpdated several json response models.\nAlso fixed a few small bugs.\n\nciphers.rs:\n  - post_ciphers_create:\n    * Prevent cipher creation to organization without a collection.\n  - update_cipher_from_data:\n    * ~~Fixed removal of user_uuid which prevent user-owned shared-cipher to be not editable anymore when set to read-only.~~\n    * Cleanup the json_data by removing the `Response` key/values from several objects.\n  - delete_all:\n    * Do not delete all Collections during the Purge of an Organization (same as upstream).\n\ncipher.rs:\n  - Cipher::to_json:\n    * Updated json response to match upstream.\n    * Return empty json object if there is no type_data instead of values which should not be set for the type_data.\n\norganizations.rs:\n  * Added two new endpoints to prevent Javascript errors regarding tax\n\norganization.rs:\n  - Organization::to_json:\n    * Updated response model to match upstream\n  - UserOrganization::to_json:\n    * Updated response model to match upstream\n\ncollection.rs:\n  - Collection::{to_json, to_json_details}:\n    * Updated the json response model, and added a detailed version used during the sync\n  - hide_passwords_for_user:\n    * Added this function to return if the passwords should be hidden or not for the user at the specific collection (used by `to_json_details`)\n\nUpdate 1: Some small changes after comments from @jjlin.\nUpdate 2: Fixed vault purge by user to make sure the cipher is not part of an organization.\n\nResolves #971\nCloses #990, Closes #991",
            "additions": 43,
            "deletions": 24,
            "change_type": "MODIFY",
            "diff": "@@ -83,7 +83,12 @@ impl Cipher {\n         use crate::util::format_date;\n \n         let attachments = Attachment::find_by_cipher(&self.uuid, conn);\n-        let attachments_json: Vec<Value> = attachments.iter().map(|c| c.to_json(host)).collect();\n+        // When there are no attachments use null instead of an empty array\n+        let attachments_json = if attachments.is_empty() {\n+            Value::Null\n+        } else {\n+            attachments.iter().map(|c| c.to_json(host)).collect()\n+        };\n \n         let fields_json = self.fields.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n         let password_history_json = self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n@@ -97,28 +102,31 @@ impl Cipher {\n                 },\n             };\n \n-        // Get the data or a default empty value to avoid issues with the mobile apps\n-        let mut data_json: Value = serde_json::from_str(&self.data).unwrap_or_else(|_| json!({\n-            \"Fields\":null,\n-            \"Name\": self.name,\n-            \"Notes\":null,\n-            \"Password\":null,\n-            \"PasswordHistory\":null,\n-            \"PasswordRevisionDate\":null,\n-            \"Response\":null,\n-            \"Totp\":null,\n-            \"Uris\":null,\n-            \"Username\":null\n-        }));\n-\n-        // TODO: ******* Backwards compat start **********\n-        // To remove backwards compatibility, just remove this entire section\n-        // and remove the compat code from ciphers::update_cipher_from_data\n-        if self.atype == 1 && data_json[\"Uris\"].is_array() {\n-            let uri = data_json[\"Uris\"][0][\"Uri\"].clone();\n-            data_json[\"Uri\"] = uri;\n+        // Get the type_data or a default to an empty json object '{}'.\n+        // If not passing an empty object, mobile clients will crash.\n+        let mut type_data_json: Value = serde_json::from_str(&self.data).unwrap_or(json!({}));\n+\n+        // NOTE: This was marked as *Backwards Compatibilty Code*, but as of January 2021 this is still being used by upstream\n+        // Set the first element of the Uris array as Uri, this is needed several (mobile) clients.\n+        if self.atype == 1 {\n+            if type_data_json[\"Uris\"].is_array() {\n+                let uri = type_data_json[\"Uris\"][0][\"Uri\"].clone();\n+                type_data_json[\"Uri\"] = uri;\n+            } else {\n+                // Upstream always has an Uri key/value\n+                type_data_json[\"Uri\"] = Value::Null;\n+            }\n         }\n-        // TODO: ******* Backwards compat end **********\n+\n+        // Clone the type_data and add some default value.\n+        let mut data_json = type_data_json.clone();\n+\n+        // NOTE: This was marked as *Backwards Compatibilty Code*, but as of January 2021 this is still being used by upstream\n+        // data_json should always contain the following keys with every atype\n+        data_json[\"Fields\"] = json!(fields_json);\n+        data_json[\"Name\"] = json!(self.name);\n+        data_json[\"Notes\"] = json!(self.notes);\n+        data_json[\"PasswordHistory\"] = json!(password_history_json);\n \n         // There are three types of cipher response models in upstream\n         // Bitwarden: \"cipherMini\", \"cipher\", and \"cipherDetails\" (in order\n@@ -137,6 +145,8 @@ impl Cipher {\n             \"Favorite\": self.is_favorite(&user_uuid, conn),\n             \"OrganizationId\": self.organization_uuid,\n             \"Attachments\": attachments_json,\n+            // We have UseTotp set to true by default within the Organization model.\n+            // This variable together with UsersGetPremium is used to show or hide the TOTP counter.\n             \"OrganizationUseTotp\": true,\n \n             // This field is specific to the cipherDetails type.\n@@ -155,6 +165,12 @@ impl Cipher {\n             \"ViewPassword\": !hide_passwords,\n \n             \"PasswordHistory\": password_history_json,\n+\n+            // All Cipher types are included by default as null, but only the matching one will be populated\n+            \"Login\": null,\n+            \"SecureNote\": null,\n+            \"Card\": null,\n+            \"Identity\": null,\n         });\n \n         let key = match self.atype {\n@@ -165,7 +181,7 @@ impl Cipher {\n             _ => panic!(\"Wrong type\"),\n         };\n \n-        json_object[key] = data_json;\n+        json_object[key] = type_data_json;\n         json_object\n     }\n \n@@ -448,7 +464,10 @@ impl Cipher {\n     pub fn find_owned_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n         db_run! {conn: {\n             ciphers::table\n-                .filter(ciphers::user_uuid.eq(user_uuid))\n+                .filter(\n+                    ciphers::user_uuid.eq(user_uuid)\n+                    .and(ciphers::organization_uuid.is_null())\n+                )\n                 .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n         }}\n     }\n",
            "comment_added_diff": [
                [
                    86,
                    "        // When there are no attachments use null instead of an empty array"
                ],
                [
                    105,
                    "        // Get the type_data or a default to an empty json object '{}'."
                ],
                [
                    106,
                    "        // If not passing an empty object, mobile clients will crash."
                ],
                [
                    109,
                    "        // NOTE: This was marked as *Backwards Compatibilty Code*, but as of January 2021 this is still being used by upstream"
                ],
                [
                    110,
                    "        // Set the first element of the Uris array as Uri, this is needed several (mobile) clients."
                ],
                [
                    116,
                    "                // Upstream always has an Uri key/value"
                ],
                [
                    121,
                    "        // Clone the type_data and add some default value."
                ],
                [
                    124,
                    "        // NOTE: This was marked as *Backwards Compatibilty Code*, but as of January 2021 this is still being used by upstream"
                ],
                [
                    125,
                    "        // data_json should always contain the following keys with every atype"
                ],
                [
                    148,
                    "            // We have UseTotp set to true by default within the Organization model."
                ],
                [
                    149,
                    "            // This variable together with UsersGetPremium is used to show or hide the TOTP counter."
                ],
                [
                    169,
                    "            // All Cipher types are included by default as null, but only the matching one will be populated"
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -14,7 +14,7 @@ use super::{\n };\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"ciphers\"]\n     #[changeset_options(treat_none_as_null=\"true\")]\n     #[belongs_to(User, foreign_key = \"user_uuid\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "9f1240d8d95eeb7fc17e746355cf6ace1577a4ee",
            "timestamp": "2021-03-27T14:03:46+00:00",
            "author": "Jake Howard",
            "commit_message": "Only construct JSON object if it's useful",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -104,7 +104,7 @@ impl Cipher {\n \n         // Get the type_data or a default to an empty json object '{}'.\n         // If not passing an empty object, mobile clients will crash.\n-        let mut type_data_json: Value = serde_json::from_str(&self.data).unwrap_or(json!({}));\n+        let mut type_data_json: Value = serde_json::from_str(&self.data).unwrap_or_else(|_| json!({}));\n \n         // NOTE: This was marked as *Backwards Compatibilty Code*, but as of January 2021 this is still being used by upstream\n         // Set the first element of the Uris array as Uri, this is needed several (mobile) clients.\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 19,
            "deletions": 19,
            "change_type": "MODIFY",
            "diff": "@@ -2,14 +2,7 @@ use chrono::{NaiveDateTime, Utc};\n use serde_json::Value;\n \n use super::{\n-    Attachment,\n-    CollectionCipher,\n-    Favorite,\n-    FolderCipher,\n-    Organization,\n-    User,\n-    UserOrgStatus,\n-    UserOrgType,\n+    Attachment, CollectionCipher, Favorite, FolderCipher, Organization, User, UserOrgStatus, UserOrgType,\n     UserOrganization,\n };\n \n@@ -90,17 +83,24 @@ impl Cipher {\n             attachments.iter().map(|c| c.to_json(host)).collect()\n         };\n \n-        let fields_json = self.fields.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n-        let password_history_json = self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n-\n-        let (read_only, hide_passwords) =\n-            match self.get_access_restrictions(&user_uuid, conn) {\n-                Some((ro, hp)) => (ro, hp),\n-                None => {\n-                    error!(\"Cipher ownership assertion failure\");\n-                    (true, true)\n-                },\n-            };\n+        let fields_json = self\n+            .fields\n+            .as_ref()\n+            .and_then(|s| serde_json::from_str(s).ok())\n+            .unwrap_or(Value::Null);\n+        let password_history_json = self\n+            .password_history\n+            .as_ref()\n+            .and_then(|s| serde_json::from_str(s).ok())\n+            .unwrap_or(Value::Null);\n+\n+        let (read_only, hide_passwords) = match self.get_access_restrictions(&user_uuid, conn) {\n+            Some((ro, hp)) => (ro, hp),\n+            None => {\n+                error!(\"Cipher ownership assertion failure\");\n+                (true, true)\n+            }\n+        };\n \n         // Get the type_data or a default to an empty json object '{}'.\n         // If not passing an empty object, mobile clients will crash.\n",
            "comment_added_diff": []
        },
        {
            "commit": "d77333576b1268cd24f17348ffe6d72e07855f54",
            "timestamp": "2021-04-05T23:07:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for auto-deleting trashed items\n\nUpstream will soon auto-delete trashed items after 30 days, but some people\nuse the trash as an archive folder, so to avoid unexpected data loss, this\nimplementation requires the user to explicitly enable auto-deletion.",
            "additions": 23,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,8 @@\n-use chrono::{NaiveDateTime, Utc};\n+use chrono::{Duration, NaiveDateTime, Utc};\n use serde_json::Value;\n \n+use crate::CONFIG;\n+\n use super::{\n     Attachment,\n     CollectionCipher,\n@@ -271,6 +273,17 @@ impl Cipher {\n         Ok(())\n     }\n \n+    /// Purge all ciphers that are old enough to be auto-deleted.\n+    pub fn purge_trash(conn: &DbConn) {\n+        if let Some(auto_delete_days) = CONFIG.trash_auto_delete_days() {\n+            let now = Utc::now().naive_utc();\n+            let dt = now - Duration::days(auto_delete_days);\n+            for cipher in Self::find_deleted_before(&dt, conn) {\n+                cipher.delete(&conn).ok();\n+            }\n+        }\n+    }\n+\n     pub fn move_to_folder(&self, folder_uuid: Option<String>, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(user_uuid, conn);\n \n@@ -511,6 +524,15 @@ impl Cipher {\n         }}\n     }\n \n+    /// Find all ciphers that were deleted before the specified datetime.\n+    pub fn find_deleted_before(dt: &NaiveDateTime, conn: &DbConn) -> Vec<Self> {\n+        db_run! {conn: {\n+            ciphers::table\n+                .filter(ciphers::deleted_at.lt(dt))\n+                .load::<CipherDb>(conn).expect(\"Error loading ciphers\").from_db()\n+        }}\n+    }\n+\n     pub fn get_collections(&self, user_id: &str, conn: &DbConn) -> Vec<String> {\n         db_run! {conn: {\n             ciphers_collections::table\n",
            "comment_added_diff": [
                [
                    276,
                    "    /// Purge all ciphers that are old enough to be auto-deleted."
                ],
                [
                    527,
                    "    /// Find all ciphers that were deleted before the specified datetime."
                ]
            ]
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 7,
            "deletions": 16,
            "change_type": "MODIFY",
            "diff": "@@ -83,16 +83,9 @@ impl Cipher {\n             attachments.iter().map(|c| c.to_json(host)).collect()\n         };\n \n-        let fields_json = self\n-            .fields\n-            .as_ref()\n-            .and_then(|s| serde_json::from_str(s).ok())\n-            .unwrap_or(Value::Null);\n-        let password_history_json = self\n-            .password_history\n-            .as_ref()\n-            .and_then(|s| serde_json::from_str(s).ok())\n-            .unwrap_or(Value::Null);\n+        let fields_json = self.fields.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n+        let password_history_json =\n+            self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n \n         let (read_only, hide_passwords) = match self.get_access_restrictions(&user_uuid, conn) {\n             Some((ro, hp)) => (ro, hp),\n@@ -195,12 +188,10 @@ impl Cipher {\n             None => {\n                 // Belongs to Organization, need to update affected users\n                 if let Some(ref org_uuid) = self.organization_uuid {\n-                    UserOrganization::find_by_cipher_and_org(&self.uuid, &org_uuid, conn)\n-                        .iter()\n-                        .for_each(|user_org| {\n-                            User::update_uuid_revision(&user_org.user_uuid, conn);\n-                            user_uuids.push(user_org.user_uuid.clone())\n-                        });\n+                    UserOrganization::find_by_cipher_and_org(&self.uuid, &org_uuid, conn).iter().for_each(|user_org| {\n+                        User::update_uuid_revision(&user_org.user_uuid, conn);\n+                        user_uuids.push(user_org.user_uuid.clone())\n+                    });\n                 }\n             }\n         };\n",
            "comment_added_diff": []
        },
        {
            "commit": "34ea10475d316ccb2ca4cd2cac67b61c4cdfb62a",
            "timestamp": "2021-04-27T23:18:32+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Project renaming",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -125,7 +125,7 @@ impl Cipher {\n \n         // There are three types of cipher response models in upstream\n         // Bitwarden: \"cipherMini\", \"cipher\", and \"cipherDetails\" (in order\n-        // of increasing level of detail). bitwarden_rs currently only\n+        // of increasing level of detail). vaultwarden currently only\n         // supports the \"cipherDetails\" type, though it seems like the\n         // Bitwarden clients will ignore extra fields.\n         //\n",
            "comment_added_diff": [
                [
                    128,
                    "        // of increasing level of detail). vaultwarden currently only"
                ]
            ]
        },
        {
            "commit": "a9a5706764a98fbcda1bc6ac2e0ef5f78ea6c202",
            "timestamp": "2021-05-11T20:09:57-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for password reprompt\n\nUpstream PR: https://github.com/bitwarden/server/pull/1269",
            "additions": 9,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -38,9 +38,16 @@ db_object! {\n \n         pub password_history: Option<String>,\n         pub deleted_at: Option<NaiveDateTime>,\n+        pub reprompt: Option<i32>,\n     }\n }\n \n+#[allow(dead_code)]\n+pub enum RepromptType {\n+    None = 0,\n+    Password = 1, // not currently used in server\n+}\n+\n /// Local methods\n impl Cipher {\n     pub fn new(atype: i32, name: String) -> Self {\n@@ -63,6 +70,7 @@ impl Cipher {\n             data: String::new(),\n             password_history: None,\n             deleted_at: None,\n+            reprompt: None,\n         }\n     }\n }\n@@ -138,6 +146,7 @@ impl Cipher {\n             \"DeletedDate\": self.deleted_at.map_or(Value::Null, |d| Value::String(format_date(&d))),\n             \"FolderId\": self.get_folder_uuid(&user_uuid, conn),\n             \"Favorite\": self.is_favorite(&user_uuid, conn),\n+            \"Reprompt\": self.reprompt.unwrap_or(RepromptType::None as i32),\n             \"OrganizationId\": self.organization_uuid,\n             \"Attachments\": attachments_json,\n             // We have UseTotp set to true by default within the Organization model.\n",
            "comment_added_diff": [
                [
                    48,
                    "    Password = 1, // not currently used in server"
                ]
            ]
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 15,
            "deletions": 15,
            "change_type": "MODIFY",
            "diff": "@@ -97,7 +97,7 @@ impl Cipher {\n         let password_history_json =\n             self.password_history.as_ref().and_then(|s| serde_json::from_str(s).ok()).unwrap_or(Value::Null);\n \n-        let (read_only, hide_passwords) = match self.get_access_restrictions(&user_uuid, conn) {\n+        let (read_only, hide_passwords) = match self.get_access_restrictions(user_uuid, conn) {\n             Some((ro, hp)) => (ro, hp),\n             None => {\n                 error!(\"Cipher ownership assertion failure\");\n@@ -144,8 +144,8 @@ impl Cipher {\n             \"Type\": self.atype,\n             \"RevisionDate\": format_date(&self.updated_at),\n             \"DeletedDate\": self.deleted_at.map_or(Value::Null, |d| Value::String(format_date(&d))),\n-            \"FolderId\": self.get_folder_uuid(&user_uuid, conn),\n-            \"Favorite\": self.is_favorite(&user_uuid, conn),\n+            \"FolderId\": self.get_folder_uuid(user_uuid, conn),\n+            \"Favorite\": self.is_favorite(user_uuid, conn),\n             \"Reprompt\": self.reprompt.unwrap_or(RepromptType::None as i32),\n             \"OrganizationId\": self.organization_uuid,\n             \"Attachments\": attachments_json,\n@@ -193,13 +193,13 @@ impl Cipher {\n         let mut user_uuids = Vec::new();\n         match self.user_uuid {\n             Some(ref user_uuid) => {\n-                User::update_uuid_revision(&user_uuid, conn);\n+                User::update_uuid_revision(user_uuid, conn);\n                 user_uuids.push(user_uuid.clone())\n             }\n             None => {\n                 // Belongs to Organization, need to update affected users\n                 if let Some(ref org_uuid) = self.organization_uuid {\n-                    UserOrganization::find_by_cipher_and_org(&self.uuid, &org_uuid, conn).iter().for_each(|user_org| {\n+                    UserOrganization::find_by_cipher_and_org(&self.uuid, org_uuid, conn).iter().for_each(|user_org| {\n                         User::update_uuid_revision(&user_org.user_uuid, conn);\n                         user_uuids.push(user_org.user_uuid.clone())\n                     });\n@@ -260,15 +260,15 @@ impl Cipher {\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for cipher in Self::find_by_org(org_uuid, &conn) {\n-            cipher.delete(&conn)?;\n+        for cipher in Self::find_by_org(org_uuid, conn) {\n+            cipher.delete(conn)?;\n         }\n         Ok(())\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for cipher in Self::find_owned_by_user(user_uuid, &conn) {\n-            cipher.delete(&conn)?;\n+        for cipher in Self::find_owned_by_user(user_uuid, conn) {\n+            cipher.delete(conn)?;\n         }\n         Ok(())\n     }\n@@ -279,7 +279,7 @@ impl Cipher {\n             let now = Utc::now().naive_utc();\n             let dt = now - Duration::days(auto_delete_days);\n             for cipher in Self::find_deleted_before(&dt, conn) {\n-                cipher.delete(&conn).ok();\n+                cipher.delete(conn).ok();\n             }\n         }\n     }\n@@ -287,7 +287,7 @@ impl Cipher {\n     pub fn move_to_folder(&self, folder_uuid: Option<String>, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(user_uuid, conn);\n \n-        match (self.get_folder_uuid(&user_uuid, conn), folder_uuid) {\n+        match (self.get_folder_uuid(user_uuid, conn), folder_uuid) {\n             // No changes\n             (None, None) => Ok(()),\n             (Some(ref old), Some(ref new)) if old == new => Ok(()),\n@@ -319,7 +319,7 @@ impl Cipher {\n     /// Returns whether this cipher is owned by an org in which the user has full access.\n     pub fn is_in_full_access_org(&self, user_uuid: &str, conn: &DbConn) -> bool {\n         if let Some(ref org_uuid) = self.organization_uuid {\n-            if let Some(user_org) = UserOrganization::find_by_user_and_org(&user_uuid, &org_uuid, conn) {\n+            if let Some(user_org) = UserOrganization::find_by_user_and_org(user_uuid, org_uuid, conn) {\n                 return user_org.has_full_access();\n             }\n         }\n@@ -336,7 +336,7 @@ impl Cipher {\n         // Check whether this cipher is directly owned by the user, or is in\n         // a collection that the user has full access to. If so, there are no\n         // access restrictions.\n-        if self.is_owned_by_user(&user_uuid) || self.is_in_full_access_org(&user_uuid, &conn) {\n+        if self.is_owned_by_user(user_uuid) || self.is_in_full_access_org(user_uuid, conn) {\n             return Some((false, false));\n         }\n \n@@ -377,14 +377,14 @@ impl Cipher {\n     }\n \n     pub fn is_write_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        match self.get_access_restrictions(&user_uuid, &conn) {\n+        match self.get_access_restrictions(user_uuid, conn) {\n             Some((read_only, _hide_passwords)) => !read_only,\n             None => false,\n         }\n     }\n \n     pub fn is_accessible_to_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        self.get_access_restrictions(&user_uuid, &conn).is_some()\n+        self.get_access_restrictions(user_uuid, conn).is_some()\n     }\n \n     // Returns whether this cipher is a favorite of the specified user.\n",
            "comment_added_diff": []
        }
    ],
    "collection.rs": [
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -35,7 +35,6 @@ impl Collection {\n \n use crate::db::schema::*;\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n",
            "comment_added_diff": []
        },
        {
            "commit": "979d010dc27376904f4435ff9dfd93b3dc52554e",
            "timestamp": "2020-07-02T21:51:20-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding passwords in a collection\n\nRef: https://github.com/bitwarden/server/pull/743",
            "additions": 6,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -199,6 +199,7 @@ pub struct CollectionUser {\n     pub user_uuid: String,\n     pub collection_uuid: String,\n     pub read_only: bool,\n+    pub hide_passwords: bool,\n }\n \n /// Database methods\n@@ -214,7 +215,7 @@ impl CollectionUser {\n     }\n \n     #[cfg(feature = \"postgresql\")]\n-    pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, conn: &DbConn) -> EmptyResult {\n+    pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, hide_passwords: bool, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&user_uuid, conn);\n \n         diesel::insert_into(users_collections::table)\n@@ -222,16 +223,18 @@ impl CollectionUser {\n                 users_collections::user_uuid.eq(user_uuid),\n                 users_collections::collection_uuid.eq(collection_uuid),\n                 users_collections::read_only.eq(read_only),\n+                users_collections::hide_passwords.eq(hide_passwords),\n             ))\n             .on_conflict((users_collections::user_uuid, users_collections::collection_uuid))\n             .do_update()\n             .set(users_collections::read_only.eq(read_only))\n+            .set(users_collections::hide_passwords.eq(hide_passwords))\n             .execute(&**conn)\n             .map_res(\"Error adding user to collection\")\n     }\n \n     #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, conn: &DbConn) -> EmptyResult {\n+    pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, hide_passwords: bool, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&user_uuid, conn);\n \n         diesel::replace_into(users_collections::table)\n@@ -239,6 +242,7 @@ impl CollectionUser {\n                 users_collections::user_uuid.eq(user_uuid),\n                 users_collections::collection_uuid.eq(collection_uuid),\n                 users_collections::read_only.eq(read_only),\n+                users_collections::hide_passwords.eq(hide_passwords),\n             ))\n             .execute(&**conn)\n             .map_res(\"Error adding user to collection\")\n",
            "comment_added_diff": []
        },
        {
            "commit": "790146bfac9b315f11836390250c96339a2d14c2",
            "timestamp": "2020-07-10T17:23:02-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix error in PostgreSQL build",
            "additions": 4,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -227,8 +227,10 @@ impl CollectionUser {\n             ))\n             .on_conflict((users_collections::user_uuid, users_collections::collection_uuid))\n             .do_update()\n-            .set(users_collections::read_only.eq(read_only))\n-            .set(users_collections::hide_passwords.eq(hide_passwords))\n+            .set((\n+                users_collections::read_only.eq(read_only),\n+                users_collections::hide_passwords.eq(hide_passwords),\n+            ))\n             .execute(&**conn)\n             .map_res(\"Error adding user to collection\")\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 252,
            "deletions": 216,
            "change_type": "MODIFY",
            "diff": "@@ -1,15 +1,39 @@\n use serde_json::Value;\n \n-use super::{Organization, UserOrgStatus, UserOrgType, UserOrganization};\n-\n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"collections\"]\n-#[belongs_to(Organization, foreign_key = \"org_uuid\")]\n-#[primary_key(uuid)]\n-pub struct Collection {\n-    pub uuid: String,\n-    pub org_uuid: String,\n-    pub name: String,\n+use super::{Organization, UserOrgStatus, UserOrgType, UserOrganization, User, Cipher};\n+\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"collections\"]\n+    #[belongs_to(Organization, foreign_key = \"org_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct Collection {\n+        pub uuid: String,\n+        pub org_uuid: String,\n+        pub name: String,\n+    }\n+\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[table_name = \"users_collections\"]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[belongs_to(Collection, foreign_key = \"collection_uuid\")]\n+    #[primary_key(user_uuid, collection_uuid)]\n+    pub struct CollectionUser {\n+        pub user_uuid: String,\n+        pub collection_uuid: String,\n+        pub read_only: bool,\n+        pub hide_passwords: bool,\n+    }\n+\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[table_name = \"ciphers_collections\"]\n+    #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n+    #[belongs_to(Collection, foreign_key = \"collection_uuid\")]\n+    #[primary_key(cipher_uuid, collection_uuid)]\n+    pub struct CollectionCipher {\n+        pub cipher_uuid: String,\n+        pub collection_uuid: String,\n+    }\n }\n \n /// Local methods\n@@ -33,36 +57,34 @@ impl Collection {\n     }\n }\n \n-use crate::db::schema::*;\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n \n /// Database methods\n impl Collection {\n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n \n-        diesel::insert_into(collections::table)\n-            .values(self)\n-            .on_conflict(collections::uuid)\n-            .do_update()\n-            .set(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving collection\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        self.update_users_revision(conn);\n-\n-        diesel::replace_into(collections::table)\n-            .values(self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving collection\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(collections::table)\n+                    .values(CollectionDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving collection\")\n+            }\n+            postgresql {\n+                let value = CollectionDb::to_db(self);\n+                diesel::insert_into(collections::table)\n+                    .values(&value)\n+                    .on_conflict(collections::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving collection\")  \n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n@@ -70,9 +92,11 @@ impl Collection {\n         CollectionCipher::delete_all_by_collection(&self.uuid, &conn)?;\n         CollectionUser::delete_all_by_collection(&self.uuid, &conn)?;\n \n-        diesel::delete(collections::table.filter(collections::uuid.eq(self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting collection\")\n+        db_run! { conn: {\n+            diesel::delete(collections::table.filter(collections::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting collection\")\n+        }}\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -91,33 +115,38 @@ impl Collection {\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        collections::table\n-            .filter(collections::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            collections::table\n+                .filter(collections::uuid.eq(uuid))\n+                .first::<CollectionDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_user_uuid(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        collections::table\n-        .left_join(users_collections::table.on(\n-            users_collections::collection_uuid.eq(collections::uuid).and(\n-                users_collections::user_uuid.eq(user_uuid)\n-            )\n-        ))\n-        .left_join(users_organizations::table.on(\n-            collections::org_uuid.eq(users_organizations::org_uuid).and(\n-                users_organizations::user_uuid.eq(user_uuid)\n-            )\n-        ))\n-        .filter(\n-            users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n-        )\n-        .filter(\n-            users_collections::user_uuid.eq(user_uuid).or( // Directly accessed collection\n-                users_organizations::access_all.eq(true) // access_all in Organization\n+        db_run! { conn: {\n+            collections::table\n+            .left_join(users_collections::table.on(\n+                users_collections::collection_uuid.eq(collections::uuid).and(\n+                    users_collections::user_uuid.eq(user_uuid)\n+                )\n+            ))\n+            .left_join(users_organizations::table.on(\n+                collections::org_uuid.eq(users_organizations::org_uuid).and(\n+                    users_organizations::user_uuid.eq(user_uuid)\n+                )\n+            ))\n+            .filter(\n+                users_organizations::status.eq(UserOrgStatus::Confirmed as i32)\n             )\n-        ).select(collections::all_columns)\n-        .load::<Self>(&**conn).expect(\"Error loading collections\")\n+            .filter(\n+                users_collections::user_uuid.eq(user_uuid).or( // Directly accessed collection\n+                    users_organizations::access_all.eq(true) // access_all in Organization\n+                )\n+            ).select(collections::all_columns)\n+            .load::<CollectionDb>(conn).expect(\"Error loading collections\").from_db()\n+        }}\n     }\n \n     pub fn find_by_organization_and_user_uuid(org_uuid: &str, user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n@@ -128,42 +157,51 @@ impl Collection {\n     }\n \n     pub fn find_by_organization(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        collections::table\n-            .filter(collections::org_uuid.eq(org_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading collections\")\n+        db_run! { conn: {\n+            collections::table\n+                .filter(collections::org_uuid.eq(org_uuid))\n+                .load::<CollectionDb>(conn)\n+                .expect(\"Error loading collections\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_uuid_and_org(uuid: &str, org_uuid: &str, conn: &DbConn) -> Option<Self> {\n-        collections::table\n-            .filter(collections::uuid.eq(uuid))\n-            .filter(collections::org_uuid.eq(org_uuid))\n-            .select(collections::all_columns)\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            collections::table\n+                .filter(collections::uuid.eq(uuid))\n+                .filter(collections::org_uuid.eq(org_uuid))\n+                .select(collections::all_columns)\n+                .first::<CollectionDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_uuid_and_user(uuid: &str, user_uuid: &str, conn: &DbConn) -> Option<Self> {\n-        collections::table\n-        .left_join(users_collections::table.on(\n-            users_collections::collection_uuid.eq(collections::uuid).and(\n-                users_collections::user_uuid.eq(user_uuid)\n-            )\n-        ))\n-        .left_join(users_organizations::table.on(\n-            collections::org_uuid.eq(users_organizations::org_uuid).and(\n-                users_organizations::user_uuid.eq(user_uuid)\n-            )\n-        ))\n-        .filter(collections::uuid.eq(uuid))\n-        .filter(\n-            users_collections::collection_uuid.eq(uuid).or( // Directly accessed collection\n-                users_organizations::access_all.eq(true).or( // access_all in Organization\n-                    users_organizations::atype.le(UserOrgType::Admin as i32) // Org admin or owner\n+        db_run! { conn: {\n+            collections::table\n+            .left_join(users_collections::table.on(\n+                users_collections::collection_uuid.eq(collections::uuid).and(\n+                    users_collections::user_uuid.eq(user_uuid)\n                 )\n-            )\n-        ).select(collections::all_columns)\n-        .first::<Self>(&**conn).ok()\n+            ))\n+            .left_join(users_organizations::table.on(\n+                collections::org_uuid.eq(users_organizations::org_uuid).and(\n+                    users_organizations::user_uuid.eq(user_uuid)\n+                )\n+            ))\n+            .filter(collections::uuid.eq(uuid))\n+            .filter(\n+                users_collections::collection_uuid.eq(uuid).or( // Directly accessed collection\n+                    users_organizations::access_all.eq(true).or( // access_all in Organization\n+                        users_organizations::atype.le(UserOrgType::Admin as i32) // Org admin or owner\n+                    )\n+                )\n+            ).select(collections::all_columns)\n+            .first::<CollectionDb>(conn).ok()\n+            .from_db()\n+        }}\n     }\n \n     pub fn is_writable_by_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n@@ -173,110 +211,108 @@ impl Collection {\n                 if user_org.access_all {\n                     true\n                 } else {\n-                    users_collections::table\n-                        .inner_join(collections::table)\n-                        .filter(users_collections::collection_uuid.eq(&self.uuid))\n-                        .filter(users_collections::user_uuid.eq(&user_uuid))\n-                        .filter(users_collections::read_only.eq(false))\n-                        .select(collections::all_columns)\n-                        .first::<Self>(&**conn)\n-                        .ok()\n-                        .is_some() // Read only or no access to collection\n+                    db_run! { conn: {\n+                        users_collections::table\n+                            .inner_join(collections::table)\n+                            .filter(users_collections::collection_uuid.eq(&self.uuid))\n+                            .filter(users_collections::user_uuid.eq(&user_uuid))\n+                            .filter(users_collections::read_only.eq(false))\n+                            .select(collections::all_columns)\n+                            .first::<CollectionDb>(conn)\n+                            .ok()\n+                            .is_some() // Read only or no access to collection\n+                    }}\n                 }\n             }\n         }\n     }\n }\n \n-use super::User;\n-\n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n-#[table_name = \"users_collections\"]\n-#[belongs_to(User, foreign_key = \"user_uuid\")]\n-#[belongs_to(Collection, foreign_key = \"collection_uuid\")]\n-#[primary_key(user_uuid, collection_uuid)]\n-pub struct CollectionUser {\n-    pub user_uuid: String,\n-    pub collection_uuid: String,\n-    pub read_only: bool,\n-    pub hide_passwords: bool,\n-}\n-\n /// Database methods\n impl CollectionUser {\n     pub fn find_by_organization_and_user_uuid(org_uuid: &str, user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_collections::table\n-            .filter(users_collections::user_uuid.eq(user_uuid))\n-            .inner_join(collections::table.on(collections::uuid.eq(users_collections::collection_uuid)))\n-            .filter(collections::org_uuid.eq(org_uuid))\n-            .select(users_collections::all_columns)\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading users_collections\")\n-    }\n-\n-    #[cfg(feature = \"postgresql\")]\n-    pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, hide_passwords: bool, conn: &DbConn) -> EmptyResult {\n-        User::update_uuid_revision(&user_uuid, conn);\n-\n-        diesel::insert_into(users_collections::table)\n-            .values((\n-                users_collections::user_uuid.eq(user_uuid),\n-                users_collections::collection_uuid.eq(collection_uuid),\n-                users_collections::read_only.eq(read_only),\n-                users_collections::hide_passwords.eq(hide_passwords),\n-            ))\n-            .on_conflict((users_collections::user_uuid, users_collections::collection_uuid))\n-            .do_update()\n-            .set((\n-                users_collections::read_only.eq(read_only),\n-                users_collections::hide_passwords.eq(hide_passwords),\n-            ))\n-            .execute(&**conn)\n-            .map_res(\"Error adding user to collection\")\n+        db_run! { conn: {\n+            users_collections::table\n+                .filter(users_collections::user_uuid.eq(user_uuid))\n+                .inner_join(collections::table.on(collections::uuid.eq(users_collections::collection_uuid)))\n+                .filter(collections::org_uuid.eq(org_uuid))\n+                .select(users_collections::all_columns)\n+                .load::<CollectionUserDb>(conn)\n+                .expect(\"Error loading users_collections\")\n+                .from_db()\n+        }}\n     }\n \n-    #[cfg(not(feature = \"postgresql\"))]\n     pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, hide_passwords: bool, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&user_uuid, conn);\n \n-        diesel::replace_into(users_collections::table)\n-            .values((\n-                users_collections::user_uuid.eq(user_uuid),\n-                users_collections::collection_uuid.eq(collection_uuid),\n-                users_collections::read_only.eq(read_only),\n-                users_collections::hide_passwords.eq(hide_passwords),\n-            ))\n-            .execute(&**conn)\n-            .map_res(\"Error adding user to collection\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(users_collections::table)\n+                    .values((\n+                        users_collections::user_uuid.eq(user_uuid),\n+                        users_collections::collection_uuid.eq(collection_uuid),\n+                        users_collections::read_only.eq(read_only),\n+                        users_collections::hide_passwords.eq(hide_passwords),\n+                    ))\n+                    .execute(conn)\n+                    .map_res(\"Error adding user to collection\")\n+            }\n+            postgresql {\n+                diesel::insert_into(users_collections::table)\n+                    .values((\n+                        users_collections::user_uuid.eq(user_uuid),\n+                        users_collections::collection_uuid.eq(collection_uuid),\n+                        users_collections::read_only.eq(read_only),\n+                        users_collections::hide_passwords.eq(hide_passwords),\n+                    ))\n+                    .on_conflict((users_collections::user_uuid, users_collections::collection_uuid))\n+                    .do_update()\n+                    .set((\n+                        users_collections::read_only.eq(read_only),\n+                        users_collections::hide_passwords.eq(hide_passwords),\n+                    ))\n+                    .execute(conn)\n+                    .map_res(\"Error adding user to collection\")\n+            }\n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n \n-        diesel::delete(\n-            users_collections::table\n-                .filter(users_collections::user_uuid.eq(&self.user_uuid))\n-                .filter(users_collections::collection_uuid.eq(&self.collection_uuid)),\n-        )\n-        .execute(&**conn)\n-        .map_res(\"Error removing user from collection\")\n+        db_run! { conn: {\n+            diesel::delete(\n+                users_collections::table\n+                    .filter(users_collections::user_uuid.eq(&self.user_uuid))\n+                    .filter(users_collections::collection_uuid.eq(&self.collection_uuid)),\n+            )\n+            .execute(conn)\n+            .map_res(\"Error removing user from collection\")\n+        }}\n     }\n \n     pub fn find_by_collection(collection_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        users_collections::table\n-            .filter(users_collections::collection_uuid.eq(collection_uuid))\n-            .select(users_collections::all_columns)\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading users_collections\")\n+        db_run! { conn: {\n+            users_collections::table\n+                .filter(users_collections::collection_uuid.eq(collection_uuid))\n+                .select(users_collections::all_columns)\n+                .load::<CollectionUserDb>(conn)\n+                .expect(\"Error loading users_collections\")\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_collection_and_user(collection_uuid: &str, user_uuid: &str, conn: &DbConn) -> Option<Self> {\n-        users_collections::table\n-            .filter(users_collections::collection_uuid.eq(collection_uuid))\n-            .filter(users_collections::user_uuid.eq(user_uuid))\n-            .select(users_collections::all_columns)\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            users_collections::table\n+                .filter(users_collections::collection_uuid.eq(collection_uuid))\n+                .filter(users_collections::user_uuid.eq(user_uuid))\n+                .select(users_collections::all_columns)\n+                .first::<CollectionUserDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn delete_all_by_collection(collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -286,81 +322,81 @@ impl CollectionUser {\n                 User::update_uuid_revision(&collection.user_uuid, conn);\n             });\n \n-        diesel::delete(users_collections::table.filter(users_collections::collection_uuid.eq(collection_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting users from collection\")\n+        db_run! { conn: {\n+            diesel::delete(users_collections::table.filter(users_collections::collection_uuid.eq(collection_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting users from collection\")\n+        }}\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&user_uuid, conn);\n \n-        diesel::delete(users_collections::table.filter(users_collections::user_uuid.eq(user_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing user from collections\")\n+        db_run! { conn: {\n+            diesel::delete(users_collections::table.filter(users_collections::user_uuid.eq(user_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing user from collections\")\n+        }}\n     }\n }\n \n-use super::Cipher;\n-\n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n-#[table_name = \"ciphers_collections\"]\n-#[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n-#[belongs_to(Collection, foreign_key = \"collection_uuid\")]\n-#[primary_key(cipher_uuid, collection_uuid)]\n-pub struct CollectionCipher {\n-    pub cipher_uuid: String,\n-    pub collection_uuid: String,\n-}\n-\n /// Database methods\n impl CollectionCipher {\n-    #[cfg(feature = \"postgresql\")]\n     pub fn save(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n         Self::update_users_revision(&collection_uuid, conn);\n-        diesel::insert_into(ciphers_collections::table)\n-            .values((\n-                ciphers_collections::cipher_uuid.eq(cipher_uuid),\n-                ciphers_collections::collection_uuid.eq(collection_uuid),\n-            ))\n-            .on_conflict((ciphers_collections::cipher_uuid, ciphers_collections::collection_uuid))\n-            .do_nothing()\n-            .execute(&**conn)\n-            .map_res(\"Error adding cipher to collection\")\n-    }\n \n-    #[cfg(not(feature = \"postgresql\"))]\n-    pub fn save(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        Self::update_users_revision(&collection_uuid, conn);\n-        diesel::replace_into(ciphers_collections::table)\n-            .values((\n-                ciphers_collections::cipher_uuid.eq(cipher_uuid),\n-                ciphers_collections::collection_uuid.eq(collection_uuid),\n-            ))\n-            .execute(&**conn)\n-            .map_res(\"Error adding cipher to collection\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(ciphers_collections::table)\n+                    .values((\n+                        ciphers_collections::cipher_uuid.eq(cipher_uuid),\n+                        ciphers_collections::collection_uuid.eq(collection_uuid),\n+                    ))\n+                    .execute(conn)\n+                    .map_res(\"Error adding cipher to collection\")\n+            }\n+            postgresql {\n+                diesel::insert_into(ciphers_collections::table)\n+                    .values((\n+                        ciphers_collections::cipher_uuid.eq(cipher_uuid),\n+                        ciphers_collections::collection_uuid.eq(collection_uuid),\n+                    ))\n+                    .on_conflict((ciphers_collections::cipher_uuid, ciphers_collections::collection_uuid))\n+                    .do_nothing()\n+                    .execute(conn)\n+                    .map_res(\"Error adding cipher to collection\")\n+            }\n+        }\n     }\n \n     pub fn delete(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n         Self::update_users_revision(&collection_uuid, conn);\n-        diesel::delete(\n-            ciphers_collections::table\n-                .filter(ciphers_collections::cipher_uuid.eq(cipher_uuid))\n-                .filter(ciphers_collections::collection_uuid.eq(collection_uuid)),\n-        )\n-        .execute(&**conn)\n-        .map_res(\"Error deleting cipher from collection\")\n+        \n+        db_run! { conn: {\n+            diesel::delete(\n+                ciphers_collections::table\n+                    .filter(ciphers_collections::cipher_uuid.eq(cipher_uuid))\n+                    .filter(ciphers_collections::collection_uuid.eq(collection_uuid)),\n+            )\n+            .execute(conn)\n+            .map_res(\"Error deleting cipher from collection\")\n+        }}\n     }\n \n     pub fn delete_all_by_cipher(cipher_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(ciphers_collections::table.filter(ciphers_collections::cipher_uuid.eq(cipher_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing cipher from collections\")\n+        db_run! { conn: {\n+            diesel::delete(ciphers_collections::table.filter(ciphers_collections::cipher_uuid.eq(cipher_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing cipher from collections\")\n+        }}\n     }\n \n     pub fn delete_all_by_collection(collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(ciphers_collections::table.filter(ciphers_collections::collection_uuid.eq(collection_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing ciphers from collection\")\n+        db_run! { conn: {\n+            diesel::delete(ciphers_collections::table.filter(ciphers_collections::collection_uuid.eq(collection_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing ciphers from collection\")\n+        }}\n     }\n \n     pub fn update_users_revision(collection_uuid: &str, conn: &DbConn) {\n",
            "comment_added_diff": [
                [
                    144,
                    "                users_collections::user_uuid.eq(user_uuid).or( // Directly accessed collection"
                ],
                [
                    145,
                    "                    users_organizations::access_all.eq(true) // access_all in Organization"
                ],
                [
                    196,
                    "                users_collections::collection_uuid.eq(uuid).or( // Directly accessed collection"
                ],
                [
                    197,
                    "                    users_organizations::access_all.eq(true).or( // access_all in Organization"
                ],
                [
                    198,
                    "                        users_organizations::atype.le(UserOrgType::Admin as i32) // Org admin or owner"
                ],
                [
                    223,
                    "                            .is_some() // Read only or no access to collection"
                ]
            ]
        },
        {
            "commit": "4c3b328aca359ebf6211f53509c15b6c94d70e3f",
            "timestamp": "2020-09-01T02:20:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Hide ciphers from non-selected collections for org owners/admins\n\nIf org owners/admins set their org access to only include selected\ncollections, then ciphers from non-selected collections shouldn't\nappear in \"My Vault\". This matches the upstream behavior.",
            "additions": 13,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -208,21 +208,20 @@ impl Collection {\n         match UserOrganization::find_by_user_and_org(&user_uuid, &self.org_uuid, &conn) {\n             None => false, // Not in Org\n             Some(user_org) => {\n-                if user_org.access_all {\n-                    true\n-                } else {\n-                    db_run! { conn: {\n-                        users_collections::table\n-                            .inner_join(collections::table)\n-                            .filter(users_collections::collection_uuid.eq(&self.uuid))\n-                            .filter(users_collections::user_uuid.eq(&user_uuid))\n-                            .filter(users_collections::read_only.eq(false))\n-                            .select(collections::all_columns)\n-                            .first::<CollectionDb>(conn)\n-                            .ok()\n-                            .is_some() // Read only or no access to collection\n-                    }}\n+                if user_org.has_full_access() {\n+                    return true;\n                 }\n+\n+                db_run! { conn: {\n+                    users_collections::table\n+                        .filter(users_collections::collection_uuid.eq(&self.uuid))\n+                        .filter(users_collections::user_uuid.eq(user_uuid))\n+                        .filter(users_collections::read_only.eq(false))\n+                        .count()\n+                        .first::<i64>(conn)\n+                        .ok()\n+                        .unwrap_or(0) != 0\n+                }}\n             }\n         }\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 40,
            "deletions": 9,
            "change_type": "MODIFY",
            "diff": "@@ -67,12 +67,23 @@ impl Collection {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n \n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(collections::table)\n+                match diesel::replace_into(collections::table)\n                     .values(CollectionDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving collection\")\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(collections::table)\n+                            .filter(collections::uuid.eq(&self.uuid))\n+                            .set(CollectionDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving collection\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving collection\")\n             }\n             postgresql {\n                 let value = CollectionDb::to_db(self);\n@@ -82,7 +93,7 @@ impl Collection {\n                     .do_update()\n                     .set(&value)\n                     .execute(conn)\n-                    .map_res(\"Error saving collection\")  \n+                    .map_res(\"Error saving collection\")\n             }\n         }\n     }\n@@ -245,9 +256,9 @@ impl CollectionUser {\n     pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, hide_passwords: bool, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&user_uuid, conn);\n \n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n-                diesel::replace_into(users_collections::table)\n+                match diesel::replace_into(users_collections::table)\n                     .values((\n                         users_collections::user_uuid.eq(user_uuid),\n                         users_collections::collection_uuid.eq(collection_uuid),\n@@ -255,7 +266,24 @@ impl CollectionUser {\n                         users_collections::hide_passwords.eq(hide_passwords),\n                     ))\n                     .execute(conn)\n-                    .map_res(\"Error adding user to collection\")\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(users_collections::table)\n+                            .filter(users_collections::user_uuid.eq(user_uuid))\n+                            .filter(users_collections::collection_uuid.eq(collection_uuid))\n+                            .set((\n+                                users_collections::user_uuid.eq(user_uuid),\n+                                users_collections::collection_uuid.eq(collection_uuid),\n+                                users_collections::read_only.eq(read_only),\n+                                users_collections::hide_passwords.eq(hide_passwords),\n+                            ))\n+                            .execute(conn)\n+                            .map_res(\"Error adding user to collection\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error adding user to collection\")\n             }\n             postgresql {\n                 diesel::insert_into(users_collections::table)\n@@ -344,8 +372,11 @@ impl CollectionCipher {\n     pub fn save(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n         Self::update_users_revision(&collection_uuid, conn);\n \n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n+                // Not checking for ForeignKey Constraints here.\n+                // Table ciphers_collections does not have ForeignKey Constraints which would cause conflicts.\n+                // This table has no constraints pointing to itself, but only to others.\n                 diesel::replace_into(ciphers_collections::table)\n                     .values((\n                         ciphers_collections::cipher_uuid.eq(cipher_uuid),\n@@ -370,7 +401,7 @@ impl CollectionCipher {\n \n     pub fn delete(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n         Self::update_users_revision(&collection_uuid, conn);\n-        \n+\n         db_run! { conn: {\n             diesel::delete(\n                 ciphers_collections::table\n",
            "comment_added_diff": [
                [
                    77,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    271,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    377,
                    "                // Not checking for ForeignKey Constraints here."
                ],
                [
                    378,
                    "                // Table ciphers_collections does not have ForeignKey Constraints which would cause conflicts."
                ],
                [
                    379,
                    "                // This table has no constraints pointing to itself, but only to others."
                ]
            ]
        },
        {
            "commit": "b5f9fe4d3bb57cada7fa01371efc3978a5937173",
            "timestamp": "2020-11-07T23:03:02+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix #1206",
            "additions": 12,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -356,13 +356,20 @@ impl CollectionUser {\n         }}\n     }\n \n-    pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        User::update_uuid_revision(&user_uuid, conn);\n+    pub fn delete_all_by_user_and_org(user_uuid: &str, org_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        let collectionusers = Self::find_by_organization_and_user_uuid(org_uuid, user_uuid, conn);\n \n         db_run! { conn: {\n-            diesel::delete(users_collections::table.filter(users_collections::user_uuid.eq(user_uuid)))\n-                .execute(conn)\n-                .map_res(\"Error removing user from collections\")\n+            for user in collectionusers {\n+                diesel::delete(users_collections::table.filter(\n+                    users_collections::user_uuid.eq(user_uuid)\n+                    .and(users_collections::collection_uuid.eq(user.collection_uuid))\n+                \n+                ))\n+                    .execute(conn)\n+                    .map_res(\"Error removing user from collections\")?;\n+            }\n+            Ok(())\n         }}\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "7dff8c01dd86f69761f4822b8b0c41709f03f271",
            "timestamp": "2021-01-31T21:46:37+01:00",
            "author": "BlackDex",
            "commit_message": "JSON Response updates and small fixes\n\nUpdated several json response models.\nAlso fixed a few small bugs.\n\nciphers.rs:\n  - post_ciphers_create:\n    * Prevent cipher creation to organization without a collection.\n  - update_cipher_from_data:\n    * ~~Fixed removal of user_uuid which prevent user-owned shared-cipher to be not editable anymore when set to read-only.~~\n    * Cleanup the json_data by removing the `Response` key/values from several objects.\n  - delete_all:\n    * Do not delete all Collections during the Purge of an Organization (same as upstream).\n\ncipher.rs:\n  - Cipher::to_json:\n    * Updated json response to match upstream.\n    * Return empty json object if there is no type_data instead of values which should not be set for the type_data.\n\norganizations.rs:\n  * Added two new endpoints to prevent Javascript errors regarding tax\n\norganization.rs:\n  - Organization::to_json:\n    * Updated response model to match upstream\n  - UserOrganization::to_json:\n    * Updated response model to match upstream\n\ncollection.rs:\n  - Collection::{to_json, to_json_details}:\n    * Updated the json response model, and added a detailed version used during the sync\n  - hide_passwords_for_user:\n    * Added this function to return if the passwords should be hidden or not for the user at the specific collection (used by `to_json_details`)\n\nUpdate 1: Some small changes after comments from @jjlin.\nUpdate 2: Fixed vault purge by user to make sure the cipher is not part of an organization.\n\nResolves #971\nCloses #990, Closes #991",
            "additions": 31,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -49,12 +49,21 @@ impl Collection {\n \n     pub fn to_json(&self) -> Value {\n         json!({\n+            \"ExternalId\": null, // Not support by us\n             \"Id\": self.uuid,\n             \"OrganizationId\": self.org_uuid,\n             \"Name\": self.name,\n             \"Object\": \"collection\",\n         })\n     }\n+\n+    pub fn to_json_details(&self, user_uuid: &str, conn: &DbConn) -> Value {\n+        let mut json_object = self.to_json();\n+        json_object[\"Object\"] = json!(\"collectionDetails\");\n+        json_object[\"ReadOnly\"] = json!(!self.is_writable_by_user(user_uuid, conn));\n+        json_object[\"HidePasswords\"] = json!(self.hide_passwords_for_user(user_uuid, conn));\n+        json_object\n+    }\n }\n \n use crate::db::DbConn;\n@@ -236,6 +245,28 @@ impl Collection {\n             }\n         }\n     }\n+\n+    pub fn hide_passwords_for_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n+        match UserOrganization::find_by_user_and_org(&user_uuid, &self.org_uuid, &conn) {\n+            None => true, // Not in Org\n+            Some(user_org) => {\n+                if user_org.has_full_access() {\n+                    return false;\n+                }\n+\n+                db_run! { conn: {\n+                    users_collections::table\n+                        .filter(users_collections::collection_uuid.eq(&self.uuid))\n+                        .filter(users_collections::user_uuid.eq(user_uuid))\n+                        .filter(users_collections::hide_passwords.eq(true))\n+                        .count()\n+                        .first::<i64>(conn)\n+                        .ok()\n+                        .unwrap_or(0) != 0\n+                }}\n+            }\n+        }\n+    }\n }\n \n /// Database methods\n@@ -364,7 +395,6 @@ impl CollectionUser {\n                 diesel::delete(users_collections::table.filter(\n                     users_collections::user_uuid.eq(user_uuid)\n                     .and(users_collections::collection_uuid.eq(user.collection_uuid))\n-                \n                 ))\n                     .execute(conn)\n                     .map_res(\"Error removing user from collections\")?;\n",
            "comment_added_diff": [
                [
                    52,
                    "            \"ExternalId\": null, // Not support by us"
                ],
                [
                    251,
                    "            None => true, // Not in Org"
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -3,7 +3,7 @@ use serde_json::Value;\n use super::{Organization, UserOrgStatus, UserOrgType, UserOrganization, User, Cipher};\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"collections\"]\n     #[belongs_to(Organization, foreign_key = \"org_uuid\")]\n     #[primary_key(uuid)]\n@@ -13,7 +13,7 @@ db_object! {\n         pub name: String,\n     }\n \n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations)]\n     #[table_name = \"users_collections\"]\n     #[belongs_to(User, foreign_key = \"user_uuid\")]\n     #[belongs_to(Collection, foreign_key = \"collection_uuid\")]\n@@ -25,7 +25,7 @@ db_object! {\n         pub hide_passwords: bool,\n     }\n \n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations)]\n     #[table_name = \"ciphers_collections\"]\n     #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n     #[belongs_to(Collection, foreign_key = \"collection_uuid\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 8,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -1,6 +1,6 @@\n use serde_json::Value;\n \n-use super::{Organization, UserOrgStatus, UserOrgType, UserOrganization, User, Cipher};\n+use super::{Cipher, Organization, User, UserOrgStatus, UserOrgType, UserOrganization};\n \n db_object! {\n     #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n@@ -284,7 +284,13 @@ impl CollectionUser {\n         }}\n     }\n \n-    pub fn save(user_uuid: &str, collection_uuid: &str, read_only: bool, hide_passwords: bool, conn: &DbConn) -> EmptyResult {\n+    pub fn save(\n+        user_uuid: &str,\n+        collection_uuid: &str,\n+        read_only: bool,\n+        hide_passwords: bool,\n+        conn: &DbConn,\n+    ) -> EmptyResult {\n         User::update_uuid_revision(&user_uuid, conn);\n \n         db_run! { conn:\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 7,
            "deletions": 14,
            "change_type": "MODIFY",
            "diff": "@@ -127,11 +127,9 @@ impl Collection {\n     }\n \n     pub fn update_users_revision(&self, conn: &DbConn) {\n-        UserOrganization::find_by_collection_and_org(&self.uuid, &self.org_uuid, conn)\n-            .iter()\n-            .for_each(|user_org| {\n-                User::update_uuid_revision(&user_org.user_uuid, conn);\n-            });\n+        UserOrganization::find_by_collection_and_org(&self.uuid, &self.org_uuid, conn).iter().for_each(|user_org| {\n+            User::update_uuid_revision(&user_org.user_uuid, conn);\n+        });\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n@@ -170,10 +168,7 @@ impl Collection {\n     }\n \n     pub fn find_by_organization_and_user_uuid(org_uuid: &str, user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        Self::find_by_user_uuid(user_uuid, conn)\n-            .into_iter()\n-            .filter(|c| c.org_uuid == org_uuid)\n-            .collect()\n+        Self::find_by_user_uuid(user_uuid, conn).into_iter().filter(|c| c.org_uuid == org_uuid).collect()\n     }\n \n     pub fn find_by_organization(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n@@ -380,11 +375,9 @@ impl CollectionUser {\n     }\n \n     pub fn delete_all_by_collection(collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        CollectionUser::find_by_collection(&collection_uuid, conn)\n-            .iter()\n-            .for_each(|collection| {\n-                User::update_uuid_revision(&collection.user_uuid, conn);\n-            });\n+        CollectionUser::find_by_collection(&collection_uuid, conn).iter().for_each(|collection| {\n+            User::update_uuid_revision(&collection.user_uuid, conn);\n+        });\n \n         db_run! { conn: {\n             diesel::delete(users_collections::table.filter(users_collections::collection_uuid.eq(collection_uuid)))\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 10,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -109,8 +109,8 @@ impl Collection {\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n-        CollectionCipher::delete_all_by_collection(&self.uuid, &conn)?;\n-        CollectionUser::delete_all_by_collection(&self.uuid, &conn)?;\n+        CollectionCipher::delete_all_by_collection(&self.uuid, conn)?;\n+        CollectionUser::delete_all_by_collection(&self.uuid, conn)?;\n \n         db_run! { conn: {\n             diesel::delete(collections::table.filter(collections::uuid.eq(self.uuid)))\n@@ -120,8 +120,8 @@ impl Collection {\n     }\n \n     pub fn delete_all_by_organization(org_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for collection in Self::find_by_organization(org_uuid, &conn) {\n-            collection.delete(&conn)?;\n+        for collection in Self::find_by_organization(org_uuid, conn) {\n+            collection.delete(conn)?;\n         }\n         Ok(())\n     }\n@@ -220,7 +220,7 @@ impl Collection {\n     }\n \n     pub fn is_writable_by_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        match UserOrganization::find_by_user_and_org(&user_uuid, &self.org_uuid, &conn) {\n+        match UserOrganization::find_by_user_and_org(user_uuid, &self.org_uuid, conn) {\n             None => false, // Not in Org\n             Some(user_org) => {\n                 if user_org.has_full_access() {\n@@ -242,7 +242,7 @@ impl Collection {\n     }\n \n     pub fn hide_passwords_for_user(&self, user_uuid: &str, conn: &DbConn) -> bool {\n-        match UserOrganization::find_by_user_and_org(&user_uuid, &self.org_uuid, &conn) {\n+        match UserOrganization::find_by_user_and_org(user_uuid, &self.org_uuid, conn) {\n             None => true, // Not in Org\n             Some(user_org) => {\n                 if user_org.has_full_access() {\n@@ -286,7 +286,7 @@ impl CollectionUser {\n         hide_passwords: bool,\n         conn: &DbConn,\n     ) -> EmptyResult {\n-        User::update_uuid_revision(&user_uuid, conn);\n+        User::update_uuid_revision(user_uuid, conn);\n \n         db_run! { conn:\n             sqlite, mysql {\n@@ -375,7 +375,7 @@ impl CollectionUser {\n     }\n \n     pub fn delete_all_by_collection(collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        CollectionUser::find_by_collection(&collection_uuid, conn).iter().for_each(|collection| {\n+        CollectionUser::find_by_collection(collection_uuid, conn).iter().for_each(|collection| {\n             User::update_uuid_revision(&collection.user_uuid, conn);\n         });\n \n@@ -406,7 +406,7 @@ impl CollectionUser {\n /// Database methods\n impl CollectionCipher {\n     pub fn save(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        Self::update_users_revision(&collection_uuid, conn);\n+        Self::update_users_revision(collection_uuid, conn);\n \n         db_run! { conn:\n             sqlite, mysql {\n@@ -436,7 +436,7 @@ impl CollectionCipher {\n     }\n \n     pub fn delete(cipher_uuid: &str, collection_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        Self::update_users_revision(&collection_uuid, conn);\n+        Self::update_users_revision(collection_uuid, conn);\n \n         db_run! { conn: {\n             diesel::delete(\n",
            "comment_added_diff": []
        }
    ],
    "folder.rs": [
        {
            "commit": "9cca64003aa7fd8e3532d20c18bba6fd9de11eb3",
            "timestamp": "2020-05-03T17:24:51+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unused dependency and simple feature, update dependencies and fix some clippy lints",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -63,7 +63,6 @@ impl FolderCipher {\n \n use crate::db::schema::{folders, folders_ciphers};\n use crate::db::DbConn;\n-use diesel;\n use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n",
            "comment_added_diff": []
        },
        {
            "commit": "0365b7c6a4d8aa88fd9328fcc14beef300fe33a2",
            "timestamp": "2020-08-24T20:11:17+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add support for multiple simultaneous database features by using macros.\nDiesel requires the following changes:\n- Separate connection and pool types per connection, the generate_connections! macro generates an enum with a variant per db type\n- Separate migrations and schemas, these were always imported as one type depending on db feature, now they are all imported under different module names\n- Separate model objects per connection, the db_object! macro generates one object for each connection with the diesel macros, a generic object, and methods to convert between the connection-specific and the generic ones\n- Separate connection queries, the db_run! macro allows writing only one that gets compiled for all databases or multiple ones",
            "additions": 110,
            "deletions": 89,
            "change_type": "MODIFY",
            "diff": "@@ -3,26 +3,28 @@ use serde_json::Value;\n \n use super::{Cipher, User};\n \n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n-#[table_name = \"folders\"]\n-#[belongs_to(User, foreign_key = \"user_uuid\")]\n-#[primary_key(uuid)]\n-pub struct Folder {\n-    pub uuid: String,\n-    pub created_at: NaiveDateTime,\n-    pub updated_at: NaiveDateTime,\n-    pub user_uuid: String,\n-    pub name: String,\n-}\n-\n-#[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n-#[table_name = \"folders_ciphers\"]\n-#[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n-#[belongs_to(Folder, foreign_key = \"folder_uuid\")]\n-#[primary_key(cipher_uuid, folder_uuid)]\n-pub struct FolderCipher {\n-    pub cipher_uuid: String,\n-    pub folder_uuid: String,\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"folders\"]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct Folder {\n+        pub uuid: String,\n+        pub created_at: NaiveDateTime,\n+        pub updated_at: NaiveDateTime,\n+        pub user_uuid: String,\n+        pub name: String,\n+    }\n+\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[table_name = \"folders_ciphers\"]\n+    #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n+    #[belongs_to(Folder, foreign_key = \"folder_uuid\")]\n+    #[primary_key(cipher_uuid, folder_uuid)]\n+    pub struct FolderCipher {\n+        pub cipher_uuid: String,\n+        pub folder_uuid: String,\n+    }\n }\n \n /// Local methods\n@@ -61,47 +63,47 @@ impl FolderCipher {\n     }\n }\n \n-use crate::db::schema::{folders, folders_ciphers};\n use crate::db::DbConn;\n-use diesel::prelude::*;\n \n use crate::api::EmptyResult;\n use crate::error::MapResult;\n \n /// Database methods\n impl Folder {\n-    #[cfg(feature = \"postgresql\")]\n-    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n-        User::update_uuid_revision(&self.user_uuid, conn);\n-        self.updated_at = Utc::now().naive_utc();\n-\n-        diesel::insert_into(folders::table)\n-            .values(&*self)\n-            .on_conflict(folders::uuid)\n-            .do_update()\n-            .set(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving folder\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n         self.updated_at = Utc::now().naive_utc();\n \n-        diesel::replace_into(folders::table)\n-            .values(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error saving folder\")\n+        db_run! { conn: \n+            sqlite, mysql {   \n+                diesel::replace_into(folders::table)\n+                    .values(FolderDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error saving folder\")\n+            }\n+            postgresql {\n+                let value = FolderDb::to_db(self);\n+                diesel::insert_into(folders::table)\n+                    .values(&value)\n+                    .on_conflict(folders::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving folder\")\n+            }\n+        }\n     }\n \n     pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n         FolderCipher::delete_all_by_folder(&self.uuid, &conn)?;\n \n-        diesel::delete(folders::table.filter(folders::uuid.eq(&self.uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error deleting folder\")\n+        \n+        db_run! { conn: {\n+            diesel::delete(folders::table.filter(folders::uuid.eq(&self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting folder\")\n+        }}\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n@@ -112,73 +114,92 @@ impl Folder {\n     }\n \n     pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n-        folders::table\n-            .filter(folders::uuid.eq(uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            folders::table\n+                .filter(folders::uuid.eq(uuid))\n+                .first::<FolderDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        folders::table\n-            .filter(folders::user_uuid.eq(user_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading folders\")\n+        db_run! { conn: {\n+            folders::table\n+                .filter(folders::user_uuid.eq(user_uuid))\n+                .load::<FolderDb>(conn)\n+                .expect(\"Error loading folders\")\n+                .from_db()\n+        }}\n     }\n }\n \n impl FolderCipher {\n-    #[cfg(feature = \"postgresql\")]\n-    pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        diesel::insert_into(folders_ciphers::table)\n-            .values(&*self)\n-            .on_conflict((folders_ciphers::cipher_uuid, folders_ciphers::folder_uuid))\n-            .do_nothing()\n-            .execute(&**conn)\n-            .map_res(\"Error adding cipher to folder\")\n-    }\n-\n-    #[cfg(not(feature = \"postgresql\"))]\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        diesel::replace_into(folders_ciphers::table)\n-            .values(&*self)\n-            .execute(&**conn)\n-            .map_res(\"Error adding cipher to folder\")\n+        db_run! { conn: \n+            sqlite, mysql {\n+                diesel::replace_into(folders_ciphers::table)\n+                    .values(FolderCipherDb::to_db(self))\n+                    .execute(conn)\n+                    .map_res(\"Error adding cipher to folder\")\n+            }\n+            postgresql {\n+                diesel::insert_into(folders_ciphers::table)\n+                    .values(FolderCipherDb::to_db(self))\n+                    .on_conflict((folders_ciphers::cipher_uuid, folders_ciphers::folder_uuid))\n+                    .do_nothing()\n+                    .execute(conn)\n+                    .map_res(\"Error adding cipher to folder\") \n+            }\n+        }  \n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(\n-            folders_ciphers::table\n-                .filter(folders_ciphers::cipher_uuid.eq(self.cipher_uuid))\n-                .filter(folders_ciphers::folder_uuid.eq(self.folder_uuid)),\n-        )\n-        .execute(&**conn)\n-        .map_res(\"Error removing cipher from folder\")\n+        db_run! { conn: {\n+            diesel::delete(\n+                folders_ciphers::table\n+                    .filter(folders_ciphers::cipher_uuid.eq(self.cipher_uuid))\n+                    .filter(folders_ciphers::folder_uuid.eq(self.folder_uuid)),\n+            )\n+            .execute(conn)\n+            .map_res(\"Error removing cipher from folder\")\n+        }}\n     }\n \n     pub fn delete_all_by_cipher(cipher_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(folders_ciphers::table.filter(folders_ciphers::cipher_uuid.eq(cipher_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing cipher from folders\")\n+        db_run! { conn: {\n+            diesel::delete(folders_ciphers::table.filter(folders_ciphers::cipher_uuid.eq(cipher_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing cipher from folders\")\n+        }}\n     }\n \n     pub fn delete_all_by_folder(folder_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        diesel::delete(folders_ciphers::table.filter(folders_ciphers::folder_uuid.eq(folder_uuid)))\n-            .execute(&**conn)\n-            .map_res(\"Error removing ciphers from folder\")\n+        db_run! { conn: {\n+            diesel::delete(folders_ciphers::table.filter(folders_ciphers::folder_uuid.eq(folder_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing ciphers from folder\")\n+        }}\n     }\n \n     pub fn find_by_folder_and_cipher(folder_uuid: &str, cipher_uuid: &str, conn: &DbConn) -> Option<Self> {\n-        folders_ciphers::table\n-            .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n-            .filter(folders_ciphers::cipher_uuid.eq(cipher_uuid))\n-            .first::<Self>(&**conn)\n-            .ok()\n+        db_run! { conn: {\n+            folders_ciphers::table\n+                .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n+                .filter(folders_ciphers::cipher_uuid.eq(cipher_uuid))\n+                .first::<FolderCipherDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n     }\n \n     pub fn find_by_folder(folder_uuid: &str, conn: &DbConn) -> Vec<Self> {\n-        folders_ciphers::table\n-            .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n-            .load::<Self>(&**conn)\n-            .expect(\"Error loading folders\")\n+        db_run! { conn: {\n+            folders_ciphers::table\n+                .filter(folders_ciphers::folder_uuid.eq(folder_uuid))\n+                .load::<FolderCipherDb>(conn)\n+                .expect(\"Error loading folders\")\n+                .from_db()\n+        }}\n     }\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "978be0b4a9a904a2ffbd227821cf8f14cf4e4243",
            "timestamp": "2020-09-22T12:13:02+02:00",
            "author": "BlackDex",
            "commit_message": "Fixed foreign-key (mariadb) errors.\n\nWhen using MariaDB v10.5+ Foreign-Key errors were popping up because of\nsome changes in that version. To mitigate this on MariaDB and other\nMySQL forks those errors are now catched, and instead of a replace_into\nan update will happen. I have tested this as thorough as possible with\nMariaDB 10.5, 10.4, 10.3 and the default MySQL on Ubuntu Focal. And\ntested it again using sqlite, all seems to be ok on all tables.\n\nresolves #1081. resolves #1065, resolves #1050",
            "additions": 22,
            "deletions": 8,
            "change_type": "MODIFY",
            "diff": "@@ -74,12 +74,23 @@ impl Folder {\n         User::update_uuid_revision(&self.user_uuid, conn);\n         self.updated_at = Utc::now().naive_utc();\n \n-        db_run! { conn: \n-            sqlite, mysql {   \n-                diesel::replace_into(folders::table)\n+        db_run! { conn:\n+            sqlite, mysql {\n+                match diesel::replace_into(folders::table)\n                     .values(FolderDb::to_db(self))\n                     .execute(conn)\n-                    .map_res(\"Error saving folder\")\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(folders::table)\n+                            .filter(folders::uuid.eq(&self.uuid))\n+                            .set(FolderDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving folder\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving folder\")\n             }\n             postgresql {\n                 let value = FolderDb::to_db(self);\n@@ -98,7 +109,7 @@ impl Folder {\n         User::update_uuid_revision(&self.user_uuid, conn);\n         FolderCipher::delete_all_by_folder(&self.uuid, &conn)?;\n \n-        \n+\n         db_run! { conn: {\n             diesel::delete(folders::table.filter(folders::uuid.eq(&self.uuid)))\n                 .execute(conn)\n@@ -136,8 +147,11 @@ impl Folder {\n \n impl FolderCipher {\n     pub fn save(&self, conn: &DbConn) -> EmptyResult {\n-        db_run! { conn: \n+        db_run! { conn:\n             sqlite, mysql {\n+                // Not checking for ForeignKey Constraints here.\n+                // Table folders_ciphers does not have ForeignKey Constraints which would cause conflicts.\n+                // This table has no constraints pointing to itself, but only to others.\n                 diesel::replace_into(folders_ciphers::table)\n                     .values(FolderCipherDb::to_db(self))\n                     .execute(conn)\n@@ -149,9 +163,9 @@ impl FolderCipher {\n                     .on_conflict((folders_ciphers::cipher_uuid, folders_ciphers::folder_uuid))\n                     .do_nothing()\n                     .execute(conn)\n-                    .map_res(\"Error adding cipher to folder\") \n+                    .map_res(\"Error adding cipher to folder\")\n             }\n-        }  \n+        }\n     }\n \n     pub fn delete(self, conn: &DbConn) -> EmptyResult {\n",
            "comment_added_diff": [
                [
                    84,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    152,
                    "                // Not checking for ForeignKey Constraints here."
                ],
                [
                    153,
                    "                // Table folders_ciphers does not have ForeignKey Constraints which would cause conflicts."
                ],
                [
                    154,
                    "                // This table has no constraints pointing to itself, but only to others."
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -4,7 +4,7 @@ use serde_json::Value;\n use super::{Cipher, User};\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n     #[table_name = \"folders\"]\n     #[belongs_to(User, foreign_key = \"user_uuid\")]\n     #[primary_key(uuid)]\n@@ -16,7 +16,7 @@ db_object! {\n         pub name: String,\n     }\n \n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations)]\n     #[table_name = \"folders_ciphers\"]\n     #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n     #[belongs_to(Folder, foreign_key = \"folder_uuid\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 0,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -109,7 +109,6 @@ impl Folder {\n         User::update_uuid_revision(&self.user_uuid, conn);\n         FolderCipher::delete_all_by_folder(&self.uuid, &conn)?;\n \n-\n         db_run! { conn: {\n             diesel::delete(folders::table.filter(folders::uuid.eq(&self.uuid)))\n                 .execute(conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -107,7 +107,7 @@ impl Folder {\n \n     pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n         User::update_uuid_revision(&self.user_uuid, conn);\n-        FolderCipher::delete_all_by_folder(&self.uuid, &conn)?;\n+        FolderCipher::delete_all_by_folder(&self.uuid, conn)?;\n \n         db_run! { conn: {\n             diesel::delete(folders::table.filter(folders::uuid.eq(&self.uuid)))\n@@ -117,8 +117,8 @@ impl Folder {\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for folder in Self::find_by_user(user_uuid, &conn) {\n-            folder.delete(&conn)?;\n+        for folder in Self::find_by_user(user_uuid, conn) {\n+            folder.delete(conn)?;\n         }\n         Ok(())\n     }\n",
            "comment_added_diff": []
        }
    ],
    "logo-gray.png": [],
    "shield-white.png": [],
    "diagnostics.hbs": [],
    "organizations.hbs": [],
    "settings.hbs": [],
    "users.hbs": [],
    "favorite.rs": [
        {
            "commit": "175d647e47fbd9abec4134c708199ba8aa1ec682",
            "timestamp": "2020-08-26T01:27:38-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Delete associated favorites when deleting a cipher or user\n\nThis prevents foreign key constraint violations.",
            "additions": 83,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,83 @@\n+use super::{Cipher, User};\n+\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[table_name = \"favorites\"]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n+    #[primary_key(user_uuid, cipher_uuid)]\n+    pub struct Favorite {\n+        pub user_uuid: String,\n+        pub cipher_uuid: String,\n+    }\n+}\n+\n+use crate::db::DbConn;\n+\n+use crate::api::EmptyResult;\n+use crate::error::MapResult;\n+\n+impl Favorite {\n+    // Returns whether the specified cipher is a favorite of the specified user.\n+    pub fn is_favorite(cipher_uuid: &str, user_uuid: &str, conn: &DbConn) -> bool {\n+        db_run!{ conn: {\n+            let query = favorites::table\n+                .filter(favorites::cipher_uuid.eq(cipher_uuid))\n+                .filter(favorites::user_uuid.eq(user_uuid))\n+                .count();\n+\n+            query.first::<i64>(conn).ok().unwrap_or(0) != 0\n+        }}\n+    }\n+\n+    // Sets whether the specified cipher is a favorite of the specified user.\n+    pub fn set_favorite(favorite: bool, cipher_uuid: &str, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        let (old, new) = (Self::is_favorite(cipher_uuid, user_uuid, &conn), favorite);\n+        match (old, new) {\n+            (false, true) => {\n+                User::update_uuid_revision(user_uuid, &conn);\n+                db_run!{ conn: {\n+                    diesel::insert_into(favorites::table)\n+                        .values((\n+                            favorites::user_uuid.eq(user_uuid),\n+                            favorites::cipher_uuid.eq(cipher_uuid),\n+                        ))\n+                        .execute(conn)\n+                        .map_res(\"Error adding favorite\")\n+                    }}\n+            }\n+            (true, false) => {\n+                User::update_uuid_revision(user_uuid, &conn);\n+                db_run!{ conn: {\n+                    diesel::delete(\n+                        favorites::table\n+                            .filter(favorites::user_uuid.eq(user_uuid))\n+                            .filter(favorites::cipher_uuid.eq(cipher_uuid))\n+                    )\n+                    .execute(conn)\n+                    .map_res(\"Error removing favorite\")\n+                }}\n+            }\n+            // Otherwise, the favorite status is already what it should be.\n+            _ => Ok(())\n+        }\n+    }\n+\n+    // Delete all favorite entries associated with the specified cipher.\n+    pub fn delete_all_by_cipher(cipher_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        db_run! { conn: {\n+            diesel::delete(favorites::table.filter(favorites::cipher_uuid.eq(cipher_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing favorites by cipher\")\n+        }}\n+    }\n+\n+    // Delete all favorite entries associated with the specified user.\n+    pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        db_run! { conn: {\n+            diesel::delete(favorites::table.filter(favorites::user_uuid.eq(user_uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing favorites by user\")\n+        }}\n+    }\n+}\n",
            "comment_added_diff": [
                [
                    21,
                    "    // Returns whether the specified cipher is a favorite of the specified user."
                ],
                [
                    33,
                    "    // Sets whether the specified cipher is a favorite of the specified user."
                ],
                [
                    61,
                    "            // Otherwise, the favorite status is already what it should be."
                ],
                [
                    66,
                    "    // Delete all favorite entries associated with the specified cipher."
                ],
                [
                    75,
                    "    // Delete all favorite entries associated with the specified user."
                ]
            ]
        },
        {
            "commit": "ce62e898c3de0ec160354d0f7f622b03a1f48c8e",
            "timestamp": "2021-03-13T22:04:04+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove debug impl from database structs\nThis is only implemented for the database specific structs, which is not what we want",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -1,7 +1,7 @@\n use super::{Cipher, User};\n \n db_object! {\n-    #[derive(Debug, Identifiable, Queryable, Insertable, Associations)]\n+    #[derive(Identifiable, Queryable, Insertable, Associations)]\n     #[table_name = \"favorites\"]\n     #[belongs_to(User, foreign_key = \"user_uuid\")]\n     #[belongs_to(Cipher, foreign_key = \"cipher_uuid\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "0af3956abd2ff9b550130716e41fc14088dac84c",
            "timestamp": "2021-03-31T21:18:35+01:00",
            "author": "Jake Howard",
            "commit_message": "Run `cargo fmt` on codebase",
            "additions": 12,
            "deletions": 12,
            "change_type": "MODIFY",
            "diff": "@@ -20,7 +20,7 @@ use crate::error::MapResult;\n impl Favorite {\n     // Returns whether the specified cipher is a favorite of the specified user.\n     pub fn is_favorite(cipher_uuid: &str, user_uuid: &str, conn: &DbConn) -> bool {\n-        db_run!{ conn: {\n+        db_run! { conn: {\n             let query = favorites::table\n                 .filter(favorites::cipher_uuid.eq(cipher_uuid))\n                 .filter(favorites::user_uuid.eq(user_uuid))\n@@ -36,19 +36,19 @@ impl Favorite {\n         match (old, new) {\n             (false, true) => {\n                 User::update_uuid_revision(user_uuid, &conn);\n-                db_run!{ conn: {\n-                    diesel::insert_into(favorites::table)\n-                        .values((\n-                            favorites::user_uuid.eq(user_uuid),\n-                            favorites::cipher_uuid.eq(cipher_uuid),\n-                        ))\n-                        .execute(conn)\n-                        .map_res(\"Error adding favorite\")\n-                    }}\n+                db_run! { conn: {\n+                diesel::insert_into(favorites::table)\n+                    .values((\n+                        favorites::user_uuid.eq(user_uuid),\n+                        favorites::cipher_uuid.eq(cipher_uuid),\n+                    ))\n+                    .execute(conn)\n+                    .map_res(\"Error adding favorite\")\n+                }}\n             }\n             (true, false) => {\n                 User::update_uuid_revision(user_uuid, &conn);\n-                db_run!{ conn: {\n+                db_run! { conn: {\n                     diesel::delete(\n                         favorites::table\n                             .filter(favorites::user_uuid.eq(user_uuid))\n@@ -59,7 +59,7 @@ impl Favorite {\n                 }}\n             }\n             // Otherwise, the favorite status is already what it should be.\n-            _ => Ok(())\n+            _ => Ok(()),\n         }\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 3,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -32,10 +32,10 @@ impl Favorite {\n \n     // Sets whether the specified cipher is a favorite of the specified user.\n     pub fn set_favorite(favorite: bool, cipher_uuid: &str, user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        let (old, new) = (Self::is_favorite(cipher_uuid, user_uuid, &conn), favorite);\n+        let (old, new) = (Self::is_favorite(cipher_uuid, user_uuid, conn), favorite);\n         match (old, new) {\n             (false, true) => {\n-                User::update_uuid_revision(user_uuid, &conn);\n+                User::update_uuid_revision(user_uuid, conn);\n                 db_run! { conn: {\n                 diesel::insert_into(favorites::table)\n                     .values((\n@@ -47,7 +47,7 @@ impl Favorite {\n                 }}\n             }\n             (true, false) => {\n-                User::update_uuid_revision(user_uuid, &conn);\n+                User::update_uuid_revision(user_uuid, conn);\n                 db_run! { conn: {\n                     diesel::delete(\n                         favorites::table\n",
            "comment_added_diff": []
        }
    ],
    "bootstrap-native.js": [],
    "bootstrap.css": [],
    "datatables.css": [],
    "datatables.js": [],
    "jquery-3.5.1.slim.js": [],
    "fallback-icon.png": [],
    "mail-github.png": [],
    "md5.js": [],
    "sends.rs": [
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 383,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,383 @@\n+use std::{io::Read, path::Path};\n+\n+use chrono::{DateTime, Duration, Utc};\n+use multipart::server::{save::SavedData, Multipart, SaveResult};\n+use rocket::{http::ContentType, Data};\n+use rocket_contrib::json::Json;\n+use serde_json::Value;\n+\n+use crate::{\n+    api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, Notify, UpdateType},\n+    auth::{Headers, Host},\n+    db::{models::*, DbConn},\n+    CONFIG,\n+};\n+\n+pub fn routes() -> Vec<rocket::Route> {\n+    routes![\n+        post_send,\n+        post_send_file,\n+        post_access,\n+        post_access_file,\n+        put_send,\n+        delete_send,\n+        put_remove_password\n+    ]\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct SendData {\n+    pub Type: i32,\n+    pub Key: String,\n+    pub Password: Option<String>,\n+    pub MaxAccessCount: Option<i32>,\n+    pub ExpirationDate: Option<DateTime<Utc>>,\n+    pub DeletionDate: DateTime<Utc>,\n+    pub Disabled: bool,\n+\n+    // Data field\n+    pub Name: String,\n+    pub Notes: Option<String>,\n+    pub Text: Option<Value>,\n+    pub File: Option<Value>,\n+}\n+\n+fn create_send(data: SendData, user_uuid: String) -> ApiResult<Send> {\n+    let data_val = if data.Type == SendType::Text as i32 {\n+        data.Text\n+    } else if data.Type == SendType::File as i32 {\n+        data.File\n+    } else {\n+        err!(\"Invalid Send type\")\n+    };\n+\n+    let data_str = if let Some(mut d) = data_val {\n+        d.as_object_mut().and_then(|o| o.remove(\"Response\"));\n+        serde_json::to_string(&d)?\n+    } else {\n+        err!(\"Send data not provided\");\n+    };\n+\n+    if data.DeletionDate > Utc::now() + Duration::days(31) {\n+        err!(\n+            \"You cannot have a Send with a deletion date that far into the future. Adjust the Deletion Date to a value less than 31 days from now and try again.\"\n+        );\n+    }\n+\n+    let mut send = Send::new(data.Type, data.Name, data_str, data.Key, data.DeletionDate.naive_utc());\n+    send.user_uuid = Some(user_uuid);\n+    send.notes = data.Notes;\n+    send.max_access_count = data.MaxAccessCount;\n+    send.expiration_date = data.ExpirationDate.map(|d| d.naive_utc());\n+    send.disabled = data.Disabled;\n+    send.atype = data.Type;\n+\n+    send.set_password(data.Password.as_deref());\n+\n+    Ok(send)\n+}\n+\n+#[post(\"/sends\", data = \"<data>\")]\n+fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    let data: SendData = data.into_inner().data;\n+\n+    if data.Type == SendType::File as i32 {\n+        err!(\"File sends should use /api/sends/file\")\n+    }\n+\n+    let mut send = create_send(data, headers.user.uuid.clone())?;\n+    send.save(&conn)?;\n+    nt.send_user_update(UpdateType::SyncSendCreate, &headers.user);\n+\n+    Ok(Json(send.to_json()))\n+}\n+\n+#[post(\"/sends/file\", format = \"multipart/form-data\", data = \"<data>\")]\n+fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    let boundary = content_type.params().next().expect(\"No boundary provided\").1;\n+\n+    let mut mpart = Multipart::with_body(data.open(), boundary);\n+\n+    // First entry is the SendData JSON\n+    let mut model_entry = match mpart.read_entry()? {\n+        Some(e) if &*e.headers.name == \"model\" => e,\n+        Some(_) => err!(\"Invalid entry name\"),\n+        None => err!(\"No model entry present\"),\n+    };\n+\n+    let mut buf = String::new();\n+    model_entry.data.read_to_string(&mut buf)?;\n+    let data = serde_json::from_str::<crate::util::UpCase<SendData>>(&buf)?;\n+\n+    // Get the file length and add an extra 10% to avoid issues\n+    const SIZE_110_MB: u64 = 115_343_360;\n+\n+    let size_limit = match CONFIG.user_attachment_limit() {\n+        Some(0) => err!(\"File uploads are disabled\"),\n+        Some(limit_kb) => {\n+            let left = (limit_kb * 1024) - Attachment::size_by_user(&headers.user.uuid, &conn);\n+            if left <= 0 {\n+                err!(\"Attachment size limit reached! Delete some files to open space\")\n+            }\n+            std::cmp::Ord::max(left as u64, SIZE_110_MB)\n+        }\n+        None => SIZE_110_MB,\n+    };\n+\n+    // Create the Send\n+    let mut send = create_send(data.data, headers.user.uuid.clone())?;\n+    let file_id: String = data_encoding::HEXLOWER.encode(&crate::crypto::get_random(vec![0; 32]));\n+\n+    if send.atype != SendType::File as i32 {\n+        err!(\"Send content is not a file\");\n+    }\n+\n+    let file_path = Path::new(&CONFIG.sends_folder()).join(&send.uuid).join(&file_id);\n+\n+    // Read the data entry and save the file\n+    let mut data_entry = match mpart.read_entry()? {\n+        Some(e) if &*e.headers.name == \"data\" => e,\n+        Some(_) => err!(\"Invalid entry name\"),\n+        None => err!(\"No model entry present\"),\n+    };\n+\n+    let size = match data_entry\n+        .data\n+        .save()\n+        .memory_threshold(0)\n+        .size_limit(size_limit)\n+        .with_path(&file_path)\n+    {\n+        SaveResult::Full(SavedData::File(_, size)) => size as i32,\n+        SaveResult::Full(other) => {\n+            std::fs::remove_file(&file_path).ok();\n+            err!(format!(\"Attachment is not a file: {:?}\", other));\n+        }\n+        SaveResult::Partial(_, reason) => {\n+            std::fs::remove_file(&file_path).ok();\n+            err!(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n+        }\n+        SaveResult::Error(e) => {\n+            std::fs::remove_file(&file_path).ok();\n+            err!(format!(\"Error: {:?}\", e));\n+        }\n+    };\n+\n+    // Set ID and sizes\n+    let mut data_value: Value = serde_json::from_str(&send.data)?;\n+    if let Some(o) = data_value.as_object_mut() {\n+        o.insert(String::from(\"Id\"), Value::String(file_id));\n+        o.insert(String::from(\"Size\"), Value::Number(size.into()));\n+        o.insert(\n+            String::from(\"SizeName\"),\n+            Value::String(crate::util::get_display_size(size)),\n+        );\n+    }\n+    send.data = serde_json::to_string(&data_value)?;\n+\n+    // Save the changes in the database\n+    send.save(&conn)?;\n+    nt.send_user_update(UpdateType::SyncSendCreate, &headers.user);\n+\n+    Ok(Json(send.to_json()))\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct SendAccessData {\n+    pub Password: Option<String>,\n+}\n+\n+#[post(\"/sends/access/<access_id>\", data = \"<data>\")]\n+fn post_access(access_id: String, data: JsonUpcase<SendAccessData>, conn: DbConn) -> JsonResult {\n+    let mut send = match Send::find_by_access_id(&access_id, &conn) {\n+        Some(s) => s,\n+        None => err_code!(\"Send not found\", 404),\n+    };\n+\n+    if let Some(max_access_count) = send.max_access_count {\n+        if send.access_count > max_access_count {\n+            err_code!(\"Max access count reached\", 404);\n+        }\n+    }\n+\n+    if let Some(expiration) = send.expiration_date {\n+        if Utc::now().naive_utc() > expiration {\n+            err_code!(\"Send has expired\", 404)\n+        }\n+    }\n+\n+    if Utc::now().naive_utc() > send.deletion_date {\n+        err_code!(\"Send has been deleted\", 404)\n+    }\n+\n+    if send.disabled {\n+        err_code!(\"Send has been disabled\", 404)\n+    }\n+\n+    if send.password_hash.is_some() {\n+        match data.into_inner().data.Password {\n+            Some(ref p) if send.check_password(p) => { /* Nothing to do here */ }\n+            Some(_) => err!(\"Invalid password.\"),\n+            None => err_code!(\"Password not provided\", 401),\n+        }\n+    }\n+\n+    // Files are incremented during the download\n+    if send.atype == SendType::Text as i32 {\n+        send.access_count += 1;\n+    }\n+\n+    send.save(&conn)?;\n+\n+    Ok(Json(send.to_json()))\n+}\n+\n+#[post(\"/sends/<send_id>/access/file/<file_id>\", data = \"<data>\")]\n+fn post_access_file(\n+    send_id: String,\n+    file_id: String,\n+    data: JsonUpcase<SendAccessData>,\n+    host: Host,\n+    conn: DbConn,\n+) -> JsonResult {\n+    let mut send = match Send::find_by_uuid(&send_id, &conn) {\n+        Some(s) => s,\n+        None => err_code!(\"Send not found\", 404),\n+    };\n+\n+    if let Some(max_access_count) = send.max_access_count {\n+        if send.access_count > max_access_count {\n+            err_code!(\"Max access count reached\", 404);\n+        }\n+    }\n+\n+    if let Some(expiration) = send.expiration_date {\n+        if Utc::now().naive_utc() > expiration {\n+            err_code!(\"Send has expired\", 404)\n+        }\n+    }\n+\n+    if Utc::now().naive_utc() > send.deletion_date {\n+        err_code!(\"Send has been deleted\", 404)\n+    }\n+\n+    if send.disabled {\n+        err_code!(\"Send has been disabled\", 404)\n+    }\n+\n+    if send.password_hash.is_some() {\n+        match data.into_inner().data.Password {\n+            Some(ref p) if send.check_password(p) => { /* Nothing to do here */ }\n+            Some(_) => err!(\"Invalid password.\"),\n+            None => err_code!(\"Password not provided\", 401),\n+        }\n+    }\n+\n+    send.access_count += 1;\n+\n+    send.save(&conn)?;\n+\n+    Ok(Json(json!({\n+        \"Object\": \"send-fileDownload\",\n+        \"Id\": file_id,\n+        \"Url\": format!(\"{}/sends/{}/{}\", &host.host, send_id, file_id)\n+    })))\n+}\n+\n+#[put(\"/sends/<id>\", data = \"<data>\")]\n+fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    let data: SendData = data.into_inner().data;\n+\n+    let mut send = match Send::find_by_uuid(&id, &conn) {\n+        Some(s) => s,\n+        None => err!(\"Send not found\"),\n+    };\n+\n+    if send.user_uuid.as_ref() != Some(&headers.user.uuid) {\n+        err!(\"Send is not owned by user\")\n+    }\n+\n+    if send.atype != data.Type {\n+        err!(\"Sends can't change type\")\n+    }\n+\n+    let data_val = if data.Type == SendType::Text as i32 {\n+        data.Text\n+    } else if data.Type == SendType::File as i32 {\n+        data.File\n+    } else {\n+        err!(\"Invalid Send type\")\n+    };\n+\n+    let data_str = if let Some(mut d) = data_val {\n+        d.as_object_mut().and_then(|d| d.remove(\"Response\"));\n+        serde_json::to_string(&d)?\n+    } else {\n+        err!(\"Send data not provided\");\n+    };\n+\n+    if data.DeletionDate > Utc::now() + Duration::days(31) {\n+        err!(\n+            \"You cannot have a Send with a deletion date that far into the future. Adjust the Deletion Date to a value less than 31 days from now and try again.\"\n+        );\n+    }\n+    send.data = data_str;\n+    send.name = data.Name;\n+    send.key = data.Key;\n+    send.deletion_date = data.DeletionDate.naive_utc();\n+    send.notes = data.Notes;\n+    send.max_access_count = data.MaxAccessCount;\n+    send.expiration_date = data.ExpirationDate.map(|d| d.naive_utc());\n+    send.disabled = data.Disabled;\n+\n+    // Only change the value if it's present\n+    if let Some(password) = data.Password {\n+        send.set_password(Some(&password));\n+    }\n+\n+    send.save(&conn)?;\n+    nt.send_user_update(UpdateType::SyncSendUpdate, &headers.user);\n+\n+    Ok(Json(send.to_json()))\n+}\n+\n+#[delete(\"/sends/<id>\")]\n+fn delete_send(id: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyResult {\n+    let send = match Send::find_by_uuid(&id, &conn) {\n+        Some(s) => s,\n+        None => err!(\"Send not found\"),\n+    };\n+\n+    if send.user_uuid.as_ref() != Some(&headers.user.uuid) {\n+        err!(\"Send is not owned by user\")\n+    }\n+\n+    if send.atype == SendType::File as i32 {\n+        std::fs::remove_dir_all(Path::new(&CONFIG.sends_folder()).join(&send.uuid)).ok();\n+    }\n+\n+    send.delete(&conn)?;\n+    nt.send_user_update(UpdateType::SyncSendDelete, &headers.user);\n+\n+    Ok(())\n+}\n+\n+#[put(\"/sends/<id>/remove-password\")]\n+fn put_remove_password(id: String, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    let mut send = match Send::find_by_uuid(&id, &conn) {\n+        Some(s) => s,\n+        None => err!(\"Send not found\"),\n+    };\n+\n+    if send.user_uuid.as_ref() != Some(&headers.user.uuid) {\n+        err!(\"Send is not owned by user\")\n+    }\n+\n+    send.set_password(None);\n+    send.save(&conn)?;\n+    nt.send_user_update(UpdateType::SyncSendUpdate, &headers.user);\n+\n+    Ok(Json(send.to_json()))\n+}\n",
            "comment_added_diff": [
                [
                    39,
                    "    // Data field"
                ],
                [
                    102,
                    "    // First entry is the SendData JSON"
                ],
                [
                    113,
                    "    // Get the file length and add an extra 10% to avoid issues"
                ],
                [
                    128,
                    "    // Create the Send"
                ],
                [
                    138,
                    "    // Read the data entry and save the file"
                ],
                [
                    167,
                    "    // Set ID and sizes"
                ],
                [
                    179,
                    "    // Save the changes in the database"
                ],
                [
                    227,
                    "    // Files are incremented during the download"
                ],
                [
                    335,
                    "    // Only change the value if it's present"
                ]
            ]
        },
        {
            "commit": "00d56d7295fc60c3f4d2cc43d2431dce7ed3edd5",
            "timestamp": "2021-03-14T23:20:49-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Send access check fixes\n\nAdjust checks for max access count, expiration date, and deletion date.\nThe date checks aren't that important, but the access count check\ncurrently allows one more access than it should.",
            "additions": 6,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -197,18 +197,18 @@ fn post_access(access_id: String, data: JsonUpcase<SendAccessData>, conn: DbConn\n     };\n \n     if let Some(max_access_count) = send.max_access_count {\n-        if send.access_count > max_access_count {\n+        if send.access_count >= max_access_count {\n             err_code!(\"Max access count reached\", 404);\n         }\n     }\n \n     if let Some(expiration) = send.expiration_date {\n-        if Utc::now().naive_utc() > expiration {\n+        if Utc::now().naive_utc() >= expiration {\n             err_code!(\"Send has expired\", 404)\n         }\n     }\n \n-    if Utc::now().naive_utc() > send.deletion_date {\n+    if Utc::now().naive_utc() >= send.deletion_date {\n         err_code!(\"Send has been deleted\", 404)\n     }\n \n@@ -248,18 +248,18 @@ fn post_access_file(\n     };\n \n     if let Some(max_access_count) = send.max_access_count {\n-        if send.access_count > max_access_count {\n+        if send.access_count >= max_access_count {\n             err_code!(\"Max access count reached\", 404);\n         }\n     }\n \n     if let Some(expiration) = send.expiration_date {\n-        if Utc::now().naive_utc() > expiration {\n+        if Utc::now().naive_utc() >= expiration {\n             err_code!(\"Send has expired\", 404)\n         }\n     }\n \n-    if Utc::now().naive_utc() > send.deletion_date {\n+    if Utc::now().naive_utc() >= send.deletion_date {\n         err_code!(\"Send has been deleted\", 404)\n     }\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "95e24ffc51db2f6834142ec86568c2d244562006",
            "timestamp": "2021-03-15T16:42:20+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "rename send key -> akey",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -325,7 +325,7 @@ fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbCo\n     }\n     send.data = data_str;\n     send.name = data.Name;\n-    send.key = data.Key;\n+    send.akey = data.Key;\n     send.deletion_date = data.DeletionDate.naive_utc();\n     send.notes = data.Notes;\n     send.max_access_count = data.MaxAccessCount;\n",
            "comment_added_diff": []
        },
        {
            "commit": "424d666a505c3e41bc1e77937a682e120e130423",
            "timestamp": "2021-03-16T02:07:45-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the Disable Send policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1130\n* https://bitwarden.com/help/article/policies/#disable-send",
            "additions": 22,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -43,6 +43,20 @@ pub struct SendData {\n     pub File: Option<Value>,\n }\n \n+/// Enforces the `Disable Send` policy. A non-owner/admin user belonging to\n+/// an org with this policy enabled isn't allowed to create new Sends or\n+/// modify existing ones, but is allowed to delete them.\n+///\n+/// Ref: https://bitwarden.com/help/article/policies/#disable-send\n+fn enforce_disable_send_policy(headers: &Headers,conn: &DbConn) -> EmptyResult {\n+    let user_uuid = &headers.user.uuid;\n+    let policy_type = OrgPolicyType::DisableSend;\n+    if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n+        err!(\"Due to an Enterprise Policy, you are only able to delete an existing Send.\")\n+    }\n+    Ok(())\n+}\n+\n fn create_send(data: SendData, user_uuid: String) -> ApiResult<Send> {\n     let data_val = if data.Type == SendType::Text as i32 {\n         data.Text\n@@ -80,6 +94,8 @@ fn create_send(data: SendData, user_uuid: String) -> ApiResult<Send> {\n \n #[post(\"/sends\", data = \"<data>\")]\n fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    enforce_disable_send_policy(&headers, &conn)?;\n+\n     let data: SendData = data.into_inner().data;\n \n     if data.Type == SendType::File as i32 {\n@@ -95,6 +111,8 @@ fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Not\n \n #[post(\"/sends/file\", format = \"multipart/form-data\", data = \"<data>\")]\n fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    enforce_disable_send_policy(&headers, &conn)?;\n+\n     let boundary = content_type.params().next().expect(\"No boundary provided\").1;\n \n     let mut mpart = Multipart::with_body(data.open(), boundary);\n@@ -288,6 +306,8 @@ fn post_access_file(\n \n #[put(\"/sends/<id>\", data = \"<data>\")]\n fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    enforce_disable_send_policy(&headers, &conn)?;\n+\n     let data: SendData = data.into_inner().data;\n \n     let mut send = match Send::find_by_uuid(&id, &conn) {\n@@ -366,6 +386,8 @@ fn delete_send(id: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyR\n \n #[put(\"/sends/<id>/remove-password\")]\n fn put_remove_password(id: String, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n+    enforce_disable_send_policy(&headers, &conn)?;\n+\n     let mut send = match Send::find_by_uuid(&id, &conn) {\n         Some(s) => s,\n         None => err!(\"Send not found\"),\n",
            "comment_added_diff": [
                [
                    46,
                    "/// Enforces the `Disable Send` policy. A non-owner/admin user belonging to"
                ],
                [
                    47,
                    "/// an org with this policy enabled isn't allowed to create new Sends or"
                ],
                [
                    48,
                    "/// modify existing ones, but is allowed to delete them."
                ],
                [
                    49,
                    "///"
                ],
                [
                    50,
                    "/// Ref: https://bitwarden.com/help/article/policies/#disable-send"
                ]
            ]
        },
        {
            "commit": "84810f2bb22a161b7ef5b6e081acde5cadcfd155",
            "timestamp": "2021-03-16T18:11:25+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary fields from send access",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -231,7 +231,7 @@ fn post_access(access_id: String, data: JsonUpcase<SendAccessData>, conn: DbConn\n \n     send.save(&conn)?;\n \n-    Ok(Json(send.to_json()))\n+    Ok(Json(send.to_json_access()))\n }\n \n #[post(\"/sends/<send_id>/access/file/<file_id>\", data = \"<data>\")]\n",
            "comment_added_diff": []
        },
        {
            "commit": "551810c4862506ed39780850a35ac12df1aca1a9",
            "timestamp": "2021-03-17T19:39:48+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix updating file send",
            "additions": 12,
            "deletions": 16,
            "change_type": "MODIFY",
            "diff": "@@ -48,7 +48,7 @@ pub struct SendData {\n /// modify existing ones, but is allowed to delete them.\n ///\n /// Ref: https://bitwarden.com/help/article/policies/#disable-send\n-fn enforce_disable_send_policy(headers: &Headers,conn: &DbConn) -> EmptyResult {\n+fn enforce_disable_send_policy(headers: &Headers, conn: &DbConn) -> EmptyResult {\n     let user_uuid = &headers.user.uuid;\n     let policy_type = OrgPolicyType::DisableSend;\n     if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n@@ -323,27 +323,23 @@ fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbCo\n         err!(\"Sends can't change type\")\n     }\n \n-    let data_val = if data.Type == SendType::Text as i32 {\n-        data.Text\n-    } else if data.Type == SendType::File as i32 {\n-        data.File\n-    } else {\n-        err!(\"Invalid Send type\")\n-    };\n-\n-    let data_str = if let Some(mut d) = data_val {\n-        d.as_object_mut().and_then(|d| d.remove(\"Response\"));\n-        serde_json::to_string(&d)?\n-    } else {\n-        err!(\"Send data not provided\");\n-    };\n+    // When updating a file Send, we receive nulls in the File field, as it's immutable,\n+    // so we only need to update the data field in the Text case\n+    if data.Type == SendType::Text as i32 {\n+        let data_str = if let Some(mut d) = data.Text {\n+            d.as_object_mut().and_then(|d| d.remove(\"Response\"));\n+            serde_json::to_string(&d)?\n+        } else {\n+            err!(\"Send data not provided\");\n+        };\n+        send.data = data_str;\n+    }\n \n     if data.DeletionDate > Utc::now() + Duration::days(31) {\n         err!(\n             \"You cannot have a Send with a deletion date that far into the future. Adjust the Deletion Date to a value less than 31 days from now and try again.\"\n         );\n     }\n-    send.data = data_str;\n     send.name = data.Name;\n     send.akey = data.Key;\n     send.deletion_date = data.DeletionDate.naive_utc();\n",
            "comment_added_diff": [
                [
                    326,
                    "    // When updating a file Send, we receive nulls in the File field, as it's immutable,"
                ],
                [
                    327,
                    "    // so we only need to update the data field in the Text case"
                ]
            ]
        },
        {
            "commit": "1fc6c30652b59a9dd7495393075df2a22246fa02",
            "timestamp": "2021-03-22T19:57:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send deletion thread and updated users revision",
            "additions": 17,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -25,6 +25,23 @@ pub fn routes() -> Vec<rocket::Route> {\n     ]\n }\n \n+pub fn start_send_deletion_scheduler(pool: crate::db::DbPool) {\n+    std::thread::spawn(move || {\n+        loop {\n+            if let Ok(conn) = pool.get() {\n+                info!(\"Initiating send deletion\");\n+                for send in Send::find_all(&conn) {\n+                    if chrono::Utc::now().naive_utc() >= send.deletion_date {\n+                        send.delete(&conn).ok();\n+                    }\n+                }\n+            }\n+\n+            std::thread::sleep(std::time::Duration::from_secs(3600));\n+        }\n+    });\n+}\n+\n #[derive(Deserialize)]\n #[allow(non_snake_case)]\n pub struct SendData {\n@@ -370,10 +387,6 @@ fn delete_send(id: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyR\n         err!(\"Send is not owned by user\")\n     }\n \n-    if send.atype == SendType::File as i32 {\n-        std::fs::remove_dir_all(Path::new(&CONFIG.sends_folder()).join(&send.uuid)).ok();\n-    }\n-\n     send.delete(&conn)?;\n     nt.send_user_update(UpdateType::SyncSendDelete, &headers.user);\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "4b6a574ee0e7ab4362c188be646369f2c440eb6c",
            "timestamp": "2021-03-23T13:39:09+00:00",
            "author": "Miro Prasil",
            "commit_message": "Return generic message when Send not available\n\nThis should help avoid leaking information about (non)existence of Send\nand be more in line with what official server returns.",
            "additions": 10,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -228,27 +228,27 @@ pub struct SendAccessData {\n fn post_access(access_id: String, data: JsonUpcase<SendAccessData>, conn: DbConn) -> JsonResult {\n     let mut send = match Send::find_by_access_id(&access_id, &conn) {\n         Some(s) => s,\n-        None => err_code!(\"Send not found\", 404),\n+        None => err_code!(\"Send does not exist or is no longer available\", 404),\n     };\n \n     if let Some(max_access_count) = send.max_access_count {\n         if send.access_count >= max_access_count {\n-            err_code!(\"Max access count reached\", 404);\n+            err_code!(\"Send does not exist or is no longer available\", 404);\n         }\n     }\n \n     if let Some(expiration) = send.expiration_date {\n         if Utc::now().naive_utc() >= expiration {\n-            err_code!(\"Send has expired\", 404)\n+            err_code!(\"Send does not exist or is no longer available\", 404)\n         }\n     }\n \n     if Utc::now().naive_utc() >= send.deletion_date {\n-        err_code!(\"Send has been deleted\", 404)\n+        err_code!(\"Send does not exist or is no longer available\", 404)\n     }\n \n     if send.disabled {\n-        err_code!(\"Send has been disabled\", 404)\n+        err_code!(\"Send does not exist or is no longer available\", 404)\n     }\n \n     if send.password_hash.is_some() {\n@@ -279,27 +279,27 @@ fn post_access_file(\n ) -> JsonResult {\n     let mut send = match Send::find_by_uuid(&send_id, &conn) {\n         Some(s) => s,\n-        None => err_code!(\"Send not found\", 404),\n+        None => err_code!(\"Send does not exist or is no longer available\", 404),\n     };\n \n     if let Some(max_access_count) = send.max_access_count {\n         if send.access_count >= max_access_count {\n-            err_code!(\"Max access count reached\", 404);\n+            err_code!(\"Send does not exist or is no longer available\", 404)\n         }\n     }\n \n     if let Some(expiration) = send.expiration_date {\n         if Utc::now().naive_utc() >= expiration {\n-            err_code!(\"Send has expired\", 404)\n+            err_code!(\"Send does not exist or is no longer available\", 404)\n         }\n     }\n \n     if Utc::now().naive_utc() >= send.deletion_date {\n-        err_code!(\"Send has been deleted\", 404)\n+        err_code!(\"Send does not exist or is no longer available\", 404)\n     }\n \n     if send.disabled {\n-        err_code!(\"Send has been disabled\", 404)\n+        err_code!(\"Send does not exist or is no longer available\", 404)\n     }\n \n     if send.password_hash.is_some() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "aa5cc642e1189196e46d98da7d424bae7d89f4b0",
            "timestamp": "2021-03-25T11:40:32+00:00",
            "author": "Miro Prasil",
            "commit_message": "Use constant for the \"inaccessible\" error message",
            "additions": 12,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -13,6 +13,8 @@ use crate::{\n     CONFIG,\n };\n \n+const SEND_INACCESSIBLE_MSG: &str = \"Send does not exist or is no longer available\";\n+\n pub fn routes() -> Vec<rocket::Route> {\n     routes![\n         post_send,\n@@ -228,27 +230,27 @@ pub struct SendAccessData {\n fn post_access(access_id: String, data: JsonUpcase<SendAccessData>, conn: DbConn) -> JsonResult {\n     let mut send = match Send::find_by_access_id(&access_id, &conn) {\n         Some(s) => s,\n-        None => err_code!(\"Send does not exist or is no longer available\", 404),\n+        None => err_code!(SEND_INACCESSIBLE_MSG, 404),\n     };\n \n     if let Some(max_access_count) = send.max_access_count {\n         if send.access_count >= max_access_count {\n-            err_code!(\"Send does not exist or is no longer available\", 404);\n+            err_code!(SEND_INACCESSIBLE_MSG, 404);\n         }\n     }\n \n     if let Some(expiration) = send.expiration_date {\n         if Utc::now().naive_utc() >= expiration {\n-            err_code!(\"Send does not exist or is no longer available\", 404)\n+            err_code!(SEND_INACCESSIBLE_MSG, 404)\n         }\n     }\n \n     if Utc::now().naive_utc() >= send.deletion_date {\n-        err_code!(\"Send does not exist or is no longer available\", 404)\n+        err_code!(SEND_INACCESSIBLE_MSG, 404)\n     }\n \n     if send.disabled {\n-        err_code!(\"Send does not exist or is no longer available\", 404)\n+        err_code!(SEND_INACCESSIBLE_MSG, 404)\n     }\n \n     if send.password_hash.is_some() {\n@@ -279,27 +281,27 @@ fn post_access_file(\n ) -> JsonResult {\n     let mut send = match Send::find_by_uuid(&send_id, &conn) {\n         Some(s) => s,\n-        None => err_code!(\"Send does not exist or is no longer available\", 404),\n+        None => err_code!(SEND_INACCESSIBLE_MSG, 404),\n     };\n \n     if let Some(max_access_count) = send.max_access_count {\n         if send.access_count >= max_access_count {\n-            err_code!(\"Send does not exist or is no longer available\", 404)\n+            err_code!(SEND_INACCESSIBLE_MSG, 404)\n         }\n     }\n \n     if let Some(expiration) = send.expiration_date {\n         if Utc::now().naive_utc() >= expiration {\n-            err_code!(\"Send does not exist or is no longer available\", 404)\n+            err_code!(SEND_INACCESSIBLE_MSG, 404)\n         }\n     }\n \n     if Utc::now().naive_utc() >= send.deletion_date {\n-        err_code!(\"Send does not exist or is no longer available\", 404)\n+        err_code!(SEND_INACCESSIBLE_MSG, 404)\n     }\n \n     if send.disabled {\n-        err_code!(\"Send does not exist or is no longer available\", 404)\n+        err_code!(SEND_INACCESSIBLE_MSG, 404)\n     }\n \n     if send.password_hash.is_some() {\n",
            "comment_added_diff": []
        },
        {
            "commit": "73ff8d79f70b36483d1d33587cdc9549c8e472bd",
            "timestamp": "2021-04-05T23:07:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add a generic job scheduler\n\nAlso rewrite deletion of old sends using the job scheduler.",
            "additions": 8,
            "deletions": 16,
            "change_type": "MODIFY",
            "diff": "@@ -9,7 +9,7 @@ use serde_json::Value;\n use crate::{\n     api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, Notify, UpdateType},\n     auth::{Headers, Host},\n-    db::{models::*, DbConn},\n+    db::{models::*, DbConn, DbPool},\n     CONFIG,\n };\n \n@@ -27,21 +27,13 @@ pub fn routes() -> Vec<rocket::Route> {\n     ]\n }\n \n-pub fn start_send_deletion_scheduler(pool: crate::db::DbPool) {\n-    std::thread::spawn(move || {\n-        loop {\n-            if let Ok(conn) = pool.get() {\n-                info!(\"Initiating send deletion\");\n-                for send in Send::find_all(&conn) {\n-                    if chrono::Utc::now().naive_utc() >= send.deletion_date {\n-                        send.delete(&conn).ok();\n-                    }\n-                }\n-            }\n-\n-            std::thread::sleep(std::time::Duration::from_secs(3600));\n-        }\n-    });\n+pub fn purge_sends(pool: DbPool) {\n+    debug!(\"Purging sends\");\n+    if let Ok(conn) = pool.get() {\n+        Send::purge(&conn);\n+    } else {\n+        error!(\"Failed to get DB connection while purging sends\")\n+    }\n }\n \n #[derive(Deserialize)]\n",
            "comment_added_diff": []
        },
        {
            "commit": "3ab90259f20063b72c5560da3346840da7223acc",
            "timestamp": "2021-04-06T21:54:42+01:00",
            "author": "Jake Howard",
            "commit_message": "Modify rustfmt file",
            "additions": 3,
            "deletions": 20,
            "change_type": "MODIFY",
            "diff": "@@ -16,15 +16,7 @@ use crate::{\n const SEND_INACCESSIBLE_MSG: &str = \"Send does not exist or is no longer available\";\n \n pub fn routes() -> Vec<rocket::Route> {\n-    routes![\n-        post_send,\n-        post_send_file,\n-        post_access,\n-        post_access_file,\n-        put_send,\n-        delete_send,\n-        put_remove_password\n-    ]\n+    routes![post_send, post_send_file, post_access, post_access_file, put_send, delete_send, put_remove_password]\n }\n \n pub fn start_send_deletion_scheduler(pool: crate::db::DbPool) {\n@@ -179,13 +171,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n         None => err!(\"No model entry present\"),\n     };\n \n-    let size = match data_entry\n-        .data\n-        .save()\n-        .memory_threshold(0)\n-        .size_limit(size_limit)\n-        .with_path(&file_path)\n-    {\n+    let size = match data_entry.data.save().memory_threshold(0).size_limit(size_limit).with_path(&file_path) {\n         SaveResult::Full(SavedData::File(_, size)) => size as i32,\n         SaveResult::Full(other) => {\n             std::fs::remove_file(&file_path).ok();\n@@ -206,10 +192,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n     if let Some(o) = data_value.as_object_mut() {\n         o.insert(String::from(\"Id\"), Value::String(file_id));\n         o.insert(String::from(\"Size\"), Value::Number(size.into()));\n-        o.insert(\n-            String::from(\"SizeName\"),\n-            Value::String(crate::util::get_display_size(size)),\n-        );\n+        o.insert(String::from(\"SizeName\"), Value::String(crate::util::get_display_size(size)));\n     }\n     send.data = serde_json::to_string(&data_value)?;\n \n",
            "comment_added_diff": []
        },
        {
            "commit": "3ff8014adda15c8d37c30556044b0e96f067da47",
            "timestamp": "2021-05-11T20:07:32-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add `sends_allowed` config setting\n\nThis provides global control over whether users can create Bitwarden Sends.",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -51,10 +51,13 @@ pub struct SendData {\n /// modify existing ones, but is allowed to delete them.\n ///\n /// Ref: https://bitwarden.com/help/article/policies/#disable-send\n+///\n+/// There is also a Vaultwarden-specific `sends_allowed` config setting that\n+/// controls this policy globally.\n fn enforce_disable_send_policy(headers: &Headers, conn: &DbConn) -> EmptyResult {\n     let user_uuid = &headers.user.uuid;\n     let policy_type = OrgPolicyType::DisableSend;\n-    if OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n+    if !CONFIG.sends_allowed() || OrgPolicy::is_applicable_to_user(user_uuid, policy_type, conn) {\n         err!(\"Due to an Enterprise Policy, you are only able to delete an existing Send.\")\n     }\n     Ok(())\n",
            "comment_added_diff": [
                [
                    54,
                    "///"
                ],
                [
                    55,
                    "/// There is also a Vaultwarden-specific `sends_allowed` config setting that"
                ],
                [
                    56,
                    "/// controls this policy globally."
                ]
            ]
        },
        {
            "commit": "d3449bfa00cff40dc1f9ef349c9c6524e78f64e1",
            "timestamp": "2021-05-11T22:51:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding the sender's email address in Bitwarden Sends\n\nNote: The original Vaultwarden implementation of Bitwarden Send would always\nhide the email address, while the upstream implementation would always show it.\n\nUpstream PR: https://github.com/bitwarden/server/pull/1234",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -38,6 +38,7 @@ pub struct SendData {\n     pub ExpirationDate: Option<DateTime<Utc>>,\n     pub DeletionDate: DateTime<Utc>,\n     pub Disabled: bool,\n+    pub HideEmail: Option<bool>,\n \n     // Data field\n     pub Name: String,\n@@ -88,6 +89,7 @@ fn create_send(data: SendData, user_uuid: String) -> ApiResult<Send> {\n     send.max_access_count = data.MaxAccessCount;\n     send.expiration_date = data.ExpirationDate.map(|d| d.naive_utc());\n     send.disabled = data.Disabled;\n+    send.hide_email = data.HideEmail;\n     send.atype = data.Type;\n \n     send.set_password(data.Password.as_deref());\n@@ -243,7 +245,7 @@ fn post_access(access_id: String, data: JsonUpcase<SendAccessData>, conn: DbConn\n \n     send.save(&conn)?;\n \n-    Ok(Json(send.to_json_access()))\n+    Ok(Json(send.to_json_access(&conn)))\n }\n \n #[post(\"/sends/<send_id>/access/file/<file_id>\", data = \"<data>\")]\n@@ -340,6 +342,7 @@ fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbCo\n     send.notes = data.Notes;\n     send.max_access_count = data.MaxAccessCount;\n     send.expiration_date = data.ExpirationDate.map(|d| d.naive_utc());\n+    send.hide_email = data.HideEmail;\n     send.disabled = data.Disabled;\n \n     // Only change the value if it's present\n",
            "comment_added_diff": []
        },
        {
            "commit": "029008bad519186d1528526f523c0220aa58ac2a",
            "timestamp": "2021-05-12T01:22:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for the `Send Options` policy\n\nUpstream refs:\n\n* https://github.com/bitwarden/server/pull/1234\n* https://bitwarden.com/help/article/policies/#send-options",
            "additions": 21,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -61,6 +61,24 @@ fn enforce_disable_send_policy(headers: &Headers, conn: &DbConn) -> EmptyResult\n     Ok(())\n }\n \n+/// Enforces the `DisableHideEmail` option of the `Send Options` policy.\n+/// A non-owner/admin user belonging to an org with this option enabled isn't\n+/// allowed to hide their email address from the recipient of a Bitwarden Send,\n+/// but is allowed to remove this option from an existing Send.\n+///\n+/// Ref: https://bitwarden.com/help/article/policies/#send-options\n+fn enforce_disable_hide_email_policy(data: &SendData, headers: &Headers, conn: &DbConn) -> EmptyResult {\n+    let user_uuid = &headers.user.uuid;\n+    let hide_email = data.HideEmail.unwrap_or(false);\n+    if hide_email && OrgPolicy::is_hide_email_disabled(user_uuid, conn) {\n+        err!(\n+            \"Due to an Enterprise Policy, you are not allowed to hide your email address \\\n+              from recipients when creating or editing a Send.\"\n+        )\n+    }\n+    Ok(())\n+}\n+\n fn create_send(data: SendData, user_uuid: String) -> ApiResult<Send> {\n     let data_val = if data.Type == SendType::Text as i32 {\n         data.Text\n@@ -102,6 +120,7 @@ fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Not\n     enforce_disable_send_policy(&headers, &conn)?;\n \n     let data: SendData = data.into_inner().data;\n+    enforce_disable_hide_email_policy(&data, &headers, &conn)?;\n \n     if data.Type == SendType::File as i32 {\n         err!(\"File sends should use /api/sends/file\")\n@@ -132,6 +151,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n     let mut buf = String::new();\n     model_entry.data.read_to_string(&mut buf)?;\n     let data = serde_json::from_str::<crate::util::UpCase<SendData>>(&buf)?;\n+    enforce_disable_hide_email_policy(&data.data, &headers, &conn)?;\n \n     // Get the file length and add an extra 10% to avoid issues\n     const SIZE_110_MB: u64 = 115_343_360;\n@@ -305,6 +325,7 @@ fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbCo\n     enforce_disable_send_policy(&headers, &conn)?;\n \n     let data: SendData = data.into_inner().data;\n+    enforce_disable_hide_email_policy(&data, &headers, &conn)?;\n \n     let mut send = match Send::find_by_uuid(&id, &conn) {\n         Some(s) => s,\n",
            "comment_added_diff": [
                [
                    64,
                    "/// Enforces the `DisableHideEmail` option of the `Send Options` policy."
                ],
                [
                    65,
                    "/// A non-owner/admin user belonging to an org with this option enabled isn't"
                ],
                [
                    66,
                    "/// allowed to hide their email address from the recipient of a Bitwarden Send,"
                ],
                [
                    67,
                    "/// but is allowed to remove this option from an existing Send."
                ],
                [
                    68,
                    "///"
                ],
                [
                    69,
                    "/// Ref: https://bitwarden.com/help/article/policies/#send-options"
                ]
            ]
        },
        {
            "commit": "29ed82a3595e0cdd39deb914dc38002478f89f97",
            "timestamp": "2021-05-25T04:14:51-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for v2 attachment upload APIs\n\nUpstream PR: https://github.com/bitwarden/server/pull/1229",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -173,7 +173,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n \n     // Create the Send\n     let mut send = create_send(data.data, headers.user.uuid.clone())?;\n-    let file_id: String = data_encoding::HEXLOWER.encode(&crate::crypto::get_random(vec![0; 32]));\n+    let file_id = crate::crypto::generate_file_id();\n \n     if send.atype != SendType::File as i32 {\n         err!(\"Send content is not a file\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "c2ef331df9d2a1a3e50ed8129b07cca0a52e6f41",
            "timestamp": "2021-05-25T23:15:24-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Rework file ID generation",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -173,7 +173,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n \n     // Create the Send\n     let mut send = create_send(data.data, headers.user.uuid.clone())?;\n-    let file_id = crate::crypto::generate_file_id();\n+    let file_id = crate::crypto::generate_send_id();\n \n     if send.atype != SendType::File as i32 {\n         err!(\"Send content is not a file\");\n",
            "comment_added_diff": []
        },
        {
            "commit": "2cd17fe7afeaef2a29787999b1cb48a512811571",
            "timestamp": "2021-06-25T20:53:26+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Add token with short expiration time to send url",
            "additions": 24,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -2,7 +2,7 @@ use std::{io::Read, path::Path};\n \n use chrono::{DateTime, Duration, Utc};\n use multipart::server::{save::SavedData, Multipart, SaveResult};\n-use rocket::{http::ContentType, Data};\n+use rocket::{http::ContentType, response::NamedFile, Data};\n use rocket_contrib::json::Json;\n use serde_json::Value;\n \n@@ -16,7 +16,16 @@ use crate::{\n const SEND_INACCESSIBLE_MSG: &str = \"Send does not exist or is no longer available\";\n \n pub fn routes() -> Vec<rocket::Route> {\n-    routes![post_send, post_send_file, post_access, post_access_file, put_send, delete_send, put_remove_password]\n+    routes![\n+        post_send,\n+        post_send_file,\n+        post_access,\n+        post_access_file,\n+        put_send,\n+        delete_send,\n+        put_remove_password,\n+        download_send\n+    ]\n }\n \n pub fn purge_sends(pool: DbPool) {\n@@ -316,13 +325,25 @@ fn post_access_file(\n \n     send.save(&conn)?;\n \n+    let token_claims = crate::auth::generate_send_claims(&send_id, &file_id);\n+    let token = crate::auth::encode_jwt(&token_claims);\n     Ok(Json(json!({\n         \"Object\": \"send-fileDownload\",\n         \"Id\": file_id,\n-        \"Url\": format!(\"{}/sends/{}/{}\", &host.host, send_id, file_id)\n+        \"Url\": format!(\"{}/api/sends/{}/{}?t={}\", &host.host, send_id, file_id, token)\n     })))\n }\n \n+#[get(\"/sends/<send_id>/<file_id>?<t>\")]\n+fn download_send(send_id: String, file_id: String, t: String) -> Option<NamedFile> {\n+    if let Ok(claims) = crate::auth::decode_send(&t) {\n+        if claims.sub == format!(\"{}/{}\", send_id, file_id) {\n+            return NamedFile::open(Path::new(&CONFIG.sends_folder()).join(send_id).join(file_id)).ok();\n+        }\n+    }\n+    None\n+}\n+\n #[put(\"/sends/<id>\", data = \"<data>\")]\n fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     enforce_disable_send_policy(&headers, &conn)?;\n",
            "comment_added_diff": []
        },
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -165,8 +165,8 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n     let data = serde_json::from_str::<crate::util::UpCase<SendData>>(&buf)?;\n     enforce_disable_hide_email_policy(&data.data, &headers, &conn)?;\n \n-    // Get the file length and add an extra 10% to avoid issues\n-    const SIZE_110_MB: u64 = 115_343_360;\n+    // Get the file length and add an extra 5% to avoid issues\n+    const SIZE_525_MB: u64 = 550_502_400;\n \n     let size_limit = match CONFIG.user_attachment_limit() {\n         Some(0) => err!(\"File uploads are disabled\"),\n@@ -175,9 +175,9 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n             if left <= 0 {\n                 err!(\"Attachment size limit reached! Delete some files to open space\")\n             }\n-            std::cmp::Ord::max(left as u64, SIZE_110_MB)\n+            std::cmp::Ord::max(left as u64, SIZE_525_MB)\n         }\n-        None => SIZE_110_MB,\n+        None => SIZE_525_MB,\n     };\n \n     // Create the Send\n",
            "comment_added_diff": [
                [
                    168,
                    "    // Get the file length and add an extra 5% to avoid issues"
                ]
            ]
        },
        {
            "commit": "6ea95d1ede727942e4677cae8c80545123b98e81",
            "timestamp": "2021-07-13T15:17:03+02:00",
            "author": "BlackDex",
            "commit_message": "Updated attachment limit descriptions\n\nThe user and org attachment limit use `size` as wording while it should\nhave been `storage` since it isn't per attachment, but the sum of all attachments.\n\n- Changed the wording in the config/env\n- Changed the wording of the error messages.\n\nResolves #1818",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -173,7 +173,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n         Some(limit_kb) => {\n             let left = (limit_kb * 1024) - Attachment::size_by_user(&headers.user.uuid, &conn);\n             if left <= 0 {\n-                err!(\"Attachment size limit reached! Delete some files to open space\")\n+                err!(\"Attachment storage limit reached! Delete some attachments to free up space\")\n             }\n             std::cmp::Ord::max(left as u64, SIZE_110_MB)\n         }\n@@ -205,7 +205,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n         }\n         SaveResult::Partial(_, reason) => {\n             std::fs::remove_file(&file_path).ok();\n-            err!(format!(\"Attachment size limit exceeded with this file: {:?}\", reason));\n+            err!(format!(\"Attachment storage limit exceeded with this file: {:?}\", reason));\n         }\n         SaveResult::Error(e) => {\n             std::fs::remove_file(&file_path).ok();\n",
            "comment_added_diff": []
        },
        {
            "commit": "e5ec245626e4a4d232b6a709338fe1e9811845e7",
            "timestamp": "2021-07-15T19:15:55+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Protect namedfile against path traversal, rocket only does it for pathbuf",
            "additions": 2,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -10,6 +10,7 @@ use crate::{\n     api::{ApiResult, EmptyResult, JsonResult, JsonUpcase, Notify, UpdateType},\n     auth::{Headers, Host},\n     db::{models::*, DbConn, DbPool},\n+    util::SafeString,\n     CONFIG,\n };\n \n@@ -335,7 +336,7 @@ fn post_access_file(\n }\n \n #[get(\"/sends/<send_id>/<file_id>?<t>\")]\n-fn download_send(send_id: String, file_id: String, t: String) -> Option<NamedFile> {\n+fn download_send(send_id: SafeString, file_id: SafeString, t: String) -> Option<NamedFile> {\n     if let Ok(claims) = crate::auth::decode_send(&t) {\n         if claims.sub == format!(\"{}/{}\", send_id, file_id) {\n             return NamedFile::open(Path::new(&CONFIG.sends_folder()).join(send_id).join(file_id)).ok();\n",
            "comment_added_diff": []
        },
        {
            "commit": "dd98fe860b33f8e34c161f49e3f6b07908d1dc3e",
            "timestamp": "2021-08-03T17:39:38+02:00",
            "author": "Fabian Thies",
            "commit_message": "Send create, update and delete notifications for `Send`s in the correct format.\nAdd endpoints to get all sends or a specific send by its uuid.",
            "additions": 33,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -18,6 +18,8 @@ const SEND_INACCESSIBLE_MSG: &str = \"Send does not exist or is no longer availab\n \n pub fn routes() -> Vec<rocket::Route> {\n     routes![\n+        get_sends,\n+        get_send,\n         post_send,\n         post_send_file,\n         post_access,\n@@ -128,6 +130,32 @@ fn create_send(data: SendData, user_uuid: String) -> ApiResult<Send> {\n     Ok(send)\n }\n \n+#[get(\"/sends\")]\n+fn get_sends(headers: Headers, conn: DbConn) -> Json<Value> {\n+    let sends = Send::find_by_user(&headers.user.uuid, &conn);\n+    let sends_json: Vec<Value> = sends.iter().map(|s| s.to_json()).collect();\n+\n+    Json(json!({\n+      \"Data\": sends_json,\n+      \"Object\": \"list\",\n+      \"ContinuationToken\": null\n+    }))\n+}\n+\n+#[get(\"/sends/<uuid>\")]\n+fn get_send(uuid: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    let send = match Send::find_by_uuid(&uuid, &conn) {\n+        Some(send) => send,\n+        None => err!(\"Send not found\"),\n+    };\n+\n+    if send.user_uuid.as_ref() != Some(&headers.user.uuid) {\n+        err!(\"Send is not owned by user\")\n+    }\n+\n+    Ok(Json(send.to_json()))\n+}\n+\n #[post(\"/sends\", data = \"<data>\")]\n fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Notify) -> JsonResult {\n     enforce_disable_send_policy(&headers, &conn)?;\n@@ -141,7 +169,7 @@ fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Not\n \n     let mut send = create_send(data, headers.user.uuid.clone())?;\n     send.save(&conn)?;\n-    nt.send_user_update(UpdateType::SyncSendCreate, &headers.user);\n+    nt.send_send_update(UpdateType::SyncSendCreate, &send, &send.update_users_revision(&conn));\n \n     Ok(Json(send.to_json()))\n }\n@@ -225,7 +253,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n \n     // Save the changes in the database\n     send.save(&conn)?;\n-    nt.send_user_update(UpdateType::SyncSendCreate, &headers.user);\n+    nt.send_send_update(UpdateType::SyncSendUpdate, &send, &send.update_users_revision(&conn));\n \n     Ok(Json(send.to_json()))\n }\n@@ -397,7 +425,7 @@ fn put_send(id: String, data: JsonUpcase<SendData>, headers: Headers, conn: DbCo\n     }\n \n     send.save(&conn)?;\n-    nt.send_user_update(UpdateType::SyncSendUpdate, &headers.user);\n+    nt.send_send_update(UpdateType::SyncSendUpdate, &send, &send.update_users_revision(&conn));\n \n     Ok(Json(send.to_json()))\n }\n@@ -414,7 +442,7 @@ fn delete_send(id: String, headers: Headers, conn: DbConn, nt: Notify) -> EmptyR\n     }\n \n     send.delete(&conn)?;\n-    nt.send_user_update(UpdateType::SyncSendDelete, &headers.user);\n+    nt.send_send_update(UpdateType::SyncSendDelete, &send, &send.update_users_revision(&conn));\n \n     Ok(())\n }\n@@ -434,7 +462,7 @@ fn put_remove_password(id: String, headers: Headers, conn: DbConn, nt: Notify) -\n \n     send.set_password(None);\n     send.save(&conn)?;\n-    nt.send_user_update(UpdateType::SyncSendUpdate, &headers.user);\n+    nt.send_send_update(UpdateType::SyncSendUpdate, &send, &send.update_users_revision(&conn));\n \n     Ok(Json(send.to_json()))\n }\n",
            "comment_added_diff": []
        },
        {
            "commit": "42ba817a4c423457a014f13cec3faba994770b21",
            "timestamp": "2021-08-04T13:25:41+02:00",
            "author": "Fabian Thies",
            "commit_message": "Fix errors that occurred in the nightly build",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -167,7 +167,7 @@ fn post_send(data: JsonUpcase<SendData>, headers: Headers, conn: DbConn, nt: Not\n         err!(\"File sends should use /api/sends/file\")\n     }\n \n-    let mut send = create_send(data, headers.user.uuid.clone())?;\n+    let mut send = create_send(data, headers.user.uuid)?;\n     send.save(&conn)?;\n     nt.send_send_update(UpdateType::SyncSendCreate, &send, &send.update_users_revision(&conn));\n \n@@ -210,7 +210,7 @@ fn post_send_file(data: Data, content_type: &ContentType, headers: Headers, conn\n     };\n \n     // Create the Send\n-    let mut send = create_send(data.data, headers.user.uuid.clone())?;\n+    let mut send = create_send(data.data, headers.user.uuid)?;\n     let file_id = crate::crypto::generate_send_id();\n \n     if send.atype != SendType::File as i32 {\n",
            "comment_added_diff": []
        }
    ],
    "send.rs": [
        {
            "commit": "8da5b994828cedad67c2d32df8d89fa79749b04f",
            "timestamp": "2021-03-14T23:35:55+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send API",
            "additions": 235,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,235 @@\n+use chrono::{NaiveDateTime, Utc};\n+use serde_json::Value;\n+\n+use super::{Organization, User};\n+\n+db_object! {\n+    #[derive(Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"sends\"]\n+    #[changeset_options(treat_none_as_null=\"true\")]\n+    #[belongs_to(User, foreign_key = \"user_uuid\")]\n+    #[belongs_to(Organization, foreign_key = \"organization_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct Send {\n+        pub uuid: String,\n+\n+        pub user_uuid: Option<String>,\n+        pub organization_uuid: Option<String>,\n+\n+\n+        pub name: String,\n+        pub notes: Option<String>,\n+\n+        pub atype: i32,\n+        pub data: String,\n+        pub key: String,\n+        pub password_hash: Option<Vec<u8>>,\n+        password_salt: Option<Vec<u8>>,\n+        password_iter: Option<i32>,\n+\n+        pub max_access_count: Option<i32>,\n+        pub access_count: i32,\n+\n+        pub creation_date: NaiveDateTime,\n+        pub revision_date: NaiveDateTime,\n+        pub expiration_date: Option<NaiveDateTime>,\n+        pub deletion_date: NaiveDateTime,\n+\n+        pub disabled: bool,\n+    }\n+}\n+\n+#[derive(Copy, Clone, PartialEq, Eq, num_derive::FromPrimitive)]\n+pub enum SendType {\n+    Text = 0,\n+    File = 1,\n+}\n+\n+impl Send {\n+    pub fn new(atype: i32, name: String, data: String, key: String, deletion_date: NaiveDateTime) -> Self {\n+        let now = Utc::now().naive_utc();\n+\n+        Self {\n+            uuid: crate::util::get_uuid(),\n+            user_uuid: None,\n+            organization_uuid: None,\n+\n+            name,\n+            notes: None,\n+\n+            atype,\n+            data,\n+            key,\n+            password_hash: None,\n+            password_salt: None,\n+            password_iter: None,\n+\n+            max_access_count: None,\n+            access_count: 0,\n+\n+            creation_date: now,\n+            revision_date: now,\n+            expiration_date: None,\n+            deletion_date,\n+\n+            disabled: false,\n+        }\n+    }\n+    \n+    pub fn set_password(&mut self, password: Option<&str>) {\n+        const PASSWORD_ITER: i32 = 100_000;\n+\n+        if let Some(password) = password {\n+            self.password_iter = Some(PASSWORD_ITER);\n+            let salt = crate::crypto::get_random_64();\n+            let hash = crate::crypto::hash_password(password.as_bytes(), &salt, PASSWORD_ITER as u32);\n+            self.password_salt = Some(salt);\n+            self.password_hash = Some(hash);\n+        } else {\n+            self.password_iter = None;\n+            self.password_salt = None;\n+            self.password_hash = None;\n+        }\n+    }\n+\n+    pub fn check_password(&self, password: &str) -> bool {\n+        match (&self.password_hash, &self.password_salt, self.password_iter) {\n+            (Some(hash), Some(salt), Some(iter)) => {\n+                crate::crypto::verify_password_hash(password.as_bytes(), salt, hash, iter as u32)\n+            }\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn to_json(&self) -> Value {\n+        use crate::util::format_date;\n+        use data_encoding::BASE64URL_NOPAD;\n+        use uuid::Uuid;\n+\n+        let data: Value = serde_json::from_str(&self.data).unwrap_or_default();\n+\n+        json!({\n+            \"Id\": self.uuid,\n+            \"AccessId\": BASE64URL_NOPAD.encode(Uuid::parse_str(&self.uuid).unwrap_or_default().as_bytes()),\n+            \"Type\": self.atype,\n+\n+            \"Name\": self.name,\n+            \"Notes\": self.notes,\n+            \"Text\": if self.atype == SendType::Text as i32 { Some(&data) } else { None },\n+            \"File\": if self.atype == SendType::File as i32 { Some(&data) } else { None },\n+\n+            \"Key\": self.key,\n+            \"MaxAccessCount\": self.max_access_count,\n+            \"AccessCount\": self.access_count,\n+            \"Password\": self.password_hash.as_deref().map(|h| BASE64URL_NOPAD.encode(h)),\n+            \"Disabled\": self.disabled,\n+\n+            \"RevisionDate\": format_date(&self.revision_date),\n+            \"ExpirationDate\": self.expiration_date.as_ref().map(format_date),\n+            \"DeletionDate\": format_date(&self.deletion_date),\n+            \"Object\": \"send\",\n+        })\n+    }\n+}\n+\n+use crate::db::DbConn;\n+\n+use crate::api::EmptyResult;\n+use crate::error::MapResult;\n+\n+impl Send {\n+    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n+        // self.update_users_revision(conn);\n+        self.revision_date = Utc::now().naive_utc();\n+\n+        db_run! { conn:\n+            sqlite, mysql {\n+                match diesel::replace_into(sends::table)\n+                    .values(SendDb::to_db(self))\n+                    .execute(conn)\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(sends::table)\n+                            .filter(sends::uuid.eq(&self.uuid))\n+                            .set(SendDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error saving send\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving send\")\n+            }\n+            postgresql {\n+                let value = SendDb::to_db(self);\n+                diesel::insert_into(sends::table)\n+                    .values(&value)\n+                    .on_conflict(sends::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving send\")\n+            }\n+        }\n+    }\n+\n+    pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n+        // self.update_users_revision(conn);\n+\n+        db_run! { conn: {\n+            diesel::delete(sends::table.filter(sends::uuid.eq(&self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error deleting send\")\n+        }}\n+    }\n+\n+    pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        for send in Self::find_by_user(user_uuid, &conn) {\n+            send.delete(&conn)?;\n+        }\n+        Ok(())\n+    }\n+\n+    pub fn find_by_access_id(access_id: &str, conn: &DbConn) -> Option<Self> {\n+        use data_encoding::BASE64URL_NOPAD;\n+        use uuid::Uuid;\n+\n+        let uuid_vec = match BASE64URL_NOPAD.decode(access_id.as_bytes()) {\n+            Ok(v) => v,\n+            Err(_) => return None,\n+        };\n+\n+        let uuid = match Uuid::from_slice(&uuid_vec) {\n+            Ok(u) => u.to_string(),\n+            Err(_) => return None,\n+        };\n+\n+        Self::find_by_uuid(&uuid, conn)\n+    }\n+\n+    pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n+        db_run! {conn: {\n+            sends::table\n+                .filter(sends::uuid.eq(uuid))\n+                .first::<SendDb>(conn)\n+                .ok()\n+                .from_db()\n+        }}\n+    }\n+\n+    pub fn find_by_user(user_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        db_run! {conn: {\n+            sends::table\n+                .filter(sends::user_uuid.eq(user_uuid))\n+                .load::<SendDb>(conn).expect(\"Error loading sends\").from_db()\n+        }}\n+    }\n+\n+    pub fn find_by_org(org_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        db_run! {conn: {\n+            sends::table\n+                .filter(sends::organization_uuid.eq(org_uuid))\n+                .load::<SendDb>(conn).expect(\"Error loading sends\").from_db()\n+        }}\n+    }\n+}\n",
            "comment_added_diff": [
                [
                    142,
                    "        // self.update_users_revision(conn);"
                ],
                [
                    152,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    177,
                    "        // self.update_users_revision(conn);"
                ]
            ]
        },
        {
            "commit": "95e24ffc51db2f6834142ec86568c2d244562006",
            "timestamp": "2021-03-15T16:42:20+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "rename send key -> akey",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -22,7 +22,7 @@ db_object! {\n \n         pub atype: i32,\n         pub data: String,\n-        pub key: String,\n+        pub akey: String,\n         pub password_hash: Option<Vec<u8>>,\n         password_salt: Option<Vec<u8>>,\n         password_iter: Option<i32>,\n@@ -46,7 +46,7 @@ pub enum SendType {\n }\n \n impl Send {\n-    pub fn new(atype: i32, name: String, data: String, key: String, deletion_date: NaiveDateTime) -> Self {\n+    pub fn new(atype: i32, name: String, data: String, akey: String, deletion_date: NaiveDateTime) -> Self {\n         let now = Utc::now().naive_utc();\n \n         Self {\n@@ -59,7 +59,7 @@ impl Send {\n \n             atype,\n             data,\n-            key,\n+            akey,\n             password_hash: None,\n             password_salt: None,\n             password_iter: None,\n@@ -118,7 +118,7 @@ impl Send {\n             \"Text\": if self.atype == SendType::Text as i32 { Some(&data) } else { None },\n             \"File\": if self.atype == SendType::File as i32 { Some(&data) } else { None },\n \n-            \"Key\": self.key,\n+            \"Key\": self.akey,\n             \"MaxAccessCount\": self.max_access_count,\n             \"AccessCount\": self.access_count,\n             \"Password\": self.password_hash.as_deref().map(|h| BASE64URL_NOPAD.encode(h)),\n",
            "comment_added_diff": []
        },
        {
            "commit": "84810f2bb22a161b7ef5b6e081acde5cadcfd155",
            "timestamp": "2021-03-16T18:11:25+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Remove unnecessary fields from send access",
            "additions": 18,
            "deletions": 0,
            "change_type": "MODIFY",
            "diff": "@@ -130,6 +130,24 @@ impl Send {\n             \"Object\": \"send\",\n         })\n     }\n+\n+    pub fn to_json_access(&self) -> Value {\n+        use crate::util::format_date;\n+\n+        let data: Value = serde_json::from_str(&self.data).unwrap_or_default();\n+\n+        json!({\n+            \"Id\": self.uuid,\n+            \"Type\": self.atype,\n+\n+            \"Name\": self.name,\n+            \"Text\": if self.atype == SendType::Text as i32 { Some(&data) } else { None },\n+            \"File\": if self.atype == SendType::File as i32 { Some(&data) } else { None },\n+\n+            \"ExpirationDate\": self.expiration_date.as_ref().map(format_date),\n+            \"Object\": \"send-access\",\n+        })\n+    }\n }\n \n use crate::db::DbConn;\n",
            "comment_added_diff": []
        },
        {
            "commit": "46a1a013cd471c473964a7113dc2fab497732cc4",
            "timestamp": "2021-03-22T19:05:15+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Update user revision date with sends",
            "additions": 14,
            "deletions": 3,
            "change_type": "MODIFY",
            "diff": "@@ -75,7 +75,7 @@ impl Send {\n             disabled: false,\n         }\n     }\n-    \n+\n     pub fn set_password(&mut self, password: Option<&str>) {\n         const PASSWORD_ITER: i32 = 100_000;\n \n@@ -157,7 +157,7 @@ use crate::error::MapResult;\n \n impl Send {\n     pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n-        // self.update_users_revision(conn);\n+        self.update_users_revision(conn);\n         self.revision_date = Utc::now().naive_utc();\n \n         db_run! { conn:\n@@ -192,7 +192,7 @@ impl Send {\n     }\n \n     pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n-        // self.update_users_revision(conn);\n+        self.update_users_revision(conn);\n \n         db_run! { conn: {\n             diesel::delete(sends::table.filter(sends::uuid.eq(&self.uuid)))\n@@ -201,6 +201,17 @@ impl Send {\n         }}\n     }\n \n+    pub fn update_users_revision(&self, conn: &DbConn) {\n+        match self.user_uuid {\n+            Some(user_uuid) => {\n+                User::update_uuid_revision(&user_uuid, conn);\n+            }\n+            None => {\n+                // Belongs to Organization, not implemented\n+            }\n+        }\n+    }\n+\n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n         for send in Self::find_by_user(user_uuid, &conn) {\n             send.delete(&conn)?;\n",
            "comment_added_diff": [
                [
                    210,
                    "                // Belongs to Organization, not implemented"
                ]
            ]
        },
        {
            "commit": "1fc6c30652b59a9dd7495393075df2a22246fa02",
            "timestamp": "2021-03-22T19:57:35+01:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Send deletion thread and updated users revision",
            "additions": 11,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -194,6 +194,10 @@ impl Send {\n     pub fn delete(&self, conn: &DbConn) -> EmptyResult {\n         self.update_users_revision(conn);\n \n+        if self.atype == SendType::File as i32 {\n+            std::fs::remove_dir_all(std::path::Path::new(&crate::CONFIG.sends_folder()).join(&self.uuid)).ok();\n+        }\n+\n         db_run! { conn: {\n             diesel::delete(sends::table.filter(sends::uuid.eq(&self.uuid)))\n                 .execute(conn)\n@@ -202,7 +206,7 @@ impl Send {\n     }\n \n     pub fn update_users_revision(&self, conn: &DbConn) {\n-        match self.user_uuid {\n+        match &self.user_uuid {\n             Some(user_uuid) => {\n                 User::update_uuid_revision(&user_uuid, conn);\n             }\n@@ -219,6 +223,12 @@ impl Send {\n         Ok(())\n     }\n \n+    pub fn find_all(conn: &DbConn) -> Vec<Self> {\n+        db_run! {conn: {\n+            sends::table.load::<SendDb>(conn).expect(\"Error loading sends\").from_db()\n+        }}\n+    }\n+\n     pub fn find_by_access_id(access_id: &str, conn: &DbConn) -> Option<Self> {\n         use data_encoding::BASE64URL_NOPAD;\n         use uuid::Uuid;\n",
            "comment_added_diff": []
        },
        {
            "commit": "73ff8d79f70b36483d1d33587cdc9549c8e472bd",
            "timestamp": "2021-04-05T23:07:15-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add a generic job scheduler\n\nAlso rewrite deletion of old sends using the job scheduler.",
            "additions": 16,
            "deletions": 6,
            "change_type": "MODIFY",
            "diff": "@@ -205,6 +205,13 @@ impl Send {\n         }}\n     }\n \n+    /// Purge all sends that are past their deletion date.\n+    pub fn purge(conn: &DbConn) {\n+        for send in Self::find_by_past_deletion_date(&conn) {\n+            send.delete(&conn).ok();\n+        }\n+    }\n+\n     pub fn update_users_revision(&self, conn: &DbConn) {\n         match &self.user_uuid {\n             Some(user_uuid) => {\n@@ -223,12 +230,6 @@ impl Send {\n         Ok(())\n     }\n \n-    pub fn find_all(conn: &DbConn) -> Vec<Self> {\n-        db_run! {conn: {\n-            sends::table.load::<SendDb>(conn).expect(\"Error loading sends\").from_db()\n-        }}\n-    }\n-\n     pub fn find_by_access_id(access_id: &str, conn: &DbConn) -> Option<Self> {\n         use data_encoding::BASE64URL_NOPAD;\n         use uuid::Uuid;\n@@ -271,4 +272,13 @@ impl Send {\n                 .load::<SendDb>(conn).expect(\"Error loading sends\").from_db()\n         }}\n     }\n+\n+    pub fn find_by_past_deletion_date(conn: &DbConn) -> Vec<Self> {\n+        let now = Utc::now().naive_utc();\n+        db_run! {conn: {\n+            sends::table\n+                .filter(sends::deletion_date.lt(now))\n+                .load::<SendDb>(conn).expect(\"Error loading sends\").from_db()\n+        }}\n+    }\n }\n",
            "comment_added_diff": [
                [
                    208,
                    "    /// Purge all sends that are past their deletion date."
                ]
            ]
        },
        {
            "commit": "d3449bfa00cff40dc1f9ef349c9c6524e78f64e1",
            "timestamp": "2021-05-11T22:51:12-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Add support for hiding the sender's email address in Bitwarden Sends\n\nNote: The original Vaultwarden implementation of Bitwarden Send would always\nhide the email address, while the upstream implementation would always show it.\n\nUpstream PR: https://github.com/bitwarden/server/pull/1234",
            "additions": 21,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -36,6 +36,7 @@ db_object! {\n         pub deletion_date: NaiveDateTime,\n \n         pub disabled: bool,\n+        pub hide_email: Option<bool>,\n     }\n }\n \n@@ -73,6 +74,7 @@ impl Send {\n             deletion_date,\n \n             disabled: false,\n+            hide_email: None,\n         }\n     }\n \n@@ -101,6 +103,22 @@ impl Send {\n         }\n     }\n \n+    pub fn creator_identifier(&self, conn: &DbConn) -> Option<String> {\n+        if let Some(hide_email) = self.hide_email {\n+            if hide_email {\n+                return None;\n+            }\n+        }\n+\n+        if let Some(user_uuid) = &self.user_uuid {\n+            if let Some(user) = User::find_by_uuid(user_uuid, conn) {\n+                return Some(user.email);\n+            }\n+        }\n+\n+        None\n+    }\n+\n     pub fn to_json(&self) -> Value {\n         use crate::util::format_date;\n         use data_encoding::BASE64URL_NOPAD;\n@@ -123,6 +141,7 @@ impl Send {\n             \"AccessCount\": self.access_count,\n             \"Password\": self.password_hash.as_deref().map(|h| BASE64URL_NOPAD.encode(h)),\n             \"Disabled\": self.disabled,\n+            \"HideEmail\": self.hide_email,\n \n             \"RevisionDate\": format_date(&self.revision_date),\n             \"ExpirationDate\": self.expiration_date.as_ref().map(format_date),\n@@ -131,7 +150,7 @@ impl Send {\n         })\n     }\n \n-    pub fn to_json_access(&self) -> Value {\n+    pub fn to_json_access(&self, conn: &DbConn) -> Value {\n         use crate::util::format_date;\n \n         let data: Value = serde_json::from_str(&self.data).unwrap_or_default();\n@@ -145,6 +164,7 @@ impl Send {\n             \"File\": if self.atype == SendType::File as i32 { Some(&data) } else { None },\n \n             \"ExpirationDate\": self.expiration_date.as_ref().map(format_date),\n+            \"CreatorIdentifier\": self.creator_identifier(conn),\n             \"Object\": \"send-access\",\n         })\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 5,
            "deletions": 5,
            "change_type": "MODIFY",
            "diff": "@@ -227,15 +227,15 @@ impl Send {\n \n     /// Purge all sends that are past their deletion date.\n     pub fn purge(conn: &DbConn) {\n-        for send in Self::find_by_past_deletion_date(&conn) {\n-            send.delete(&conn).ok();\n+        for send in Self::find_by_past_deletion_date(conn) {\n+            send.delete(conn).ok();\n         }\n     }\n \n     pub fn update_users_revision(&self, conn: &DbConn) {\n         match &self.user_uuid {\n             Some(user_uuid) => {\n-                User::update_uuid_revision(&user_uuid, conn);\n+                User::update_uuid_revision(user_uuid, conn);\n             }\n             None => {\n                 // Belongs to Organization, not implemented\n@@ -244,8 +244,8 @@ impl Send {\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n-        for send in Self::find_by_user(user_uuid, &conn) {\n-            send.delete(&conn)?;\n+        for send in Self::find_by_user(user_uuid, conn) {\n+            send.delete(conn)?;\n         }\n         Ok(())\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "dd98fe860b33f8e34c161f49e3f6b07908d1dc3e",
            "timestamp": "2021-08-03T17:39:38+02:00",
            "author": "Fabian Thies",
            "commit_message": "Send create, update and delete notifications for `Send`s in the correct format.\nAdd endpoints to get all sends or a specific send by its uuid.",
            "additions": 7,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -232,15 +232,18 @@ impl Send {\n         }\n     }\n \n-    pub fn update_users_revision(&self, conn: &DbConn) {\n-        match &self.user_uuid {\n-            Some(user_uuid) => {\n+    pub fn update_users_revision(&self, conn: &DbConn) -> Vec<String> {\n+        let mut user_uuids = Vec::new();\n+        match self.user_uuid {\n+            Some(ref user_uuid) => {\n                 User::update_uuid_revision(user_uuid, conn);\n+                user_uuids.push(user_uuid.clone())\n             }\n             None => {\n                 // Belongs to Organization, not implemented\n             }\n-        }\n+        };\n+        user_uuids\n     }\n \n     pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n",
            "comment_added_diff": []
        },
        {
            "commit": "42ba817a4c423457a014f13cec3faba994770b21",
            "timestamp": "2021-08-04T13:25:41+02:00",
            "author": "Fabian Thies",
            "commit_message": "Fix errors that occurred in the nightly build",
            "additions": 2,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -234,8 +234,8 @@ impl Send {\n \n     pub fn update_users_revision(&self, conn: &DbConn) -> Vec<String> {\n         let mut user_uuids = Vec::new();\n-        match self.user_uuid {\n-            Some(ref user_uuid) => {\n+        match &self.user_uuid {\n+            Some(user_uuid) => {\n                 User::update_uuid_revision(user_uuid, conn);\n                 user_uuids.push(user_uuid.clone())\n             }\n",
            "comment_added_diff": []
        }
    ],
    ".dockerignore": [],
    ".editorconfig": [],
    "build.yml": [],
    "hadolint.yml": [],
    "send_2fa_removed_from_org.hbs": [],
    "send_2fa_removed_from_org.html.hbs": [],
    "bug_report.md": [],
    "config.yml": [],
    "README.md": [],
    "Dockerfile.buildx": [],
    "start.sh": [],
    "build": [],
    "push": [],
    "send_org_invite.hbs": [],
    "send_org_invite.html.hbs": [],
    "twofactor_email.hbs": [],
    "twofactor_email.html.hbs": [],
    "vaultwarden-icon.png": [],
    "email_footer.hbs": [],
    "email_footer_text.hbs": [],
    "email_header.hbs": [],
    "webauthn.rs": [
        {
            "commit": "c380d9c3792f6587b22e417c82adf4de54695d18",
            "timestamp": "2021-06-16T19:06:40+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Support for webauthn and u2f->webauthn migrations",
            "additions": 394,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,394 @@\n+use rocket::Route;\n+use rocket_contrib::json::Json;\n+use serde_json::Value;\n+use webauthn_rs::{base64_data::Base64UrlSafeData, proto::*, AuthenticationState, RegistrationState, Webauthn};\n+\n+use crate::{\n+    api::{\n+        core::two_factor::_generate_recover_code, EmptyResult, JsonResult, JsonUpcase, NumberOrString, PasswordData,\n+    },\n+    auth::Headers,\n+    db::{\n+        models::{TwoFactor, TwoFactorType},\n+        DbConn,\n+    },\n+    error::Error,\n+    CONFIG,\n+};\n+\n+pub fn routes() -> Vec<Route> {\n+    routes![get_webauthn, generate_webauthn_challenge, activate_webauthn, activate_webauthn_put, delete_webauthn,]\n+}\n+\n+struct WebauthnConfig {\n+    url: String,\n+    rpid: String,\n+}\n+\n+impl WebauthnConfig {\n+    fn load() -> Webauthn<Self> {\n+        let domain = CONFIG.domain();\n+        Webauthn::new(Self {\n+            rpid: reqwest::Url::parse(&domain)\n+                .map(|u| u.domain().map(str::to_owned))\n+                .ok()\n+                .flatten()\n+                .unwrap_or_default(),\n+            url: domain,\n+        })\n+    }\n+}\n+\n+impl webauthn_rs::WebauthnConfig for WebauthnConfig {\n+    fn get_relying_party_name(&self) -> &str {\n+        &self.url\n+    }\n+\n+    fn get_origin(&self) -> &str {\n+        &self.url\n+    }\n+\n+    fn get_relying_party_id(&self) -> &str {\n+        &self.rpid\n+    }\n+}\n+\n+impl webauthn_rs::WebauthnConfig for &WebauthnConfig {\n+    fn get_relying_party_name(&self) -> &str {\n+        &self.url\n+    }\n+\n+    fn get_origin(&self) -> &str {\n+        &self.url\n+    }\n+\n+    fn get_relying_party_id(&self) -> &str {\n+        &self.rpid\n+    }\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct WebauthnRegistration {\n+    pub id: i32,\n+    pub name: String,\n+    pub migrated: bool,\n+\n+    pub credential: Credential,\n+}\n+\n+impl WebauthnRegistration {\n+    fn to_json(&self) -> Value {\n+        json!({\n+            \"Id\": self.id,\n+            \"Name\": self.name,\n+            \"migrated\": self.migrated,\n+        })\n+    }\n+}\n+\n+#[post(\"/two-factor/get-webauthn\", data = \"<data>\")]\n+fn get_webauthn(data: JsonUpcase<PasswordData>, headers: Headers, conn: DbConn) -> JsonResult {\n+    if !CONFIG.domain_set() {\n+        err!(\"`DOMAIN` environment variable is not set. Webauthn disabled\")\n+    }\n+\n+    if !headers.user.check_valid_password(&data.data.MasterPasswordHash) {\n+        err!(\"Invalid password\");\n+    }\n+\n+    let (enabled, registrations) = get_webauthn_registrations(&headers.user.uuid, &conn)?;\n+    let registrations_json: Vec<Value> = registrations.iter().map(WebauthnRegistration::to_json).collect();\n+\n+    Ok(Json(json!({\n+        \"Enabled\": enabled,\n+        \"Keys\": registrations_json,\n+        \"Object\": \"twoFactorWebAuthn\"\n+    })))\n+}\n+\n+#[post(\"/two-factor/get-webauthn-challenge\", data = \"<data>\")]\n+fn generate_webauthn_challenge(data: JsonUpcase<PasswordData>, headers: Headers, conn: DbConn) -> JsonResult {\n+    if !headers.user.check_valid_password(&data.data.MasterPasswordHash) {\n+        err!(\"Invalid password\");\n+    }\n+\n+    let registrations = get_webauthn_registrations(&headers.user.uuid, &conn)?\n+        .1\n+        .into_iter()\n+        .map(|r| r.credential.cred_id) // We return the credentialIds to the clients to avoid double registering\n+        .collect();\n+\n+    let (challenge, state) = WebauthnConfig::load().generate_challenge_register_options(\n+        headers.user.uuid.as_bytes().to_vec(),\n+        headers.user.email,\n+        headers.user.name,\n+        Some(registrations),\n+        None,\n+        None,\n+    )?;\n+\n+    let type_ = TwoFactorType::WebauthnRegisterChallenge;\n+    TwoFactor::new(headers.user.uuid.clone(), type_, serde_json::to_string(&state)?).save(&conn)?;\n+\n+    let mut challenge_value = serde_json::to_value(challenge.public_key)?;\n+    challenge_value[\"status\"] = \"ok\".into();\n+    challenge_value[\"errorMessage\"] = \"\".into();\n+    Ok(Json(challenge_value))\n+}\n+\n+#[derive(Debug, Deserialize)]\n+#[allow(non_snake_case)]\n+struct EnableWebauthnData {\n+    Id: NumberOrString, // 1..5\n+    Name: String,\n+    MasterPasswordHash: String,\n+    DeviceResponse: RegisterPublicKeyCredentialCopy,\n+}\n+\n+// This is copied from RegisterPublicKeyCredential to change the Response objects casing\n+#[derive(Debug, Deserialize)]\n+#[allow(non_snake_case)]\n+struct RegisterPublicKeyCredentialCopy {\n+    pub Id: String,\n+    pub RawId: Base64UrlSafeData,\n+    pub Response: AuthenticatorAttestationResponseRawCopy,\n+    pub Type: String,\n+}\n+\n+// This is copied from AuthenticatorAttestationResponseRaw to change clientDataJSON to clientDataJson\n+#[derive(Debug, Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct AuthenticatorAttestationResponseRawCopy {\n+    pub AttestationObject: Base64UrlSafeData,\n+    pub ClientDataJson: Base64UrlSafeData,\n+}\n+\n+impl From<RegisterPublicKeyCredentialCopy> for RegisterPublicKeyCredential {\n+    fn from(r: RegisterPublicKeyCredentialCopy) -> Self {\n+        Self {\n+            id: r.Id,\n+            raw_id: r.RawId,\n+            response: AuthenticatorAttestationResponseRaw {\n+                attestation_object: r.Response.AttestationObject,\n+                client_data_json: r.Response.ClientDataJson,\n+            },\n+            type_: r.Type,\n+        }\n+    }\n+}\n+\n+// This is copied from PublicKeyCredential to change the Response objects casing\n+#[derive(Debug, Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct PublicKeyCredentialCopy {\n+    pub Id: String,\n+    pub RawId: Base64UrlSafeData,\n+    pub Response: AuthenticatorAssertionResponseRawCopy,\n+    pub Extensions: Option<AuthenticationExtensionsClientOutputsCopy>,\n+    pub Type: String,\n+}\n+\n+// This is copied from AuthenticatorAssertionResponseRaw to change clientDataJSON to clientDataJson\n+#[derive(Debug, Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct AuthenticatorAssertionResponseRawCopy {\n+    pub AuthenticatorData: Base64UrlSafeData,\n+    pub ClientDataJson: Base64UrlSafeData,\n+    pub Signature: Base64UrlSafeData,\n+    pub UserHandle: Option<Base64UrlSafeData>,\n+}\n+\n+#[derive(Debug, Deserialize)]\n+#[allow(non_snake_case)]\n+pub struct AuthenticationExtensionsClientOutputsCopy {\n+    #[serde(default)]\n+    pub Appid: bool,\n+}\n+\n+impl From<PublicKeyCredentialCopy> for PublicKeyCredential {\n+    fn from(r: PublicKeyCredentialCopy) -> Self {\n+        Self {\n+            id: r.Id,\n+            raw_id: r.RawId,\n+            response: AuthenticatorAssertionResponseRaw {\n+                authenticator_data: r.Response.AuthenticatorData,\n+                client_data_json: r.Response.ClientDataJson,\n+                signature: r.Response.Signature,\n+                user_handle: r.Response.UserHandle,\n+            },\n+            extensions: r.Extensions.map(|e| AuthenticationExtensionsClientOutputs {\n+                appid: e.Appid,\n+            }),\n+            type_: r.Type,\n+        }\n+    }\n+}\n+\n+#[post(\"/two-factor/webauthn\", data = \"<data>\")]\n+fn activate_webauthn(data: JsonUpcase<EnableWebauthnData>, headers: Headers, conn: DbConn) -> JsonResult {\n+    let data: EnableWebauthnData = data.into_inner().data;\n+    let mut user = headers.user;\n+\n+    if !user.check_valid_password(&data.MasterPasswordHash) {\n+        err!(\"Invalid password\");\n+    }\n+\n+    // Retrieve and delete the saved challenge state\n+    let type_ = TwoFactorType::WebauthnRegisterChallenge as i32;\n+    let state = match TwoFactor::find_by_user_and_type(&user.uuid, type_, &conn) {\n+        Some(tf) => {\n+            let state: RegistrationState = serde_json::from_str(&tf.data)?;\n+            tf.delete(&conn)?;\n+            state\n+        }\n+        None => err!(\"Can't recover challenge\"),\n+    };\n+\n+    // Verify the credentials with the saved state\n+    let (credential, _data) =\n+        WebauthnConfig::load().register_credential(&data.DeviceResponse.into(), &state, |_| Ok(false))?;\n+\n+    let mut registrations: Vec<_> = get_webauthn_registrations(&user.uuid, &conn)?.1;\n+    // TODO: Check for repeated ID's\n+    registrations.push(WebauthnRegistration {\n+        id: data.Id.into_i32()?,\n+        name: data.Name,\n+        migrated: false,\n+\n+        credential,\n+    });\n+\n+    // Save the registrations and return them\n+    TwoFactor::new(user.uuid.clone(), TwoFactorType::Webauthn, serde_json::to_string(&registrations)?).save(&conn)?;\n+    _generate_recover_code(&mut user, &conn);\n+\n+    let keys_json: Vec<Value> = registrations.iter().map(WebauthnRegistration::to_json).collect();\n+    Ok(Json(json!({\n+        \"Enabled\": true,\n+        \"Keys\": keys_json,\n+        \"Object\": \"twoFactorU2f\"\n+    })))\n+}\n+\n+#[put(\"/two-factor/webauthn\", data = \"<data>\")]\n+fn activate_webauthn_put(data: JsonUpcase<EnableWebauthnData>, headers: Headers, conn: DbConn) -> JsonResult {\n+    activate_webauthn(data, headers, conn)\n+}\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct DeleteU2FData {\n+    Id: NumberOrString,\n+    MasterPasswordHash: String,\n+}\n+\n+#[delete(\"/two-factor/webauthn\", data = \"<data>\")]\n+fn delete_webauthn(data: JsonUpcase<DeleteU2FData>, headers: Headers, conn: DbConn) -> JsonResult {\n+    let id = data.data.Id.into_i32()?;\n+    if !headers.user.check_valid_password(&data.data.MasterPasswordHash) {\n+        err!(\"Invalid password\");\n+    }\n+\n+    let type_ = TwoFactorType::Webauthn as i32;\n+    let mut tf = match TwoFactor::find_by_user_and_type(&headers.user.uuid, type_, &conn) {\n+        Some(tf) => tf,\n+        None => err!(\"Webauthn data not found!\"),\n+    };\n+\n+    let mut data: Vec<WebauthnRegistration> = serde_json::from_str(&tf.data)?;\n+\n+    let item_pos = match data.iter().position(|r| r.id != id) {\n+        Some(p) => p,\n+        None => err!(\"Webauthn entry not found\"),\n+    };\n+\n+    let removed_item = data.remove(item_pos);\n+    tf.data = serde_json::to_string(&data)?;\n+    tf.save(&conn)?;\n+    drop(tf);\n+\n+    // If entry is migrated from u2f, delete the u2f entry as well\n+    if let Some(mut u2f) = TwoFactor::find_by_user_and_type(&headers.user.uuid, TwoFactorType::U2f as i32, &conn) {\n+        use crate::api::core::two_factor::u2f::U2FRegistration;\n+        let mut data: Vec<U2FRegistration> = match serde_json::from_str(&u2f.data) {\n+            Ok(d) => d,\n+            Err(_) => err!(\"Error parsing U2F data\"),\n+        };\n+\n+        data.retain(|r| r.reg.key_handle != removed_item.credential.cred_id);\n+        let new_data_str = serde_json::to_string(&data)?;\n+\n+        u2f.data = new_data_str;\n+        u2f.save(&conn)?;\n+    }\n+\n+    let keys_json: Vec<Value> = data.iter().map(WebauthnRegistration::to_json).collect();\n+\n+    Ok(Json(json!({\n+        \"Enabled\": true,\n+        \"Keys\": keys_json,\n+        \"Object\": \"twoFactorU2f\"\n+    })))\n+}\n+\n+pub fn get_webauthn_registrations(user_uuid: &str, conn: &DbConn) -> Result<(bool, Vec<WebauthnRegistration>), Error> {\n+    let type_ = TwoFactorType::Webauthn as i32;\n+    match TwoFactor::find_by_user_and_type(user_uuid, type_, conn) {\n+        Some(tf) => Ok((tf.enabled, serde_json::from_str(&tf.data)?)),\n+        None => Ok((false, Vec::new())), // If no data, return empty list\n+    }\n+}\n+\n+pub fn generate_webauthn_login(user_uuid: &str, conn: &DbConn) -> JsonResult {\n+    // Load saved credentials\n+    let creds: Vec<Credential> =\n+        get_webauthn_registrations(user_uuid, conn)?.1.into_iter().map(|r| r.credential).collect();\n+\n+    if creds.is_empty() {\n+        err!(\"No Webauthn devices registered\")\n+    }\n+\n+    // Generate a challenge based on the credentials\n+    let ext = RequestAuthenticationExtensions::builder().appid(format!(\"{}/app-id.json\", &CONFIG.domain())).build();\n+    let (response, state) = WebauthnConfig::load().generate_challenge_authenticate_options(creds, Some(ext))?;\n+\n+    // Save the challenge state for later validation\n+    TwoFactor::new(user_uuid.into(), TwoFactorType::WebauthnLoginChallenge, serde_json::to_string(&state)?)\n+        .save(&conn)?;\n+\n+    // Return challenge to the clients\n+    Ok(Json(serde_json::to_value(response.public_key)?))\n+}\n+\n+pub fn validate_webauthn_login(user_uuid: &str, response: &str, conn: &DbConn) -> EmptyResult {\n+    let type_ = TwoFactorType::WebauthnLoginChallenge as i32;\n+    let state = match TwoFactor::find_by_user_and_type(user_uuid, type_, conn) {\n+        Some(tf) => {\n+            let state: AuthenticationState = serde_json::from_str(&tf.data)?;\n+            tf.delete(&conn)?;\n+            state\n+        }\n+        None => err!(\"Can't recover login challenge\"),\n+    };\n+\n+    let rsp: crate::util::UpCase<PublicKeyCredentialCopy> = serde_json::from_str(response)?;\n+    let rsp: PublicKeyCredential = rsp.data.into();\n+\n+    let mut registrations = get_webauthn_registrations(user_uuid, conn)?.1;\n+\n+    // If the credential we received is migrated from U2F, enable the U2F compatibility\n+    //let use_u2f = registrations.iter().any(|r| r.migrated && r.credential.cred_id == rsp.raw_id.0);\n+    let (cred_id, auth_data) = WebauthnConfig::load().authenticate_credential(&rsp, &state)?;\n+\n+    for reg in &mut registrations {\n+        if &reg.credential.cred_id == cred_id {\n+            reg.credential.counter = auth_data.counter;\n+\n+            TwoFactor::new(user_uuid.to_string(), TwoFactorType::Webauthn, serde_json::to_string(&registrations)?)\n+                .save(&conn)?;\n+            return Ok(());\n+        }\n+    }\n+\n+    err!(\"Credential not present\")\n+}\n",
            "comment_added_diff": [
                [
                    118,
                    "        .map(|r| r.credential.cred_id) // We return the credentialIds to the clients to avoid double registering"
                ],
                [
                    142,
                    "    Id: NumberOrString, // 1..5"
                ],
                [
                    148,
                    "// This is copied from RegisterPublicKeyCredential to change the Response objects casing"
                ],
                [
                    158,
                    "// This is copied from AuthenticatorAttestationResponseRaw to change clientDataJSON to clientDataJson"
                ],
                [
                    180,
                    "// This is copied from PublicKeyCredential to change the Response objects casing"
                ],
                [
                    191,
                    "// This is copied from AuthenticatorAssertionResponseRaw to change clientDataJSON to clientDataJson"
                ],
                [
                    236,
                    "    // Retrieve and delete the saved challenge state"
                ],
                [
                    247,
                    "    // Verify the credentials with the saved state"
                ],
                [
                    252,
                    "    // TODO: Check for repeated ID's"
                ],
                [
                    261,
                    "    // Save the registrations and return them"
                ],
                [
                    310,
                    "    // If entry is migrated from u2f, delete the u2f entry as well"
                ],
                [
                    338,
                    "        None => Ok((false, Vec::new())), // If no data, return empty list"
                ],
                [
                    343,
                    "    // Load saved credentials"
                ],
                [
                    351,
                    "    // Generate a challenge based on the credentials"
                ],
                [
                    355,
                    "    // Save the challenge state for later validation"
                ],
                [
                    359,
                    "    // Return challenge to the clients"
                ],
                [
                    379,
                    "    // If the credential we received is migrated from U2F, enable the U2F compatibility"
                ],
                [
                    380,
                    "    //let use_u2f = registrations.iter().any(|r| r.migrated && r.credential.cred_id == rsp.raw_id.0);"
                ]
            ]
        },
        {
            "commit": "9254cf9d9c1b43a4ad3bc640610048c0a798424e",
            "timestamp": "2021-06-19T22:02:03+02:00",
            "author": "Daniel Garc\u00eda",
            "commit_message": "Fix clippy lints",
            "additions": 4,
            "deletions": 4,
            "change_type": "MODIFY",
            "diff": "@@ -128,7 +128,7 @@ fn generate_webauthn_challenge(data: JsonUpcase<PasswordData>, headers: Headers,\n     )?;\n \n     let type_ = TwoFactorType::WebauthnRegisterChallenge;\n-    TwoFactor::new(headers.user.uuid.clone(), type_, serde_json::to_string(&state)?).save(&conn)?;\n+    TwoFactor::new(headers.user.uuid, type_, serde_json::to_string(&state)?).save(&conn)?;\n \n     let mut challenge_value = serde_json::to_value(challenge.public_key)?;\n     challenge_value[\"status\"] = \"ok\".into();\n@@ -354,7 +354,7 @@ pub fn generate_webauthn_login(user_uuid: &str, conn: &DbConn) -> JsonResult {\n \n     // Save the challenge state for later validation\n     TwoFactor::new(user_uuid.into(), TwoFactorType::WebauthnLoginChallenge, serde_json::to_string(&state)?)\n-        .save(&conn)?;\n+        .save(conn)?;\n \n     // Return challenge to the clients\n     Ok(Json(serde_json::to_value(response.public_key)?))\n@@ -365,7 +365,7 @@ pub fn validate_webauthn_login(user_uuid: &str, response: &str, conn: &DbConn) -\n     let state = match TwoFactor::find_by_user_and_type(user_uuid, type_, conn) {\n         Some(tf) => {\n             let state: AuthenticationState = serde_json::from_str(&tf.data)?;\n-            tf.delete(&conn)?;\n+            tf.delete(conn)?;\n             state\n         }\n         None => err!(\"Can't recover login challenge\"),\n@@ -385,7 +385,7 @@ pub fn validate_webauthn_login(user_uuid: &str, response: &str, conn: &DbConn) -\n             reg.credential.counter = auth_data.counter;\n \n             TwoFactor::new(user_uuid.to_string(), TwoFactorType::Webauthn, serde_json::to_string(&registrations)?)\n-                .save(&conn)?;\n+                .save(conn)?;\n             return Ok(());\n         }\n     }\n",
            "comment_added_diff": []
        },
        {
            "commit": "ffdcafa0446aa110e27266a920b4497490cddb6f",
            "timestamp": "2021-07-25T14:49:55+02:00",
            "author": "BlackDex",
            "commit_message": "Fix WebAuthn issues and some small updates\n\n- Updated some packages\n- Updated code related to package updates.\n- Disabled User Verification enforcement when WebAuthn Key sends UV=1\n  This makes it compatible with upstream and resolves #1840\n- Fixed a bug where removing an individual WebAuthn key deleted the wrong key.",
            "additions": 7,
            "deletions": 15,
            "change_type": "MODIFY",
            "diff": "@@ -51,19 +51,12 @@ impl webauthn_rs::WebauthnConfig for WebauthnConfig {\n     fn get_relying_party_id(&self) -> &str {\n         &self.rpid\n     }\n-}\n-\n-impl webauthn_rs::WebauthnConfig for &WebauthnConfig {\n-    fn get_relying_party_name(&self) -> &str {\n-        &self.url\n-    }\n-\n-    fn get_origin(&self) -> &str {\n-        &self.url\n-    }\n \n-    fn get_relying_party_id(&self) -> &str {\n-        &self.rpid\n+    /// We have WebAuthn configured to discourage user verification\n+    /// if we leave this enabled, it will cause verification issues when a keys send UV=1.\n+    /// Upstream (the library they use) ignores this when set to discouraged, so we should too.\n+    fn get_require_uv_consistency(&self) -> bool {\n+        false\n     }\n }\n \n@@ -289,15 +282,14 @@ fn delete_webauthn(data: JsonUpcase<DeleteU2FData>, headers: Headers, conn: DbCo\n         err!(\"Invalid password\");\n     }\n \n-    let type_ = TwoFactorType::Webauthn as i32;\n-    let mut tf = match TwoFactor::find_by_user_and_type(&headers.user.uuid, type_, &conn) {\n+    let mut tf = match TwoFactor::find_by_user_and_type(&headers.user.uuid, TwoFactorType::Webauthn as i32, &conn) {\n         Some(tf) => tf,\n         None => err!(\"Webauthn data not found!\"),\n     };\n \n     let mut data: Vec<WebauthnRegistration> = serde_json::from_str(&tf.data)?;\n \n-    let item_pos = match data.iter().position(|r| r.id != id) {\n+    let item_pos = match data.iter().position(|r| r.id == id) {\n         Some(p) => p,\n         None => err!(\"Webauthn entry not found\"),\n     };\n",
            "comment_added_diff": [
                [
                    55,
                    "    /// We have WebAuthn configured to discourage user verification"
                ],
                [
                    56,
                    "    /// if we leave this enabled, it will cause verification issues when a keys send UV=1."
                ],
                [
                    57,
                    "    /// Upstream (the library they use) ignores this when set to discouraged, so we should too."
                ]
            ]
        },
        {
            "commit": "0cdc0cb147e39a382a1e8345191f19ac69df6217",
            "timestamp": "2021-08-29T15:53:25-07:00",
            "author": "Jeremy Lin",
            "commit_message": "Fix incorrect WebAuthn origin\n\nThis mainly affects users running Vaultwarden under a subpath.\n\nRefs:\n\n* https://github.com/kanidm/webauthn-rs/blob/b2cbb34/src/core.rs#L941-L948\n* https://github.com/kanidm/webauthn-rs/blob/b2cbb34/src/core.rs#L316\n* https://w3c.github.io/webauthn/#dictionary-client-data",
            "additions": 4,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -22,12 +22,14 @@ pub fn routes() -> Vec<Route> {\n \n struct WebauthnConfig {\n     url: String,\n+    origin: String,\n     rpid: String,\n }\n \n impl WebauthnConfig {\n     fn load() -> Webauthn<Self> {\n         let domain = CONFIG.domain();\n+        let domain_origin = CONFIG.domain_origin();\n         Webauthn::new(Self {\n             rpid: reqwest::Url::parse(&domain)\n                 .map(|u| u.domain().map(str::to_owned))\n@@ -35,6 +37,7 @@ impl WebauthnConfig {\n                 .flatten()\n                 .unwrap_or_default(),\n             url: domain,\n+            origin: domain_origin,\n         })\n     }\n }\n@@ -45,7 +48,7 @@ impl webauthn_rs::WebauthnConfig for WebauthnConfig {\n     }\n \n     fn get_origin(&self) -> &str {\n-        &self.url\n+        &self.origin\n     }\n \n     fn get_relying_party_id(&self) -> &str {\n",
            "comment_added_diff": []
        }
    ],
    "jquery-3.6.0.slim.js": [],
    "emergency_access.rs": [
        {
            "commit": "403f35b571ae2abb8e1df118bfa543e35805a52f",
            "timestamp": "2021-07-04T23:02:56+02:00",
            "author": "BlackDex",
            "commit_message": "Added web-vault v2.21.x support + some misc fixes\n\n- The new web-vault v2.21.0+ has support for Master Password Reset. For\nthis to work it generates a public/private key-pair which needs to be\nstored in the database. Currently the Master Password Reset is not\nfixed, but there are endpoints which are needed even if we do not\nsupport this feature (yet). This PR fixes those endpoints, and stores\nthe keys already in the database.\n\n- There was an issue when you want to do a key-rotate when you change\nyour password, it also called an Emergency Access endpoint, which we do\nnot yet support. Because this endpoint failed to reply correctly\nproduced some errors, and also prevent the user from being forced to\nlogout. This resolves #1826 by adding at least that endpoint.\n\nBecause of that extra endpoint check to Emergency Access is done using\nan old user stamp, i also modified the stamp exception to allow multiple\nrocket routes to be called, and added an expiration timestamp to it.\n\nDuring these tests i stumbled upon an issue that after my key-change was\ndone, it triggered the websockets to try and reload my ciphers, because\nthey were updated. This shouldn't happen when rotating they keys, since\nall access should be invalided. Now there will be no websocket\nnotification for this, which also prevents error toasts.\n\n- Increased Send Size limit to 500MB (with a litle overhead)\n\nAs a side note, i tested these changes on both v2.20.4 and v2.21.1 web-vault versions, all keeps working.",
            "additions": 24,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,24 @@\n+use rocket::Route;\n+use rocket_contrib::json::Json;\n+\n+use crate::{api::JsonResult, auth::Headers, db::DbConn};\n+\n+pub fn routes() -> Vec<Route> {\n+    routes![get_contacts,]\n+}\n+\n+/// This endpoint is expected to return at least something.\n+/// If we return an error message that will trigger error toasts for the user.\n+/// To prevent this we just return an empty json result with no Data.\n+/// When this feature is going to be implemented it also needs to return this empty Data\n+/// instead of throwing an error/4XX unless it really is an error.\n+#[get(\"/emergency-access/trusted\")]\n+fn get_contacts(_headers: Headers, _conn: DbConn) -> JsonResult {\n+    debug!(\"Emergency access is not supported.\");\n+\n+    Ok(Json(json!({\n+      \"Data\": [],\n+      \"Object\": \"list\",\n+      \"ContinuationToken\": null\n+    })))\n+}\n",
            "comment_added_diff": [
                [
                    10,
                    "/// This endpoint is expected to return at least something."
                ],
                [
                    11,
                    "/// If we return an error message that will trigger error toasts for the user."
                ],
                [
                    12,
                    "/// To prevent this we just return an empty json result with no Data."
                ],
                [
                    13,
                    "/// When this feature is going to be implemented it also needs to return this empty Data"
                ],
                [
                    14,
                    "/// instead of throwing an error/4XX unless it really is an error."
                ]
            ]
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 827,
            "deletions": 10,
            "change_type": "MODIFY",
            "diff": "@@ -1,24 +1,841 @@\n+use chrono::{Duration, Utc};\n use rocket::Route;\n use rocket_contrib::json::Json;\n+use serde_json::Value;\n+use std::borrow::Borrow;\n \n-use crate::{api::JsonResult, auth::Headers, db::DbConn};\n+use crate::{\n+    api::{EmptyResult, JsonResult, JsonUpcase, NumberOrString},\n+    auth::{decode_emergency_access_invite, Headers},\n+    db::{models::*, DbConn, DbPool},\n+    mail, CONFIG,\n+};\n \n pub fn routes() -> Vec<Route> {\n-    routes![get_contacts,]\n+    routes![\n+        get_contacts,\n+        get_grantees,\n+        get_emergency_access,\n+        put_emergency_access,\n+        delete_emergency_access,\n+        post_delete_emergency_access,\n+        send_invite,\n+        resend_invite,\n+        accept_invite,\n+        confirm_emergency_access,\n+        initiate_emergency_access,\n+        approve_emergency_access,\n+        reject_emergency_access,\n+        takeover_emergency_access,\n+        password_emergency_access,\n+        view_emergency_access,\n+        policies_emergency_access,\n+    ]\n }\n \n-/// This endpoint is expected to return at least something.\n-/// If we return an error message that will trigger error toasts for the user.\n-/// To prevent this we just return an empty json result with no Data.\n-/// When this feature is going to be implemented it also needs to return this empty Data\n-/// instead of throwing an error/4XX unless it really is an error.\n+// region get\n+\n #[get(\"/emergency-access/trusted\")]\n-fn get_contacts(_headers: Headers, _conn: DbConn) -> JsonResult {\n-    debug!(\"Emergency access is not supported.\");\n+fn get_contacts(headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let emergency_access_list = EmergencyAccess::find_all_by_grantor_uuid(&headers.user.uuid, &conn);\n+\n+    let emergency_access_list_json: Vec<Value> =\n+        emergency_access_list.iter().map(|e| e.to_json_grantee_details(&conn)).collect();\n+\n+    Ok(Json(json!({\n+      \"Data\": emergency_access_list_json,\n+      \"Object\": \"list\",\n+      \"ContinuationToken\": null\n+    })))\n+}\n+\n+#[get(\"/emergency-access/granted\")]\n+fn get_grantees(headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let emergency_access_list = EmergencyAccess::find_all_by_grantee_uuid(&headers.user.uuid, &conn);\n+\n+    let emergency_access_list_json: Vec<Value> =\n+        emergency_access_list.iter().map(|e| e.to_json_grantor_details(&conn)).collect();\n \n     Ok(Json(json!({\n-      \"Data\": [],\n+      \"Data\": emergency_access_list_json,\n       \"Object\": \"list\",\n       \"ContinuationToken\": null\n     })))\n }\n+\n+#[get(\"/emergency-access/<emer_id>\")]\n+fn get_emergency_access(emer_id: String, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emergency_access) => Ok(Json(emergency_access.to_json_grantee_details(&conn))),\n+        None => err!(\"Emergency access not valid.\"),\n+    }\n+}\n+\n+// endregion\n+\n+// region put/post\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct EmergencyAccessUpdateData {\n+    Type: NumberOrString,\n+    WaitTimeDays: i32,\n+    KeyEncrypted: Option<String>,\n+}\n+\n+#[put(\"/emergency-access/<emer_id>\", data = \"<data>\")]\n+fn put_emergency_access(emer_id: String, data: JsonUpcase<EmergencyAccessUpdateData>, conn: DbConn) -> JsonResult {\n+    post_emergency_access(emer_id, data, conn)\n+}\n+\n+#[post(\"/emergency-access/<emer_id>\", data = \"<data>\")]\n+fn post_emergency_access(emer_id: String, data: JsonUpcase<EmergencyAccessUpdateData>, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let data: EmergencyAccessUpdateData = data.into_inner().data;\n+\n+    let mut emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emergency_access) => emergency_access,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    let new_type = match EmergencyAccessType::from_str(&data.Type.into_string()) {\n+        Some(new_type) => new_type as i32,\n+        None => err!(\"Invalid emergency access type.\"),\n+    };\n+\n+    emergency_access.atype = new_type;\n+    emergency_access.wait_time_days = data.WaitTimeDays;\n+    emergency_access.key_encrypted = data.KeyEncrypted;\n+\n+    emergency_access.save(&conn)?;\n+    Ok(Json(emergency_access.to_json()))\n+}\n+\n+// endregion\n+\n+// region delete\n+\n+#[delete(\"/emergency-access/<emer_id>\")]\n+fn delete_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> EmptyResult {\n+    check_emergency_access_allowed()?;\n+\n+    let grantor_user = headers.user;\n+\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => {\n+            if emer.grantor_uuid != grantor_user.uuid && emer.grantee_uuid != Some(grantor_user.uuid) {\n+                err!(\"Emergency access not valid.\")\n+            }\n+            emer\n+        }\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+    emergency_access.delete(&conn)?;\n+    Ok(())\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/delete\")]\n+fn post_delete_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> EmptyResult {\n+    delete_emergency_access(emer_id, headers, conn)\n+}\n+\n+// endregion\n+\n+// region invite\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct EmergencyAccessInviteData {\n+    Email: String,\n+    Type: NumberOrString,\n+    WaitTimeDays: i32,\n+}\n+\n+#[post(\"/emergency-access/invite\", data = \"<data>\")]\n+fn send_invite(data: JsonUpcase<EmergencyAccessInviteData>, headers: Headers, conn: DbConn) -> EmptyResult {\n+    check_emergency_access_allowed()?;\n+\n+    let data: EmergencyAccessInviteData = data.into_inner().data;\n+    let email = data.Email.to_lowercase();\n+    let wait_time_days = data.WaitTimeDays;\n+\n+    let emergency_access_status = EmergencyAccessStatus::Invited as i32;\n+\n+    let new_type = match EmergencyAccessType::from_str(&data.Type.into_string()) {\n+        Some(new_type) => new_type as i32,\n+        None => err!(\"Invalid emergency access type.\"),\n+    };\n+\n+    let grantor_user = headers.user;\n+\n+    // avoid setting yourself as emergency contact\n+    if email == grantor_user.email {\n+        err!(\"You can not set yourself as an emergency contact.\")\n+    }\n+\n+    let grantee_user = match User::find_by_mail(&email, &conn) {\n+        None => {\n+            if !CONFIG.signups_allowed() {\n+                err!(format!(\"Grantee user does not exist: {}\", email))\n+            }\n+\n+            if !CONFIG.is_email_domain_allowed(&email) {\n+                err!(\"Email domain not eligible for invitations\")\n+            }\n+\n+            if !CONFIG.mail_enabled() {\n+                let invitation = Invitation::new(email.clone());\n+                invitation.save(&conn)?;\n+            }\n+\n+            let mut user = User::new(email.clone());\n+            user.save(&conn)?;\n+            user\n+        }\n+        Some(user) => user,\n+    };\n+\n+    if EmergencyAccess::find_by_grantor_uuid_and_grantee_uuid_or_email(\n+        &grantor_user.uuid,\n+        &grantee_user.uuid,\n+        &grantee_user.email,\n+        &conn,\n+    )\n+    .is_some()\n+    {\n+        err!(format!(\"Grantee user already invited: {}\", email))\n+    }\n+\n+    let mut new_emergency_access = EmergencyAccess::new(\n+        grantor_user.uuid.clone(),\n+        Some(grantee_user.email.clone()),\n+        emergency_access_status,\n+        new_type,\n+        wait_time_days,\n+    );\n+    new_emergency_access.save(&conn)?;\n+\n+    if CONFIG.mail_enabled() {\n+        mail::send_emergency_access_invite(\n+            &grantee_user.email,\n+            &grantee_user.uuid,\n+            Some(new_emergency_access.uuid),\n+            Some(grantor_user.name.clone()),\n+            Some(grantor_user.email),\n+        )?;\n+    } else {\n+        // Automatically mark user as accepted if no email invites\n+        match User::find_by_mail(&email, &conn) {\n+            Some(user) => {\n+                match accept_invite_process(user.uuid, new_emergency_access.uuid, Some(email), conn.borrow()) {\n+                    Ok(v) => (v),\n+                    Err(e) => err!(e.to_string()),\n+                }\n+            }\n+            None => err!(\"Grantee user not found.\"),\n+        }\n+    }\n+\n+    Ok(())\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/reinvite\")]\n+fn resend_invite(emer_id: String, headers: Headers, conn: DbConn) -> EmptyResult {\n+    check_emergency_access_allowed()?;\n+\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if emergency_access.grantor_uuid != headers.user.uuid {\n+        err!(\"Emergency access not valid.\");\n+    }\n+\n+    if emergency_access.status != EmergencyAccessStatus::Invited as i32 {\n+        err!(\"The grantee user is already accepted or confirmed to the organization\");\n+    }\n+\n+    let email = match emergency_access.email.clone() {\n+        Some(email) => email,\n+        None => err!(\"Email not valid.\"),\n+    };\n+\n+    if !CONFIG.is_email_domain_allowed(&email) {\n+        err!(\"Email domain not eligible for invitations.\")\n+    }\n+\n+    let grantee_user = match User::find_by_mail(&email, &conn) {\n+        None => err!(\"Grantee user not found.\"),\n+        Some(user) => user,\n+    };\n+\n+    let grantor_user = headers.user;\n+\n+    if CONFIG.mail_enabled() {\n+        mail::send_emergency_access_invite(\n+            &email,\n+            &grantor_user.uuid,\n+            Some(emergency_access.uuid),\n+            Some(grantor_user.name.clone()),\n+            Some(grantor_user.email),\n+        )?;\n+    } else {\n+        if Invitation::find_by_mail(&email, &conn).is_none() {\n+            let invitation = Invitation::new(email);\n+            invitation.save(&conn)?;\n+        }\n+\n+        // Automatically mark user as accepted if no email invites\n+        match accept_invite_process(grantee_user.uuid, emergency_access.uuid, emergency_access.email, conn.borrow()) {\n+            Ok(v) => (v),\n+            Err(e) => err!(e.to_string()),\n+        }\n+    }\n+\n+    Ok(())\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct AcceptData {\n+    Token: String,\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/accept\", data = \"<data>\")]\n+fn accept_invite(emer_id: String, data: JsonUpcase<AcceptData>, conn: DbConn) -> EmptyResult {\n+    check_emergency_access_allowed()?;\n+\n+    let data: AcceptData = data.into_inner().data;\n+    let token = &data.Token;\n+    let claims = decode_emergency_access_invite(token)?;\n+\n+    let grantee_user = match User::find_by_mail(&claims.email, &conn) {\n+        Some(user) => {\n+            Invitation::take(&claims.email, &conn);\n+            user\n+        }\n+        None => err!(\"Invited user not found\"),\n+    };\n+\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    // get grantor user to send Accepted email\n+    let grantor_user = match User::find_by_uuid(&emergency_access.grantor_uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    if (claims.emer_id.is_some() && emer_id == claims.emer_id.unwrap())\n+        && (claims.grantor_name.is_some() && grantor_user.name == claims.grantor_name.unwrap())\n+        && (claims.grantor_email.is_some() && grantor_user.email == claims.grantor_email.unwrap())\n+    {\n+        match accept_invite_process(grantee_user.uuid.clone(), emer_id, Some(grantee_user.email.clone()), &conn) {\n+            Ok(v) => (v),\n+            Err(e) => err!(e.to_string()),\n+        }\n+\n+        if CONFIG.mail_enabled() {\n+            if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n+                err!(\"Email domain not valid.\")\n+            }\n+\n+            mail::send_emergency_access_invite_accepted(&grantor_user.email, &grantee_user.email)?;\n+        }\n+\n+        Ok(())\n+    } else {\n+        err!(\"Emergency access invitation error.\")\n+    }\n+}\n+\n+fn accept_invite_process(grantee_uuid: String, emer_id: String, email: Option<String>, conn: &DbConn) -> EmptyResult {\n+    let mut emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    let emer_email = emergency_access.email;\n+    if emer_email.is_none() || emer_email != email {\n+        err!(\"User email does not match invite.\");\n+    }\n+\n+    if emergency_access.status == EmergencyAccessStatus::Accepted as i32 {\n+        err!(\"Emergency contact already accepted.\");\n+    }\n+\n+    emergency_access.status = EmergencyAccessStatus::Accepted as i32;\n+    emergency_access.grantee_uuid = Some(grantee_uuid);\n+    emergency_access.email = None;\n+    emergency_access.save(conn)\n+}\n+\n+#[derive(Deserialize)]\n+#[allow(non_snake_case)]\n+struct ConfirmData {\n+    Key: String,\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/confirm\", data = \"<data>\")]\n+fn confirm_emergency_access(\n+    emer_id: String,\n+    data: JsonUpcase<ConfirmData>,\n+    headers: Headers,\n+    conn: DbConn,\n+) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let confirming_user = headers.user;\n+    let data: ConfirmData = data.into_inner().data;\n+    let key = data.Key;\n+\n+    let mut emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if emergency_access.status != EmergencyAccessStatus::Accepted as i32\n+        || emergency_access.grantor_uuid != confirming_user.uuid\n+    {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let grantor_user = match User::find_by_uuid(&confirming_user.uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    if let Some(grantee_uuid) = emergency_access.grantee_uuid.as_ref() {\n+        let grantee_user = match User::find_by_uuid(grantee_uuid, &conn) {\n+            Some(user) => user,\n+            None => err!(\"Grantee user not found.\"),\n+        };\n+\n+        emergency_access.status = EmergencyAccessStatus::Confirmed as i32;\n+        emergency_access.key_encrypted = Some(key);\n+        emergency_access.email = None;\n+\n+        emergency_access.save(&conn)?;\n+\n+        if CONFIG.mail_enabled() {\n+            if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n+                err!(\"Email domain not valid.\")\n+            }\n+\n+            mail::send_emergency_access_invite_confirmed(&grantee_user.email, &grantor_user.name)?;\n+        }\n+        Ok(Json(emergency_access.to_json()))\n+    } else {\n+        err!(\"Grantee user not found.\")\n+    }\n+}\n+\n+// endregion\n+\n+// region access emergency access\n+\n+#[post(\"/emergency-access/<emer_id>/initiate\")]\n+fn initiate_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let initiating_user = headers.user;\n+    let mut emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if emergency_access.status != EmergencyAccessStatus::Confirmed as i32\n+        || emergency_access.grantee_uuid != Some(initiating_user.uuid.clone())\n+    {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let grantor_user = match User::find_by_uuid(&emergency_access.grantor_uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    let now = Utc::now().naive_utc();\n+    emergency_access.status = EmergencyAccessStatus::RecoveryInitiated as i32;\n+    emergency_access.updated_at = now;\n+    emergency_access.recovery_initiated_at = Some(now);\n+    emergency_access.last_notification_at = Some(now);\n+    emergency_access.save(&conn)?;\n+\n+    if CONFIG.mail_enabled() {\n+        if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n+            err!(\"Email domain not valid.\")\n+        }\n+\n+        mail::send_emergency_access_recovery_initiated(\n+            &grantor_user.email,\n+            &initiating_user.name,\n+            emergency_access.get_atype_as_str(),\n+            &emergency_access.wait_time_days.clone().to_string(),\n+        )?;\n+    }\n+    Ok(Json(emergency_access.to_json()))\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/approve\")]\n+fn approve_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let approving_user = headers.user;\n+    let mut emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if emergency_access.status != EmergencyAccessStatus::RecoveryInitiated as i32\n+        || emergency_access.grantor_uuid != approving_user.uuid\n+    {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let grantor_user = match User::find_by_uuid(&approving_user.uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    if let Some(grantee_uuid) = emergency_access.grantee_uuid.as_ref() {\n+        let grantee_user = match User::find_by_uuid(grantee_uuid, &conn) {\n+            Some(user) => user,\n+            None => err!(\"Grantee user not found.\"),\n+        };\n+\n+        emergency_access.status = EmergencyAccessStatus::RecoveryApproved as i32;\n+        emergency_access.save(&conn)?;\n+\n+        if CONFIG.mail_enabled() {\n+            if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n+                err!(\"Email domain not valid.\")\n+            }\n+\n+            mail::send_emergency_access_recovery_approved(&grantee_user.email, &grantor_user.name)?;\n+        }\n+        Ok(Json(emergency_access.to_json()))\n+    } else {\n+        err!(\"Grantee user not found.\")\n+    }\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/reject\")]\n+fn reject_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let rejecting_user = headers.user;\n+    let mut emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if (emergency_access.status != EmergencyAccessStatus::RecoveryInitiated as i32\n+        && emergency_access.status != EmergencyAccessStatus::RecoveryApproved as i32)\n+        || emergency_access.grantor_uuid != rejecting_user.uuid\n+    {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let grantor_user = match User::find_by_uuid(&rejecting_user.uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    if let Some(grantee_uuid) = emergency_access.grantee_uuid.as_ref() {\n+        let grantee_user = match User::find_by_uuid(grantee_uuid, &conn) {\n+            Some(user) => user,\n+            None => err!(\"Grantee user not found.\"),\n+        };\n+\n+        emergency_access.status = EmergencyAccessStatus::Confirmed as i32;\n+        emergency_access.key_encrypted = None;\n+        emergency_access.save(&conn)?;\n+\n+        if CONFIG.mail_enabled() {\n+            if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n+                err!(\"Email domain not valid.\")\n+            }\n+\n+            mail::send_emergency_access_recovery_rejected(&grantee_user.email, &grantor_user.name)?;\n+        }\n+        Ok(Json(emergency_access.to_json()))\n+    } else {\n+        err!(\"Grantee user not found.\")\n+    }\n+}\n+\n+// endregion\n+\n+// region action\n+\n+#[post(\"/emergency-access/<emer_id>/view\")]\n+fn view_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let requesting_user = headers.user;\n+    let host = headers.host;\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if !is_valid_request(&emergency_access, requesting_user.uuid, EmergencyAccessType::View) {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let ciphers = Cipher::find_owned_by_user(&emergency_access.grantor_uuid, &conn);\n+\n+    let ciphers_json: Vec<Value> =\n+        ciphers.iter().map(|c| c.to_json(&host, &emergency_access.grantor_uuid, &conn)).collect();\n+\n+    Ok(Json(json!({\n+      \"Ciphers\": ciphers_json,\n+      \"KeyEncrypted\": &emergency_access.key_encrypted,\n+      \"Object\": \"emergencyAccessView\",\n+    })))\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/takeover\")]\n+fn takeover_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    check_emergency_access_allowed()?;\n+\n+    let requesting_user = headers.user;\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if !is_valid_request(&emergency_access, requesting_user.uuid, EmergencyAccessType::Takeover) {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let grantor_user = match User::find_by_uuid(&emergency_access.grantor_uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    Ok(Json(json!({\n+      \"Kdf\": grantor_user.client_kdf_type,\n+      \"KdfIterations\": grantor_user.client_kdf_iter,\n+      \"KeyEncrypted\": &emergency_access.key_encrypted,\n+      \"Object\": \"emergencyAccessTakeover\",\n+    })))\n+}\n+\n+#[derive(Deserialize, Debug)]\n+#[allow(non_snake_case)]\n+struct EmergencyAccessPasswordData {\n+    NewMasterPasswordHash: String,\n+    Key: String,\n+}\n+\n+#[post(\"/emergency-access/<emer_id>/password\", data = \"<data>\")]\n+fn password_emergency_access(\n+    emer_id: String,\n+    data: JsonUpcase<EmergencyAccessPasswordData>,\n+    headers: Headers,\n+    conn: DbConn,\n+) -> EmptyResult {\n+    check_emergency_access_allowed()?;\n+\n+    let data: EmergencyAccessPasswordData = data.into_inner().data;\n+    let new_master_password_hash = &data.NewMasterPasswordHash;\n+    let key = data.Key;\n+\n+    let requesting_user = headers.user;\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if !is_valid_request(&emergency_access, requesting_user.uuid, EmergencyAccessType::Takeover) {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let mut grantor_user = match User::find_by_uuid(&emergency_access.grantor_uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    // change grantor_user password\n+    grantor_user.set_password(new_master_password_hash, None);\n+    grantor_user.akey = key;\n+    grantor_user.save(&conn)?;\n+\n+    // Disable TwoFactor providers since they will otherwise block logins\n+    TwoFactor::delete_all_by_user(&grantor_user.uuid, &conn)?;\n+\n+    // Removing owner, check that there are at least another owner\n+    let user_org_grantor = UserOrganization::find_any_state_by_user(&grantor_user.uuid, &conn);\n+\n+    // Remove grantor from all organisations unless Owner\n+    for user_org in user_org_grantor {\n+        if user_org.atype != UserOrgType::Owner as i32 {\n+            user_org.delete(&conn)?;\n+        }\n+    }\n+    Ok(())\n+}\n+\n+// endregion\n+\n+#[get(\"/emergency-access/<emer_id>/policies\")]\n+fn policies_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> JsonResult {\n+    let requesting_user = headers.user;\n+    let emergency_access = match EmergencyAccess::find_by_uuid(&emer_id, &conn) {\n+        Some(emer) => emer,\n+        None => err!(\"Emergency access not valid.\"),\n+    };\n+\n+    if !is_valid_request(&emergency_access, requesting_user.uuid, EmergencyAccessType::Takeover) {\n+        err!(\"Emergency access not valid.\")\n+    }\n+\n+    let grantor_user = match User::find_by_uuid(&emergency_access.grantor_uuid, &conn) {\n+        Some(user) => user,\n+        None => err!(\"Grantor user not found.\"),\n+    };\n+\n+    let policies = OrgPolicy::find_by_user(&grantor_user.uuid, &conn);\n+    let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n+\n+    Ok(Json(json!({\n+        \"Data\": policies_json,\n+        \"Object\": \"list\",\n+        \"ContinuationToken\": null\n+    })))\n+}\n+\n+fn is_valid_request(\n+    emergency_access: &EmergencyAccess,\n+    requesting_user_uuid: String,\n+    requested_access_type: EmergencyAccessType,\n+) -> bool {\n+    emergency_access.grantee_uuid == Some(requesting_user_uuid)\n+        && emergency_access.status == EmergencyAccessStatus::RecoveryApproved as i32\n+        && emergency_access.atype == requested_access_type as i32\n+}\n+\n+fn check_emergency_access_allowed() -> EmptyResult {\n+    if !CONFIG.emergency_access_allowed() {\n+        err!(\"Emergency access is not allowed.\")\n+    }\n+    Ok(())\n+}\n+\n+pub fn emergency_request_timeout_job(pool: DbPool) {\n+    debug!(\"Start emergency_request_timeout_job\");\n+    if !CONFIG.emergency_access_allowed() {\n+        return;\n+    }\n+\n+    if let Ok(conn) = pool.get() {\n+        let emergency_access_list = EmergencyAccess::find_all_recoveries(&conn);\n+\n+        if emergency_access_list.is_empty() {\n+            debug!(\"No emergency request timeout to approve\");\n+        }\n+\n+        for mut emer in emergency_access_list {\n+            if emer.recovery_initiated_at.is_some()\n+                && Utc::now().naive_utc()\n+                    >= emer.recovery_initiated_at.unwrap() + Duration::days(emer.wait_time_days as i64)\n+            {\n+                emer.status = EmergencyAccessStatus::RecoveryApproved as i32;\n+                emer.save(&conn).expect(\"Cannot save emergency access on job\");\n+\n+                if CONFIG.mail_enabled() {\n+                    // get grantor user to send Accepted email\n+                    let grantor_user = User::find_by_uuid(&emer.grantor_uuid, &conn).expect(\"Grantor user not found.\");\n+\n+                    // get grantee user to send Accepted email\n+                    let grantee_user =\n+                        User::find_by_uuid(&emer.grantee_uuid.clone().expect(\"Grantee user invalid.\"), &conn)\n+                            .expect(\"Grantee user not found.\");\n+\n+                    if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n+                        error!(\"Email domain not valid.\")\n+                    }\n+\n+                    mail::send_emergency_access_recovery_timed_out(\n+                        &grantor_user.email,\n+                        &grantee_user.name.clone(),\n+                        emer.get_atype_as_str(),\n+                    )\n+                    .expect(\"Error on sending email\");\n+\n+                    if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n+                        error!(\"Email not valid.\")\n+                    }\n+\n+                    mail::send_emergency_access_recovery_approved(&grantee_user.email, &grantor_user.name.clone())\n+                        .expect(\"Error on sending email\");\n+                }\n+            }\n+        }\n+    } else {\n+        error!(\"Failed to get DB connection while searching emergency request timed out\")\n+    }\n+}\n+\n+pub fn emergency_notification_reminder_job(pool: DbPool) {\n+    debug!(\"Start emergency_notification_reminder_job\");\n+    if !CONFIG.emergency_access_allowed() {\n+        return;\n+    }\n+\n+    if let Ok(conn) = pool.get() {\n+        let emergency_access_list = EmergencyAccess::find_all_recoveries(&conn);\n+\n+        if emergency_access_list.is_empty() {\n+            debug!(\"No emergency request reminder notification to send\");\n+        }\n+\n+        for mut emer in emergency_access_list {\n+            if (emer.recovery_initiated_at.is_some()\n+                && Utc::now().naive_utc()\n+                    >= emer.recovery_initiated_at.unwrap() + Duration::days((emer.wait_time_days as i64) - 1))\n+                && (emer.last_notification_at.is_none()\n+                    || (emer.last_notification_at.is_some()\n+                        && Utc::now().naive_utc() >= emer.last_notification_at.unwrap() + Duration::days(1)))\n+            {\n+                emer.save(&conn).expect(\"Cannot save emergency access on job\");\n+\n+                if CONFIG.mail_enabled() {\n+                    // get grantor user to send Accepted email\n+                    let grantor_user = User::find_by_uuid(&emer.grantor_uuid, &conn).expect(\"Grantor user not found.\");\n+\n+                    if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n+                        error!(\"Email not valid.\")\n+                    }\n+\n+                    // get grantee user to send Accepted email\n+                    let grantee_user =\n+                        User::find_by_uuid(&emer.grantee_uuid.clone().expect(\"Grantee user invalid.\"), &conn)\n+                            .expect(\"Grantee user not found.\");\n+\n+                    mail::send_emergency_access_recovery_reminder(\n+                        &grantor_user.email,\n+                        &grantee_user.name.clone(),\n+                        emer.get_atype_as_str(),\n+                        &emer.wait_time_days.to_string(),\n+                    )\n+                    .expect(\"Error on sending email\");\n+                }\n+            }\n+        }\n+    } else {\n+        error!(\"Failed to get DB connection while searching emergency notification reminder\")\n+    }\n+}\n",
            "comment_added_diff": [
                [
                    36,
                    "// region get"
                ],
                [
                    80,
                    "// endregion"
                ],
                [
                    82,
                    "// region put/post"
                ],
                [
                    121,
                    "// endregion"
                ],
                [
                    123,
                    "// region delete"
                ],
                [
                    149,
                    "// endregion"
                ],
                [
                    151,
                    "// region invite"
                ],
                [
                    178,
                    "    // avoid setting yourself as emergency contact"
                ],
                [
                    234,
                    "        // Automatically mark user as accepted if no email invites"
                ],
                [
                    296,
                    "        // Automatically mark user as accepted if no email invites"
                ],
                [
                    333,
                    "    // get grantor user to send Accepted email"
                ],
                [
                    443,
                    "// endregion"
                ],
                [
                    445,
                    "// region access emergency access"
                ],
                [
                    578,
                    "// endregion"
                ],
                [
                    580,
                    "// region action"
                ],
                [
                    671,
                    "    // change grantor_user password"
                ],
                [
                    676,
                    "    // Disable TwoFactor providers since they will otherwise block logins"
                ],
                [
                    679,
                    "    // Removing owner, check that there are at least another owner"
                ],
                [
                    682,
                    "    // Remove grantor from all organisations unless Owner"
                ],
                [
                    691,
                    "// endregion"
                ],
                [
                    759,
                    "                    // get grantor user to send Accepted email"
                ],
                [
                    762,
                    "                    // get grantee user to send Accepted email"
                ],
                [
                    816,
                    "                    // get grantor user to send Accepted email"
                ],
                [
                    823,
                    "                    // get grantee user to send Accepted email"
                ]
            ]
        },
        {
            "commit": "4ab936297186746f00a275182b8e01d54466fc3d",
            "timestamp": "2021-09-17T01:25:44+02:00",
            "author": "thelittlefireman",
            "commit_message": "Add Emergency contact feature\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 288,
            "deletions": 0,
            "change_type": "ADD",
            "diff": "@@ -0,0 +1,288 @@\n+use chrono::{NaiveDateTime, Utc};\n+use serde_json::Value;\n+\n+use super::User;\n+\n+db_object! {\n+    #[derive(Debug, Identifiable, Queryable, Insertable, Associations, AsChangeset)]\n+    #[table_name = \"emergency_access\"]\n+    #[changeset_options(treat_none_as_null=\"true\")]\n+    #[belongs_to(User, foreign_key = \"grantor_uuid\")]\n+    #[primary_key(uuid)]\n+    pub struct EmergencyAccess {\n+        pub uuid: String,\n+        pub grantor_uuid: String,\n+        pub grantee_uuid: Option<String>,\n+        pub email: Option<String>,\n+        pub key_encrypted: Option<String>,\n+        pub atype: i32, //EmergencyAccessType\n+        pub status: i32, //EmergencyAccessStatus\n+        pub wait_time_days: i32,\n+        pub recovery_initiated_at: Option<NaiveDateTime>,\n+        pub last_notification_at: Option<NaiveDateTime>,\n+        pub updated_at: NaiveDateTime,\n+        pub created_at: NaiveDateTime,\n+    }\n+}\n+\n+/// Local methods\n+\n+impl EmergencyAccess {\n+    pub fn new(grantor_uuid: String, email: Option<String>, status: i32, atype: i32, wait_time_days: i32) -> Self {\n+        Self {\n+            uuid: crate::util::get_uuid(),\n+            grantor_uuid,\n+            grantee_uuid: None,\n+            email,\n+            status,\n+            atype,\n+            wait_time_days,\n+            recovery_initiated_at: None,\n+            created_at: Utc::now().naive_utc(),\n+            updated_at: Utc::now().naive_utc(),\n+            key_encrypted: None,\n+            last_notification_at: None,\n+        }\n+    }\n+\n+    pub fn get_atype_as_str(&self) -> &'static str {\n+        if self.atype == EmergencyAccessType::View as i32 {\n+            \"View\"\n+        } else {\n+            \"Takeover\"\n+        }\n+    }\n+\n+    pub fn to_json(&self) -> Value {\n+        json!({\n+            \"Id\": self.uuid,\n+            \"Status\": self.status,\n+            \"Type\": self.atype,\n+            \"WaitTimeDays\": self.wait_time_days,\n+            \"Object\": \"emergencyAccess\",\n+        })\n+    }\n+\n+    pub fn to_json_grantor_details(&self, conn: &DbConn) -> Value {\n+        // find grantor\n+        let grantor_user = User::find_by_uuid(&self.grantor_uuid, conn).unwrap();\n+        json!({\n+             \"Id\": self.uuid,\n+            \"Status\": self.status,\n+            \"Type\": self.atype,\n+            \"WaitTimeDays\": self.wait_time_days,\n+            \"GrantorId\": grantor_user.uuid,\n+            \"Email\": grantor_user.email,\n+            \"Name\": grantor_user.name,\n+            \"Object\": \"emergencyAccessGrantorDetails\",})\n+    }\n+\n+    pub fn to_json_grantee_details(&self, conn: &DbConn) -> Value {\n+        if self.grantee_uuid.is_some() {\n+            let grantee_user =\n+                User::find_by_uuid(&self.grantee_uuid.clone().unwrap(), conn).expect(\"Grantee user not found.\");\n+\n+            json!({\n+                \"Id\": self.uuid,\n+                \"Status\": self.status,\n+                \"Type\": self.atype,\n+                \"WaitTimeDays\": self.wait_time_days,\n+                \"GranteeId\": grantee_user.uuid,\n+                \"Email\": grantee_user.email,\n+                \"Name\": grantee_user.name,\n+                \"Object\": \"emergencyAccessGranteeDetails\",})\n+        } else if self.email.is_some() {\n+            let grantee_user = User::find_by_mail(&self.email.clone().unwrap(), conn).expect(\"Grantee user not found.\");\n+            json!({\n+                    \"Id\": self.uuid,\n+                    \"Status\": self.status,\n+                    \"Type\": self.atype,\n+                    \"WaitTimeDays\": self.wait_time_days,\n+                    \"GranteeId\": grantee_user.uuid,\n+                    \"Email\": grantee_user.email,\n+                    \"Name\": grantee_user.name,\n+                    \"Object\": \"emergencyAccessGranteeDetails\",})\n+        } else {\n+            json!({\n+                \"Id\": self.uuid,\n+                \"Status\": self.status,\n+                \"Type\": self.atype,\n+                \"WaitTimeDays\": self.wait_time_days,\n+                \"GranteeId\": \"\",\n+                \"Email\": \"\",\n+                \"Name\": \"\",\n+                \"Object\": \"emergencyAccessGranteeDetails\",})\n+        }\n+    }\n+}\n+\n+#[derive(Copy, Clone, PartialEq, Eq, num_derive::FromPrimitive)]\n+pub enum EmergencyAccessType {\n+    View = 0,\n+    Takeover = 1,\n+}\n+\n+impl EmergencyAccessType {\n+    pub fn from_str(s: &str) -> Option<Self> {\n+        match s {\n+            \"0\" | \"View\" => Some(EmergencyAccessType::View),\n+            \"1\" | \"Takeover\" => Some(EmergencyAccessType::Takeover),\n+            _ => None,\n+        }\n+    }\n+}\n+\n+impl PartialEq<i32> for EmergencyAccessType {\n+    fn eq(&self, other: &i32) -> bool {\n+        *other == *self as i32\n+    }\n+}\n+\n+impl PartialEq<EmergencyAccessType> for i32 {\n+    fn eq(&self, other: &EmergencyAccessType) -> bool {\n+        *self == *other as i32\n+    }\n+}\n+\n+pub enum EmergencyAccessStatus {\n+    Invited = 0,\n+    Accepted = 1,\n+    Confirmed = 2,\n+    RecoveryInitiated = 3,\n+    RecoveryApproved = 4,\n+}\n+\n+// region Database methods\n+\n+use crate::db::DbConn;\n+\n+use crate::api::EmptyResult;\n+use crate::error::MapResult;\n+\n+impl EmergencyAccess {\n+    pub fn save(&mut self, conn: &DbConn) -> EmptyResult {\n+        User::update_uuid_revision(&self.grantor_uuid, conn);\n+        self.updated_at = Utc::now().naive_utc();\n+\n+        db_run! { conn:\n+            sqlite, mysql {\n+                match diesel::replace_into(emergency_access::table)\n+                    .values(EmergencyAccessDb::to_db(self))\n+                    .execute(conn)\n+                {\n+                    Ok(_) => Ok(()),\n+                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first.\n+                    Err(diesel::result::Error::DatabaseError(diesel::result::DatabaseErrorKind::ForeignKeyViolation, _)) => {\n+                        diesel::update(emergency_access::table)\n+                            .filter(emergency_access::uuid.eq(&self.uuid))\n+                            .set(EmergencyAccessDb::to_db(self))\n+                            .execute(conn)\n+                            .map_res(\"Error updating emergency access\")\n+                    }\n+                    Err(e) => Err(e.into()),\n+                }.map_res(\"Error saving emergency access\")\n+            }\n+            postgresql {\n+                let value = EmergencyAccessDb::to_db(self);\n+                diesel::insert_into(emergency_access::table)\n+                    .values(&value)\n+                    .on_conflict(emergency_access::uuid)\n+                    .do_update()\n+                    .set(&value)\n+                    .execute(conn)\n+                    .map_res(\"Error saving emergency access\")\n+            }\n+        }\n+    }\n+\n+    pub fn delete_all_by_user(user_uuid: &str, conn: &DbConn) -> EmptyResult {\n+        for user_org in Self::find_all_by_grantor_uuid(user_uuid, conn) {\n+            user_org.delete(conn)?;\n+        }\n+        for user_org in Self::find_all_by_grantee_uuid(user_uuid, conn) {\n+            user_org.delete(conn)?;\n+        }\n+        Ok(())\n+    }\n+\n+    pub fn delete(self, conn: &DbConn) -> EmptyResult {\n+        User::update_uuid_revision(&self.grantor_uuid, conn);\n+\n+        db_run! { conn: {\n+            diesel::delete(emergency_access::table.filter(emergency_access::uuid.eq(self.uuid)))\n+                .execute(conn)\n+                .map_res(\"Error removing user from organization\")\n+        }}\n+    }\n+\n+    pub fn find_by_uuid(uuid: &str, conn: &DbConn) -> Option<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::uuid.eq(uuid))\n+                .first::<EmergencyAccessDb>(conn)\n+                .ok().from_db()\n+        }}\n+    }\n+\n+    pub fn find_by_grantor_uuid_and_grantee_uuid_or_email(\n+        grantor_uuid: &str,\n+        grantee_uuid: &str,\n+        email: &str,\n+        conn: &DbConn,\n+    ) -> Option<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::grantor_uuid.eq(grantor_uuid))\n+                .filter(emergency_access::grantee_uuid.eq(grantee_uuid).or(emergency_access::email.eq(email)))\n+                .first::<EmergencyAccessDb>(conn)\n+                .ok().from_db()\n+        }}\n+    }\n+\n+    pub fn find_all_recoveries(conn: &DbConn) -> Vec<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::status.eq(EmergencyAccessStatus::RecoveryInitiated as i32))\n+                .load::<EmergencyAccessDb>(conn).expect(\"Error loading emergency_access\").from_db()\n+\n+        }}\n+    }\n+\n+    pub fn find_by_uuid_and_grantor_uuid(uuid: &str, grantor_uuid: &str, conn: &DbConn) -> Option<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::uuid.eq(uuid))\n+                .filter(emergency_access::grantor_uuid.eq(grantor_uuid))\n+                .first::<EmergencyAccessDb>(conn)\n+                .ok().from_db()\n+        }}\n+    }\n+\n+    pub fn find_all_by_grantee_uuid(grantee_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::grantee_uuid.eq(grantee_uuid))\n+                .load::<EmergencyAccessDb>(conn).expect(\"Error loading emergency_access\").from_db()\n+        }}\n+    }\n+\n+    pub fn find_invited_by_grantee_email(grantee_email: &str, conn: &DbConn) -> Option<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::email.eq(grantee_email))\n+                .filter(emergency_access::status.eq(EmergencyAccessStatus::Invited as i32))\n+                .first::<EmergencyAccessDb>(conn)\n+                .ok().from_db()\n+        }}\n+    }\n+\n+    pub fn find_all_by_grantor_uuid(grantor_uuid: &str, conn: &DbConn) -> Vec<Self> {\n+        db_run! { conn: {\n+            emergency_access::table\n+                .filter(emergency_access::grantor_uuid.eq(grantor_uuid))\n+                .load::<EmergencyAccessDb>(conn).expect(\"Error loading emergency_access\").from_db()\n+        }}\n+    }\n+}\n+\n+// endregion\n",
            "comment_added_diff": [
                [
                    18,
                    "        pub atype: i32, //EmergencyAccessType"
                ],
                [
                    19,
                    "        pub status: i32, //EmergencyAccessStatus"
                ],
                [
                    28,
                    "/// Local methods"
                ],
                [
                    67,
                    "        // find grantor"
                ],
                [
                    155,
                    "// region Database methods"
                ],
                [
                    174,
                    "                    // Record already exists and causes a Foreign Key Violation because replace_into() wants to delete the record first."
                ],
                [
                    288,
                    "// endregion"
                ]
            ]
        },
        {
            "commit": "ca20b3d80c75e42b9229ab3a9625a334c83e79a8",
            "timestamp": "2021-09-17T01:25:47+02:00",
            "author": "thelittlefireman",
            "commit_message": "[PATCH] Some fixes to the Emergency Access PR\n\n- Changed the date of the migration folders to be from this date.\n- Removed a lot is_email_domain_allowed checks.\n  This check only needs to be done during the invite it self, else\neverything else will fail even if a user has an account created via the\n/admin interface which bypasses that specific check! Also, the check was\nat the wrong place anyway's, since it would only not send out an e-mail,\nbut would still have allowed an not allowed domain to be used when\ne-mail would have been disabled. While that check always works, even if\nsending e-mails is disasbled.\n- Added an extra allowed route during password/key-rotation change which\nupdates/checks the public-key afterwards.\n- A small change with some `Some` and `None` orders.\n- Change the new invite object to only generate the UTC time once, since\nit could be possible that there will be a second difference, and we only\nneed to call it just once.\n\nby black.dex@gmail.com\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 1,
            "deletions": 37,
            "change_type": "MODIFY",
            "diff": "@@ -268,13 +268,9 @@ fn resend_invite(emer_id: String, headers: Headers, conn: DbConn) -> EmptyResult\n         None => err!(\"Email not valid.\"),\n     };\n \n-    if !CONFIG.is_email_domain_allowed(&email) {\n-        err!(\"Email domain not eligible for invitations.\")\n-    }\n-\n     let grantee_user = match User::find_by_mail(&email, &conn) {\n-        None => err!(\"Grantee user not found.\"),\n         Some(user) => user,\n+        None => err!(\"Grantee user not found.\"),\n     };\n \n     let grantor_user = headers.user;\n@@ -346,10 +342,6 @@ fn accept_invite(emer_id: String, data: JsonUpcase<AcceptData>, conn: DbConn) ->\n         }\n \n         if CONFIG.mail_enabled() {\n-            if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n-                err!(\"Email domain not valid.\")\n-            }\n-\n             mail::send_emergency_access_invite_accepted(&grantor_user.email, &grantee_user.email)?;\n         }\n \n@@ -428,10 +420,6 @@ fn confirm_emergency_access(\n         emergency_access.save(&conn)?;\n \n         if CONFIG.mail_enabled() {\n-            if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n-                err!(\"Email domain not valid.\")\n-            }\n-\n             mail::send_emergency_access_invite_confirmed(&grantee_user.email, &grantor_user.name)?;\n         }\n         Ok(Json(emergency_access.to_json()))\n@@ -473,10 +461,6 @@ fn initiate_emergency_access(emer_id: String, headers: Headers, conn: DbConn) ->\n     emergency_access.save(&conn)?;\n \n     if CONFIG.mail_enabled() {\n-        if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n-            err!(\"Email domain not valid.\")\n-        }\n-\n         mail::send_emergency_access_recovery_initiated(\n             &grantor_user.email,\n             &initiating_user.name,\n@@ -518,10 +502,6 @@ fn approve_emergency_access(emer_id: String, headers: Headers, conn: DbConn) ->\n         emergency_access.save(&conn)?;\n \n         if CONFIG.mail_enabled() {\n-            if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n-                err!(\"Email domain not valid.\")\n-            }\n-\n             mail::send_emergency_access_recovery_approved(&grantee_user.email, &grantor_user.name)?;\n         }\n         Ok(Json(emergency_access.to_json()))\n@@ -563,10 +543,6 @@ fn reject_emergency_access(emer_id: String, headers: Headers, conn: DbConn) -> J\n         emergency_access.save(&conn)?;\n \n         if CONFIG.mail_enabled() {\n-            if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n-                err!(\"Email domain not valid.\")\n-            }\n-\n             mail::send_emergency_access_recovery_rejected(&grantee_user.email, &grantor_user.name)?;\n         }\n         Ok(Json(emergency_access.to_json()))\n@@ -764,10 +740,6 @@ pub fn emergency_request_timeout_job(pool: DbPool) {\n                         User::find_by_uuid(&emer.grantee_uuid.clone().expect(\"Grantee user invalid.\"), &conn)\n                             .expect(\"Grantee user not found.\");\n \n-                    if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n-                        error!(\"Email domain not valid.\")\n-                    }\n-\n                     mail::send_emergency_access_recovery_timed_out(\n                         &grantor_user.email,\n                         &grantee_user.name.clone(),\n@@ -775,10 +747,6 @@ pub fn emergency_request_timeout_job(pool: DbPool) {\n                     )\n                     .expect(\"Error on sending email\");\n \n-                    if !CONFIG.is_email_domain_allowed(&grantee_user.email) {\n-                        error!(\"Email not valid.\")\n-                    }\n-\n                     mail::send_emergency_access_recovery_approved(&grantee_user.email, &grantor_user.name.clone())\n                         .expect(\"Error on sending email\");\n                 }\n@@ -816,10 +784,6 @@ pub fn emergency_notification_reminder_job(pool: DbPool) {\n                     // get grantor user to send Accepted email\n                     let grantor_user = User::find_by_uuid(&emer.grantor_uuid, &conn).expect(\"Grantor user not found.\");\n \n-                    if !CONFIG.is_email_domain_allowed(&grantor_user.email) {\n-                        error!(\"Email not valid.\")\n-                    }\n-\n                     // get grantee user to send Accepted email\n                     let grantee_user =\n                         User::find_by_uuid(&emer.grantee_uuid.clone().expect(\"Grantee user invalid.\"), &conn)\n",
            "comment_added_diff": []
        },
        {
            "commit": "ca20b3d80c75e42b9229ab3a9625a334c83e79a8",
            "timestamp": "2021-09-17T01:25:47+02:00",
            "author": "thelittlefireman",
            "commit_message": "[PATCH] Some fixes to the Emergency Access PR\n\n- Changed the date of the migration folders to be from this date.\n- Removed a lot is_email_domain_allowed checks.\n  This check only needs to be done during the invite it self, else\neverything else will fail even if a user has an account created via the\n/admin interface which bypasses that specific check! Also, the check was\nat the wrong place anyway's, since it would only not send out an e-mail,\nbut would still have allowed an not allowed domain to be used when\ne-mail would have been disabled. While that check always works, even if\nsending e-mails is disasbled.\n- Added an extra allowed route during password/key-rotation change which\nupdates/checks the public-key afterwards.\n- A small change with some `Some` and `None` orders.\n- Change the new invite object to only generate the UTC time once, since\nit could be possible that there will be a second difference, and we only\nneed to call it just once.\n\nby black.dex@gmail.com\n\nSigned-off-by: thelittlefireman <thelittlefireman@users.noreply.github.com>",
            "additions": 4,
            "deletions": 2,
            "change_type": "MODIFY",
            "diff": "@@ -29,6 +29,8 @@ db_object! {\n \n impl EmergencyAccess {\n     pub fn new(grantor_uuid: String, email: Option<String>, status: i32, atype: i32, wait_time_days: i32) -> Self {\n+        let now = Utc::now().naive_utc();\n+\n         Self {\n             uuid: crate::util::get_uuid(),\n             grantor_uuid,\n@@ -38,8 +40,8 @@ impl EmergencyAccess {\n             atype,\n             wait_time_days,\n             recovery_initiated_at: None,\n-            created_at: Utc::now().naive_utc(),\n-            updated_at: Utc::now().naive_utc(),\n+            created_at: now,\n+            updated_at: now,\n             key_encrypted: None,\n             last_notification_at: None,\n         }\n",
            "comment_added_diff": []
        },
        {
            "commit": "d014eede9a7fa85e4f809656a7f6aed61caafff0",
            "timestamp": "2021-10-02T19:30:19+02:00",
            "author": "Adam Jones",
            "commit_message": "feature: Support single organization policy\n\nThis adds back-end support for the [single organization policy](https://bitwarden.com/help/article/policies/#single-organization).",
            "additions": 1,
            "deletions": 1,
            "change_type": "MODIFY",
            "diff": "@@ -683,7 +683,7 @@ fn policies_emergency_access(emer_id: String, headers: Headers, conn: DbConn) ->\n         None => err!(\"Grantor user not found.\"),\n     };\n \n-    let policies = OrgPolicy::find_by_user(&grantor_user.uuid, &conn);\n+    let policies = OrgPolicy::find_confirmed_by_user(&grantor_user.uuid, &conn);\n     let policies_json: Vec<Value> = policies.iter().map(OrgPolicy::to_json).collect();\n \n     Ok(Json(json!({\n",
            "comment_added_diff": []
        }
    ],
    "emergency_access_invite_accepted.hbs": [],
    "emergency_access_invite_accepted.html.hbs": [],
    "emergency_access_invite_confirmed.hbs": [],
    "emergency_access_invite_confirmed.html.hbs": [],
    "emergency_access_recovery_approved.hbs": [],
    "emergency_access_recovery_approved.html.hbs": [],
    "emergency_access_recovery_initiated.hbs": [],
    "emergency_access_recovery_initiated.html.hbs": [],
    "emergency_access_recovery_rejected.hbs": [],
    "emergency_access_recovery_rejected.html.hbs": [],
    "emergency_access_recovery_reminder.hbs": [],
    "emergency_access_recovery_reminder.html.hbs": [],
    "emergency_access_recovery_timed_out.hbs": [],
    "emergency_access_recovery_timed_out.html.hbs": [],
    "send_emergency_access_invite.hbs": [],
    "send_emergency_access_invite.html.hbs": [],
    "send_single_org_removed_from_org.hbs": [],
    "send_single_org_removed_from_org.html.hbs": []
}