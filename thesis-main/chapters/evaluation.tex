\chapter{Evaluation}
\label{chap:eval}


\section{Experimental Setup}
\begin{itemize}
	\item Reason for chosen repositories
	\item Inputs and outputs in pipeline
	\item Algorithms used for code quality
	\item Algorithms used for process discovery and conformance checking
\end{itemize}

\section{Results}
Expected results:
\begin{itemize}
	\item Code quality initially low, improves to a certain level, where initial bugs are fixed, slightly decreases as project gets more complex
	\item Process discovered different per repository, with similar sub-sequences
	\item Time taken longer than proposed and order not according to concept (mainly in one of three repositories, where clear expected/wanted process is given)
\end{itemize}

\section{Threats to Validity}
\begin{itemize}
	\item Code quality metrics are only metrics, impossible to capture all aspects of code quality
	\item Process variance large despite splitting process model evolution in parts
	\item Conformance checking to information updated infrequently
\end{itemize}
