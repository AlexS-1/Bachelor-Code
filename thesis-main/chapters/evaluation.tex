\chapter{Evaluation}
\label{chap:eval}

\section{Experimental Setup}
\begin{itemize}
	\item Python repositories were chosen because of relevance for scientific community
	\item URL as input to extraction, OCEL as output for process mining and analysis with PM4Py
	\item Why were maintainability index and Pylint chosen for code quality analysis
	\item Algorithms used for process discovery and conformance checking using PM4Py
	\item Implementation of flattening algorithm for visualizing process workflows from different viewpoints
\end{itemize}

\section{Expected Results}
\begin{itemize}
	\item Changes in code quality are noticeable and do depend  on changes in contribution guidelines
	\item Processes discovered per repository differ, highlighting value of the presented tool
	\item Time taken to implement changes and adhere to guidelines often longer than proposed in documentation
	\item Order of steps in workflow differ per user
\end{itemize}

\section{Threats to Validity}
\begin{itemize}
	\item Code quality metrics are only measurements, therefore impossible to capture all aspects of code quality
	\item Process variance large despite splitting process model evolution in parts
	\item Conformance checking information updated infrequently
\end{itemize}
