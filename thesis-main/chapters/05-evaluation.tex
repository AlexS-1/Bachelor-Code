\chapter{Evaluation}
\label{chap:eval}

In order to verify the method explained in \autoref{chap:method}, this case study aims to exploit the full capabilities of the presented pipeline i.e., create easy-to-understand graphics and visualizations for new developers to understand, why code quality and adhering to contribution workflows is important 

\section{Experimental Setup}
\begin{itemize}
	\item Python repositories were chosen because of relevance for scientific community
	\item URL as input to extraction, OCEL as output for process mining and analysis with PM4Py
	\item Algorithms used for process discovery and conformance checking using PM4Py
\end{itemize}

\section{Expected Results}
\begin{itemize}
	\item Changes in code quality are noticeable and do depend  on changes in contribution guidelines
	\item Processes discovered per repository differ, highlighting value of the presented tool
	\item Time taken to implement changes and adhere to guidelines often longer than proposed in documentation
	\item Order of steps in workflow differ per user
\end{itemize}

\section{Threats to Validity}
\begin{itemize}
	\item Code quality metrics are only measurements, therefore impossible to capture all aspects of code quality
	\item Process variance large despite splitting process model evolution in parts
	\item Conformance checking information updated infrequently % verify
\end{itemize}
